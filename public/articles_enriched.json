[
  {
    "title": "Automated Visualization Makeovers with LLMs",
    "title_es": "Maquillaje automatizado de visualizaciones con LLM",
    "url": "https://arxiv.org/abs/2508.05637",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05637v1 Tipo de anuncio: nuevo\nResumen: Hacer un buen gráfico que transmita con precisión y eficiencia el mensaje deseado a la audiencia es tanto un arte como una ciencia, que normalmente no se enseña en los planes de estudio de la ciencia de datos. Visualisation makeovers son ejercicios en los que la comunidad intercambia opiniones para mejorar los gráficos y las visualizaciones de datos. ¿Pueden los grandes modelos de lenguaje multimodales (LLM) emular esta tarea? Dado un gráfico en forma de archivo de imagen, o el código utilizado para generarlo, se emplea un LLM, preparado con una lista de mejores prácticas de visualización, para generar semiautomáticamente críticas constructivas para producir un gráfico mejor. Nuestro sistema se centra en la ingeniería rápida de un modelo preentrenado, basándose en una combinación de directrices especificadas por el usuario y cualquier conocimiento latente de prácticas de visualización de datos que pueda haber en el corpus de entrenamiento de un LLM. A diferencia de otros trabajos, la atención no se centra en generar guiones de visualización válidos a partir de datos brutos o indicaciones, sino en enseñar al usuario a mejorar sus visualizaciones de datos existentes de acuerdo con una interpretación de las mejores prácticas. Se realiza una evaluación cuantitativa para medir la sensibilidad del agente LLM a varios problemas de trazado en diferentes tipos de gráficos. La herramienta está disponible como un sencillo applet autoalojado con una interfaz web accesible.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Maquillaje automatizado de visualizaciones con LLM\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "automated",
      "visualization",
      "makeovers"
    ],
    "category": "noticia"
  },
  {
    "title": "Request-Only Optimization for Recommendation Systems",
    "title_es": "Optimización sólo a petición para sistemas de recomendación",
    "url": "https://arxiv.org/abs/2508.05640",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05640v1 Tipo de anuncio: nuevo\nResumen: Los modelos de recomendación de aprendizaje profundo (DLRM) representan una de las mayores aplicaciones de aprendizaje automático del planeta. Los DLRMs a escala industrial se entrenan con petabytes de datos de recomendación para servir a miles de millones de usuarios cada día. Para utilizar las ricas señales de los usuarios en su largo historial, los DLRM se han escalado hasta alcanzar una complejidad sin precedentes, de hasta billones de operaciones en coma flotante (TFLOPs) por ejemplo. Esta escala, unida a la enorme cantidad de datos de entrenamiento, hace necesarios nuevos algoritmos de almacenamiento y entrenamiento para mejorar eficientemente la calidad de estos complejos sistemas de recomendación. En este artículo, presentamos un paradigma de entrenamiento y modelado basado en optimizaciones sólo a petición (ROO, Request-Only Optimizations). ROO mejora simultáneamente la eficiencia del almacenamiento y la formación, así como la calidad del modelo de los sistemas de recomendación. Abordamos este reto de forma holística a través del codiseño de datos (es decir, datos sólo a petición), infraestructura (es decir, canal de procesamiento de datos sólo a petición) y arquitectura de modelos (es decir, arquitecturas neuronales sólo a petición). Nuestro paradigma de formación y modelado de ROO trata las solicitudes de los usuarios como unidades de datos de formación. En comparación con la práctica establecida de tratar una impresión de usuario como una unidad, nuestro nuevo diseño consigue la deduplicación nativa de características en el registro de datos, con el consiguiente ahorro de almacenamiento de datos. En segundo lugar, al desduplicar los cálculos y las comunicaciones entre las múltiples impresiones de una solicitud, este nuevo paradigma permite a las arquitecturas de redes neuronales de gran escala captar mejor las señales de interés del usuario, como los recomendadores generativos (GR) y otras arquitecturas que sólo atienden a las solicitudes.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Optimización sólo a petición para sistemas de recomendación\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "requestonly",
      "optimization",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "A Humanoid Social Robot as a Teaching Assistant in the Classroom",
    "title_es": "Un robot humanoide social como ayudante en el aula",
    "url": "https://arxiv.org/abs/2508.05646",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05646v1 Tipo de anuncio: nuevo\nResumen: Aunque la innovación y el apoyo de las nuevas tecnologías son muy necesarios para aliviar la carga del sistema educativo, los robots sociales en las escuelas para ayudar a los profesores con las tareas educativas son poco frecuentes. La interacción niño-robot (IRR) podría servir de apoyo a los profesores y añadir un componente social encarnado a los modernos entornos de aprendizaje multimodales y multisensoriales que ya se utilizan. El robot social Pepper, conectado al Large Language Model (LLM) ChatGPT, se utilizó en un aula de secundaria para enseñar nuevos contenidos de aprendizaje a grupos de alumnos. Probé las posibilidades técnicas con el robot in situ y pregunté a los alumnos sobre su aceptación y la utilidad percibida de enseñar con la ayuda de un robot social. Todos los participantes consideraron que la presentación del material didáctico por parte del robot era adecuada o al menos parcialmente adecuada y que su uso tenía sentido.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Un robot humanoide social como ayudante en el aula\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "humanoid",
      "social"
    ],
    "category": "noticia"
  },
  {
    "title": "Query-Aware Graph Neural Networks for Enhanced Retrieval-Augmented Generation",
    "title_es": "Redes neuronales de grafos sensibles a las consultas para mejorar la recuperación y la generación aumentada",
    "url": "https://arxiv.org/abs/2508.05647",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05647v1 Tipo de anuncio: nuevo\nResumen: Presentamos una nueva arquitectura de redes neuronales de grafos (GNN) para la generación de recuperación aumentada (RAG) que aprovecha los mecanismos de atención a las consultas y las cabezas de puntuación aprendidas para mejorar la precisión de la recuperación en preguntas complejas de múltiples saltos. A diferencia de los métodos tradicionales de recuperación densa, que tratan los documentos como entidades independientes, nuestro enfoque construye grafos de conocimiento por episodios que capturan las relaciones secuenciales y semánticas entre trozos de texto. Introducimos una red de atención gráfica mejorada con agrupación guiada por consultas que se centra dinámicamente en las partes relevantes del grafo en función de las consultas del usuario. Los resultados experimentales demuestran que nuestro enfoque supera con creces a los recuperadores densos estándar en tareas complejas de respuesta a preguntas, especialmente en las que requieren razonamiento multidocumento. Nuestra implementación aprovecha PyTorch Geometric para el procesamiento eficiente de datos estructurados en grafos, lo que permite su despliegue escalable en sistemas de recuperación en producción.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Redes neuronales de grafos sensibles a las consultas para mejorar la recuperación y la generación aumentada\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "queryaware",
      "graph",
      "neural"
    ],
    "category": "noticia"
  },
  {
    "title": "AquiLLM: a RAG Tool for Capturing Tacit Knowledge in Research Groups",
    "title_es": "AquiLLM: una herramienta RAG para captar el conocimiento tácito en los grupos de investigación",
    "url": "https://arxiv.org/abs/2508.05648",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05648v1 Tipo de anuncio: nuevo\nResumen: Los grupos de investigación se enfrentan a retos persistentes a la hora de capturar, almacenar y recuperar el conocimiento distribuido entre los miembros del equipo. Aunque los datos estructurados destinados al análisis y la publicación suelen estar bien gestionados, gran parte del conocimiento colectivo de un grupo sigue siendo informal, fragmentado o no documentado, a menudo transmitido oralmente a través de reuniones, tutorías y colaboración diaria. Esto incluye recursos privados como correos electrónicos, notas de reuniones, materiales de formación y documentación ad hoc. En conjunto, reflejan el conocimiento tácito del grupo, es decir, los conocimientos informales basados en la experiencia que subyacen a gran parte de su trabajo. Acceder a estos conocimientos puede resultar difícil, ya que requiere mucho tiempo y comprensión interna. Los sistemas de generación aumentada por recuperación (RAG) ofrecen soluciones prometedoras al permitir a los usuarios consultar y generar respuestas basadas en el material de origen pertinente. Sin embargo, la mayoría de los sistemas RAG-LLM actuales están orientados a documentos públicos y pasan por alto los problemas de privacidad de los materiales de investigación internos. Presentamos AquiLLM, un sistema RAG ligero y modular diseñado para satisfacer las necesidades de los grupos de investigación. AquiLLM admite diversos tipos de documentos y parámetros de privacidad configurables, lo que permite un acceso más eficaz a los conocimientos formales e informales de los grupos académicos.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AquiLLM: una herramienta RAG para captar el conocimiento tácito en los grupos de investigación\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "aquillm",
      "a",
      "rag"
    ],
    "category": "noticia"
  },
  {
    "title": "AI Guided Accelerator For Search Experience",
    "title_es": "Acelerador guiado por IA para la experiencia de búsqueda",
    "url": "https://arxiv.org/abs/2508.05649",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05649v1 Tipo de anuncio: nuevo\nResumen: La reformulación efectiva de consultas es fundamental para reducir la brecha entre el comportamiento de búsqueda exploratoria de un usuario y la identificación de productos relevantes en entornos de comercio electrónico. Aunque los enfoques tradicionales modelan predominantemente la reformulación de consultas como pares aislados, a menudo no logran capturar la dinámica secuencial y transitoria inherente al comportamiento del usuario en el mundo real. En este trabajo, proponemos un nuevo marco que modela explícitamente las consultas transitorias, es decir, las reformulaciones intermedias que se producen durante el viaje del usuario hacia su intención de compra final. Mediante la extracción de trayectorias de consulta estructuradas de los registros de interacción de usuarios a gran escala de eBay, reconstruimos secuencias de consulta que reflejan cambios en la intención al tiempo que preservan la coherencia semántica. Este enfoque nos permite modelar el embudo de compras de un usuario, en el que las transiciones a mitad del recorrido reflejan el comportamiento exploratorio y el refinamiento de la intención. Además, incorporamos modelos generativos de grandes lenguajes (LLM) para producir consultas alternativas semánticamente diversas y que preserven la intención, yendo más allá de lo que puede derivarse únicamente mediante el filtrado colaborativo. Estas reformulaciones pueden aprovecharse para rellenar las búsquedas relacionadas o para impulsar carruseles agrupados por intención en la página de resultados de la búsqueda, mejorando tanto el descubrimiento como el compromiso. Nuestras contribuciones incluyen (i) la identificación formal y el modelado de las consultas transicionales, (ii) la introducción de un proceso de minería de secuencias de consulta estructuradas para la comprensión del flujo de intenciones, y (iii) la aplicación de LLMs para una expansión de consultas escalable y consciente de las intenciones. La evaluación empírica demuestra mejoras mensurables en las métricas de conversión y compromiso en comparación con el módulo de búsquedas relacionadas existente, lo que valida la eficacia de nuestro enfoque en entornos de comercio electrónico del mundo real.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Acelerador guiado por IA para la experiencia de búsqueda\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ai",
      "guided",
      "accelerator"
    ],
    "category": "noticia"
  },
  {
    "title": "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools",
    "title_es": "OmniBench-RAG: plataforma de evaluación multidominio para herramientas de generación mejorada de recuperación",
    "url": "https://arxiv.org/abs/2508.05650",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05650v1 Tipo de anuncio: nuevo\nResumen: Aunque la Generación Aumentada de Recuperación (RAG, por sus siglas en inglés) está siendo ampliamente adoptada para mejorar los LLM, la evaluación de sus verdaderos beneficios de rendimiento de una manera reproducible e interpretable sigue siendo un gran obstáculo. Los métodos existentes a menudo se quedan cortos: carecen de cobertura de dominio, emplean métricas gruesas que pasan por alto la precisión subdocumental y no captan las compensaciones computacionales. Y lo que es más grave, no ofrecen un marco estandarizado para comparar la eficacia de la GAR entre distintos modelos y dominios.\n  Presentamos OmniBench RAG, una novedosa plataforma automatizada para la evaluación multidominio de sistemas RAG. La plataforma cuantifica las ganancias de rendimiento en las dimensiones de precisión y eficiencia, abarcando nueve campos del conocimiento, como la cultura, la geografía y la salud. Introducimos dos métricas estandarizadas: Mejoras (aumento de la precisión) y Transformación (diferencias de eficiencia entre los modelos anteriores y posteriores a la RAG), que permiten comparaciones reproducibles entre modelos y tareas. La plataforma cuenta con generación dinámica de pruebas, canales de evaluación modulares y construcción automatizada de bases de conocimiento. Nuestra evaluación revela una sorprendente variabilidad en la eficacia de las RAG, desde ganancias significativas en cultura hasta descensos en matemáticas, lo que subraya la importancia crítica de una evaluación sistemática y consciente del dominio. Hay un vídeo de demostración disponible en: https://www.youtube.com/watch?v=BZx83QFcTCI. Código y conjuntos de datos: https://github.com/Garnett-Liang/Omnibench-RAG.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"OmniBench-RAG: plataforma de evaluación multidominio para herramientas de generación mejorada de recuperación\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "omnibenchrag",
      "a",
      "multidomain"
    ],
    "category": "noticia"
  },
  {
    "title": "Lessons from A Large Language Model-based Outdoor Trail Recommendation Chatbot with Retrieval Augmented Generation",
    "title_es": "Lecciones de un gran chatbot de recomendación de rutas al aire libre basado en modelos lingüísticos con generación aumentada de recuperaciones",
    "url": "https://arxiv.org/abs/2508.05652",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05652v1 Tipo de anuncio: nuevo\nResumen: La creciente popularidad de las actividades recreativas al aire libre (como el senderismo y el ciclismo) ha impulsado la demanda de un sistema de IA conversacional para proporcionar sugerencias informativas y personalizadas sobre senderos al aire libre. Los retos que se plantean son (1) cómo proporcionar información precisa sobre los senderos al aire libre a través de la IA conversacional; y (2) cómo habilitar servicios de recomendación utilizables y eficientes. Para responder a estos retos, este artículo analiza las lecciones preliminares y prácticas aprendidas en el desarrollo de Judy, un chatbot de recomendación de rutas al aire libre basado en el modelo de lenguaje amplio (LLM) con generación aumentada de recuperación (RAG). Para obtener información concreta sobre el sistema, hemos realizado estudios de caso con los senderos al aire libre en Connecticut (CT), EE.UU.. Hemos llevado a cabo estudios de recopilación de datos basados en la web, gestión de datos de senderos al aire libre y rendimiento del modelo LLM en la recomendación basada en RAG. Nuestros resultados experimentales han demostrado la precisión, eficacia y utilidad de Judy en la recomendación de senderos al aire libre basada en el LLM con RAG.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Lecciones de un gran chatbot de recomendación de rutas al aire libre basado en modelos lingüísticos con generación aumentada de recuperaciones\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lessons",
      "from",
      "a"
    ],
    "category": "noticia"
  },
  {
    "title": "Modeling Interactive Narrative Systems: A Formal Approach",
    "title_es": "Modelado de sistemas narrativos interactivos: Un enfoque formal",
    "url": "https://arxiv.org/abs/2508.05653",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05653v1 Tipo de anuncio: nuevo\nResumen: Los Sistemas Narrativos Interactivos (SIN) han revolucionado las experiencias digitales al permitir a los usuarios dar forma activa a sus historias, alejándose de la narración pasiva tradicional. Sin embargo, este campo se enfrenta a retos debido a la fragmentación de los esfuerzos de investigación y a las diversas representaciones de los sistemas. Este artículo presenta un marco de representación formal para los sistemas de narración digital, inspirado en diversos enfoques del estado de la técnica. Al proporcionar un vocabulario y una estructura de modelado coherentes, el marco facilita el análisis, la descripción y la comparación de las propiedades de los SRI. Validaciones experimentales en el escenario de \"Caperucita Roja\" ponen de relieve la utilidad del formalismo propuesto y su impacto en la mejora de la evaluación de los INS. Este trabajo pretende fomentar la colaboración y la coherencia dentro de la comunidad investigadora de los SIN proponiendo una metodología para representar formalmente estos sistemas.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Modelado de sistemas narrativos interactivos: Un enfoque formal\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "modeling",
      "interactive",
      "narrative"
    ],
    "category": "noticia"
  },
  {
    "title": "Comparison of Information Retrieval Techniques Applied to IT Support Tickets",
    "title_es": "Comparación de las técnicas de recuperación de información aplicadas a los tickets de soporte informático",
    "url": "https://arxiv.org/abs/2508.05654",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05654v1 Tipo de anuncio: nuevo\nResumen: Las instituciones que dependen de los servicios y recursos informáticos reconocen la importancia crucial de un sistema de help desk informático, que actúa como un eje centralizado que conecta al personal informático y a los usuarios para las solicitudes de servicio. Empleando varios modelos de Aprendizaje Automático, estos sistemas de help desk de TI permiten acceder a las acciones correctivas utilizadas en el pasado, pero cada modelo tiene un rendimiento diferente cuando se aplica a diferentes conjuntos de datos. Este trabajo compara once técnicas de Recuperación de Información en un conjunto de datos de tickets de soporte de TI, con el objetivo de implementar un software que facilite el trabajo de los analistas de soporte de Tecnologías de la Información. Los mejores resultados se obtuvieron con la técnica Sentence-BERT, en su variante multilingüe distilluse-base-multilingual-cased-v1, donde el 78,7% de las recomendaciones realizadas por el modelo se consideraron relevantes. Las técnicas TF-IDF (69,0%), Word2vec (68,7%) y LDA (66,3%) también obtuvieron resultados coherentes. Además, los conjuntos de datos utilizados y las partes esenciales de la codificación se han publicado y convertido en código abierto. También se demostró la viabilidad de un sistema de recuperación de tickets de soporte mediante la implementación de un prototipo viable mínimo, y se describió en detalle la implementación del sistema. Por último, este trabajo propuso una nueva métrica para comparar las técnicas, cuyo objetivo es reflejar fielmente la percepción de los analistas informáticos sobre la calidad de la recuperación.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Comparación de las técnicas de recuperación de información aplicadas a los tickets de soporte informático\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "comparison",
      "of",
      "information"
    ],
    "category": "noticia"
  },
  {
    "title": "Blockchain-Based Decentralized Domain Name System",
    "title_es": "Sistema de nombres de dominio descentralizado basado en blockchain",
    "url": "https://arxiv.org/abs/2508.05655",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05655v1 Tipo de anuncio: nuevo\nResumen: La actual infraestructura del Sistema de Nombres de Dominio (DNS) se enfrenta a vulnerabilidades críticas que incluyen ataques de envenenamiento, mecanismos de censura y puntos de fallo centralizados que comprometen la libertad y la seguridad en Internet. Incidentes recientes como los ataques de envenenamiento de DNS a clientes de ISP ponen de relieve la urgente necesidad de alternativas resistentes. Este artículo presenta un novedoso Sistema Descentralizado de Nombres de Dominio (DDNS) basado en blockchain. Hemos diseñado una cadena de bloques Proof-of-Work especializada para maximizar el soporte de los protocolos relacionados con DNS y lograr la descentralización de los nodos. El sistema integra nuestro blockchain con IPFS para el almacenamiento distribuido, implementa primitivas criptográficas para firmas de confianza de extremo a extremo, y logra la verificación de confianza cero Never Trust, Always Verify. Nuestra implementación logra tiempos de propagación de registros de dominio de 15 segundos, admite 20 tipos de registros DNS estándar y proporciona dominios .ddns gratuitos a perpetuidad. El sistema se ha desplegado en infraestructuras distribuidas en San José, Los Ángeles y Orange County, demostrando su escalabilidad práctica y su resistencia a las técnicas tradicionales de manipulación de DNS. La evaluación del rendimiento muestra que el sistema puede manejar hasta Max Theor. TPS 1.111,1 tx/s (transacciones mínimas) y Max Theor. TPS 266,7 tx/s (transacciones normales) para operaciones de dominio, manteniendo al mismo tiempo una resolución de consultas inferior al segundo gracias a mecanismos inteligentes de almacenamiento en caché.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Sistema de nombres de dominio descentralizado basado en blockchain\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "blockchainbased",
      "decentralized",
      "domain"
    ],
    "category": "noticia"
  },
  {
    "title": "Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation",
    "title_es": "Más allá de las etiquetas únicas: Mejora de la recomendación conversacional mediante la ampliación de datos con LLM",
    "url": "https://arxiv.org/abs/2508.05657",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05657v1 Tipo de anuncio: nuevo\nResumen: Los sistemas de recomendación conversacionales (SRC) mejoran la calidad de las recomendaciones al involucrar a los usuarios en diálogos de varios turnos, capturando las preferencias matizadas a través de interacciones de lenguaje natural. Sin embargo, estos sistemas se enfrentan a menudo al problema de los falsos negativos, donde los elementos que podrían gustar a un usuario se etiquetan incorrectamente como negativos durante el entrenamiento, lo que conduce a recomendaciones subóptimas. Ampliar el conjunto de etiquetas mediante el aumento de datos presenta una solución intuitiva, pero se enfrenta al reto de equilibrar dos aspectos clave: garantizar la relevancia semántica y preservar la información colaborativa inherente a los conjuntos de datos CRS. Para abordar estas cuestiones, proponemos un novedoso marco de aumento de datos que, en primer lugar, aprovecha un recuperador semántico basado en LLM para identificar elementos diversos y semánticamente relevantes, que luego son filtrados por un puntuador de relevancia para eliminar los candidatos ruidosos. Sobre esta base, introducimos una estrategia de formación en dos fases que equilibra la relevancia semántica y la información colaborativa. Experimentos exhaustivos con dos conjuntos de datos de referencia y simuladores de usuario demuestran mejoras significativas y constantes en el rendimiento de varios recomendadores, lo que pone de relieve la eficacia de nuestro planteamiento para mejorar el rendimiento de los SRI.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Más allá de las etiquetas únicas: Mejora de la recomendación conversacional mediante la ampliación de datos con LLM\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "beyond",
      "single",
      "labels"
    ],
    "category": "noticia"
  },
  {
    "title": "Universally Unfiltered and Unseen:Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards",
    "title_es": "Universalmente sin filtro y sin ser vistos: fugas multimodales de entrada agnóstica contra las salvaguardas del modelo texto-imagen",
    "url": "https://arxiv.org/abs/2508.05658",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05658v1 Tipo de anuncio: nuevo\nResumen: Se han implementado varios filtros (de texto) y verificadores de seguridad (de imagen) para mitigar el mal uso de los modelos Texto-a-Imagen (T2I) en la creación de contenido No-Seguro-Para-El-Trabajo (NSFW).Sin embargo, los jailbreaks existentes se limitan a perturbaciones específicas del prompt y de la imagen, que adolecen de escasa escalabilidad y de una optimización que requiere mucho tiempo. Para abordar estas limitaciones, proponemos el Ataque Universalmente No Filtrado y No Visto (U3)-Attack, un método de ataque multimodal contra las salvaguardas T2I.En concreto, U3-Attack optimiza un parche adversario en el fondo de la imagen para eludir universalmente los verificadores de seguridad y optimiza un conjunto de paráfrasis seguras a partir de una palabra sensible para eludir universalmente los filtros de aviso al tiempo que elimina los cálculos redundantes.Amplios resultados experimentales demuestran la superioridad de nuestro ataque U3 tanto en modelos T2I comerciales como de código abierto. Por ejemplo, en el modelo comercial Runway-inpainting con filtro de aviso y verificador de seguridad, nuestro ataque U3 consigue tasas de éxito 4 veces superiores a las del ataque multimodal MMA-Diffusion: Este artículo incluye ejemplos de contenido NSFW.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Universalmente sin filtro y sin ser vistos: fugas multimodales de entrada agnóstica contra las salvaguardas del modelo texto-imagen\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "universally",
      "unfiltered",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty",
    "title_es": "Diagramas a dinámicas (D2D): Exploración de los puntos de influencia de los diagramas de bucles causales en condiciones de incertidumbre",
    "url": "https://arxiv.org/abs/2508.05659",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05659v1 Tipo de anuncio: nuevo\nResumen: Los diagramas de bucles causales (CLD, por sus siglas en inglés) se utilizan ampliamente en la investigación sanitaria y medioambiental para representar estructuras causales hipotéticas subyacentes a problemas complejos. Sin embargo, como representaciones cualitativas y estáticas, los CLDs son limitados en su capacidad para apoyar el análisis dinámico e informar las estrategias de intervención. Además, los métodos cuantitativos de análisis de CLD, como el análisis de centralidad de redes, a menudo conducen a falsas inferencias. Proponemos Diagrams-to-Dynamics (D2D), un método para convertir los CLD en modelos exploratorios de dinámica de sistemas (SDM) en ausencia de datos empíricos. Con una mínima intervención del usuario -siguiendo un protocolo para etiquetar variables como existencias, flujos/auxiliares o constantes-, D2D aprovecha la información estructural ya codificada en los CLD, a saber, la existencia y polaridad de los vínculos, para simular intervenciones hipotéticas y explorar posibles puntos de influencia en condiciones de incertidumbre. Los resultados sugieren que D2D ayuda a distinguir entre puntos de influencia de alto y bajo rango. Comparamos D2D con un SDM basado en datos construido a partir del mismo CLD y etiquetado de variables. D2D mostró una mayor coherencia con el modelo basado en datos que el análisis de centralidad de red, al tiempo que proporcionaba estimaciones de incertidumbre y orientación para la futura recopilación de datos. El método se ha implementado en un paquete Python de código abierto y en una aplicación basada en la web para facilitar la realización de más pruebas y reducir la barrera que supone el modelado dinámico para los investigadores que trabajan con CLD. Esperamos que la validación adicional establezca aún más la utilidad del enfoque en una amplia gama de casos y dominios.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Diagramas a dinámicas (D2D): Exploración de los puntos de influencia de los diagramas de bucles causales en condiciones de incertidumbre\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "diagramstodynamics",
      "dd",
      "exploring"
    ],
    "category": "noticia"
  },
  {
    "title": "Open-Source Agentic Hybrid RAG Framework for Scientific Literature Review",
    "title_es": "Marco Agentic RAG híbrido de código abierto para la revisión de la literatura científica",
    "url": "https://arxiv.org/abs/2508.05660",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05660v1 Tipo de anuncio: nuevo\nResumen: La oleada de publicaciones científicas desafía los métodos de revisión tradicionales, exigiendo herramientas que integren metadatos estructurados con análisis de texto completo. Los sistemas híbridos de Generación Aumentada de Recuperación (RAG), que combinan consultas gráficas con búsqueda vectorial, son prometedores, pero suelen ser estáticos, dependen de herramientas propietarias y carecen de estimaciones de incertidumbre. Presentamos un enfoque basado en agentes que encapsula el proceso RAG híbrido en un agente autónomo capaz de (1) seleccionar dinámicamente entre GraphRAG y VectorRAG para cada consulta, (2) adaptar la generación ajustada a las instrucciones en tiempo real a las necesidades del investigador, y (3) cuantificar la incertidumbre durante la inferencia. Esta orquestación dinámica mejora la relevancia, reduce las alucinaciones y fomenta la reproducibilidad.\n  Nuestro proceso ingiere datos bibliométricos de acceso abierto de las API de PubMed, arXiv y Google Scholar, construye un grafo de conocimiento (KG) basado en citas de Neo4j e incorpora PDF de texto completo a un almacén vectorial FAISS (VS) utilizando el modelo all-MiniLM-L6-v2. Un agente Llama-3.3-70B selecciona GraphRAG (que traduce las consultas a Cypher para el KG) o VectorRAG (que combina la recuperación dispersa y densa con la reclasificación). El ajuste de instrucciones refina la generación específica del dominio, y la evaluación bootstrapped arroja una desviación estándar para las métricas de evaluación.\n  En pruebas de referencia sintéticas que imitan las consultas reales, el agente ajustado por instrucciones con optimización directa de preferencias (OPD) supera a la línea de base, logrando una ganancia de 0,63 en recuperación de contexto de VS y de 0,56 en precisión de contexto global. Otras mejoras son 0,24 en fidelidad de VS, 0,12 en precisión de VS y relevancia de respuesta de KG, 0,11 en fidelidad general, 0,05 en recuperación de contexto de KG y 0,04 en relevancia de respuesta de VS y precisión general. Estos resultados ponen de relieve la mejora del razonamiento del sistema sobre fuentes heterogéneas y establecen un marco escalable para el descubrimiento científico autónomo y agencial.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Marco Agentic RAG híbrido de código abierto para la revisión de la literatura científica\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "opensource",
      "agentic",
      "hybrid"
    ],
    "category": "noticia"
  },
  {
    "title": "Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace",
    "title_es": "Zero-Shot Retrieval para una búsqueda visual escalable en un mercado de dos caras",
    "url": "https://arxiv.org/abs/2508.05661",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05661v1 Tipo de anuncio: nuevo\nResumen: La búsqueda visual ofrece una forma intuitiva para que los clientes exploren diversos catálogos de productos, en particular en los mercados de consumidor a consumidor (C2C), donde los listados son a menudo desestructurados y visuales. Este artículo presenta un sistema de búsqueda visual escalable desplegado en el mercado C2C de Mercari, donde los usuarios finales actúan como compradores y vendedores. Se evalúan modelos recientes de lenguaje de visión para la recuperación de imágenes sin disparos y se compara su rendimiento con el de una base de referencia existente. El sistema integra flujos de trabajo de inferencia en tiempo real e indexación en segundo plano, con el apoyo de un proceso unificado de incrustación optimizado mediante la reducción de la dimensionalidad. La evaluación fuera de línea mediante registros de interacción con el usuario muestra que el modelo SigLIP multilingüe supera a otros modelos en múltiples métricas de recuperación, logrando un aumento del 13,3% en nDCG@5 con respecto a la línea de base. Una prueba A/B en línea de una semana de duración en producción confirma aún más el impacto en el mundo real, con el grupo de tratamiento mostrando ganancias sustanciales en el compromiso y la conversión, hasta un aumento del 40,9% en la tasa de transacciones a través de la búsqueda de imágenes. Nuestros resultados ponen de relieve que los recientes modelos de cero disparos pueden servir como base sólida y práctica para el uso en producción, lo que permite a los equipos desplegar sistemas eficaces de búsqueda visual con una sobrecarga mínima, al tiempo que conserva la flexibilidad para realizar ajustes en función de los datos futuros o las necesidades específicas del dominio.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Zero-Shot Retrieval para una búsqueda visual escalable en un mercado de dos caras\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "zeroshot",
      "retrieval",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "From Static to Dynamic: A Streaming RAG Approach to Real-time Knowledge Base",
    "title_es": "De lo estático a lo dinámico: Un enfoque RAG de flujo para una base de conocimientos en tiempo real",
    "url": "https://arxiv.org/abs/2508.05662",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05662v1 Tipo de anuncio: nuevo\nResumen: Los flujos dinámicos de noticias, redes sociales, redes de sensores y mercados financieros suponen un reto para los marcos RAG estáticos. Los índices a gran escala incurren en elevados costes de memoria; las reconstrucciones periódicas introducen una latencia que socava la frescura de los datos; el muestreo ingenuo sacrifica la cobertura semántica. Presentamos Streaming RAG, un proceso unificado que combina el cribado multivectorial por coseno, la agrupación en minilotes y un filtro basado en contadores para mantener un conjunto de prototipos compacto. Además, demostramos un límite de aproximación \\$E[R(K\\_t)] \\ge R^\\* - L \\Delta\\$ que vincula la calidad de la recuperación con la varianza de la agrupación. Un mecanismo de actualización incremental del índice actualiza los prototipos sin interrumpir las consultas. Los experimentos con ocho flujos en tiempo real muestran mejoras estadísticamente significativas en Recall@10 (hasta 3 puntos, p < 0,01), una latencia de extremo a extremo inferior a 15 ms y un rendimiento superior a 900 documentos por segundo con un presupuesto de 150 MB. El análisis de sensibilidad de hiperparámetros sobre el recuento de clusters, la probabilidad de admisión, el umbral de relevancia y la capacidad del contador valida los ajustes por defecto. En la respuesta a preguntas de dominio abierto con GPT-3.5 Turbo, registramos una ganancia de 3,2 puntos en Exact Match y de 2,8 puntos en F1 sobre SQuAD; el resumen abstracto produce mejoras ROUGE-L. Streaming RAG establece una nueva frontera de Pareto para el aumento de la recuperación.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"De lo estático a lo dinámico: Un enfoque RAG de flujo para una base de conocimientos en tiempo real\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "from",
      "static",
      "to"
    ],
    "category": "noticia"
  },
  {
    "title": "Enhancing Retrieval-Augmented Generation for Electric Power Industry Customer Support",
    "title_es": "Mejora de la generación aumentada por recuperación para la atención al cliente del sector eléctrico",
    "url": "https://arxiv.org/abs/2508.05664",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05664v1 Tipo de anuncio: nuevo\nResumen: Muchos sistemas de atención al cliente basados en Inteligencia Artificial utilizan canales estándar de PLN o modelos lingüísticos ajustados, que a menudo se quedan cortos en consultas ambiguas, multiintento o con detalles específicos. Este estudio de caso evalúa técnicas recientes: reescritura de consultas, fusión de RAG, aumento de palabras clave, reconocimiento de intenciones y reordenación de contextos, para crear un sistema robusto de atención al cliente en el ámbito de la energía eléctrica. Comparamos marcos RAG basados en vectores y en grafos, y finalmente seleccionamos el RAG basado en grafos por su mayor rendimiento en el manejo de consultas complejas. Comprobamos que la reescritura de consultas mejora la recuperación de las que utilizan terminología no estándar o requieren detalles precisos. La fusión de RAG aumenta el rendimiento de las consultas imprecisas o multifacéticas al fusionar varias recuperaciones. La reordenación reduce las alucinaciones filtrando los contextos irrelevantes. El reconocimiento de intenciones permite descomponer preguntas complejas en subconsultas más específicas, lo que aumenta la pertinencia y la eficacia. En cambio, el aumento de palabras clave afecta negativamente a los resultados debido a una selección sesgada de las mismas. Nuestro sistema final combina el reconocimiento de intención, la fusión RAG y la reordenación para gestionar la desambiguación y las consultas con múltiples fuentes. Evaluado tanto en un conjunto de datos generado por GPT-4 como en un conjunto de datos de preguntas frecuentes de proveedores de electricidad del mundo real, alcanza una precisión del 97,9% y el 89,6% respectivamente, superando sustancialmente a los modelos RAG de referencia.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Mejora de la generación aumentada por recuperación para la atención al cliente del sector eléctrico\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "enhancing",
      "retrievalaugmented",
      "generation"
    ],
    "category": "noticia"
  },
  {
    "title": "HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis",
    "title_es": "HySemRAG: un marco híbrido de recuperación semántica y generación mejorada para la síntesis bibliográfica automatizada y el análisis de lagunas metodológicas.",
    "url": "https://arxiv.org/abs/2508.05666",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05666v1 Tipo de anuncio: nuevo\nResumen: Presentamos HySemRAG, un marco que combina Extract, Transform, Load (ETL) pipelines con Retrieval-Augmented Generation (RAG) para automatizar la síntesis de literatura a gran escala e identificar lagunas metodológicas de investigación. El sistema aborda las limitaciones de las arquitecturas RAG existentes mediante un enfoque multicapa: recuperación híbrida que combina la búsqueda semántica, el filtrado de palabras clave y el recorrido por el grafo de conocimiento; un marco de autocorrección agencial con garantía de calidad iterativa; y verificación de citas post-hoc que garantiza una trazabilidad completa. Nuestra implementación procesa la literatura académica a través de ocho etapas integradas: adquisición de metadatos de múltiples fuentes, recuperación asíncrona de PDF, análisis personalizado de la disposición de los documentos mediante una arquitectura Docling modificada, gestión bibliográfica, extracción de campos basada en LLM, modelado de temas, unificación semántica y construcción de grafos de conocimiento. El sistema crea productos de datos duales -un grafo de conocimiento Neo4j que permite consultas de relaciones complejas y colecciones de vectores Qdrant que soportan la búsqueda semántica- que sirven como infraestructura fundacional para la síntesis de información verificable. La evaluación de 643 observaciones de 60 sesiones de prueba demuestra que la extracción de campos estructurados logra puntuaciones de similitud semántica un 35,1% superiores (0,655 $\\pm$ 0,178) en comparación con los enfoques de fragmentación de PDF (0,485 $\\pm$ 0,204, p < 0,000001). El mecanismo agéntico de garantía de calidad logra tasas de éxito de una sola pasada del 68,3% con una precisión de citación del 99,0% en las respuestas validadas. Aplicado a la bibliografía de epidemiología geoespacial sobre la exposición al ozono y las enfermedades cardiovasculares, el sistema identifica tendencias metodológicas y lagunas en la investigación, demostrando una amplia aplicabilidad en todos los ámbitos científicos para acelerar la síntesis y el descubrimiento de pruebas.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"HySemRAG: un marco híbrido de recuperación semántica y generación mejorada para la síntesis bibliográfica automatizada y el análisis de lagunas metodológicas.\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hysemrag",
      "a",
      "hybrid"
    ],
    "category": "noticia"
  },
  {
    "title": "ITDR: An Instruction Tuning Dataset for Enhancing Large Language Models in Recommendations",
    "title_es": "ITDR: un conjunto de datos de ajuste de instrucciones para mejorar grandes modelos lingüísticos en las recomendaciones",
    "url": "https://arxiv.org/abs/2508.05667",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05667v1 Tipo de anuncio: nuevo\nResumen: Los modelos de lenguaje amplio (LLM) han demostrado un rendimiento excepcional en tareas de procesamiento del lenguaje natural. Sin embargo, en el campo de los sistemas de recomendación, debido a las diferencias estructurales entre los datos de comportamiento del usuario y el lenguaje natural, los LLMs luchan por modelar eficazmente las asociaciones entre las preferencias del usuario y los artículos. Aunque los métodos basados en sugerencias pueden generar resultados de recomendación, su comprensión inadecuada de las tareas de recomendación conduce a un rendimiento limitado. Para abordar esta carencia, en este trabajo construimos un conjunto de datos de ajuste de instrucciones suficiente, ITDR, que abarca 7 subtareas a través de dos tareas raíz fundamentales: la interacción usuario-artículo y la comprensión usuario-artículo. El conjunto de datos integra datos de 13 conjuntos de datos de recomendación públicos y se construye utilizando plantillas estandarizadas elaboradas manualmente, que comprenden aproximadamente 200.000 instancias. Los resultados experimentales demuestran que ITDR mejora significativamente el rendimiento de los principales LLM de código abierto como GLM-4, Qwen2.5, Qwen2.5-Instruct y LLaMA-3.2 en tareas de recomendación. Además, analizamos las correlaciones entre tareas y exploramos el impacto de las descripciones de tareas y la escala de datos en la eficacia del ajuste de instrucciones. Por último, realizamos experimentos comparativos con LLM de código cerrado con parámetros sustanciales. Nuestro conjunto de datos de ajuste ITDR y los grandes modelos de recomendación ajustados pueden consultarse en https://github.com/hellolzk/ITDR.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ITDR: un conjunto de datos de ajuste de instrucciones para mejorar grandes modelos lingüísticos en las recomendaciones\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "itdr",
      "an",
      "instruction"
    ],
    "category": "noticia"
  },
  {
    "title": "A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges",
    "title_es": "Estudio de los agentes de búsqueda profunda basados en LLM: Paradigma, optimización, evaluación y retos",
    "url": "https://arxiv.org/abs/2508.05668",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05668v1 Tipo de anuncio: nuevo\nResumen: La llegada de los Large Language Models (LLMs) ha revolucionado significativamente la búsqueda en la web. La aparición de agentes de búsqueda basados en LLMs marca un cambio fundamental hacia una búsqueda de información más profunda, dinámica y autónoma. Estos agentes pueden comprender las intenciones del usuario y el contexto ambiental y ejecutar recuperaciones multi-vuelta con planificación dinámica, extendiendo las capacidades de búsqueda mucho más allá de la web. Ejemplos destacados como la investigación profunda de OpenAI ponen de relieve su potencial para la búsqueda profunda de información y las aplicaciones en el mundo real. Este estudio proporciona el primer análisis sistemático de los agentes de búsqueda. Analizamos y categorizamos exhaustivamente los trabajos existentes desde las perspectivas de la arquitectura, la optimización, la aplicación y la evaluación, identificando en última instancia los retos críticos pendientes y esbozando futuras direcciones de investigación prometedoras en este campo en rápida evolución. Nuestro repositorio está disponible en https://github.com/YunjiaXi/Awesome-Search-Agent-Papers.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Estudio de los agentes de búsqueda profunda basados en LLM: Paradigma, optimización, evaluación y retos\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "survey",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports",
    "title_es": "Perfeccionamiento de modelos de visión-idioma para la conversión a Markdown de tablas financieras en informes financieros auditados de Malasia",
    "url": "https://arxiv.org/abs/2508.05669",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05669v1 Tipo de anuncio: nuevo\nResumen: Extraer y representar con precisión la estructura de los datos tabulares de los documentos financieros sigue siendo un reto crítico en la comprensión de documentos, en particular para los casos de uso normativo y analítico. Este estudio aborda la complejidad de convertir tablas financieras de informes financieros auditados de Malasia al formato Markdown, una tarea complicada por los diseños rotados, los encabezados de varios niveles y las pistas estructurales implícitas. Proponemos un modelo de visión-lenguaje (VLM) basado en Qwen2.5-VL-7B, optimizado para la generación de Markdown de alta fidelidad a partir de imágenes de documentos. Nuestro enfoque incluye un conjunto de datos de 2.152 pares imagen-texto con aumentos y una estrategia de ajuste fino supervisada mediante LoRA. Para evaluar el rendimiento, evaluamos nuestro modelo en 100 tablas fuera de muestra utilizando un marco dual: un LLM como juez basado en criterios para la precisión fina y nuestra nueva métrica de similitud Markdown basada en la distancia de edición de árboles (TEDS) para la fidelidad estructural holística. Nuestro modelo alcanza una precisión global del 92,20% en la evaluación basada en criterios y una puntuación TEDS basada en Markdown del 96,53%. Este rendimiento supera con creces a su modelo base Qwen2.5-VL-7B, a los VLM de mayor escala y a los modelos especializados de razonamiento. En comparación con estas alternativas autoalojadas, también reduce significativamente el tiempo de inferencia. Además, su precisión supera la de modelos propietarios ampliamente utilizados, como GPT-4o de OpenAI y Gemini 2.5 Flash. Estos resultados demuestran que el ajuste fino específico del dominio proporciona un método eficaz y eficiente para salvar la brecha entre los documentos financieros no estructurados y la automatización posterior, rivalizando con modelos mucho más grandes y generales sin su sobrecarga computacional.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Perfeccionamiento de modelos de visión-idioma para la conversión a Markdown de tablas financieras en informes financieros auditados de Malasia\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "finetuning",
      "visionlanguage",
      "models"
    ],
    "category": "noticia"
  },
  {
    "title": "Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity?",
    "title_es": "¿Pueden los LLM ofrecer escenarios basados en la teoría de juegos para la ciberseguridad?",
    "url": "https://arxiv.org/abs/2508.05670",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05670v1 Tipo de anuncio: nuevo\nResumen: La teoría de juegos ha servido durante mucho tiempo como herramienta fundamental en ciberseguridad para probar, predecir y diseñar interacciones estratégicas entre atacantes y defensores. El reciente advenimiento de los Modelos de Lenguaje Grande (LLMs) ofrece nuevas herramientas y desafíos para la seguridad de los sistemas informáticos; En este trabajo, investigamos si los marcos clásicos de la teoría de juegos pueden capturar eficazmente los comportamientos de los actores y bots impulsados por LLMs. Utilizando un marco reproducible para agentes LLM teóricos de juegos, investigamos dos escenarios canónicos -el juego de suma cero de un solo disparo y el dilema del prisionero dinámico- y comprobamos si los LLM convergen a los resultados esperados o muestran desviaciones debidas a sesgos incorporados. Nuestros experimentos incluyen cuatro LLM de última generación y abarcan cinco idiomas naturales, inglés, francés, árabe, vietnamita y chino mandarín, para evaluar la sensibilidad lingüística. En ambos juegos, observamos que los resultados finales se ven influidos por las características de los agentes, como los rasgos de personalidad o el conocimiento de las rondas repetidas. Además, descubrimos una sensibilidad inesperada de los beneficios finales a la elección de idiomas, lo que debería alertar contra la aplicación indiscriminada de los LLM en aplicaciones de ciberseguridad y exigir estudios en profundidad, ya que los LLM pueden comportarse de forma diferente cuando se despliegan en distintos países. También empleamos métricas cuantitativas para evaluar la consistencia interna y la estabilidad entre lenguajes de los agentes LLM, para ayudar a guiar la selección de los LLM más estables y optimizar los modelos para aplicaciones seguras.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"¿Pueden los LLM ofrecer escenarios basados en la teoría de juegos para la ciberseguridad?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "can",
      "llms",
      "effectively"
    ],
    "category": "noticia"
  },
  {
    "title": "DINA: A Dual Defense Framework Against Internal Noise and External Attacks in Natural Language Processing",
    "title_es": "DINA: un marco de defensa dual contra el ruido interno y los ataques externos en el procesamiento del lenguaje natural",
    "url": "https://arxiv.org/abs/2508.05671",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05671v1 Tipo de anuncio: nuevo\nResumen: A medida que los grandes modelos lingüísticos (LLMs) y la IA generativa se integran cada vez más en aplicaciones de servicio al cliente y moderación, surgen amenazas adversariales tanto de manipulaciones externas como de corrupción interna de etiquetas. En este trabajo, identificamos y abordamos sistemáticamente estas amenazas adversas duales introduciendo DINA (Dual Defense Against Internal Noise and Adversarial Attacks), un novedoso marco unificado adaptado específicamente a la PNL. Nuestro enfoque adapta métodos avanzados de aprendizaje de etiquetas ruidosas de la visión por ordenador y los integra con el entrenamiento adversarial para mitigar simultáneamente el sabotaje interno de etiquetas y las perturbaciones adversariales externas. Extensos experimentos realizados en un conjunto de datos reales de un servicio de juegos en línea demuestran que DINA mejora significativamente la robustez y precisión del modelo en comparación con los modelos de referencia. Nuestros hallazgos no sólo ponen de relieve la necesidad crítica de defensas de doble amenaza, sino que también ofrecen estrategias prácticas para salvaguardar los sistemas de PNL en escenarios adversarios realistas, subrayando implicaciones más amplias para el despliegue justo y responsable de la IA.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DINA: un marco de defensa dual contra el ruido interno y los ataques externos en el procesamiento del lenguaje natural\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dina",
      "a",
      "dual"
    ],
    "category": "noticia"
  },
  {
    "title": "LMAR: Language Model Augmented Retriever for Domain-specific Knowledge Indexing",
    "title_es": "LMAR: Language Model Augmented Retriever para la indexación de conocimientos específicos de un dominio",
    "url": "https://arxiv.org/abs/2508.05672",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05672v1 Tipo de anuncio: nuevo\nResumen: Los sistemas de Generación Aumentada de Recuperación (RAG) a menudo tienen dificultades con el conocimiento específico del dominio debido al deterioro del rendimiento de las incrustaciones preentrenadas y a los costes computacionales prohibitivos de los recuperadores basados en grandes modelos de lenguaje (LLM). Aunque el ajuste fino de los modelos de incrustación de aumento de datos ofrece una dirección prometedora, su eficacia se ve limitada por la necesidad de datos de entrenamiento de alta calidad y estrategias de fragmentación fiables que preserven la integridad contextual. Proponemos LMAR (Language Model Augmented Retriever), un marco agnóstico de modelos que aborda estos retos combinando la síntesis de datos guiada por LLM con la adaptación de incrustación contrastiva y la agrupación eficiente de textos. LMAR consiste en un proceso de dos etapas: (1) muestreo de tripletes y aumento de datos sintéticos, en el que los LLM actúan como etiquetadores y validadores para garantizar una supervisión de alta fidelidad en todo el proceso. Los resultados experimentales en múltiples conjuntos de datos de referencia de dominios específicos demuestran que LMAR supera a múltiples modelos de referencia, al tiempo que mantiene unos requisitos de hardware moderados y una baja latencia. Además, su naturaleza agnóstica permite una integración perfecta con arquitecturas RAG emergentes y modelos de incrustación de texto, lo que garantiza mejoras continuas sin necesidad de rediseñar el proceso. Estos resultados ponen de manifiesto que LMAR es una solución práctica y rentable para la adaptación escalable de dominios específicos.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LMAR: Language Model Augmented Retriever para la indexación de conocimientos específicos de un dominio\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lmar",
      "language",
      "model"
    ],
    "category": "noticia"
  },
  {
    "title": "Breaking the Top-$K$ Barrier: Advancing Top-$K$ Ranking Metrics Optimization in Recommender Systems",
    "title_es": "Romper la barrera del Top-$K$: Optimización de las métricas de clasificación Top-$K$ en los sistemas de recomendación",
    "url": "https://arxiv.org/abs/2508.05673",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05673v1 Tipo de anuncio: nuevo\nResumen: En el ámbito de los sistemas de recomendación (SR), las métricas de clasificación Top-$K$, como NDCG@$K$, son el patrón oro para evaluar el rendimiento de las recomendaciones. Sin embargo, durante el entrenamiento de los modelos de recomendación, la optimización de NDCG@$K$ plantea importantes retos debido a su inherente naturaleza discontinua y al intrincado truncamiento Top-$K$. Los esfuerzos recientes por optimizar el NDCG@$K$ han pasado por alto el truncamiento Top-$K$ o han adolecido de elevados costes computacionales e inestabilidad en el entrenamiento. Para superar estas limitaciones, proponemos SoftmaxLoss@$K$ (SL@$K$), una nueva pérdida de recomendación adaptada a la optimización de NDCG@$K$. En concreto, integramos la técnica cuantílica para gestionar el truncamiento Top-$K$ y derivamos un límite superior suave para optimizar NDCG@$K$ con el fin de abordar la discontinuidad. La pérdida SL@$K$ resultante tiene varias propiedades deseables, como garantías teóricas, facilidad de implementación, eficiencia computacional, estabilidad de gradiente y robustez frente al ruido. Experimentos exhaustivos con cuatro conjuntos de datos reales y tres redes troncales de recomendación demuestran que SL@$K$ supera las pérdidas existentes con una notable mejora media del 6,03%. El código está disponible en https://github.com/Tiny-Snow/IR-Benchmark.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Romper la barrera del Top-$K$: Optimización de las métricas de clasificación Top-$K$ en los sistemas de recomendación\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "breaking",
      "the",
      "topk"
    ],
    "category": "noticia"
  },
  {
    "title": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark",
    "title_es": "Hacia agentes LLM de seguridad ofensiva eficaces: Ajuste de hiperparámetros, LLM como juez y una prueba de CTF ligera",
    "url": "https://arxiv.org/abs/2508.05674",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05674v1 Tipo de anuncio: nuevo\nResumen: Los recientes avances en los sistemas de agentes LLM han mejorado la automatización de las tareas de seguridad ofensiva, en particular para los desafíos de Capturar la Bandera (CTF). Investigamos sistemáticamente los factores clave que impulsan el éxito de los agentes y proporcionamos una receta detallada para construir agentes de seguridad ofensiva eficaces basados en LLM. En primer lugar, presentamos CTFJudge, un marco que aprovecha el LLM como juez para analizar las trayectorias de los agentes y proporcionar una evaluación detallada de los pasos de resolución de CTF. En segundo lugar, proponemos una nueva métrica, el índice de competencia CTF (CCI) para la corrección parcial, que revela hasta qué punto las soluciones de los agentes se ajustan a los estándares de oro creados por humanos. En tercer lugar, examinamos cómo los hiperparámetros LLM, a saber, temperatura, top-p y longitud máxima de token, influyen en el rendimiento del agente y en la planificación automatizada de tareas de ciberseguridad. Para una evaluación rápida, presentamos CTFTiny, una referencia curada de 50 desafíos CTF representativos de explotación binaria, web, ingeniería inversa, análisis forense y criptografía. Nuestros hallazgos identifican configuraciones óptimas de coordinación multiagente y sientan las bases para futuras investigaciones sobre agentes LLM en ciberseguridad. Ponemos CTFTiny a disposición del público en https://github.com/NYU-LLM-CTF/CTFTiny junto con CTFJudge en https://github.com/NYU-LLM-CTF/CTFJudge.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hacia agentes LLM de seguridad ofensiva eficaces: Ajuste de hiperparámetros, LLM como juez y una prueba de CTF ligera\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "towards",
      "effective",
      "offensive"
    ],
    "category": "noticia"
  },
  {
    "title": "Principle-Guided Verilog Optimization: IP-Safe Knowledge Transfer via Local-Cloud Collaboration",
    "title_es": "Optimización Verilog guiada por principios: Transferencia segura de conocimientos IP mediante colaboración local-nube",
    "url": "https://arxiv.org/abs/2508.05675",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05675v1 Tipo de anuncio: nuevo\nResumen: En los últimos años se ha observado un creciente interés en la adopción de grandes modelos de lenguaje (LLMs) para la optimización de código a nivel de transferencia de registro (RTL). Aunque los potentes LLMs basados en la nube ofrecen capacidades de optimización superiores, plantean riesgos inaceptables de fuga de propiedad intelectual (IP) al procesar diseños de hardware propietarios. En este artículo, proponemos un nuevo escenario en el que el código Verilog debe optimizarse para atributos específicos sin filtrar información sensible de IP. Presentamos el primer marco colaborativo borde-nube que preserva la propiedad intelectual y aprovecha las ventajas de ambos paradigmas. Nuestro enfoque emplea pequeños LLM locales (por ejemplo, Qwen-2.5-Coder-7B) para realizar análisis comparativos seguros entre diseños de alta calidad emparejados y borradores de códigos novatos, obteniendo principios generales de diseño que resumen las ideas clave para las mejoras. A continuación, estos principios se utilizan para consultar LLM en la nube más potentes (por ejemplo, Deepseek-V3) con el fin de mejorar el código específico, garantizando que sólo la orientación abstracta y segura para IP llegue a los servicios externos. Nuestros resultados experimentales demuestran que el marco logra tasas de éxito de optimización significativamente más altas en comparación con los métodos de referencia. Por ejemplo, la combinación de Qwen-2.5-Coder-7B y Deepseek-V3 alcanza una tasa de éxito de optimización del 66,67% para la utilización de energía, superando a Deepseek-V3 por sí solo (49,81%) e incluso a modelos comerciales como GPT-4o (55,81%). Un estudio más detallado de las combinaciones de LLM local y en la nube revela que los distintos emparejamientos de modelos presentan diferentes puntos fuertes para objetivos de optimización específicos, y que surgen tendencias interesantes al variar el número de pares de códigos comparativos. Nuestro trabajo establece un nuevo paradigma para la optimización del diseño de hardware seguro que equilibra las ganancias de rendimiento con la protección de la propiedad intelectual.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Optimización Verilog guiada por principios: Transferencia segura de conocimientos IP mediante colaboración local-nube\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "principleguided",
      "verilog",
      "optimization"
    ],
    "category": "noticia"
  },
  {
    "title": "Domain-Specific Fine-Tuning and Prompt-Based Learning: A Comparative Study for developing Natural Language-Based BIM Information Retrieval Systems",
    "title_es": "Perfeccionamiento específico del dominio y aprendizaje basado en instrucciones: Un estudio comparativo para desarrollar sistemas de recuperación de información BIM basados en el lenguaje natural",
    "url": "https://arxiv.org/abs/2508.05676",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05676v1 Tipo de anuncio: nuevo\nResumen: Building Information Modeling (BIM) es esencial para la gestión de datos de construcción a lo largo de todo el ciclo de vida, apoyando las tareas desde el diseño hasta el mantenimiento. Los sistemas de interfaz de lenguaje natural (NLI) se exploran cada vez más como herramientas de fácil uso para la recuperación de información en entornos de modelado de información de edificios (BIM). A pesar de su potencial, la extracción precisa de datos relacionados con BIM a través de consultas en lenguaje natural sigue siendo un reto persistente debido a la complejidad de las consultas de uso y la especificidad del conocimiento del dominio. Este estudio presenta un análisis comparativo de dos enfoques destacados para el desarrollo de sistemas de recuperación de información BIM basados en NLI: el ajuste fino específico del dominio y el aprendizaje basado en instrucciones utilizando grandes modelos de lenguaje (LLM). Para evaluar la eficacia de ambos enfoques, se implementa un marco en dos fases consistente en el reconocimiento de intenciones y la respuesta a preguntas basadas en tablas. Para apoyar esta evaluación, se construye un conjunto de datos específico de BIM de 1.740 consultas anotadas de diversos tipos a través de 69 modelos. Los resultados experimentales muestran que el ajuste fino específico del dominio ofrece un rendimiento superior en las tareas de reconocimiento de intenciones, mientras que el aprendizaje basado en instrucciones, en particular con GPT-4o, muestra su fortaleza en la respuesta a preguntas basadas en tablas. Basándose en estos resultados, este estudio identifica una configuración híbrida que combina el ajuste fino para el reconocimiento de intenciones con el aprendizaje basado en instrucciones para la respuesta a preguntas, logrando un rendimiento más equilibrado y sólido en todas las tareas. Este enfoque integrado se pone a prueba mediante estudios de casos con modelos BIM de diversa complejidad. Este estudio proporciona un análisis sistemático de los puntos fuertes y las limitaciones de cada enfoque y analiza la aplicabilidad de la NLI a escenarios BIM del mundo real. Los resultados ofrecen ideas para investigadores y profesionales a la hora de diseñar sistemas BIM inteligentes y basados en el lenguaje.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Perfeccionamiento específico del dominio y aprendizaje basado en instrucciones: Un estudio comparativo para desarrollar sistemas de recuperación de información BIM basados en el lenguaje natural\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "domainspecific",
      "finetuning",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Adversarial Attacks on Reinforcement Learning-based Medical Questionnaire Systems: Input-level Perturbation Strategies and Medical Constraint Validation",
    "title_es": "Ataques adversarios a sistemas de cuestionarios médicos basados en el aprendizaje por refuerzo: Estrategias de Perturbación a Nivel de Entrada y Validación de Restricciones Médicas",
    "url": "https://arxiv.org/abs/2508.05677",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05677v1 Tipo de anuncio: nuevo\nResumen: Los sistemas de cuestionarios médicos basados en RL han mostrado un gran potencial en escenarios médicos. Sin embargo, su seguridad y robustez siguen sin resolverse. Este estudio realiza una evaluación exhaustiva sobre métodos de ataque adversarial para identificar y analizar sus posibles vulnerabilidades. Formulamos el proceso de diagnóstico como un Proceso de Decisión de Markov (MDP), en el que el estado son las respuestas del paciente y las preguntas no formuladas, y la acción es formular una pregunta o realizar un diagnóstico. Implementamos seis métodos de ataque principales, incluyendo el Método de Gradiente Rápido (FGSM), el Descenso Gradiente Proyectado (PGD), el Ataque de Carlini & Wagner (C&W), el Método Iterativo Básico (BIM), DeepFool y AutoAttack, con siete valores epsilon cada uno. Para garantizar que los ejemplos adversos generados sigan siendo clínicamente plausibles, desarrollamos un marco de validación médica integral que consta de 247 restricciones médicas, incluidos límites fisiológicos, correlaciones de síntomas y restricciones médicas condicionales. Alcanzamos una tasa de éxito del 97,6% en la generación de muestras adversas clínicamente plausibles. Realizamos nuestro experimento con el conjunto de datos de la Encuesta Nacional de Salud (NHIS) (https://www.cdc.gov/nchs/nhis/), que consta de 182.630 muestras, para predecir la tasa de mortalidad a 4 años de los participantes. Evaluamos nuestros ataques en el marco AdaptiveFS propuesto en arXiv:2004.00994. Nuestros resultados muestran que los ataques adversarios pueden afectar significativamente a la precisión del diagnóstico, con tasas de éxito de los ataques que oscilan entre el 33,08% (FGSM) y el 64,70% (AutoAttack). Nuestro trabajo ha demostrado que incluso bajo estrictas restricciones médicas en la entrada, tales sistemas de cuestionarios médicos basados en RL siguen mostrando vulnerabilidades significativas.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Ataques adversarios a sistemas de cuestionarios médicos basados en el aprendizaje por refuerzo: Estrategias de Perturbación a Nivel de Entrada y Validación de Restricciones Médicas\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "adversarial",
      "attacks",
      "on"
    ],
    "category": "noticia"
  },
  {
    "title": "Are All Genders Equal in the Eyes of Algorithms? -- Analysing Search and Retrieval Algorithms for Algorithmic Gender Fairness",
    "title_es": "¿Son todos los géneros iguales a los ojos de los algoritmos? -- Análisis de los algoritmos de búsqueda y recuperación para determinar si son justos desde el punto de vista del género.",
    "url": "https://arxiv.org/abs/2508.05680",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05680v1 Tipo de anuncio: nuevo\nResumen: Los sistemas algorítmicos, como los motores de búsqueda y las plataformas de recuperación de información, influyen significativamente en la visibilidad académica y la difusión del conocimiento. A pesar de los supuestos de neutralidad, estos sistemas pueden reproducir o reforzar sesgos sociales, incluidos los relacionados con el género. Este artículo introduce y aplica una definición de equidad de género algorítmica que preserva los prejuicios y evalúa si los resultados algorítmicos reflejan las distribuciones de género del mundo real sin introducir o amplificar disparidades. Utilizando un conjunto de datos heterogéneos de perfiles académicos de universidades alemanas y universidades de ciencias aplicadas, analizamos las diferencias de género en la exhaustividad de los metadatos, la recuperación de publicaciones en bases de datos académicas y la visibilidad en los resultados de búsqueda de Google. Aunque no observamos ninguna discriminación algorítmica manifiesta, nuestros resultados revelan desequilibrios sutiles pero consistentes: los profesores varones se asocian a un mayor número de resultados de búsqueda y a registros de publicación más alineados, mientras que las profesoras muestran una mayor variabilidad en la visibilidad digital. Estos patrones reflejan la interacción entre los algoritmos de las plataformas, la gestión institucional y la autopresentación individual. Nuestro estudio subraya la necesidad de evaluaciones de equidad que tengan en cuenta tanto el rendimiento técnico como la igualdad de representación en los sistemas digitales.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"¿Son todos los géneros iguales a los ojos de los algoritmos? -- Análisis de los algoritmos de búsqueda y recuperación para determinar si son justos desde el punto de vista del género.\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "are",
      "all",
      "genders"
    ],
    "category": "noticia"
  },
  {
    "title": "Selection-Based Vulnerabilities: Clean-Label Backdoor Attacks in Active Learning",
    "title_es": "Vulnerabilidades basadas en la selección: Ataques de puerta trasera de etiqueta limpia en el aprendizaje activo",
    "url": "https://arxiv.org/abs/2508.05681",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05681v1 Tipo de anuncio: nuevo\nResumen: El aprendizaje activo (AL), que sirve como paradigma representativo del aprendizaje eficiente de etiquetas, se ha aplicado ampliamente en escenarios con recursos limitados. El logro del AL se atribuye a las funciones de adquisición, que están diseñadas para identificar los datos más importantes a etiquetar. A pesar de este éxito, una pregunta sigue sin respuesta: ¿es AL seguro? En este trabajo, presentamos ALA, un marco práctico y el primero en utilizar la función de adquisición como superficie de ataque de envenenamiento para revelar la debilidad del aprendizaje activo. En concreto, ALA optimiza las entradas envenenadas imperceptiblemente para que presenten puntuaciones de incertidumbre elevadas, aumentando su probabilidad de ser seleccionadas por las funciones de adquisición. Para evaluar ALA, realizamos experimentos exhaustivos con tres conjuntos de datos, tres funciones de adquisición y dos tipos de activadores de puerta trasera de etiqueta limpia. Los resultados muestran que nuestro ataque puede lograr altas tasas de éxito (hasta el 94%) incluso con presupuestos de envenenamiento bajos (0,5%-1,0%), preservando la utilidad del modelo y permaneciendo indetectable para los anotadores humanos. Nuestros hallazgos recuerdan a los usuarios de aprendizaje activo que las funciones de adquisición pueden ser fácilmente explotadas y que el aprendizaje activo debe desplegarse con precaución en escenarios de datos fiables.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Vulnerabilidades basadas en la selección: Ataques de puerta trasera de etiqueta limpia en el aprendizaje activo\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "selectionbased",
      "vulnerabilities",
      "cleanlabel"
    ],
    "category": "noticia"
  },
  {
    "title": "MM-FusionNet: Context-Aware Dynamic Fusion for Multi-modal Fake News Detection with Large Vision-Language Models",
    "title_es": "MM-FusionNet: Fusión dinámica consciente del contexto para la detección multimodal de noticias falsas con grandes modelos de visión y lenguaje",
    "url": "https://arxiv.org/abs/2508.05684",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05684v1 Tipo de anuncio: nuevo\nResumen: La proliferación de noticias falsas multimodales en las redes sociales supone una importante amenaza para la confianza pública y la estabilidad social. Los métodos de detección tradicionales, basados principalmente en texto, a menudo se quedan cortos debido a la engañosa interacción entre texto e imágenes engañosas. Aunque los grandes modelos de visión y lenguaje (LVLM) ofrecen vías prometedoras para la comprensión multimodal, la fusión eficaz de información modal diversa, especialmente cuando su importancia está desequilibrada o es contradictoria, sigue siendo un reto crítico. Este artículo presenta MM-FusionNet, un marco innovador que aprovecha los LVLM para la detección robusta de noticias falsas multimodales. Nuestra principal aportación es el Módulo de Fusión Dinámica Consciente del Contexto (CADFM), que emplea la atención bidireccional intermodal y una novedosa red de compuerta modal dinámica. Este mecanismo aprende de forma adaptativa y asigna pesos de importancia a las características textuales y visuales en función de su relevancia contextual, lo que permite priorizar la información de forma inteligente. Evaluada en el conjunto de datos multimodal de noticias falsas a gran escala (LMFND), compuesto por 80.000 muestras, MM-FusionNet alcanza una puntuación F1 de 0,938, superando en aproximadamente un 0,5% a las líneas de base multimodales existentes y superando significativamente a los enfoques monomodales. Otros análisis demuestran la capacidad de ponderación dinámica del modelo, su solidez frente a las perturbaciones de la modalidad y un rendimiento notablemente cercano al humano, lo que subraya su eficacia práctica y su interpretabilidad para la detección de noticias falsas en el mundo real.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MM-FusionNet: Fusión dinámica consciente del contexto para la detección multimodal de noticias falsas con grandes modelos de visión y lenguaje\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mmfusionnet",
      "contextaware",
      "dynamic"
    ],
    "category": "noticia"
  },
  {
    "title": "DogFit: Domain-guided Fine-tuning for Efficient Transfer Learning of Diffusion Models",
    "title_es": "DogFit: Ajuste fino guiado por el dominio para el aprendizaje por transferencia eficiente de modelos de difusión",
    "url": "https://arxiv.org/abs/2508.05685",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05685v1 Tipo de anuncio: nuevo\nResumen: El aprendizaje por transferencia de modelos de difusión a dominios objetivo más pequeños es un reto, ya que el ajuste fino ingenuo del modelo a menudo resulta en una pobre generalización. Los métodos de orientación en tiempo de prueba ayudan a mitigar esta situación ofreciendo mejoras controlables en la fidelidad de la imagen a través de un compromiso con la diversidad de muestras. Sin embargo, esta ventaja tiene un alto coste computacional, ya que suele requerir dos pasadas durante el muestreo. Proponemos el método de ajuste fino guiado por dominio (DogFit), un mecanismo de guiado eficaz para el aprendizaje por transferencia de difusión que mantiene la controlabilidad sin incurrir en una sobrecarga computacional adicional. DogFit inyecta en la pérdida de entrenamiento una compensación de guiado consciente del dominio, internalizando de forma efectiva el comportamiento guiado durante el proceso de ajuste fino. Este diseño está motivado por nuestra observación de que durante el ajuste fino, el modelo fuente incondicional ofrece una estimación marginal más fuerte que el modelo objetivo. Para poder controlar eficazmente los equilibrios entre fidelidad y diversidad durante la inferencia, codificamos el valor de la fuerza de orientación como una entrada adicional del modelo mediante un mecanismo de condicionamiento ligero. Además, investigamos la ubicación y el momento óptimos de la compensación de la orientación durante el entrenamiento y proponemos dos estrategias de programación sencillas, a saber, el inicio tardío y el corte, que mejoran la calidad de la generación y la estabilidad del entrenamiento. Los experimentos realizados en redes troncales DiT y SiT en seis dominios distintos demuestran que DogFit puede superar a los métodos de guiado anteriores en el aprendizaje por transferencia en términos de FID y FDDINOV2, al tiempo que requiere hasta dos veces menos TFLOPS de muestreo.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DogFit: Ajuste fino guiado por el dominio para el aprendizaje por transferencia eficiente de modelos de difusión\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dogfit",
      "domainguided",
      "finetuning"
    ],
    "category": "noticia"
  },
  {
    "title": "Risk Analysis Techniques for Governed LLM-based Multi-Agent Systems",
    "title_es": "Técnicas de análisis de riesgos para sistemas multiagente gobernados basados en LLM",
    "url": "https://arxiv.org/abs/2508.05687",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05687v1 Tipo de anuncio: nuevo\nResumen: Las organizaciones están empezando a adoptar agentes de IA basados en LLM, y sus despliegues evolucionan de forma natural desde agentes individuales hacia redes interconectadas de múltiples agentes. Sin embargo, una colección de agentes seguros no garantiza una colección segura de agentes, ya que las interacciones entre agentes a lo largo del tiempo crean comportamientos emergentes e inducen nuevos modos de fallo. Esto significa que los sistemas multiagente requieren un planteamiento de análisis de riesgos fundamentalmente distinto del utilizado para un agente único.\n  Este informe aborda las primeras fases de la identificación y el análisis de riesgos en sistemas de IA multiagente que operan en entornos gobernados en los que las organizaciones controlan la configuración y el despliegue de sus agentes. En este contexto, examinamos seis modos de fallo críticos: fallos de fiabilidad en cascada, fallos de comunicación entre agentes, colapso de la monocultura, sesgo de conformidad, teoría de la mente deficiente y dinámica de motivos mixtos. Para cada uno de ellos, proporcionamos un conjunto de herramientas que los profesionales pueden ampliar o integrar en sus marcos existentes para evaluar estos modos de fallo en sus contextos organizativos.\n  Dadas las limitaciones fundamentales de la comprensión actual del comportamiento en LLM, nuestro enfoque se centra en la validez del análisis, y aboga por aumentar progresivamente la validez mediante pruebas por etapas a través de fases de abstracción y despliegue que aumenten gradualmente la exposición a posibles impactos negativos, al tiempo que se recopilan pruebas convergentes mediante simulación, análisis observacional, evaluación comparativa y red teaming. Esta metodología sienta las bases para una sólida gestión del riesgo organizativo a medida que se despliegan y operan estos sistemas multiagente basados en LLM.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Técnicas de análisis de riesgos para sistemas multiagente gobernados basados en LLM\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "risk",
      "analysis",
      "techniques"
    ],
    "category": "noticia"
  },
  {
    "title": "LLM4ES: Learning User Embeddings from Event Sequences via Large Language Models",
    "title_es": "LLM4ES: Aprendizaje de incrustaciones de usuario a partir de secuencias de eventos mediante modelos lingüísticos amplios",
    "url": "https://arxiv.org/abs/2508.05688",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05688v1 Tipo de anuncio: nuevo\nResumen: Este artículo presenta LLM4ES, un nuevo marco que explota grandes modelos de lenguaje pre-entrenados (LLMs) para derivar incrustaciones de usuario a partir de secuencias de eventos. Las secuencias de eventos se transforman en una representación textual, que posteriormente se utiliza para afinar un LLM mediante la predicción del siguiente token para generar incrustaciones de alta calidad. Introducimos una técnica de enriquecimiento textual que mejora la adaptación del LLM a los datos de secuencias de eventos, mejorando la calidad de la representación para dominios de baja variabilidad. Los resultados experimentales demuestran que LLM4ES alcanza un rendimiento puntero en tareas de clasificación de usuarios en dominios financieros y de otro tipo, superando a los métodos de incrustación existentes. Las incrustaciones de usuario resultantes pueden incorporarse a una amplia gama de aplicaciones, desde la segmentación de usuarios en finanzas hasta la predicción de resultados de pacientes en sanidad.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LLM4ES: Aprendizaje de incrustaciones de usuario a partir de secuencias de eventos mediante modelos lingüísticos amplios\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "llmes",
      "learning",
      "user"
    ],
    "category": "noticia"
  },
  {
    "title": "Boosting Adversarial Transferability via Residual Perturbation Attack",
    "title_es": "Aumento de la transferibilidad adversarial mediante un ataque de perturbación residual",
    "url": "https://arxiv.org/abs/2508.05689",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05689v1 Tipo de anuncio: nuevo\nResumen: Las redes neuronales profundas son susceptibles a ejemplos adversarios y sufren predicciones incorrectas a través de perturbaciones imperceptibles. Los ataques basados en transferencia crean ejemplos adversos para modelos sustitutos y transfieren estos ejemplos a modelos objetivo en escenarios de caja negra. Estudios recientes revelan que los ejemplos adversos en paisajes de pérdidas planas presentan una transferibilidad superior para aliviar el sobreajuste en modelos sustitutos. Sin embargo, las artes anteriores pasan por alto la influencia de las direcciones de perturbación, lo que resulta en una transferibilidad limitada. En este artículo, proponemos un nuevo método de ataque, denominado Ataque de Perturbación Residual (ResPA), que se basa en el gradiente residual como dirección de perturbación para guiar los ejemplos adversarios hacia las regiones planas de la función de pérdida. En concreto, ResPA realiza una media móvil exponencial sobre los gradientes de entrada para obtener el primer momento como gradiente de referencia, que abarca la dirección de los gradientes históricos. En lugar de depender en gran medida de la planitud local que se deriva de los gradientes actuales como dirección de perturbación, ResPA considera además el residuo entre el gradiente actual y el gradiente de referencia para capturar los cambios en la dirección de perturbación global. Los resultados experimentales demuestran la mejor transferibilidad de ResPA que los métodos de ataque basados en transferencia típicos existentes, mientras que la transferibilidad puede mejorarse aún más combinando ResPA con los métodos de transformación de entrada actuales. El código está disponible en https://github.com/ZezeTao/ResPA.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Aumento de la transferibilidad adversarial mediante un ataque de perturbación residual\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "boosting",
      "adversarial",
      "transferability"
    ],
    "category": "noticia"
  },
  {
    "title": "Leveraging large language models for SQL behavior-based database intrusion detection",
    "title_es": "Leveraging large language models for SQL behavior-based database intrusion detection",
    "url": "https://arxiv.org/abs/2508.05690",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05690v1 Announce Type: new \nAbstract: Database systems are extensively used to store critical data across various domains. However, the frequency of abnormal database access behaviors, such as database intrusion by internal and external attacks, continues to rise. Internal masqueraders often have greater organizational knowledge, making it easier to mimic employee behavior effectively. In contrast, external masqueraders may behave differently due to their lack of familiarity with the organization. Current approaches lack the granularity needed to detect anomalies at the operational level, frequently misclassifying entire sequences of operations as anomalies, even though most operations are likely to represent normal behavior. On the other hand, some anomalous behaviors often resemble normal activities, making them difficult for existing detection methods to identify. This paper introduces a two-tiered anomaly detection approach for Structured Query Language (SQL) using the Bidirectional Encoder Representations from Transformers (BERT) model, specifically DistilBERT, a more efficient, pre-trained version. Our method combines both unsupervised and supervised machine learning techniques to accurately identify anomalous activities while minimizing the need for data labeling. First, the unsupervised method uses ensemble anomaly detectors that flag embedding vectors distant from learned normal patterns of typical user behavior across the database (out-of-scope queries). Second, the supervised method uses fine-tuned transformer-based models to detect internal attacks with high precision (in-scope queries), using role-labeled classification, even on limited labeled SQL data. Our findings make a significant contribution by providing an effective solution for safeguarding critical database systems from sophisticated threats.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Leveraging large language models for SQL behavior-based database intrusion detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "leveraging",
      "large",
      "language"
    ],
    "category": "noticia"
  },
  {
    "title": "AuthPrint: Fingerprinting Generative Models Against Malicious Model Providers",
    "title_es": "AuthPrint: Fingerprinting Generative Models Against Malicious Model Providers",
    "url": "https://arxiv.org/abs/2508.05691",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05691v1 Announce Type: new \nAbstract: Generative models are increasingly adopted in high-stakes domains, yet current deployments offer no mechanisms to verify the origin of model outputs. We address this gap by extending model fingerprinting techniques beyond the traditional collaborative setting to one where the model provider may act adversarially. To our knowledge, this is the first work to evaluate fingerprinting for provenance attribution under such a threat model. The methods rely on a trusted verifier that extracts secret fingerprints from the model's output space, unknown to the provider, and trains a model to predict and verify them. Our empirical evaluation shows that our methods achieve near-zero FPR@95%TPR for instances of GAN and diffusion models, even when tested on small modifications to the original architecture and training data. Moreover, the methods remain robust against adversarial attacks that actively modify the outputs to bypass detection. Source codes are available at https://github.com/PSMLab/authprint.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AuthPrint: Fingerprinting Generative Models Against Malicious Model Providers\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "authprint",
      "fingerprinting",
      "generative"
    ],
    "category": "noticia"
  },
  {
    "title": "Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach",
    "title_es": "Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach",
    "url": "https://arxiv.org/abs/2508.05693",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05693v1 Announce Type: new \nAbstract: Selecting third-party software packages in open-source ecosystems like Python is challenging due to the large number of alternatives and limited transparent evidence for comparison. Generative AI tools are increasingly used in development workflows, but their suggestions often overlook dependency evaluation, emphasize popularity over suitability, and lack reproducibility. This creates risks for projects that require transparency, long-term reliability, maintainability, and informed architectural decisions. This study formulates software package selection as a Multi-Criteria Decision-Making (MCDM) problem and proposes a data-driven framework for technology evaluation. Automated data pipelines continuously collect and integrate software metadata, usage trends, vulnerability information, and developer sentiment from GitHub, PyPI, and Stack Overflow. These data are structured into a decision model representing relationships among packages, domain features, and quality attributes. The framework is implemented in PySelect, a decision support system that uses large language models to interpret user intent and query the model to identify contextually appropriate packages. The approach is evaluated using 798,669 Python scripts from 16,887 GitHub repositories and a user study based on the Technology Acceptance Model. Results show high data extraction precision, improved recommendation quality over generative AI baselines, and positive user evaluations of usefulness and ease of use. This work introduces a scalable, interpretable, and reproducible framework that supports evidence-based software selection using MCDM principles, empirical data, and AI-assisted intent modeling.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "empirical",
      "evaluation",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "DMFI: Dual-Modality Fine-Tuning and Inference Framework for LLM-Based Insider Threat Detection",
    "title_es": "DMFI: Dual-Modality Fine-Tuning and Inference Framework for LLM-Based Insider Threat Detection",
    "url": "https://arxiv.org/abs/2508.05694",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05694v1 Announce Type: new \nAbstract: Insider threat detection (ITD) poses a persistent and high-impact challenge in cybersecurity due to the subtle, long-term, and context-dependent nature of malicious insider behaviors. Traditional models often struggle to capture semantic intent and complex behavior dynamics, while existing LLM-based solutions face limitations in prompt adaptability and modality coverage. To bridge this gap, we propose DMFI, a dual-modality framework that integrates semantic inference with behavior-aware fine-tuning. DMFI converts raw logs into two structured views: (1) a semantic view that processes content-rich artifacts (e.g., emails, https) using instruction-formatted prompts; and (2) a behavioral abstraction, constructed via a 4W-guided (When-Where-What-Which) transformation to encode contextual action sequences. Two LoRA-enhanced LLMs are fine-tuned independently, and their outputs are fused via a lightweight MLP-based decision module. We further introduce DMFI-B, a discriminative adaptation strategy that separates normal and abnormal behavior representations, improving robustness under severe class imbalance. Experiments on CERT r4.2 and r5.2 datasets demonstrate that DMFI outperforms state-of-the-art methods in detection accuracy. Our approach combines the semantic reasoning power of LLMs with structured behavior modeling, offering a scalable and effective solution for real-world insider threat detection. Our work demonstrates the effectiveness of combining LLM reasoning with structured behavioral modeling, offering a scalable and deployable solution for modern insider threat detection.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DMFI: Dual-Modality Fine-Tuning and Inference Framework for LLM-Based Insider Threat Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dmfi",
      "dualmodality",
      "finetuning"
    ],
    "category": "noticia"
  },
  {
    "title": "MambaITD: An Efficient Cross-Modal Mamba Network for Insider Threat Detection",
    "title_es": "MambaITD: An Efficient Cross-Modal Mamba Network for Insider Threat Detection",
    "url": "https://arxiv.org/abs/2508.05695",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05695v1 Announce Type: new \nAbstract: Enterprises are facing increasing risks of insider threats, while existing detection methods are unable to effectively address these challenges due to reasons such as insufficient temporal dynamic feature modeling, computational efficiency and real-time bottlenecks and cross-modal information island problem. This paper proposes a new insider threat detection framework MambaITD based on the Mamba state space model and cross-modal adaptive fusion. First, the multi-source log preprocessing module aligns heterogeneous data through behavioral sequence encoding, interval smoothing, and statistical feature extraction. Second, the Mamba encoder models long-range dependencies in behavioral and interval sequences, and combines the sequence and statistical information dynamically in combination with the gated feature fusion mechanism. Finally, we propose an adaptive threshold optimization method based on maximizing inter-class variance, which dynamically adjusts the decision threshold by analyzing the probability distribution, effectively identifies anomalies, and alleviates class imbalance and concept drift. Compared with traditional methods, MambaITD shows significant advantages in modeling efficiency and feature fusion capabilities, outperforming Transformer-based methods, and provides a more effective solution for insider threat detection.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MambaITD: An Efficient Cross-Modal Mamba Network for Insider Threat Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mambaitd",
      "an",
      "efficient"
    ],
    "category": "noticia"
  },
  {
    "title": "Log2Sig: Frequency-Aware Insider Threat Detection via Multivariate Behavioral Signal Decomposition",
    "title_es": "Log2Sig: Frequency-Aware Insider Threat Detection via Multivariate Behavioral Signal Decomposition",
    "url": "https://arxiv.org/abs/2508.05696",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05696v1 Announce Type: new \nAbstract: Insider threat detection presents a significant challenge due to the deceptive nature of malicious behaviors, which often resemble legitimate user operations. However, existing approaches typically model system logs as flat event sequences, thereby failing to capture the inherent frequency dynamics and multiscale disturbance patterns embedded in user behavior. To address these limitations, we propose Log2Sig, a robust anomaly detection framework that transforms user logs into multivariate behavioral frequency signals, introducing a novel representation of user behavior. Log2Sig employs Multivariate Variational Mode Decomposition (MVMD) to extract Intrinsic Mode Functions (IMFs), which reveal behavioral fluctuations across multiple temporal scales. Based on this, the model further performs joint modeling of behavioral sequences and frequency-decomposed signals: the daily behavior sequences are encoded using a Mamba-based temporal encoder to capture long-term dependencies, while the corresponding frequency components are linearly projected to match the encoder's output dimension. These dual-view representations are then fused to construct a comprehensive user behavior profile, which is fed into a multilayer perceptron for precise anomaly detection. Experimental results on the CERT r4.2 and r5.2 datasets demonstrate that Log2Sig significantly outperforms state-of-the-art baselines in both accuracy and F1 score.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Log2Sig: Frequency-Aware Insider Threat Detection via Multivariate Behavioral Signal Decomposition\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "logsig",
      "frequencyaware",
      "insider"
    ],
    "category": "noticia"
  },
  {
    "title": "Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking",
    "title_es": "Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking",
    "url": "https://arxiv.org/abs/2508.05700",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05700v1 Announce Type: new \nAbstract: Large embedding tables are indispensable in modern recommendation systems, thanks to their ability to effectively capture and memorize intricate details of interactions among diverse entities. As we explore integrating large embedding tables into Pinterest's ads ranking models, we encountered not only common challenges such as sparsity and scalability, but also several obstacles unique to our context. Notably, our initial attempts to train large embedding tables from scratch resulted in neutral metrics. To tackle this, we introduced a novel multi-faceted pretraining scheme that incorporates multiple pretraining algorithms. This approach greatly enriched the embedding tables and resulted in significant performance improvements. As a result, the multi-faceted large embedding tables bring great performance gain on both the Click-Through Rate (CTR) and Conversion Rate (CVR) domains. Moreover, we designed a CPU-GPU hybrid serving infrastructure to overcome GPU memory limits and elevate the scalability. This framework has been deployed in the Pinterest Ads system and achieved 1.34% online CPC reduction and 2.60% CTR increase with neutral end-to-end latency change.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "multifaceted",
      "large",
      "embedding"
    ],
    "category": "noticia"
  },
  {
    "title": "Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control",
    "title_es": "Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control",
    "url": "https://arxiv.org/abs/2508.05702",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05702v1 Announce Type: new \nAbstract: The increasing penetration of Distributed Energy Resources (DERs), widespread adoption of Electric Vehicles (EVs), and the growing frequency of extreme weather events have significantly increased the complexity of power grid planning, operation, and management. Traditional rule-based systems and numerical optimization approaches often struggle with the scale, dynamics, and adaptability required by modern power networks. This paper introduces Grid-Agent, an autonomous, AI-driven framework that combines Large Language Models (LLMs) with multi-agent reinforcement learning to detect and remediate grid violations in real time. Grid-Agent integrates semantic reasoning with numerical precision through a modular agent architecture: a planning agent generates coordinated action sequences using numerical power flow solvers, while a validation agent evaluates system stability and action effectiveness via sandboxed execution with safety rollbacks. To ensure scalability, Grid-Agent incorporates an adaptive multiscale network representation that dynamically selects optimal encoding schemes based on network size and complexity. The framework enables coordinated violation resolution through optimizing switch configurations, battery deployment, and load curtailment strategies. Experimental results in standard IEEE and CIGRE test systems (IEEE 69-bus, CIGRE MV, and IEEE 30-bus) demonstrate superior violation mitigation performance. Additionally, the framework's built-in data collection and learning capabilities enable continuous learning and adaptation to diverse network topologies. The autonomous nature of the framework makes it particularly suitable for modern smart grid applications requiring rapid response to dynamic operating conditions.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "semantic",
      "reasoning",
      "meets"
    ],
    "category": "noticia"
  },
  {
    "title": "System Security Framework for 5G Advanced /6G IoT Integrated Terrestrial Network-Non-Terrestrial Network (TN-NTN) with AI-Enabled Cloud Security",
    "title_es": "System Security Framework for 5G Advanced /6G IoT Integrated Terrestrial Network-Non-Terrestrial Network (TN-NTN) with AI-Enabled Cloud Security",
    "url": "https://arxiv.org/abs/2508.05707",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05707v1 Announce Type: new \nAbstract: The integration of Terrestrial Networks (TN) and Non-Terrestrial Networks (NTN), including 5G Advanced/6G and the Internet of Things (IoT) technologies, using Low Earth Orbit (LEO) satellites, high-altitude platforms (HAPS), and Unmanned Aerial Vehicles (UAVs), is redefining the landscape of global connectivity. This paper introduces a new system-level security framework for 5G Advanced/6G IoT-integrated TN-NTN architectures with AI-native-enabled cloud security. Due to the heterogeneity, scale, and distributed nature of these networks, new security challenges have emerged. Leveraging AI-native cloud platforms offers powerful capabilities for real-time threat detection, security automation, and intelligent policy enforcement. The NTN satellite access function enhances security for discontinuous coverage via satellite connections. In addition, this paper explores the security risks associated with integrated 5G Advanced/6G IoT TN-NTN systems, including full network segmentation, network slicing, and the cloudification of the RAN and core. We present a comprehensive AI-enabled cloud security framework and conclude with proposals for implementing AI-powered, satellite-based NTN within future 5G Advanced/6G IoT networks. Our approach emphasizes zero-trust principles, federated learning, secure orchestration, a layered security framework, and resilience against adversarial threats.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"System Security Framework for 5G Advanced /6G IoT Integrated Terrestrial Network-Non-Terrestrial Network (TN-NTN) with AI-Enabled Cloud Security\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "system",
      "security",
      "framework"
    ],
    "category": "noticia"
  },
  {
    "title": "G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation",
    "title_es": "G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation",
    "url": "https://arxiv.org/abs/2508.05709",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05709v1 Announce Type: new \nAbstract: User feedback is critical for refining recommendation systems, yet explicit feedback (e.g., likes or dislikes) remains scarce in practice. As a more feasible alternative, inferring user preferences from massive implicit feedback has shown great potential (e.g., a user quickly skipping a recommended video usually indicates disinterest). Unfortunately, implicit feedback is often noisy: a user might skip a video due to accidental clicks or other reasons, rather than disliking it. Such noise can easily misjudge user interests, thereby undermining recommendation performance. To address this issue, we propose a novel Group-aware User Behavior Simulation (G-UBS) paradigm, which leverages contextual guidance from relevant user groups, enabling robust and in-depth interpretation of implicit feedback for individual users. Specifically, G-UBS operates via two key agents. First, the User Group Manager (UGM) effectively clusters users to generate group profiles utilizing a ``summarize-cluster-reflect\" workflow based on LLMs. Second, the User Feedback Modeler (UFM) employs an innovative group-aware reinforcement learning approach, where each user is guided by the associated group profiles during the reinforcement learning process, allowing UFM to robustly and deeply examine the reasons behind implicit feedback. To assess our G-UBS paradigm, we have constructed a Video Recommendation benchmark with Implicit Feedback (IF-VR). To the best of our knowledge, this is the first multi-modal benchmark for implicit feedback evaluation in video recommendation, encompassing 15k users, 25k videos, and 933k interaction records with implicit feedback. Extensive experiments on IF-VR demonstrate that G-UBS significantly outperforms mainstream LLMs and MLLMs, with a 4.0% higher proportion of videos achieving a play rate > 30% and 14.9% higher reasoning accuracy on IF-VR.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "gubs",
      "towards",
      "robust"
    ],
    "category": "noticia"
  },
  {
    "title": "Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning",
    "title_es": "Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.05710",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05710v1 Announce Type: new \nAbstract: Precise, correct feedback is crucial for effectively training large language models (LLMs) in code reinforcement learning. However, synthesizing high-quality test cases remains a profoundly challenging and unsolved problem. In this work, we present Klear-CodeTest, a comprehensive test case synthesis framework featuring rigorous verification to ensure quality and reliability of test cases. Our approach achieves broad coverage of programming problems via a novel Generator-Validation (G-V) framework, ensuring correctness through a consistency validation mechanism that verifies outputs against gold solutions. The proposed G-V framework generates comprehensive test cases including both regular and corner cases, enhancing test coverage and discriminative power for solution correctness assessment in code reinforcement learning. In addition, we design a multi-layered security sandbox system optimized for online verification platforms, guaranteeing safe and reliable code execution. Through comprehensive experiments, we demonstrate the effectiveness of our curated dataset, showing significant improvements in model performance and training stability. The source codes, curated dataset and sandbox system are available at: https://github.com/Kwai-Klear/CodeTest.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "klearcodetest",
      "scalable",
      "test"
    ],
    "category": "noticia"
  },
  {
    "title": "On Digital Twins in Defence: Overview and Applications",
    "title_es": "On Digital Twins in Defence: Overview and Applications",
    "url": "https://arxiv.org/abs/2508.05717",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05717v1 Announce Type: new \nAbstract: Digital twin technology has gained increasing attention across various sectors due to its ability to create virtual replicas of physical systems, enabling real-time monitoring, optimization, and simulation. This paper explores the integration of digital twins within defence applications, focusing on key use cases ranging from system design and development, operational planning and training, to mission execution and debriefing. By examining the application of digital twin technologies across defense platforms, we highlight their key advantages such as enhanced operational performance, predictive capabilities, and increased system uptime. Additionally, we introduce a novel characterization framework for digital twins that aims to standardize and unify their application across different defence domains to facilitate interoperability. Thereafter, we discuss the main challenges, gaps and limitations in implementing and adopting digital twins within defence organizations by analyzing a combination of scientific literature, current industry practices, governmental strategies, and the findings from a comprehensive survey of industrial stakeholders and ministries of defense. Finally, we outline future research directions and development opportunities, emphasizing the need for robust frameworks and interdisciplinary collaborations to fully realize the potential of digital twins in the defence sector.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"On Digital Twins in Defence: Overview and Applications\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "on",
      "digital",
      "twins"
    ],
    "category": "noticia"
  },
  {
    "title": "PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare",
    "title_es": "PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare",
    "url": "https://arxiv.org/abs/2508.05722",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05722v1 Announce Type: new \nAbstract: This paper introduces PEACH, a sentence-aligned parallel English-Arabic corpus of healthcare texts encompassing patient information leaflets and educational materials. The corpus contains 51,671 parallel sentences, totaling approximately 590,517 English and 567,707 Arabic word tokens. Sentence lengths vary between 9.52 and 11.83 words on average. As a manually aligned corpus, PEACH is a gold-standard corpus, aiding researchers in contrastive linguistics, translation studies, and natural language processing. It can be used to derive bilingual lexicons, adapt large language models for domain-specific machine translation, evaluate user perceptions of machine translation in healthcare, assess patient information leaflets and educational materials' readability and lay-friendliness, and as an educational resource in translation studies. PEACH is publicly accessible.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "peach",
      "a",
      "sentencealigned"
    ],
    "category": "noticia"
  },
  {
    "title": "A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics",
    "title_es": "A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics",
    "url": "https://arxiv.org/abs/2508.05724",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05724v1 Announce Type: new \nAbstract: This work introduces a novel framework for representing and analyzing physical laws as a weighted knowledge graph. We constructed a database of 659 distinct physical equations, subjected to rigorous semantic cleaning to resolve notational ambiguities, resulting in a corpus of 400 advanced physics equations. We developed an enhanced graph representation where both physical concepts and equations are nodes, connected by weighted inter-equation bridges. These weights are objectively defined using normalized metrics for variable overlap, physics-informed importance scores, and bibliometric data. A Graph Attention Network (GAT) was trained for link prediction, achieving a test AUC of 0.9742 +/- 0.0018 across five independent runs, significantly outperforming both classical heuristics (best baseline AUC: 0.9487) and established GNN architectures like GraphSAGE (AUC: 0.9504, p = 0.029). Statistical testing confirmed significance of all comparisons (p < 0.05), with 2.7% improvement over the best baseline. Our analysis reveals three key findings: (i) The model autonomously rediscovers the known macroscopic structure of physics, identifying strong conceptual axes between Electromagnetism and Statistical Mechanics. (ii) It identifies central hub equations that serve as critical bridges between multiple physical domains. (iii) The model generates stable, computationally-derived hypotheses for cross-domain relationships, identifying both known principles and suggesting novel mathematical analogies for further theoretical investigation. The framework can generate hundreds of such hypotheses, enabling the creation of specialized datasets for targeted analysis of specific physics subfields. Code and data available at https://github.com/kingelanci/graphysics",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "graph",
      "neural"
    ],
    "category": "noticia"
  },
  {
    "title": "InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization",
    "title_es": "InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization",
    "url": "https://arxiv.org/abs/2508.05731",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05731v1 Announce Type: new \nAbstract: The emergence of Multimodal Large Language Models (MLLMs) has propelled the development of autonomous agents that operate on Graphical User Interfaces (GUIs) using pure visual input. A fundamental challenge is robustly grounding natural language instructions. This requires a precise spatial alignment, which accurately locates the coordinates of each element, and, more critically, a correct semantic alignment, which matches the instructions to the functionally appropriate UI element. Although Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be effective at improving spatial alignment for these MLLMs, we find that inefficient exploration bottlenecks semantic alignment, which prevent models from learning difficult semantic associations. To address this exploration problem, we present Adaptive Exploration Policy Optimization (AEPO), a new policy optimization framework. AEPO employs a multi-answer generation strategy to enforce broader exploration, which is then guided by a theoretically grounded Adaptive Exploration Reward (AER) function derived from first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B and InfiGUI-G1-7B, establish new state-of-the-art results across multiple challenging GUI grounding benchmarks, achieving significant relative improvements of up to 9.0% against the naive RLVR baseline on benchmarks designed to test generalization and semantic understanding. Resources are available at https://github.com/InfiXAI/InfiGUI-G1.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "infiguig",
      "advancing",
      "gui"
    ],
    "category": "noticia"
  },
  {
    "title": "Generalized Few-Shot Out-of-Distribution Detection",
    "title_es": "Generalized Few-Shot Out-of-Distribution Detection",
    "url": "https://arxiv.org/abs/2508.05732",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05732v1 Announce Type: new \nAbstract: Few-shot Out-of-Distribution (OOD) detection has emerged as a critical research direction in machine learning for practical deployment. Most existing Few-shot OOD detection methods suffer from insufficient generalization capability for the open world. Due to the few-shot learning paradigm, the OOD detection ability is often overfit to the limited training data itself, thus degrading the performance on generalized data and performing inconsistently across different scenarios. To address this challenge, we proposed a Generalized Few-shot OOD Detection (GOOD) framework, which empowers the general knowledge of the OOD detection model with an auxiliary General Knowledge Model (GKM), instead of directly learning from few-shot data. We proceed to reveal the few-shot OOD detection from a generalization perspective and theoretically derive the Generality-Specificity balance (GS-balance) for OOD detection, which provably reduces the upper bound of generalization error with a general knowledge model. Accordingly, we propose a Knowledge Dynamic Embedding (KDE) mechanism to adaptively modulate the guidance of general knowledge. KDE dynamically aligns the output distributions of the OOD detection model to the general knowledge model based on the Generalized Belief (G-Belief) of GKM, thereby boosting the GS-balance. Experiments on real-world OOD benchmarks demonstrate our superiority. Codes will be available.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Generalized Few-Shot Out-of-Distribution Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "generalized",
      "fewshot",
      "outofdistribution"
    ],
    "category": "noticia"
  },
  {
    "title": "Utilizing Composer Packages to Accelerate Laravel-Based Project Development Among Students: A Pedagogical and Practical Framework",
    "title_es": "Utilizing Composer Packages to Accelerate Laravel-Based Project Development Among Students: A Pedagogical and Practical Framework",
    "url": "https://arxiv.org/abs/2508.05747",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05747v1 Announce Type: new \nAbstract: Laravel has emerged as a foundational framework in university web development curricula. However, despite its scaffolding capabilities, students often struggle to complete projects within limited academic timelines. This conceptual paper introduces Composer, PHP's standard dependency manager, and categorizes a curated selection of Composer packages that significantly reduce development effort while fostering professional software practices. Grounded in practical and pedagogical considerations, the paper illustrates how educators and learners can strategically leverage these tools to build typical academic or personal Laravel-based systems. Central to this approach is maintaining code quality and reinforcing conceptual understanding. The paper also addresses potential risks such as package conflicts and over-reliance on tools, providing best-practice recommendations to mitigate them. While the goal is to accelerate development, the deeper objective is to reinforce professional workflows and industry readiness. Exposure to Composer packages enhances curriculum relevance and smooths the transition from academia to the workplace. However, effective integration requires deliberate instructional design aligned with learning objectives. Without guidance, students may treat packages as black boxes. Thus, educators must teach not only how to use these tools, but also when and why, encouraging critical evaluation of their utility and limitations. This ensures that practical convenience supports rather than supplants deep learning.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Utilizing Composer Packages to Accelerate Laravel-Based Project Development Among Students: A Pedagogical and Practical Framework\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "utilizing",
      "composer",
      "packages"
    ],
    "category": "noticia"
  },
  {
    "title": "WebWatcher: Breaking New Frontiers of Vision-Language Deep Research Agent",
    "title_es": "WebWatcher: Breaking New Frontiers of Vision-Language Deep Research Agent",
    "url": "https://arxiv.org/abs/2508.05748",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05748v1 Announce Type: new \nAbstract: Web agents such as Deep Research have demonstrated superhuman cognitive abilities, capable of solving highly challenging information-seeking problems. However, most research remains primarily text-centric, overlooking visual information in the real world. This makes multimodal Deep Research highly challenging, as such agents require much stronger reasoning abilities in perception, logic, knowledge, and the use of more sophisticated tools compared to text-based agents. To address this limitation, we introduce WebWatcher, a multi-modal Agent for Deep Research equipped with enhanced visual-language reasoning capabilities. It leverages high-quality synthetic multimodal trajectories for efficient cold start training, utilizes various tools for deep reasoning, and further enhances generalization through reinforcement learning. To better evaluate the capabilities of multimodal agents, we propose BrowseComp-VL, a benchmark with BrowseComp-style that requires complex information retrieval involving both visual and textual information. Experimental results show that WebWatcher significantly outperforms proprietary baseline, RAG workflow and open-source agents in four challenging VQA benchmarks, which paves the way for solving complex multimodal information-seeking tasks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"WebWatcher: Breaking New Frontiers of Vision-Language Deep Research Agent\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "webwatcher",
      "breaking",
      "new"
    ],
    "category": "noticia"
  },
  {
    "title": "UnGuide: Learning to Forget with LoRA-Guided Diffusion Models",
    "title_es": "UnGuide: Learning to Forget with LoRA-Guided Diffusion Models",
    "url": "https://arxiv.org/abs/2508.05755",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05755v1 Announce Type: new \nAbstract: Recent advances in large-scale text-to-image diffusion models have heightened concerns about their potential misuse, especially in generating harmful or misleading content. This underscores the urgent need for effective machine unlearning, i.e., removing specific knowledge or concepts from pretrained models without compromising overall performance. One possible approach is Low-Rank Adaptation (LoRA), which offers an efficient means to fine-tune models for targeted unlearning. However, LoRA often inadvertently alters unrelated content, leading to diminished image fidelity and realism. To address this limitation, we introduce UnGuide -- a novel approach which incorporates UnGuidance, a dynamic inference mechanism that leverages Classifier-Free Guidance (CFG) to exert precise control over the unlearning process. UnGuide modulates the guidance scale based on the stability of a few first steps of denoising processes, enabling selective unlearning by LoRA adapter. For prompts containing the erased concept, the LoRA module predominates and is counterbalanced by the base model; for unrelated prompts, the base model governs generation, preserving content fidelity. Empirical results demonstrate that UnGuide achieves controlled concept removal and retains the expressive power of diffusion models, outperforming existing LoRA-based methods in both object erasure and explicit content removal tasks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"UnGuide: Learning to Forget with LoRA-Guided Diffusion Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "unguide",
      "learning",
      "to"
    ],
    "category": "noticia"
  },
  {
    "title": "A Framework for Inherently Safer AGI through Language-Mediated Active Inference",
    "title_es": "A Framework for Inherently Safer AGI through Language-Mediated Active Inference",
    "url": "https://arxiv.org/abs/2508.05766",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05766v1 Announce Type: new \nAbstract: This paper proposes a novel framework for developing safe Artificial General Intelligence (AGI) by combining Active Inference principles with Large Language Models (LLMs). We argue that traditional approaches to AI safety, focused on post-hoc interpretability and reward engineering, have fundamental limitations. We present an architecture where safety guarantees are integrated into the system's core design through transparent belief representations and hierarchical value alignment. Our framework leverages natural language as a medium for representing and manipulating beliefs, enabling direct human oversight while maintaining computational tractability. The architecture implements a multi-agent system where agents self-organize according to Active Inference principles, with preferences and safety constraints flowing through hierarchical Markov blankets. We outline specific mechanisms for ensuring safety, including: (1) explicit separation of beliefs and preferences in natural language, (2) bounded rationality through resource-aware free energy minimization, and (3) compositional safety through modular agent structures. The paper concludes with a research agenda centered on the Abstraction and Reasoning Corpus (ARC) benchmark, proposing experiments to validate our framework's safety properties. Our approach offers a path toward AGI development that is inherently safer, rather than retrofitted with safety measures.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Framework for Inherently Safer AGI through Language-Mediated Active Inference\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "framework",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Improving Masked Style Transfer using Blended Partial Convolution",
    "title_es": "Improving Masked Style Transfer using Blended Partial Convolution",
    "url": "https://arxiv.org/abs/2508.05769",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05769v1 Announce Type: new \nAbstract: Artistic style transfer has long been possible with the advancements of convolution- and transformer-based neural networks. Most algorithms apply the artistic style transfer to the whole image, but individual users may only need to apply a style transfer to a specific region in the image. The standard practice is to simply mask the image after the stylization. This work shows that this approach tends to improperly capture the style features in the region of interest. We propose a partial-convolution-based style transfer network that accurately applies the style features exclusively to the region of interest. Additionally, we present network-internal blending techniques that account for imperfections in the region selection. We show that this visually and quantitatively improves stylization using examples from the SA-1B dataset. Code is publicly available at https://github.com/davidmhart/StyleTransferMasked.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Improving Masked Style Transfer using Blended Partial Convolution\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "improving",
      "masked",
      "style"
    ],
    "category": "noticia"
  },
  {
    "title": "MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss",
    "title_es": "MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss",
    "url": "https://arxiv.org/abs/2508.05772",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05772v1 Announce Type: new \nAbstract: Medical image synthesis is an important topic for both clinical and research applications. Recently, diffusion models have become a leading approach in this area. Despite their strengths, many existing methods struggle with (1) limited generalizability that only work for specific body regions or voxel spacings, (2) slow inference, which is a common issue for diffusion models, and (3) weak alignment with input conditions, which is a critical issue for medical imaging. MAISI, a previously proposed framework, addresses generalizability issues but still suffers from slow inference and limited condition consistency. In this work, we present MAISI-v2, the first accelerated 3D medical image synthesis framework that integrates rectified flow to enable fast and high quality generation. To further enhance condition fidelity, we introduce a novel region-specific contrastive loss to enhance the sensitivity to region of interest. Our experiments show that MAISI-v2 can achieve SOTA image quality with $33 \\times$ acceleration for latent diffusion model. We also conducted a downstream segmentation experiment to show that the synthetic images can be used for data augmentation. We release our code, training details, model weights, and a GUI demo to facilitate reproducibility and promote further development within the community.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "maisiv",
      "accelerated",
      "d"
    ],
    "category": "noticia"
  },
  {
    "title": "GPU-Accelerated Barrier-Rate Guided MPPI Control for Tractor-Trailer Systems",
    "title_es": "GPU-Accelerated Barrier-Rate Guided MPPI Control for Tractor-Trailer Systems",
    "url": "https://arxiv.org/abs/2508.05773",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05773v1 Announce Type: new \nAbstract: Articulated vehicles such as tractor-trailers, yard trucks, and similar platforms must often reverse and maneuver in cluttered spaces where pedestrians are present. We present how Barrier-Rate guided Model Predictive Path Integral (BR-MPPI) control can solve navigation in such challenging environments. BR-MPPI embeds Control Barrier Function (CBF) constraints directly into the path-integral update. By steering the importance-sampling distribution toward collision-free, dynamically feasible trajectories, BR-MPPI enhances the exploration strength of MPPI and improves robustness of resulting trajectories. The method is evaluated in the high-fidelity CarMaker simulator on a 12 [m] tractor-trailer tasked with reverse and forward parking in a parking lot. BR-MPPI computes control inputs in above 100 [Hz] on a single GPU (for scenarios with eight obstacles) and maintains better parking clearance than a standard MPPI baseline and an MPPI with collision cost baseline.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"GPU-Accelerated Barrier-Rate Guided MPPI Control for Tractor-Trailer Systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "gpuaccelerated",
      "barrierrate",
      "guided"
    ],
    "category": "noticia"
  },
  {
    "title": "Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation",
    "title_es": "Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation",
    "url": "https://arxiv.org/abs/2508.05775",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05775v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have revolutionized content creation across digital platforms, offering unprecedented capabilities in natural language generation and understanding. These models enable beneficial applications such as content generation, question and answering (Q&A), programming, and code reasoning. Meanwhile, they also pose serious risks by inadvertently or intentionally producing toxic, offensive, or biased content. This dual role of LLMs, both as powerful tools for solving real-world problems and as potential sources of harmful language, presents a pressing sociotechnical challenge. In this survey, we systematically review recent studies spanning unintentional toxicity, adversarial jailbreaking attacks, and content moderation techniques. We propose a unified taxonomy of LLM-related harms and defenses, analyze emerging multimodal and LLM-assisted jailbreak strategies, and assess mitigation efforts, including reinforcement learning with human feedback (RLHF), prompt engineering, and safety alignment. Our synthesis highlights the evolving landscape of LLM safety, identifies limitations in current evaluation methodologies, and outlines future research directions to guide the development of robust and ethically aligned language technologies.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "guardians",
      "and",
      "offenders"
    ],
    "category": "noticia"
  },
  {
    "title": "Whither symbols in the era of advanced neural networks?",
    "title_es": "Whither symbols in the era of advanced neural networks?",
    "url": "https://arxiv.org/abs/2508.05776",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05776v1 Announce Type: new \nAbstract: Some of the strongest evidence that human minds should be thought about in terms of symbolic systems has been the way they combine ideas, produce novelty, and learn quickly. We argue that modern neural networks -- and the artificial intelligence systems built upon them -- exhibit similar abilities. This undermines the argument that the cognitive processes and representations used by human minds are symbolic, although the fact that these neural networks are typically trained on data generated by symbolic systems illustrates that such systems play an important role in characterizing the abstract problems that human minds have to solve. This argument leads us to offer a new agenda for research on the symbolic basis of human thought.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Whither symbols in the era of advanced neural networks?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "whither",
      "symbols",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems",
    "title_es": "Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems",
    "url": "https://arxiv.org/abs/2508.05778",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05778v1 Announce Type: new \nAbstract: Nudging is an empirical data assimilation technique that incorporates an observation-driven control term into the model dynamics. The trajectory of the nudged system approaches the true system trajectory over time, even when the initial conditions differ. For linear state space models, such control terms can be derived under mild assumptions. However, designing effective nudging terms becomes significantly more challenging in the nonlinear setting. In this work, we propose neural network nudging, a data-driven method for learning nudging terms in nonlinear state space models. We establish a theoretical existence result based on the Kazantzis--Kravaris--Luenberger observer theory. The proposed approach is evaluated on three benchmark problems that exhibit chaotic behavior: the Lorenz 96 model, the Kuramoto--Sivashinsky equation, and the Kolmogorov flow.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "machine",
      "learningbased",
      "nonlinear"
    ],
    "category": "noticia"
  },
  {
    "title": "ConiQ: Enabling Concatenated Quantum Error Correction on Neutral Atom Arrays",
    "title_es": "ConiQ: Enabling Concatenated Quantum Error Correction on Neutral Atom Arrays",
    "url": "https://arxiv.org/abs/2508.05779",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05779v1 Announce Type: new \nAbstract: Recent progress on concatenated codes, especially many-hypercube codes, achieves unprecedented space efficiency. Yet two critical challenges persist in practice. First, these codes lack efficient implementations of addressable logical gates. Second, the required high degree of parallelism and long-range interactions pose significant challenges for current hardware platforms. In this paper, we propose an efficient compilation approach for concatenated codes, specifically many-hypercube codes, targeted at neutral atom arrays, which provide the necessary parallelism and long-range interactions. Our approach builds on two key innovations. First, we introduce Automorphism-assisted Hierarchical Addressing (AHA) logical CNOT gates that significantly reduce spacetime overhead compared to conventional distillation-based methods. Second, we develop Virtual Atom Intermediate Representation (VAIR) that enables level-wise optimization and legalization. We implement these innovations in ConiQ, a hardware-aware quantum compiler designed to compile fault-tolerant quantum circuits for neutral atom arrays using many-hypercube codes. Our evaluation demonstrates that ConiQ achieves up to 2000x reduction in spacetime overhead and up to 10^6x reduction in compilation time compared to state-of-the-art compilers, with our AHA gates providing an additional overhead reduction of up to 20x. These results establish concatenated codes as a promising approach for fault-tolerant quantum computing in the near future.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ConiQ: Enabling Concatenated Quantum Error Correction on Neutral Atom Arrays\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "coniq",
      "enabling",
      "concatenated"
    ],
    "category": "noticia"
  },
  {
    "title": "FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification",
    "title_es": "FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification",
    "url": "https://arxiv.org/abs/2508.05782",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05782v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are known to produce hallucinations - factually incorrect or fabricated information - which poses significant challenges for many Natural Language Processing (NLP) applications, such as dialogue systems. As a result, detecting hallucinations has become a critical area of research. Current approaches to hallucination detection in dialogue systems primarily focus on verifying the factual consistency of generated responses. However, these responses often contain a mix of accurate, inaccurate or unverifiable facts, making one factual label overly simplistic and coarse-grained. In this paper, we introduce a benchmark, FineDialFact, for fine-grained dialogue fact verification, which involves verifying atomic facts extracted from dialogue responses. To support this, we construct a dataset based on publicly available dialogue datasets and evaluate it using various baseline methods. Experimental results demonstrate that methods incorporating Chain-of-Thought (CoT) reasoning can enhance performance in dialogue fact verification. Despite this, the best F1-score achieved on the HybriDialogue, an open-domain dialogue dataset, is only 0.75, indicating that the benchmark remains a challenging task for future research. Our dataset and code will be public on GitHub.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "finedialfact",
      "a",
      "benchmark"
    ],
    "category": "noticia"
  },
  {
    "title": "Few-Shot Deployment of Pretrained MRI Transformers in Brain Imaging Tasks",
    "title_es": "Few-Shot Deployment of Pretrained MRI Transformers in Brain Imaging Tasks",
    "url": "https://arxiv.org/abs/2508.05783",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05783v1 Announce Type: new \nAbstract: Machine learning using transformers has shown great potential in medical imaging, but its real-world applicability remains limited due to the scarcity of annotated data. In this study, we propose a practical framework for the few-shot deployment of pretrained MRI transformers in diverse brain imaging tasks. By utilizing the Masked Autoencoder (MAE) pretraining strategy on a large-scale, multi-cohort brain MRI dataset comprising over 31 million slices, we obtain highly transferable latent representations that generalize well across tasks and datasets. For high-level tasks such as classification, a frozen MAE encoder combined with a lightweight linear head achieves state-of-the-art accuracy in MRI sequence identification with minimal supervision. For low-level tasks such as segmentation, we propose MAE-FUnet, a hybrid architecture that fuses multiscale CNN features with pretrained MAE embeddings. This model consistently outperforms other strong baselines in both skull stripping and multi-class anatomical segmentation under data-limited conditions. With extensive quantitative and qualitative evaluations, our framework demonstrates efficiency, stability, and scalability, suggesting its suitability for low-resource clinical environments and broader neuroimaging applications.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Few-Shot Deployment of Pretrained MRI Transformers in Brain Imaging Tasks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fewshot",
      "deployment",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Functional Connectivity Graph Neural Networks",
    "title_es": "Functional Connectivity Graph Neural Networks",
    "url": "https://arxiv.org/abs/2508.05786",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05786v1 Announce Type: new \nAbstract: Real-world networks often benefit from capturing both local and global interactions. Inspired by multi-modal analysis in brain imaging, where structural and functional connectivity offer complementary views of network organization, we propose a graph neural network framework that generalizes this approach to other domains. Our method introduces a functional connectivity block based on persistent graph homology to capture global topological features. Combined with structural information, this forms a multi-modal architecture called Functional Connectivity Graph Neural Networks. Experiments show consistent performance gains over existing methods, demonstrating the value of brain-inspired representations for graph-level classification across diverse networks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Functional Connectivity Graph Neural Networks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "functional",
      "connectivity",
      "graph"
    ],
    "category": "noticia"
  },
  {
    "title": "From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data",
    "title_es": "From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data",
    "url": "https://arxiv.org/abs/2508.05791",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05791v1 Announce Type: new \nAbstract: Accurate distribution grid topology is essential for reliable modern grid operations. However, real-world utility data originates from multiple sources with varying characteristics and levels of quality. In this work, developed in collaboration with Oncor Electric Delivery, we propose a scalable framework that reconstructs a trustworthy grid topology by systematically integrating heterogeneous data. We observe that distribution topology is fundamentally governed by two complementary dimensions: the spatial layout of physical infrastructure (e.g., GIS and asset metadata) and the dynamic behavior of the system in the signal domain (e.g., voltage time series). When jointly leveraged, these dimensions support a complete and physically coherent reconstruction of network connectivity. To address the challenge of uneven data quality without compromising observability, we introduce a confidence-aware inference mechanism that preserves structurally informative yet imperfect inputs, while quantifying the reliability of each inferred connection for operator interpretation. This soft handling of uncertainty is tightly coupled with hard enforcement of physical feasibility: we embed operational constraints, such as transformer capacity limits and radial topology requirements, directly into the learning process. Together, these components ensure that inference is both uncertainty-aware and structurally valid, enabling rapid convergence to actionable, trustworthy topologies under real-world deployment conditions. The proposed framework is validated using data from over 8000 meters across 3 feeders in Oncor's service territory, demonstrating over 95% accuracy in topology reconstruction and substantial improvements in confidence calibration and computational efficiency relative to baseline methods.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "from",
      "imperfect",
      "signals"
    ],
    "category": "noticia"
  },
  {
    "title": "Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making",
    "title_es": "Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making",
    "url": "https://arxiv.org/abs/2508.05792",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05792v1 Announce Type: new \nAbstract: Current eXplainable AI (XAI) methods largely serve developers, often focusing on justifying model outputs rather than supporting diverse stakeholder needs. A recent shift toward Evaluative AI reframes explanation as a tool for hypothesis testing, but still focuses primarily on operational organizations. We introduce Holistic-XAI (H-XAI), a unified framework that integrates causal rating methods with traditional XAI methods to support explanation as an interactive, multi-method process. H-XAI allows stakeholders to ask a series of questions, test hypotheses, and compare model behavior against automatically constructed random and biased baselines. It combines instance-level and global explanations, adapting to each stakeholder's goals, whether understanding individual decisions, assessing group-level bias, or evaluating robustness under perturbations. We demonstrate the generality of our approach through two case studies spanning six scenarios: binary credit risk classification and financial time-series forecasting. H-XAI fills critical gaps left by existing XAI methods by combining causal ratings and post-hoc explanations to answer stakeholder-specific questions at both the individual decision level and the overall model level.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "holistic",
      "explainable",
      "ai"
    ],
    "category": "noticia"
  },
  {
    "title": "On the Choice of Subspace for the Quasi-minimal Residual Method for Linear Inverse Problems",
    "title_es": "On the Choice of Subspace for the Quasi-minimal Residual Method for Linear Inverse Problems",
    "url": "https://arxiv.org/abs/2508.05793",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05793v1 Announce Type: new \nAbstract: Inverse problems arise in various scientific and engineering applications, necessitating robust numerical methods for their solution. In this work, we consider the effectiveness of Krylov subspace iterative methods, including GMRES, QMR, and their range restricted variants for solving linear discrete ill-posed problems. We analyze the impact of subspace selection on solution quality. Our findings indicate that range restricted QMR can outperform standard QMR, and confirm the previously observed behavior that range restricted GMRES can be superior to conventional GMRES in terms of approximation efficacy. Notably, range restricted QMR demonstrates a key advantage over GMRES with respect to range restricted QMR's singular spectrum which can make the method less sensitive to errors that are naturally present making it particularly effective when the noise level in the problem is uncertain.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"On the Choice of Subspace for the Quasi-minimal Residual Method for Linear Inverse Problems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "on",
      "the",
      "choice"
    ],
    "category": "noticia"
  },
  {
    "title": "Accelerating Data Chunking in Deduplication Systems using Vector Instructions",
    "title_es": "Accelerating Data Chunking in Deduplication Systems using Vector Instructions",
    "url": "https://arxiv.org/abs/2508.05797",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05797v1 Announce Type: new \nAbstract: Content-defined Chunking (CDC) algorithms dictate the overall space savings that deduplication systems achieve. However, due to their need to scan each file in its entirety, they are slow and often the main performance bottleneck within data deduplication. We present VectorCDC, a method to accelerate hashless CDC algorithms using vector CPU instructions, such as SSE / AVX. Our evaluation shows that VectorCDC is effective on Intel, AMD, ARM, and IBM CPUs, achieving 8.35x - 26.2x higher throughput than existing vector-accelerated techniques without affecting the deduplication space savings.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Accelerating Data Chunking in Deduplication Systems using Vector Instructions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "accelerating",
      "data",
      "chunking"
    ],
    "category": "noticia"
  },
  {
    "title": "Basic interactive algorithms: Preview",
    "title_es": "Basic interactive algorithms: Preview",
    "url": "https://arxiv.org/abs/2508.05798",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05798v1 Announce Type: new \nAbstract: This dialog paper offers a preview and provides a foretaste of an upcoming work on the axiomatization of basic interactive algorithms.\n  The modern notion of algorithm was elucidated in the 1930s--1950s. It was axiomatized a quarter of a century ago as the notion of ``sequential algorithm'' or ``classical algorithm''; we prefer to call it ``basic algorithm\" now. The axiomatization was used to show that for every basic algorithm there is a behaviorally equivalent abstract state machine. It was also used to prove the Church-Turing thesis as it has been understood by the logicians.\n  Starting from the 1960s, the notion of algorithm has expanded -- probabilistic algorithms, quantum algorithms, etc. -- prompting introduction of a much more ambitious version of the Church-Turing thesis commonly known as the ``physical thesis.'' We emphasize the difference between the two versions of the Church-Turing thesis and illustrate how nondeterministic and probabilistic algorithms can be viewed as basic algorithms with appropriate oracles. The same view applies to quantum circuit algorithms and many other classes of algorithms.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Basic interactive algorithms: Preview\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "basic",
      "interactive",
      "algorithms"
    ],
    "category": "noticia"
  },
  {
    "title": "AI-Guided Exploration of Large-Scale Codebases",
    "title_es": "AI-Guided Exploration of Large-Scale Codebases",
    "url": "https://arxiv.org/abs/2508.05799",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05799v1 Announce Type: new \nAbstract: Understanding large-scale, complex software systems is a major challenge for developers, who spend a significant portion of their time on program comprehension. Traditional tools such as static visualizations and reverse engineering techniques provide structural insights but often lack interactivity, adaptability, and integration with contextual information. Recent advancements in large language models (LLMs) offer new opportunities to enhance code exploration workflows, yet their lack of grounding and integration with structured views limits their effectiveness. This work introduces a hybrid approach that integrates deterministic reverse engineering with LLM-guided, intent-aware visual exploration. The proposed system combines UML-based visualization, dynamic user interfaces, historical context, and collaborative features into an adaptive tool for code comprehension. By interpreting user queries and interaction patterns, the LLM helps developers navigate and understand complex codebases more effectively. A prototype implementation for Java demonstrates the feasibility of this approach. Future work includes empirical evaluation, scaling to polyglot systems, and exploring GUI-driven LLM interaction models. This research lays the groundwork for intelligent, interactive environments that align with developer cognition and collaborative workflows.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AI-Guided Exploration of Large-Scale Codebases\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "aiguided",
      "exploration",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models",
    "title_es": "Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models",
    "url": "https://arxiv.org/abs/2508.05803",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05803v1 Announce Type: new \nAbstract: Human memory is fleeting. As words are processed, the exact wordforms that make up incoming sentences are rapidly lost. Cognitive scientists have long believed that this limitation of memory may, paradoxically, help in learning language - an idea supported by classic connectionist modelling work. The rise of Transformers appears to challenge this idea, as these models can learn language effectively, despite lacking memory limitations or other architectural recency biases. Here, we investigate the hypothesized benefit of fleeting memory for language learning in tightly controlled experiments on transformer language models. Training transformers with and without fleeting memory on a developmentally realistic training set, we find that fleeting memory consistently improves language learning (as quantified by both overall language modelling performance and targeted syntactic evaluation) but, unexpectedly, impairs surprisal-based prediction of human reading times. Interestingly, follow up analyses revealed that this discrepancy - better language modeling, yet worse reading time prediction - could not be accounted for by prior explanations of why better language models sometimes fit human reading time worse. Together, these results support a benefit of memory limitations on neural network language learning - but not on predicting behavior.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "humanlike",
      "fleeting",
      "memory"
    ],
    "category": "noticia"
  },
  {
    "title": "Optimization-Free Style Transfer for 3D Gaussian Splats",
    "title_es": "Optimization-Free Style Transfer for 3D Gaussian Splats",
    "url": "https://arxiv.org/abs/2508.05813",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05813v1 Announce Type: new \nAbstract: The task of style transfer for 3D Gaussian splats has been explored in many previous works, but these require reconstructing or fine-tuning the splat while incorporating style information or optimizing a feature extraction network on the splat representation. We propose a reconstruction- and optimization-free approach to stylizing 3D Gaussian splats. This is done by generating a graph structure across the implicit surface of the splat representation. A feed-forward, surface-based stylization method is then used and interpolated back to the individual splats in the scene. This allows for any style image and 3D Gaussian splat to be used without any additional training or optimization. This also allows for fast stylization of splats, achieving speeds under 2 minutes even on consumer-grade hardware. We demonstrate the quality results this approach achieves and compare to other 3D Gaussian splat style transfer methods. Code is publicly available at https://github.com/davidmhart/FastSplatStyler.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Optimization-Free Style Transfer for 3D Gaussian Splats\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "optimizationfree",
      "style",
      "transfer"
    ],
    "category": "noticia"
  },
  {
    "title": "MZEN: Multi-Zoom Enhanced NeRF for 3-D Reconstruction with Unknown Camera Poses",
    "title_es": "MZEN: Multi-Zoom Enhanced NeRF for 3-D Reconstruction with Unknown Camera Poses",
    "url": "https://arxiv.org/abs/2508.05819",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05819v1 Announce Type: new \nAbstract: Neural Radiance Fields (NeRF) methods excel at 3D reconstruction from multiple 2D images, even those taken with unknown camera poses. However, they still miss the fine-detailed structures that matter in industrial inspection, e.g., detecting sub-micron defects on a production line or analyzing chips with Scanning Electron Microscopy (SEM). In these scenarios, the sensor resolution is fixed and compute budgets are tight, so the only way to expose fine structure is to add zoom-in images; yet, this breaks the multi-view consistency that pose-free NeRF training relies on. We propose Multi-Zoom Enhanced NeRF (MZEN), the first NeRF framework that natively handles multi-zoom image sets. MZEN (i) augments the pin-hole camera model with an explicit, learnable zoom scalar that scales the focal length, and (ii) introduces a novel pose strategy: wide-field images are solved first to establish a global metric frame, and zoom-in images are then pose-primed to the nearest wide-field counterpart via a zoom-consistent crop-and-match procedure before joint refinement. Across eight forward-facing scenes$\\unicode{x2013}$synthetic TCAD models, real SEM of micro-structures, and BLEFF objects$\\unicode{x2013}$MZEN consistently outperforms pose-free baselines and even high-resolution variants, boosting PSNR by up to $28 \\%$, SSIM by $10 \\%$, and reducing LPIPS by up to $222 \\%$. MZEN, therefore, extends NeRF to real-world factory settings, preserving global accuracy while capturing the micron-level details essential for industrial inspection.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MZEN: Multi-Zoom Enhanced NeRF for 3-D Reconstruction with Unknown Camera Poses\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mzen",
      "multizoom",
      "enhanced"
    ],
    "category": "noticia"
  },
  {
    "title": "A Dynamic Approach to Load Balancing in Cloud Infrastructure: Enhancing Energy Efficiency and Resource Utilization",
    "title_es": "A Dynamic Approach to Load Balancing in Cloud Infrastructure: Enhancing Energy Efficiency and Resource Utilization",
    "url": "https://arxiv.org/abs/2508.05821",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05821v1 Announce Type: new \nAbstract: Cloud computing has grown rapidly in recent years, mainly due to the sharp increase in data transferred over the internet. This growth makes load balancing a key part of cloud systems, as it helps distribute user requests across servers to maintain performance, prevent overload, and ensure a smooth user experience. Despite its importance, managing server resources and keeping workloads balanced over time remains a major challenge in cloud environments. This paper introduces a novel Score-Based Dynamic Load Balancer (SBDLB) that allocates workloads to virtual machines based on real-time performance metrics. The objective is to enhance resource utilization and overall system efficiency. The method was thoroughly tested using the CloudSim 7G platform, comparing its performance against the throttled load balancing strategy. Evaluations were conducted across a variety of workloads and scenarios, demonstrating the SBDLB's ability to adapt dynamically to workload fluctuations while optimizing resource usage. The proposed method outperformed the throttled strategy, improving average response times by 34% and 37% in different scenarios. It also reduced data center processing times by an average of 13%. Over a 24-hour simulation, the method decreased operational costs by 15%, promoting a more energy-efficient and sustainable cloud infrastructure through reduced energy consumption.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Dynamic Approach to Load Balancing in Cloud Infrastructure: Enhancing Energy Efficiency and Resource Utilization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "dynamic",
      "approach"
    ],
    "category": "noticia"
  },
  {
    "title": "A United Framework for Planning Electric Vehicle Charging Accessibility",
    "title_es": "A United Framework for Planning Electric Vehicle Charging Accessibility",
    "url": "https://arxiv.org/abs/2508.05827",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05827v1 Announce Type: new \nAbstract: The shift towards electric vehicles (EVs) is crucial for establishing sustainable and low-emission urban transportation systems. However, the success of this transition depends on the strategic placement of the charging infrastructure. This paper addresses the challenge of optimizing charging station locations in dense urban environments while balancing efficiency with spatial accessibility. We propose an optimization framework that integrates traffic simulation, energy consumption modeling, and a mobility equity measure to evaluate the social reach of each potential charging station. Using New York City as a case study, we demonstrate consistent improvements in accessibility (15-20% reduction in travel time variability). Our results provide a scalable methodology for incorporating equity considerations into EV infrastructure planning, although economic factors and grid integration remain important areas for future development.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A United Framework for Planning Electric Vehicle Charging Accessibility\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "united",
      "framework"
    ],
    "category": "noticia"
  },
  {
    "title": "TSMS-SAM2: Multi-scale Temporal Sampling Augmentation and Memory-Splitting Pruning for Promptable Video Object Segmentation and Tracking in Surgical Scenarios",
    "title_es": "TSMS-SAM2: Multi-scale Temporal Sampling Augmentation and Memory-Splitting Pruning for Promptable Video Object Segmentation and Tracking in Surgical Scenarios",
    "url": "https://arxiv.org/abs/2508.05829",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05829v1 Announce Type: new \nAbstract: Promptable video object segmentation and tracking (VOST) has seen significant advances with the emergence of foundation models like Segment Anything Model 2 (SAM2); however, their application in surgical video analysis remains challenging due to complex motion dynamics and the redundancy of memory that impedes effective learning. In this work, we propose TSMS-SAM2, a novel framework that enhances promptable VOST in surgical videos by addressing challenges of rapid object motion and memory redundancy in SAM2. TSMS-SAM2 introduces two key strategies: multi-temporal-scale video sampling augmentation to improve robustness against motion variability, and a memory splitting and pruning mechanism that organizes and filters past frame features for more efficient and accurate segmentation. Evaluated on EndoVis2017 and EndoVis2018 datasets, TSMS-SAM2 achieved the highest mean Dice scores of 95.24 and 86.73, respectively, outperforming prior SAM-based and task-specific methods. Extensive ablation studies confirm the effectiveness of multiscale temporal augmentation and memory splitting, highlighting the framework's potential for robust, efficient segmentation in complex surgical scenarios. Our source code will be available at https://github.com/apple1986/TSMS-SAM2.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"TSMS-SAM2: Multi-scale Temporal Sampling Augmentation and Memory-Splitting Pruning for Promptable Video Object Segmentation and Tracking in Surgical Scenarios\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "tsmssam",
      "multiscale",
      "temporal"
    ],
    "category": "noticia"
  },
  {
    "title": "\"Mirror\" Language AI Models of Depression are Criterion-Contaminated",
    "title_es": "\"Mirror\" Language AI Models of Depression are Criterion-Contaminated",
    "url": "https://arxiv.org/abs/2508.05830",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05830v1 Announce Type: new \nAbstract: A growing number of studies show near-perfect LLM language-based prediction of depression assessment scores (up to R2 of .70). However, many develop these models directly from language responses to depression assessments. These \"Mirror models\" suffer from \"criterion contamination\", which arises when a predicted score depends in part on the predictors themselves. This causes artificial effect size inflation which reduces model generalizability. The present study compares the performance of Mirror models versus \"Non-Mirror models\", which are developed from language that does not mirror the assessment they are developed to predict. N = 110 research participants completed two different interviews: structured diagnostic and life history interviews. GPT-4, GPT-4o and LLaMA3-70B were then prompted to predict structured diagnostic interview depression scores from the two transcripts separately. Mirror models (using structured diagnostic data) showed very large effect sizes (e.g., R2 = .80). As expected, NonMirror models (using life history data) demonstrated smaller effect sizes, but were relatively large (e.g., R2 = .27). When Mirror and Non-Mirror model-predicted structured interview depression scores were correlated with self-reported depression symptoms, Mirror and NonMirror performed the same (e.g., r = ~.54), indicating that Mirror models contain bias perhaps due to criterion contamination. Topic modeling identified clusters across Mirror and Non-Mirror models, as well as between true-positive and false-positive predictions. In this head-to-head comparison study, Mirror language AI models of depression showed artificially inflated effect sizes and less generalizability. As language AI models for depression continue to evolve, incorporating Non-Mirror models may identify interpretable, and generalizable semantic features that have unique utility in real-world psychological assessment.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"\"Mirror\" Language AI Models of Depression are Criterion-Contaminated\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mirror",
      "language",
      "ai"
    ],
    "category": "noticia"
  },
  {
    "title": "Optimal Linear Baseline Models for Scientific Machine Learning",
    "title_es": "Optimal Linear Baseline Models for Scientific Machine Learning",
    "url": "https://arxiv.org/abs/2508.05831",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05831v1 Announce Type: new \nAbstract: Across scientific domains, a fundamental challenge is to characterize and compute the mappings from underlying physical processes to observed signals and measurements. While nonlinear neural networks have achieved considerable success, they remain theoretically opaque, which hinders adoption in contexts where interpretability is paramount. In contrast, linear neural networks serve as a simple yet effective foundation for gaining insight into these complex relationships. In this work, we develop a unified theoretical framework for analyzing linear encoder-decoder architectures through the lens of Bayes risk minimization for solving data-driven scientific machine learning problems. We derive closed-form, rank-constrained linear and affine linear optimal mappings for forward modeling and inverse recovery tasks. Our results generalize existing formulations by accommodating rank-deficiencies in data, forward operators, and measurement processes. We validate our theoretical results by conducting numerical experiments on datasets from simple biomedical imaging, financial factor analysis, and simulations involving nonlinear fluid dynamics via the shallow water equations. This work provides a robust baseline for understanding and benchmarking learned neural network models for scientific machine learning problems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Optimal Linear Baseline Models for Scientific Machine Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "optimal",
      "linear",
      "baseline"
    ],
    "category": "noticia"
  },
  {
    "title": "An Effective Approach for Node Classification in Textual Graphs",
    "title_es": "An Effective Approach for Node Classification in Textual Graphs",
    "url": "https://arxiv.org/abs/2508.05836",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05836v1 Announce Type: new \nAbstract: Textual Attribute Graphs (TAGs) are critical for modeling complex networks like citation networks, but effective node classification remains challenging due to difficulties in integrating rich semantics from text with structural graph information. Existing methods often struggle with capturing nuanced domain-specific terminology, modeling long-range dependencies, adapting to temporal evolution, and scaling to massive datasets. To address these issues, we propose a novel framework that integrates TAPE (Text-Attributed Graph Representation Enhancement) with Graphormer. Our approach leverages a large language model (LLM), specifically ChatGPT, within the TAPE framework to generate semantically rich explanations from paper content, which are then fused into enhanced node representations. These embeddings are combined with structural features using a novel integration layer with learned attention weights. Graphormer's path-aware position encoding and multi-head attention mechanisms are employed to effectively capture long-range dependencies across the citation network. We demonstrate the efficacy of our framework on the challenging ogbn-arxiv dataset, achieving state-of-the-art performance with a classification accuracy of 0.772, significantly surpassing the best GCN baseline of 0.713. Our method also yields strong results in precision (0.671), recall (0.577), and F1-score (0.610). We validate our approach through comprehensive ablation studies that quantify the contribution of each component, demonstrating the synergy between semantic and structural information. Our framework provides a scalable and robust solution for node classification in dynamic TAGs, offering a promising direction for future research in knowledge systems and scientific discovery.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"An Effective Approach for Node Classification in Textual Graphs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "an",
      "effective",
      "approach"
    ],
    "category": "noticia"
  },
  {
    "title": "Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction",
    "title_es": "Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction",
    "url": "https://arxiv.org/abs/2508.05838",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05838v1 Announce Type: new \nAbstract: This paper presents a novel approach that integrates vision foundation models with reinforcement learning to enhance object interaction capabilities in simulated environments. By combining the Segment Anything Model (SAM) and YOLOv5 with a Proximal Policy Optimization (PPO) agent operating in the AI2-THOR simulation environment, we enable the agent to perceive and interact with objects more effectively. Our comprehensive experiments, conducted across four diverse indoor kitchen settings, demonstrate significant improvements in object interaction success rates and navigation efficiency compared to a baseline agent without advanced perception. The results show a 68% increase in average cumulative reward, a 52.5% improvement in object interaction success rate, and a 33% increase in navigation efficiency. These findings highlight the potential of integrating foundation models with reinforcement learning for complex robotic tasks, paving the way for more sophisticated and capable autonomous agents.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "integrating",
      "vision",
      "foundation"
    ],
    "category": "noticia"
  },
  {
    "title": "Discovering Properties of Inflectional Morphology in Neural Emergent Communication",
    "title_es": "Discovering Properties of Inflectional Morphology in Neural Emergent Communication",
    "url": "https://arxiv.org/abs/2508.05843",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05843v1 Announce Type: new \nAbstract: Emergent communication (EmCom) with deep neural network-based agents promises to yield insights into the nature of human language, but remains focused primarily on a few subfield-specific goals and metrics that prioritize communication schemes which represent attributes with unique characters one-to-one and compose them syntactically. We thus reinterpret a common EmCom setting, the attribute-value reconstruction game, by imposing a small-vocabulary constraint to simulate double articulation, and formulating a novel setting analogous to naturalistic inflectional morphology (enabling meaningful comparison to natural language communication schemes). We develop new metrics and explore variations of this game motivated by real properties of inflectional morphology: concatenativity and fusionality. Through our experiments, we discover that simulated phonological constraints encourage concatenative morphology, and emergent languages replicate the tendency of natural languages to fuse grammatical attributes.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Discovering Properties of Inflectional Morphology in Neural Emergent Communication\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "discovering",
      "properties",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Stochastic Bandits for Crowdsourcing and Multi-Platform Autobidding",
    "title_es": "Stochastic Bandits for Crowdsourcing and Multi-Platform Autobidding",
    "url": "https://arxiv.org/abs/2508.05844",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05844v1 Announce Type: new \nAbstract: Motivated by applications in crowdsourcing, where a fixed sum of money is split among $K$ workers, and autobidding, where a fixed budget is used to bid in $K$ simultaneous auctions, we define a stochastic bandit model where arms belong to the $K$-dimensional probability simplex and represent the fraction of budget allocated to each task/auction. The reward in each round is the sum of $K$ stochastic rewards, where each of these rewards is unlocked with a probability that varies with the fraction of the budget allocated to that task/auction. We design an algorithm whose expected regret after $T$ steps is of order $K\\sqrt{T}$ (up to log factors) and prove a matching lower bound. Improved bounds of order $K (\\log T)^2$ are shown when the function mapping budget to probability of unlocking the reward (i.e., terminating the task or winning the auction) satisfies additional diminishing-returns conditions.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Stochastic Bandits for Crowdsourcing and Multi-Platform Autobidding\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "stochastic",
      "bandits",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Towards Transparent Ethical AI: A Roadmap for Trustworthy Robotic Systems",
    "title_es": "Towards Transparent Ethical AI: A Roadmap for Trustworthy Robotic Systems",
    "url": "https://arxiv.org/abs/2508.05846",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05846v1 Announce Type: new \nAbstract: As artificial intelligence (AI) and robotics increasingly permeate society, ensuring the ethical behavior of these systems has become paramount. This paper contends that transparency in AI decision-making processes is fundamental to developing trustworthy and ethically aligned robotic systems. We explore how transparency facilitates accountability, enables informed consent, and supports the debugging of ethical algorithms. The paper outlines technical, ethical, and practical challenges in implementing transparency and proposes novel approaches to enhance it, including standardized metrics, explainable AI techniques, and user-friendly interfaces. This paper introduces a framework that connects technical implementation with ethical considerations in robotic systems, focusing on the specific challenges of achieving transparency in dynamic, real-world contexts. We analyze how prioritizing transparency can impact public trust, regulatory policies, and avenues for future research. By positioning transparency as a fundamental element in ethical AI system design, we aim to add to the ongoing discussion on responsible AI and robotics, providing direction for future advancements in this vital field.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Towards Transparent Ethical AI: A Roadmap for Trustworthy Robotic Systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "towards",
      "transparent",
      "ethical"
    ],
    "category": "noticia"
  },
  {
    "title": "Public support for misinformation interventions depends on perceived fairness, effectiveness, and intrusiveness",
    "title_es": "Public support for misinformation interventions depends on perceived fairness, effectiveness, and intrusiveness",
    "url": "https://arxiv.org/abs/2508.05849",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05849v1 Announce Type: new \nAbstract: The proliferation of misinformation on social media has concerning possible consequences, such as the degradation of democratic norms. While recent research on countering misinformation has largely focused on analyzing the effectiveness of interventions, the factors associated with public support for these interventions have received little attention. We asked 1,010 American social media users to rate their support for and perceptions of ten misinformation interventions implemented by the government or social media companies. Our results indicate that the perceived fairness of the intervention is the most important factor in determining support, followed by the perceived effectiveness of that intervention and then the intrusiveness. Interventions that supported user agency and transparency, such as labeling content or fact-checking ads, were more popular than those that involved moderating or removing content or accounts. We found some demographic differences in support levels, with Democrats and women supporting interventions more and finding them more fair, more effective, and less intrusive than Republicans and men, respectively. It is critical to understand which interventions are supported and why, as public opinion can play a key role in the rollout and effectiveness of policies.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Public support for misinformation interventions depends on perceived fairness, effectiveness, and intrusiveness\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "public",
      "support",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Temporal Cluster Assignment for Efficient Real-Time Video Segmentation",
    "title_es": "Temporal Cluster Assignment for Efficient Real-Time Video Segmentation",
    "url": "https://arxiv.org/abs/2508.05851",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05851v1 Announce Type: new \nAbstract: Vision Transformers have substantially advanced the capabilities of segmentation models across both image and video domains. Among them, the Swin Transformer stands out for its ability to capture hierarchical, multi-scale representations, making it a popular backbone for segmentation in videos. However, despite its window-attention scheme, it still incurs a high computational cost, especially in larger variants commonly used for dense prediction in videos. This remains a major bottleneck for real-time, resource-constrained applications. Whilst token reduction methods have been proposed to alleviate this, the window-based attention mechanism of Swin requires a fixed number of tokens per window, limiting the applicability of conventional pruning techniques. Meanwhile, training-free token clustering approaches have shown promise in image segmentation while maintaining window consistency. Nevertheless, they fail to exploit temporal redundancy, missing a key opportunity to further optimize video segmentation performance. We introduce Temporal Cluster Assignment (TCA), a lightweight and effective, fine-tuning-free strategy that enhances token clustering by leveraging temporal coherence across frames. Instead of indiscriminately dropping redundant tokens, TCA refines token clusters using temporal correlations, thereby retaining fine-grained details while significantly reducing computation. Extensive evaluations on YouTube-VIS 2019, YouTube-VIS 2021, OVIS, and a private surgical video dataset show that TCA consistently boosts the accuracy-speed trade-off of existing clustering-based methods. Our results demonstrate that TCA generalizes competently across both natural and domain-specific videos.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Temporal Cluster Assignment for Efficient Real-Time Video Segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "temporal",
      "cluster",
      "assignment"
    ],
    "category": "noticia"
  },
  {
    "title": "VISTA: Vision-Language Imitation of Situational Thinking and Attention for Human-Like Driver Focus in Dynamic Environments",
    "title_es": "VISTA: Vision-Language Imitation of Situational Thinking and Attention for Human-Like Driver Focus in Dynamic Environments",
    "url": "https://arxiv.org/abs/2508.05852",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05852v1 Announce Type: new \nAbstract: Driver visual attention prediction is a critical task in autonomous driving and human-computer interaction (HCI) research. Most prior studies focus on estimating attention allocation at a single moment in time, typically using static RGB images such as driving scene pictures. In this work, we propose a vision-language framework that models the changing landscape of drivers' gaze through natural language, using few-shot and zero-shot learning on single RGB images. We curate and refine high-quality captions from the BDD-A dataset using human-in-the-loop feedback, then fine-tune LLaVA to align visual perception with attention-centric scene understanding. Our approach integrates both low-level cues and top-down context (e.g., route semantics, risk anticipation), enabling language-based descriptions of gaze behavior. We evaluate performance across training regimes (few shot, and one-shot) and introduce domain-specific metrics for semantic alignment and response diversity. Results show that our fine-tuned model outperforms general-purpose VLMs in attention shift detection and interpretability. To our knowledge, this is among the first attempts to generate driver visual attention allocation and shifting predictions in natural language, offering a new direction for explainable AI in autonomous driving. Our approach provides a foundation for downstream tasks such as behavior forecasting, human-AI teaming, and multi-agent coordination.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"VISTA: Vision-Language Imitation of Situational Thinking and Attention for Human-Like Driver Focus in Dynamic Environments\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "vista",
      "visionlanguage",
      "imitation"
    ],
    "category": "noticia"
  },
  {
    "title": "Safety of Embodied Navigation: A Survey",
    "title_es": "Safety of Embodied Navigation: A Survey",
    "url": "https://arxiv.org/abs/2508.05855",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05855v1 Announce Type: new \nAbstract: As large language models (LLMs) continue to advance and gain influence, the development of embodied AI has accelerated, drawing significant attention, particularly in navigation scenarios. Embodied navigation requires an agent to perceive, interact with, and adapt to its environment while moving toward a specified target in unfamiliar settings. However, the integration of embodied navigation into critical applications raises substantial safety concerns. Given their deployment in dynamic, real-world environments, ensuring the safety of such systems is critical. This survey provides a comprehensive analysis of safety in embodied navigation from multiple perspectives, encompassing attack strategies, defense mechanisms, and evaluation methodologies. Beyond conducting a comprehensive examination of existing safety challenges, mitigation technologies, and various datasets and metrics that assess effectiveness and robustness, we explore unresolved issues and future research directions in embodied navigation safety. These include potential attack methods, mitigation strategies, more reliable evaluation techniques, and the implementation of verification frameworks. By addressing these critical gaps, this survey aims to provide valuable insights that can guide future research toward the development of safer and more reliable embodied navigation systems. Furthermore, the findings of this study have broader implications for enhancing societal safety and increasing industrial efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Safety of Embodied Navigation: A Survey\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "safety",
      "of",
      "embodied"
    ],
    "category": "noticia"
  },
  {
    "title": "Multi-view Gaze Target Estimation",
    "title_es": "Multi-view Gaze Target Estimation",
    "url": "https://arxiv.org/abs/2508.05857",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05857v1 Announce Type: new \nAbstract: This paper presents a method that utilizes multiple camera views for the gaze target estimation (GTE) task. The approach integrates information from different camera views to improve accuracy and expand applicability, addressing limitations in existing single-view methods that face challenges such as face occlusion, target ambiguity, and out-of-view targets. Our method processes a pair of camera views as input, incorporating a Head Information Aggregation (HIA) module for leveraging head information from both views for more accurate gaze estimation, an Uncertainty-based Gaze Selection (UGS) for identifying the most reliable gaze output, and an Epipolar-based Scene Attention (ESA) module for cross-view background information sharing. This approach significantly outperforms single-view baselines, especially when the second camera provides a clear view of the person's face. Additionally, our method can estimate the gaze target in the first view using the image of the person in the second view only, a capability not possessed by single-view GTE methods. Furthermore, the paper introduces a multi-view dataset for developing and evaluating multi-view GTE methods. Data and code are available at https://www3.cs.stonybrook.edu/~cvl/multiview_gte.html",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Multi-view Gaze Target Estimation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "multiview",
      "gaze",
      "target"
    ],
    "category": "noticia"
  },
  {
    "title": "Sprouting technology otherwise, hospicing negative commons -- Rethinking technology in the transition to sustainability-oriented futures",
    "title_es": "Sprouting technology otherwise, hospicing negative commons -- Rethinking technology in the transition to sustainability-oriented futures",
    "url": "https://arxiv.org/abs/2508.05860",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05860v1 Announce Type: new \nAbstract: Due to its significant and growing environmental harms, both directly through its materiality and indirectly through its pervasive integration into unsustainable economic systems, ICT will need to be radically redirected to align with sustainability-oriented futures. While the role of ICT in such futures will likely diverge significantly from current dynamics, it will probably not be entirely disconnected from the present. Instead, such transition involves complex dynamics of continuity, adaptation and rupture. Drawing from recent work in transition studies, the commons (particularly \"negative commons\"), as well as some of the Limits literature, this article proposes a conceptual framework for navigating this redirection. The framework attempts to bring together the disentanglement from sociotechnical elements incompatible with long-term sustainability and the support of existing practices that may serve as foundations for alternative technological paths. It introduces four categories: ruins, ghosts, seeds and visions, to examine how material and cultural aspects of computing may become obsolete, persist in latent or reinterpreted forms, or contribute to sustainability-oriented futures. Through both empirical and speculative examples, I intend to show how this lens can help researchers and practitioners engage more concretely with the tensions, inheritances, and opportunities involved in redirecting computing towards more sustainable and equitable futures.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Sprouting technology otherwise, hospicing negative commons -- Rethinking technology in the transition to sustainability-oriented futures\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sprouting",
      "technology",
      "otherwise"
    ],
    "category": "noticia"
  },
  {
    "title": "Secure and Scalable Blockchain Voting: A Comparative Framework and the Role of Large Language Models",
    "title_es": "Secure and Scalable Blockchain Voting: A Comparative Framework and the Role of Large Language Models",
    "url": "https://arxiv.org/abs/2508.05865",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05865v1 Announce Type: new \nAbstract: Blockchain technology offers a promising foundation for modernizing E-Voting systems by enhancing transparency, decentralization, and security. Yet, real-world adoption remains limited due to persistent challenges such as scalability constraints, high computational demands, and complex privacy requirements. This paper presents a comparative framework for analyzing blockchain-based E-Voting architectures, consensus mechanisms, and cryptographic protocols. We examine the limitations of prevalent models like Proof of Work, Proof of Stake, and Delegated Proof of Stake, and propose optimization strategies that include hybrid consensus, lightweight cryptography, and decentralized identity management. Additionally, we explore the novel role of Large Language Models (LLMs) in smart contract generation, anomaly detection, and user interaction. Our findings offer a foundation for designing secure, scalable, and intelligent blockchain-based E-Voting systems suitable for national-scale deployment. This work lays the groundwork for building an end-to-end blockchain E-Voting prototype enhanced by LLM-guided smart contract generation and validation, supported by a systematic framework and simulation-based analysis.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Secure and Scalable Blockchain Voting: A Comparative Framework and the Role of Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "secure",
      "and",
      "scalable"
    ],
    "category": "noticia"
  },
  {
    "title": "The Memory Wars: AI Memory, Network Effects, and the Geopolitics of Cognitive Sovereignty",
    "title_es": "The Memory Wars: AI Memory, Network Effects, and the Geopolitics of Cognitive Sovereignty",
    "url": "https://arxiv.org/abs/2508.05867",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05867v1 Announce Type: new \nAbstract: The advent of continuously learning Artificial Intelligence (AI) assistants marks a paradigm shift from episodic interactions to persistent, memory-driven relationships. This paper introduces the concept of \"Cognitive Sovereignty\", the ability of individuals, groups, and nations to maintain autonomous thought and preserve identity in the age of powerful AI systems, especially those that hold their deep personal memory. It argues that the primary risk of these technologies transcends traditional data privacy to become an issue of cognitive and geopolitical control. We propose \"Network Effect 2.0,\" a model where value scales with the depth of personalized memory, creating powerful cognitive moats and unprecedented user lock-in. We analyze the psychological risks of such systems, including cognitive offloading and identity dependency, by drawing on the \"extended mind\" thesis. These individual-level risks scale to geopolitical threats, such as a new form of digital colonialism and subtle shifting of public discourse. To counter these threats, we propose a policy framework centered on memory portability, transparency, sovereign cognitive infrastructure, and strategic alliances. This work reframes the discourse on AI assistants in an era of increasingly intimate machines, pointing to challenges to individual and national sovereignty.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"The Memory Wars: AI Memory, Network Effects, and the Geopolitics of Cognitive Sovereignty\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "memory",
      "wars"
    ],
    "category": "noticia"
  },
  {
    "title": "Energy Experience Design",
    "title_es": "Energy Experience Design",
    "url": "https://arxiv.org/abs/2508.05869",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05869v1 Announce Type: new \nAbstract: The material footprint of information and communications technology (ICT) systems is both significant and growing, inspiring a variety of conversations around sustainability and climate justice. In part this effort has been catalysed by past scholarship and analysis from the LIMITS community. This paper examines energy storage systems for computing, particularly batteries -- which are discarded at the rate of 15 billion a year worldwide. The International Energy Agency (IEA) is now referring to the energy transition toward low carbon systems as a critical mineral problem, and countries are speaking openly of 'mineral security' in policy documents. In this paper I 1) present a definition for energy experience and what this means for the design and making of devices, interactions and experiences. I also 2) explore a series of electronics device prototypes converted to run from batteryless sustainable energy that are extremely long lasting, and make limited use of critical minerals. As transitional energy experience device-design experiments, what do prototypes like these suggest for more mainstream, mass-manufactured systems?",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Energy Experience Design\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "energy",
      "experience",
      "design"
    ],
    "category": "noticia"
  },
  {
    "title": "A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance",
    "title_es": "A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance",
    "url": "https://arxiv.org/abs/2508.05876",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05876v1 Announce Type: new \nAbstract: This work presents a Markov decision process (MDP) framework to model decision-making for collision avoidance maneuver (CAM) and a reinforcement learning policy gradient (RL-PG) algorithm to train an autonomous guidance policy using historic CAM data. In addition to maintaining acceptable collision risks, this approach seeks to minimize the average fuel consumption of CAMs by making early maneuver decisions. We model CAM as a continuous state, discrete action and finite horizon MDP, where the critical decision is determining when to initiate the maneuver. The MDP model also incorporates analytical models for conjunction risk, propellant consumption, and transit orbit geometry. The Markov policy effectively trades-off maneuver delay-which improves the reliability of conjunction risk indicators-with propellant consumption-which increases with decreasing maneuver time. Using historical data of tracked conjunction events, we verify this framework and conduct an extensive ablation study on the hyper-parameters used within the MDP. On synthetic conjunction events, the trained policy significantly minimizes both the overall and average propellant consumption per CAM when compared to a conventional cut-off policy that initiates maneuvers 24 hours before the time of closest approach (TCA). On historical conjunction events, the trained policy consumes more propellant overall but reduces the average propellant consumption per CAM. For both historical and synthetic conjunction events, the trained policy achieves equal if not higher overall collision risk guarantees.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "markov",
      "decision"
    ],
    "category": "noticia"
  },
  {
    "title": "Training chord recognition models on artificially generated audio",
    "title_es": "Training chord recognition models on artificially generated audio",
    "url": "https://arxiv.org/abs/2508.05878",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05878v1 Announce Type: new \nAbstract: One of the challenging problems in Music Information Retrieval is the acquisition of enough non-copyrighted audio recordings for model training and evaluation. This study compares two Transformer-based neural network models for chord sequence recognition in audio recordings and examines the effectiveness of using an artificially generated dataset for this purpose. The models are trained on various combinations of Artificial Audio Multitracks (AAM), Schubert's Winterreise Dataset, and the McGill Billboard Dataset and evaluated with three metrics: Root, MajMin and Chord Content Metric (CCM). The experiments prove that even though there are certainly differences in complexity and structure between artificially generated and human-composed music, the former can be useful in certain scenarios. Specifically, AAM can enrich a smaller training dataset of music composed by a human or can even be used as a standalone training set for a model that predicts chord sequences in pop music, if no other data is available.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Training chord recognition models on artificially generated audio\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "training",
      "chord",
      "recognition"
    ],
    "category": "noticia"
  },
  {
    "title": "Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models",
    "title_es": "Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models",
    "url": "https://arxiv.org/abs/2508.05880",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05880v1 Announce Type: new \nAbstract: Affective Computing has been established as a crucial field of inquiry to advance the holistic development of Artificial Intelligence (AI) systems. Foundation models -- especially Large Language Models (LLMs) -- have been evaluated, trained, or instruction-tuned in several past works, to become better predictors or generators of emotion. Most of these studies, however, approach emotion-related tasks in a supervised manner, assessing or training the capabilities of LLMs using discrete emotion labels associated with stimuli (e.g., text, images, video, audio). Evaluation studies, in particular, have often been limited to standard and superficial emotion-related tasks, such as the recognition of evoked or expressed emotions. In this paper, we move beyond surface-level emotion tasks to investigate how LLMs reason about emotions through cognitive dimensions. Drawing from cognitive appraisal theory, we examine whether LLMs produce coherent and plausible cognitive reasoning when reasoning about emotionally charged stimuli. We introduce a large-scale benchmark on Cognitive Reasoning for Emotions - CoRE - to evaluate internal cognitive structures implicitly used by LLMs for emotional reasoning. Through a plethora of evaluation experiments and analysis, we seek to answer: (a) Are models more likely to implicitly rely on specific cognitive appraisal dimensions?, (b) What cognitive dimensions are important for characterizing specific emotions?, and, (c) Can the internal representations of different emotion categories in LLMs be interpreted through cognitive appraisal dimensions? Our results and analyses reveal diverse reasoning patterns across different LLMs. Our benchmark and code will be made publicly available.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "do",
      "machines",
      "think"
    ],
    "category": "noticia"
  },
  {
    "title": "User-Intent-Driven Semantic Communication via Adaptive Deep Understanding",
    "title_es": "User-Intent-Driven Semantic Communication via Adaptive Deep Understanding",
    "url": "https://arxiv.org/abs/2508.05884",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05884v1 Announce Type: new \nAbstract: Semantic communication focuses on transmitting task-relevant semantic information, aiming for intent-oriented communication. While existing systems improve efficiency by extracting key semantics, they still fail to deeply understand and generalize users' real intentions. To overcome this, we propose a user-intention-driven semantic communication system that interprets diverse abstract intents. First, we integrate a multi-modal large model as semantic knowledge base to generate user-intention prior. Next, a mask-guided attention module is proposed to effectively highlight critical semantic regions. Further, a channel state awareness module ensures adaptive, robust transmission across varying channel conditions. Extensive experiments demonstrate that our system achieves deep intent understanding and outperforms DeepJSCC, e.g., under a Rayleigh channel at an SNR of 5 dB, it achieves improvements of 8%, 6%, and 19% in PSNR, SSIM, and LPIPS, respectively.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"User-Intent-Driven Semantic Communication via Adaptive Deep Understanding\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "userintentdriven",
      "semantic",
      "communication"
    ],
    "category": "noticia"
  },
  {
    "title": "Distributed Optimization and Learning for Automated Stepsize Selection with Finite Time Coordination",
    "title_es": "Distributed Optimization and Learning for Automated Stepsize Selection with Finite Time Coordination",
    "url": "https://arxiv.org/abs/2508.05887",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05887v1 Announce Type: new \nAbstract: Distributed optimization and learning algorithms are designed to operate over large scale networks enabling processing of vast amounts of data effectively and efficiently. One of the main challenges for ensuring a smooth learning process in gradient-based methods is the appropriate selection of a learning stepsize. Most current distributed approaches let individual nodes adapt their stepsizes locally. However, this may introduce stepsize heterogeneity in the network, thus disrupting the learning process and potentially leading to divergence. In this paper, we propose a distributed learning algorithm that incorporates a novel mechanism for automating stepsize selection among nodes. Our main idea relies on implementing a finite time coordination algorithm for eliminating stepsize heterogeneity among nodes. We analyze the operation of our algorithm and we establish its convergence to the optimal solution. We conclude our paper with numerical simulations for a linear regression problem, showcasing that eliminating stepsize heterogeneity enhances convergence speed and accuracy against current approaches.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Distributed Optimization and Learning for Automated Stepsize Selection with Finite Time Coordination\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "distributed",
      "optimization",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning",
    "title_es": "Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning",
    "url": "https://arxiv.org/abs/2508.05888",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05888v1 Announce Type: new \nAbstract: Effective tool retrieval is essential for AI agents to select from a vast array of tools when identifying and planning actions in the context of complex user queries. Despite its central role in planning, this aspect remains underexplored in the literature. Traditional approaches rely primarily on similarities between user queries and tool descriptions, which significantly limits retrieval accuracy, specifically when handling multi-step user requests. To address these limitations, we propose a Knowledge Graph (KG)-based tool retrieval framework that captures the semantic relationships between tools and their functional dependencies. Our retrieval algorithm leverages ensembles of 1-hop ego tool graphs to model direct and indirect connections between tools, enabling more comprehensive and contextual tool selection for multi-step tasks. We evaluate our approach on a synthetically generated internal dataset across six defined user classes, extending previous work on coherent dialogue synthesis and too retrieval benchmarks. Results demonstrate that our tool graph-based method achieves 91.85% tool coverage on the micro-average Complete Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid retrieval, the strongest non-KG baseline in our experiments. These findings support our hypothesis that the structural information in the KG provides complementary signals to pure similarity matching, particularly for queries requiring sequential tool composition.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "planning",
      "agents",
      "on"
    ],
    "category": "noticia"
  },
  {
    "title": "Flow-Based Task Assignment for Large-Scale Online Multi-Agent Pickup and Delivery",
    "title_es": "Flow-Based Task Assignment for Large-Scale Online Multi-Agent Pickup and Delivery",
    "url": "https://arxiv.org/abs/2508.05890",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05890v1 Announce Type: new \nAbstract: We study the problem of online Multi-Agent Pickup and Delivery (MAPD), where a team of agents must repeatedly serve dynamically appearing tasks on a shared map. Existing online methods either rely on simple heuristics, which result in poor decisions, or employ complex reasoning, which suffers from limited scalability under real-time constraints. In this work, we focus on the task assignment subproblem and formulate it as a minimum-cost flow over the environment graph. This eliminates the need for pairwise distance computations and allows agents to be simultaneously assigned to tasks and routed toward them. The resulting flow network also supports efficient guide path extraction to integrate with the planner and accelerates planning under real-time constraints. To improve solution quality, we introduce two congestion-aware edge cost models that incorporate real-time traffic estimates. This approach supports real-time execution and scales to over 20000 agents and 30000 tasks within 1-second planning time, outperforming existing baselines in both computational efficiency and assignment quality.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Flow-Based Task Assignment for Large-Scale Online Multi-Agent Pickup and Delivery\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "flowbased",
      "task",
      "assignment"
    ],
    "category": "noticia"
  },
  {
    "title": "Distributed Quantized Average Consensus in Open Multi-Agent Systems with Dynamic Communication Links",
    "title_es": "Distributed Quantized Average Consensus in Open Multi-Agent Systems with Dynamic Communication Links",
    "url": "https://arxiv.org/abs/2508.05895",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05895v1 Announce Type: new \nAbstract: In this paper, we focus on the distributed quantized average consensus problem in open multi-agent systems consisting of communication links that change dynamically over time. Open multi-agent systems exhibiting the aforementioned characteristic are referred to as \\textit{open dynamic multi-agent systems} in this work. We present a distributed algorithm that enables active nodes in the open dynamic multi-agent system to calculate the quantized average of their initial states. Our algorithm consists of the following advantages: (i) ensures efficient communication by enabling nodes to exchange quantized valued messages, and (ii) exhibits finite time convergence to the desired solution. We establish the correctness of our algorithm and we present necessary and sufficient topological conditions for it to successfully solve the quantized average consensus problem in an open dynamic multi-agent system. Finally, we illustrate the performance of our algorithm with numerical simulations.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Distributed Quantized Average Consensus in Open Multi-Agent Systems with Dynamic Communication Links\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "distributed",
      "quantized",
      "average"
    ],
    "category": "noticia"
  },
  {
    "title": "ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates",
    "title_es": "ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates",
    "url": "https://arxiv.org/abs/2508.05898",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05898v1 Announce Type: new \nAbstract: Pretrained vision-language models (VLMs) like CLIP show strong zero-shot performance but struggle with generalization under distribution shifts. Test-Time Adaptation (TTA) addresses this by adapting VLMs to unlabeled test data in new domains. While some TTA methods rely on prompt-tuning, training-free cache-based approaches are preferred for efficiency. However, current cache-based TTA models store only a limited set of high-confidence samples, restricting the decision boundary to these samples and ignoring the influence of other incoming test data. To address this, we propose Efficient Test-Time Adaptation (ETTA), introducing a Recursive Updating module that integrates all incoming test samples, progressively refining the decision boundary. This strategy mimics an unbounded cache, dynamically updating contextual embeddings for improved accuracy with minimal memory and computational overhead. ETTA also includes an Adaptive Ensemble module to reduce prompt dependency in image-to-text scores by dynamically selecting optimal prompts for each class. Furthermore, ETTA adaptively combines scores from both modules based on confidence levels, leveraging their complementary strengths. Extensive experiments on two benchmarks confirm that ETTA surpasses the state-of-the-art TTA models in computational complexity and accuracy, setting a new standard for effective, efficient test-time adaptation. The code has been released at https://github.com/hamidreza-dastmalchi/ETTA.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "etta",
      "efficient",
      "testtime"
    ],
    "category": "noticia"
  },
  {
    "title": "HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing",
    "title_es": "HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing",
    "url": "https://arxiv.org/abs/2508.05899",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05899v1 Announce Type: new \nAbstract: 3D scene generation plays a crucial role in gaming, artistic creation, virtual reality and many other domains. However, current 3D scene design still relies heavily on extensive manual effort from creators, and existing automated methods struggle to generate open-domain scenes or support flexible editing. As a result, generating 3D worlds directly from text has garnered increasing attention. In this paper, we introduce HOLODECK 2.0, an advanced vision-language-guided framework for 3D world generation with support for interactive scene editing based on human feedback. HOLODECK 2.0 can generate diverse and stylistically rich 3D scenes (e.g., realistic, cartoon, anime, and cyberpunk styles) that exhibit high semantic fidelity to fine-grained input descriptions, suitable for both indoor and open-domain environments. HOLODECK 2.0 leverages vision-language models (VLMs) to identify and parse the objects required in a scene and generates corresponding high-quality assets via state-of-the-art 3D generative models. It then iteratively applies spatial constraints derived from the VLMs to achieve semantically coherent and physically plausible layouts. Human evaluations and CLIP-based assessments demonstrate that HOLODECK 2.0 effectively generates high-quality scenes closely aligned with detailed textual descriptions, consistently outperforming baselines across indoor and open-domain scenarios. Additionally, we provide editing capabilities that flexibly adapt to human feedback, supporting layout refinement and style-consistent object edits. Finally, we present a practical application of HOLODECK 2.0 in procedural game modeling, generating visually rich and immersive environments, potentially boosting efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "holodeck",
      "",
      "visionlanguageguided"
    ],
    "category": "noticia"
  },
  {
    "title": "Robust Image Stitching with Optimal Plane",
    "title_es": "Robust Image Stitching with Optimal Plane",
    "url": "https://arxiv.org/abs/2508.05903",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05903v1 Announce Type: new \nAbstract: We present \\textit{RopStitch}, an unsupervised deep image stitching framework with both robustness and naturalness. To ensure the robustness of \\textit{RopStitch}, we propose to incorporate the universal prior of content perception into the image stitching model by a dual-branch architecture. It separately captures coarse and fine features and integrates them to achieve highly generalizable performance across diverse unseen real-world scenes. Concretely, the dual-branch model consists of a pretrained branch to capture semantically invariant representations and a learnable branch to extract fine-grained discriminative features, which are then merged into a whole by a controllable factor at the correlation level. Besides, considering that content alignment and structural preservation are often contradictory to each other, we propose a concept of virtual optimal planes to relieve this conflict. To this end, we model this problem as a process of estimating homography decomposition coefficients, and design an iterative coefficient predictor and minimal semantic distortion constraint to identify the optimal plane. This scheme is finally incorporated into \\textit{RopStitch} by warping both views onto the optimal plane bidirectionally. Extensive experiments across various datasets demonstrate that \\textit{RopStitch} significantly outperforms existing methods, particularly in scene robustness and content naturalness. The code is available at {\\color{red}https://github.com/MmelodYy/RopStitch}.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Robust Image Stitching with Optimal Plane\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "robust",
      "image",
      "stitching"
    ],
    "category": "noticia"
  },
  {
    "title": "Snowpark: Performant, Secure, User-Friendly Data Engineering and AI/ML Next To Your Data",
    "title_es": "Snowpark: Performant, Secure, User-Friendly Data Engineering and AI/ML Next To Your Data",
    "url": "https://arxiv.org/abs/2508.05904",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05904v1 Announce Type: new \nAbstract: Snowflake revolutionized data analytics with an elastic architecture that decouples compute and storage, enabling scalable solutions supporting data architectures like data lake, data warehouse, data lakehouse, and data mesh. Building on this foundation, Snowflake has advanced its AI Data Cloud vision by introducing Snowpark, a managed turnkey solution that supports data engineering and AI and ML workloads using Python and other programming languages.\n  This paper outlines Snowpark's design objectives towards high performance, strong security and governance, and ease of use. We detail the architecture of Snowpark, highlighting its elastic scalability and seamless integration with Snowflake core compute infrastructure. This includes leveraging Snowflake control plane for distributed computing and employing a secure sandbox for isolating Snowflake SQL workloads from Snowpark executions. Additionally, we present core innovations in Snowpark that drive further performance enhancements, such as query initialization latency reduction through Python package caching, improved workload scheduling for customized workloads, and data skew management via efficient row redistribution. Finally, we showcase real-world case studies that illustrate Snowpark's efficiency and effectiveness for large-scale data engineering and AI and ML tasks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Snowpark: Performant, Secure, User-Friendly Data Engineering and AI/ML Next To Your Data\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "snowpark",
      "performant",
      "secure"
    ],
    "category": "noticia"
  },
  {
    "title": "The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)",
    "title_es": "The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)",
    "url": "https://arxiv.org/abs/2508.05905",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05905v1 Announce Type: new \nAbstract: Quantization is usually regarded as a means to trade quality of performance for reduced compute requirements, i.e., as a suboptimal approximation. However, if examined in terms of a fixed overall resource budget, a very different perspective arises. We introduce Signed-Zero Ternary (SZT), a 2-bit quantization that deterministically provides gradient information with no forward-path penalty. Our analysis provides evidence that it may improve information density compared to non-quantized alternatives.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "fourth",
      "state"
    ],
    "category": "noticia"
  },
  {
    "title": "Neural Field Representations of Mobile Computational Photography",
    "title_es": "Neural Field Representations of Mobile Computational Photography",
    "url": "https://arxiv.org/abs/2508.05907",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05907v1 Announce Type: new \nAbstract: Over the past two decades, mobile imaging has experienced a profound transformation, with cell phones rapidly eclipsing all other forms of digital photography in popularity. Today's cell phones are equipped with a diverse range of imaging technologies - laser depth ranging, multi-focal camera arrays, and split-pixel sensors - alongside non-visual sensors such as gyroscopes, accelerometers, and magnetometers. This, combined with on-board integrated chips for image and signal processing, makes the cell phone a versatile pocket-sized computational imaging platform. Parallel to this, we have seen in recent years how neural fields - small neural networks trained to map continuous spatial input coordinates to output signals - enable the reconstruction of complex scenes without explicit data representations such as pixel arrays or point clouds. In this thesis, I demonstrate how carefully designed neural field models can compactly represent complex geometry and lighting effects. Enabling applications such as depth estimation, layer separation, and image stitching directly from collected in-the-wild mobile photography data. These methods outperform state-of-the-art approaches without relying on complex pre-processing steps, labeled ground truth data, or machine learning priors. Instead, they leverage well-constructed, self-regularized models that tackle challenging inverse problems through stochastic gradient descent, fitting directly to raw measurements from a smartphone.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Neural Field Representations of Mobile Computational Photography\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "neural",
      "field",
      "representations"
    ],
    "category": "noticia"
  },
  {
    "title": "Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation",
    "title_es": "Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation",
    "url": "https://arxiv.org/abs/2508.05909",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05909v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown improved generation performance through retrieval-augmented generation (RAG) following the retriever-reader paradigm, which supplements model inputs with externally retrieved knowledge. However, prior work often evaluates RAG holistically, assessing the retriever and reader jointly, making it difficult to isolate the true contribution of retrieval, particularly given the prompt sensitivity of LLMs used as readers. We introduce Spectrum Projection Score (SPS), a lightweight, supervision-free metric that allows the reader to gauge the semantic alignment of a retrieved summary with its hidden representation by comparing the area formed by generated tokens from the summary, and the principal directions of subspace in the reader and to measure the relevance. Building on SPS we present xCompress, an inference time controller framework that dynamically samples, ranks, and compresses retrieval summary candidates. Extensive experiments on five QA benchmarks with four open source LLMs show that SPS not only enhances performance across a range of tasks but also provides a principled perspective on the interaction between retrieval and generation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "spectrum",
      "projection",
      "score"
    ],
    "category": "noticia"
  },
  {
    "title": "Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction",
    "title_es": "Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction",
    "url": "https://arxiv.org/abs/2508.05913",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05913v1 Announce Type: new \nAbstract: As AI systems become increasingly embedded in organizational workflows and consumer applications, ethical principles such as fairness, transparency, and robustness have been widely endorsed in policy and industry guidelines. However, there is still scarce empirical evidence on whether these principles are recognized, valued, or impactful from the perspective of users. This study investigates the link between ethical AI and user satisfaction by analyzing over 100,000 user reviews of AI products from G2. Using transformer-based language models, we measure sentiment across seven ethical dimensions defined by the EU Ethics Guidelines for Trustworthy AI. Our findings show that all seven dimensions are positively associated with user satisfaction. Yet, this relationship varies systematically across user and product types. Technical users and reviewers of AI development platforms more frequently discuss system-level concerns (e.g., transparency, data governance), while non-technical users and reviewers of end-user applications emphasize human-centric dimensions (e.g., human agency, societal well-being). Moreover, the association between ethical AI and user satisfaction is significantly stronger for non-technical users and end-user applications across all dimensions. Our results highlight the importance of ethical AI design from users' perspectives and underscore the need to account for contextual differences across user roles and product types.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "do",
      "ethical",
      "ai"
    ],
    "category": "noticia"
  },
  {
    "title": "Dual Signal Decomposition of Stochastic Time Series",
    "title_es": "Dual Signal Decomposition of Stochastic Time Series",
    "url": "https://arxiv.org/abs/2508.05915",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05915v1 Announce Type: new \nAbstract: The research paper addresses decomposition of a stochastic time series into three time series representing a dual signal i.e., the mean and the dispersion, with noise isolated. Decomposition is done by applying machine learning to fit a dual signal. Machine learning minimizes the loss function which compromises between fitting the original time series and penalizing irregularities of the dual signal. The latter includes terms based on the first and second order derivatives along time. To preserve special patterns, weighting of the regularization components of the loss function has been introduced based on Statistical Process Control methodology. The proposed decomposition can be applied as a smoothing algorithm against the mean and dispersion of the time series. By isolating noise, the proposed decomposition can be seen as a denoising algorithm. Two approaches of the learning process have been considered: sequential and jointly. The former approach learns the mean signal first and then dispersion. The latter approach fits the dual signal jointly. Jointly learning can uncover complex relationships for the time series with heteroskedasticity. Learning has been set by solving the direct non-linear unconstrained optimization problem or by applying neural networks that have sequential or twin output architectures. Tuning of the loss function hyperparameters focuses on the isolated noise to be a stationary stochastic process without autocorrelation properties. Depending on the applications, the hyperparameters of the learning can be tuned towards either the discrete states by stepped signal or smoothed series. The decomposed dual signal can be represented on the 2D space and used to learn inherent structures, to forecast both mean and dispersion, or to analyze cross effects in case of multiple time series.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Dual Signal Decomposition of Stochastic Time Series\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dual",
      "signal",
      "decomposition"
    ],
    "category": "noticia"
  },
  {
    "title": "Debiasing Polynomial and Fourier Regression",
    "title_es": "Debiasing Polynomial and Fourier Regression",
    "url": "https://arxiv.org/abs/2508.05920",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05920v1 Announce Type: new \nAbstract: We study the problem of approximating an unknown function $f:\\mathbb{R}\\to\\mathbb{R}$ by a degree-$d$ polynomial using as few function evaluations as possible, where error is measured with respect to a probability distribution $\\mu$. Existing randomized algorithms achieve near-optimal sample complexities to recover a $ (1+\\varepsilon) $-optimal polynomial but produce biased estimates of the best polynomial approximation, which is undesirable.\n  We propose a simple debiasing method based on a connection between polynomial regression and random matrix theory. Our method involves evaluating $f(\\lambda_1),\\ldots,f(\\lambda_{d+1})$ where $\\lambda_1,\\ldots,\\lambda_{d+1}$ are the eigenvalues of a suitably designed random complex matrix tailored to the distribution $\\mu$. Our estimator is unbiased, has near-optimal sample complexity, and experimentally outperforms iid leverage score sampling.\n  Additionally, our techniques enable us to debias existing methods for approximating a periodic function with a truncated Fourier series with near-optimal sample complexity.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Debiasing Polynomial and Fourier Regression\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "debiasing",
      "polynomial",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations",
    "title_es": "Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations",
    "url": "https://arxiv.org/abs/2508.05921",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05921v1 Announce Type: new \nAbstract: Accuracy in neural PDE solvers often breaks down not because of limited expressivity, but due to poor optimisation caused by ill-conditioning, especially in multi-fidelity and stiff problems. We study this issue in Physics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural PDE solvers, and show that asymptotic components in governing equations can produce highly ill-conditioned activation matrices, severely limiting convergence. We introduce Shifted Gaussian Encoding, a simple yet effective activation filtering step that increases matrix rank and expressivity while preserving convexity. Our method extends the solvable range of Peclet numbers in steady advection-diffusion equations by over two orders of magnitude, achieves up to six orders lower error on multi-frequency function learning, and fits high-fidelity image vectors more accurately and faster than deep networks with over a million parameters. This work highlights that conditioning, not depth, is often the bottleneck in scientific neural solvers and that simple architectural changes can unlock substantial gains.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fast",
      "convex",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Enhancing Construction Site Analysis and Understanding with 3D Segmentation",
    "title_es": "Enhancing Construction Site Analysis and Understanding with 3D Segmentation",
    "url": "https://arxiv.org/abs/2508.05922",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05922v1 Announce Type: new \nAbstract: Monitoring construction progress is crucial yet resource-intensive, prompting the exploration of computer-vision-based methodologies for enhanced efficiency and scalability. Traditional data acquisition methods, primarily focusing on indoor environments, falter in construction site's complex, cluttered, and dynamically changing conditions. This paper critically evaluates the application of two advanced 3D segmentation methods, Segment Anything Model (SAM) and Mask3D, in challenging outdoor and indoor conditions. Trained initially on indoor datasets, both models' adaptability and performance are assessed in real-world construction settings, highlighting the gap in current segmentation approaches due to the absence of benchmarks for outdoor scenarios. Through a comparative analysis, this study not only showcases the relative effectiveness of SAM and Mask3D but also addresses the critical need for tailored segmentation workflows capable of extracting actionable insights from construction site data, thereby advancing the field towards more automated and precise monitoring techniques.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Enhancing Construction Site Analysis and Understanding with 3D Segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "enhancing",
      "construction",
      "site"
    ],
    "category": "noticia"
  },
  {
    "title": "Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm",
    "title_es": "Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm",
    "url": "https://arxiv.org/abs/2508.05923",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05923v1 Announce Type: new \nAbstract: Software vulnerabilities continue to undermine the reliability and security of modern systems, particularly as software complexity outpaces the capabilities of traditional detection methods. This study introduces a genetic algorithm-based method for test input generation that innovatively integrates genetic operators and adaptive learning to enhance software vulnerability detection. A key contribution is the application of the crossover operator, which facilitates exploration by searching across a broader space of potential test inputs. Complementing this, an adaptive feedback mechanism continuously learns from the system's execution behavior and dynamically guides input generation toward promising areas of the input space. Rather than relying on fixed or randomly selected inputs, the approach evolves a population of structurally valid test cases using feedback-driven selection, enabling deeper and more effective code traversal. This strategic integration of exploration and exploitation ensures that both diverse and targeted test inputs are developed over time. Evaluation was conducted across nine open-source JSON-processing libraries. The proposed method achieved substantial improvements in coverage compared to a benchmark evolutionary fuzzing method, with average gains of 39.8% in class coverage, 62.4% in method coverage, 105.0% in line coverage, 114.0% in instruction coverage, and 166.0% in branch coverage. These results highlight the method's capacity to detect deeper and more complex vulnerabilities, offering a scalable and adaptive solution to software security testing.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "enhancing",
      "software",
      "vulnerability"
    ],
    "category": "noticia"
  },
  {
    "title": "Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting",
    "title_es": "Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting",
    "url": "https://arxiv.org/abs/2508.05928",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05928v1 Announce Type: new \nAbstract: Group-Relative Policy Optimization (GRPO) is a key technique for training large reasoning models, yet it suffers from a critical vulnerability: the \\emph{Think-Answer Mismatch}, where noisy reward signals corrupt the learning process. This problem is most severe in unbalanced response groups, paradoxically degrading the signal precisely when it should be most informative. To address this challenge, we propose Stable Group-Relative Policy Optimization (S-GRPO), a principled enhancement that derives optimal, noise-aware advantage weights to stabilize training. Our comprehensive experiments on mathematical reasoning benchmarks demonstrate S-GRPO's effectiveness and robustness. On various models, S-GRPO significantly outperforms DR. GRPO, achieving performance gains of +2.5% on Qwen-Math-7B-Base, +2.2% on Llama-3.2-3B-Base, and +2.4% on Qwen-Math-1.5B-Instruct. Most critically, while standard GRPO fails to learn under 20% synthetic reward noise, S-GRPO maintains stable learning progress. These results highlight S-GRPO's potential for more robust and effective training of large-scale reasoning models. \\footnote{Code and data are available at: https://github.com/shenpeijun0212/S-GRPO",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mitigating",
      "thinkanswer",
      "mismatch"
    ],
    "category": "noticia"
  },
  {
    "title": "Towards Reliable Generative AI-Driven Scaffolding: Reducing Hallucinations and Enhancing Quality in Self-Regulated Learning Support",
    "title_es": "Towards Reliable Generative AI-Driven Scaffolding: Reducing Hallucinations and Enhancing Quality in Self-Regulated Learning Support",
    "url": "https://arxiv.org/abs/2508.05929",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05929v1 Announce Type: new \nAbstract: Generative Artificial Intelligence (GenAI) holds a potential to advance existing educational technologies with capabilities to automatically generate personalised scaffolds that support students' self-regulated learning (SRL). While advancements in large language models (LLMs) promise improvements in the adaptability and quality of educational technologies for SRL, there remain concerns about the hallucinations in content generated by LLMs, which can compromise both the learning experience and ethical standards. To address these challenges, we proposed GenAI-enabled approaches for evaluating personalised SRL scaffolds before they are presented to students, aiming for reducing hallucinations and improving the overall quality of LLM-generated personalised scaffolds. Specifically, two approaches are investigated. The first approach involved developing a multi-agent system approach for reliability evaluation to assess the extent to which LLM-generated scaffolds accurately target relevant SRL processes. The second approach utilised the \"LLM-as-a-Judge\" technique for quality evaluation that evaluates LLM-generated scaffolds for their helpfulness in supporting students. We constructed evaluation datasets, and compared our results with single-agent LLM systems and machine learning approach baselines. Our findings indicate that the reliability evaluation approach is highly effective and outperforms the baselines, showing almost perfect alignment with human experts' evaluations. Moreover, both proposed evaluation approaches can be harnessed to effectively reduce hallucinations. Additionally, we identified and discussed bias limitations of the \"LLM-as-a-Judge\" technique in evaluating LLM-generated scaffolds. We suggest incorporating these approaches into GenAI-powered personalised SRL scaffolding systems to mitigate hallucination issues and improve the overall scaffolding quality.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Towards Reliable Generative AI-Driven Scaffolding: Reducing Hallucinations and Enhancing Quality in Self-Regulated Learning Support\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "towards",
      "reliable",
      "generative"
    ],
    "category": "noticia"
  },
  {
    "title": "REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition",
    "title_es": "REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition",
    "url": "https://arxiv.org/abs/2508.05933",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05933v1 Announce Type: new \nAbstract: The affective brain-computer interface is a crucial technology for affective interaction and emotional intelligence, emerging as a significant area of research in the human-computer interaction. Compared to single-type features, multi-type EEG features provide a multi-level representation for analyzing multi-dimensional emotions. However, the high dimensionality of multi-type EEG features, combined with the relatively small number of high-quality EEG samples, poses challenges such as classifier overfitting and suboptimal real-time performance in multi-dimensional emotion recognition. Moreover, practical applications of affective brain-computer interface frequently encounters partial absence of multi-dimensional emotional labels due to the open nature of the acquisition environment, and ambiguity and variability in individual emotion perception. To address these challenges, this study proposes a novel EEG feature selection method for missing multi-dimensional emotion recognition. The method leverages adaptive orthogonal non-negative matrix factorization to reconstruct the multi-dimensional emotional label space through second-order and higher-order correlations, which could reduce the negative impact of missing values and outliers on label reconstruction. Simultaneously, it employs least squares regression with graph-based manifold learning regularization and global feature redundancy minimization regularization to enable EEG feature subset selection despite missing information, ultimately achieving robust EEG-based multi-dimensional emotion recognition. Simulation experiments on three widely used multi-dimensional emotional datasets, DREAMER, DEAP and HDED, reveal that the proposed method outperforms thirteen advanced feature selection methods in terms of robustness for EEG emotional feature selection.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "refs",
      "robust",
      "eeg"
    ],
    "category": "noticia"
  },
  {
    "title": "ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection",
    "title_es": "ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection",
    "url": "https://arxiv.org/abs/2508.05934",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05934v1 Announce Type: new \nAbstract: Recently, multi-modal physiological signals based emotion recognition has garnered increasing attention in the field of brain-computer interfaces. Nevertheness, the associated multi-modal physiological features are often high-dimensional and inevitably include irrelevant, redundant, and noisy representation, which can easily lead to overfitting, poor performance, and high computational complexity in emotion classifiers. Feature selection has been widely applied to address these challenges. However, previous studies generally assumed that multi-modal physiological data are complete, whereas in reality, the data are often incomplete due to the openness of the acquisition and operational environment. For example, a part of samples are available in several modalities but not in others. To address this issue, we propose a novel method for incomplete multi-modal physiological signal feature selection called adaptive shared latent structure learning (ASLSL). Based on the property that similar features share similar emotional labels, ASLSL employs adaptive shared latent structure learning to explore a common latent space shared for incomplete multi-modal physiological signals and multi-dimensional emotional labels, thereby mitigating the impact of missing information and mining consensus information. Two most popular multi-modal physiological emotion datasets (DEAP and DREAMER) with multi-dimensional emotional labels were utilized to compare the performance between compare ASLSL and seventeen feature selection methods. Comprehensive experimental results on these datasets demonstrate the effectiveness of ASLSL.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "aslsl",
      "adaptive",
      "shared"
    ],
    "category": "noticia"
  },
  {
    "title": "Modular Vacuum-Based Fixturing System for Adaptive Disassembly Workspace Integration",
    "title_es": "Modular Vacuum-Based Fixturing System for Adaptive Disassembly Workspace Integration",
    "url": "https://arxiv.org/abs/2508.05936",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05936v1 Announce Type: new \nAbstract: The disassembly of small household appliances poses significant challenges due to their complex and curved geometries, which render traditional rigid fixtures inadequate. In this paper, we propose a modular vacuum-based fixturing system that leverages commercially available balloon-type soft grippers to conform to arbitrarily shaped surfaces and provide stable support during screw-removal tasks. To enable a reliable deployment of the system, we develop a stability-aware planning framework that samples the bottom surface of the target object, filters candidate contact points based on geometric continuity, and evaluates support configurations using convex hull-based static stability criteria. We compare the quality of object placement under different numbers and configurations of balloon hands. In addition, real-world experiments were conducted to compare the success rates of traditional rigid fixtures with our proposed system. The results demonstrate that our method consistently achieves higher success rates and superior placement stability during screw removal tasks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Modular Vacuum-Based Fixturing System for Adaptive Disassembly Workspace Integration\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "modular",
      "vacuumbased",
      "fixturing"
    ],
    "category": "noticia"
  },
  {
    "title": "Affordance-Guided Dual-Armed Disassembly Teleoperation for Mating Parts",
    "title_es": "Affordance-Guided Dual-Armed Disassembly Teleoperation for Mating Parts",
    "url": "https://arxiv.org/abs/2508.05937",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05937v1 Announce Type: new \nAbstract: Robotic non-destructive disassembly of mating parts remains challenging due to the need for flexible manipulation and the limited visibility of internal structures. This study presents an affordance-guided teleoperation system that enables intuitive human demonstrations for dual-arm fix-and-disassemble tasks for mating parts. The system visualizes feasible grasp poses and disassembly directions in a virtual environment, both derived from the object's geometry, to address occlusions and structural complexity. To prevent excessive position tracking under load when following the affordance, we integrate a hybrid controller that combines position and impedance control into the teleoperated disassembly arm. Real-world experiments validate the effectiveness of the proposed system, showing improved task success rates and reduced object pose deviation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Affordance-Guided Dual-Armed Disassembly Teleoperation for Mating Parts\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "affordanceguided",
      "dualarmed",
      "disassembly"
    ],
    "category": "noticia"
  },
  {
    "title": "Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale",
    "title_es": "Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale",
    "url": "https://arxiv.org/abs/2508.05938",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05938v1 Announce Type: new \nAbstract: Detecting prosociality in text--communication intended to affirm, support, or improve others' behavior--is a novel and increasingly important challenge for trust and safety systems. Unlike toxic content detection, prosociality lacks well-established definitions and labeled data, requiring new approaches to both annotation and deployment. We present a practical, three-stage pipeline that enables scalable, high-precision prosocial content classification while minimizing human labeling effort and inference costs. First, we identify the best LLM-based labeling strategy using a small seed set of human-labeled examples. We then introduce a human-AI refinement loop, where annotators review high-disagreement cases between GPT-4 and humans to iteratively clarify and expand the task definition-a critical step for emerging annotation tasks like prosociality. This process results in improved label quality and definition alignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train a two-stage inference system: a lightweight classifier handles high-confidence predictions, while only $\\sim$35\\% of ambiguous instances are escalated to GPT-4o. This architecture reduces inference costs by $\\sim$70% while achieving high precision ($\\sim$0.90). Our pipeline demonstrates how targeted human-AI interaction, careful task formulation, and deployment-aware architecture design can unlock scalable solutions for novel responsible AI tasks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "prosocial",
      "behavior",
      "detection"
    ],
    "category": "noticia"
  },
  {
    "title": "It's a Complete Haystack: Understanding Dependency Management Needs in Computer-Aided Design",
    "title_es": "It's a Complete Haystack: Understanding Dependency Management Needs in Computer-Aided Design",
    "url": "https://arxiv.org/abs/2508.05940",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05940v1 Announce Type: new \nAbstract: In today's landscape, hardware development teams face increasing demands for better quality products, greater innovation, and shorter manufacturing lead times. Despite the need for more efficient and effective processes, hardware designers continue to struggle with a lack of awareness of design changes and other collaborators' actions, a persistent issue in decades of CSCW research. One significant and unaddressed challenge is understanding and managing dependencies between 3D CAD (computer-aided design) models, especially when products can contain thousands of interconnected components. In this two-phase formative study, we explore designers' pain points of CAD dependency management through a thematic analysis of 100 online forum discussions and semi-structured interviews with 10 designers. We identify nine key challenges related to the traceability, navigation, and consistency of CAD dependencies, that harm the effective coordination of hardware development teams. To address these challenges, we propose design goals and necessary features to enhance hardware designers' awareness and management of dependencies, ultimately with the goal of improving collaborative workflows.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"It's a Complete Haystack: Understanding Dependency Management Needs in Computer-Aided Design\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "its",
      "a",
      "complete"
    ],
    "category": "noticia"
  },
  {
    "title": "Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution",
    "title_es": "Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution",
    "url": "https://arxiv.org/abs/2508.05941",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05941v1 Announce Type: new \nAbstract: Visuomotor policies trained via behavior cloning are vulnerable to covariate shift, where small deviations from expert trajectories can compound into failure. Common strategies to mitigate this issue involve expanding the training distribution through human-in-the-loop corrections or synthetic data augmentation. However, these approaches are often labor-intensive, rely on strong task assumptions, or compromise the quality of imitation. We introduce Latent Policy Barrier, a framework for robust visuomotor policy learning. Inspired by Control Barrier Functions, LPB treats the latent embeddings of expert demonstrations as an implicit barrier separating safe, in-distribution states from unsafe, out-of-distribution (OOD) ones. Our approach decouples the role of precise expert imitation and OOD recovery into two separate modules: a base diffusion policy solely on expert data, and a dynamics model trained on both expert and suboptimal policy rollout data. At inference time, the dynamics model predicts future latent states and optimizes them to stay within the expert distribution. Both simulated and real-world experiments show that LPB improves both policy robustness and data efficiency, enabling reliable manipulation from limited expert data and without additional human correction or annotation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "latent",
      "policy",
      "barrier"
    ],
    "category": "noticia"
  },
  {
    "title": "Social and Telepresence Robots for Accessibility and Inclusion in Small Museums",
    "title_es": "Social and Telepresence Robots for Accessibility and Inclusion in Small Museums",
    "url": "https://arxiv.org/abs/2508.05946",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05946v1 Announce Type: new \nAbstract: There are still many museums that present accessibility barriers, particularly regarding perceptual, cultural, and cognitive aspects. This is especially evident in low-density population areas. The aim of the ROBSO-PM project is to improve the accessibility of small museums through the use of social robots and social telepresence robots, focusing on three museums as case studies: the Museum of the Holy Shroud in Turin, a small but globally known institution, and two lesser known mountain museums: the Museum of the Champlas du Col Carnival and the Pragelato Museum of Alpine Peoples' Costumes and Traditions. The project explores two main applications for robots: as guides supporting inclusive visits for foreign or disabled visitors, and as telepresence tools allowing people with limited mobility to access museums remotely. From a research perspective, key topics include storytelling, robot personality, empathy, personalization, and, in the case of telepresence, collaboration between the robot and the person, with clearly defined roles and autonomy.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Social and Telepresence Robots for Accessibility and Inclusion in Small Museums\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "social",
      "and",
      "telepresence"
    ],
    "category": "noticia"
  },
  {
    "title": "A Minimal Perturbation Approach For The Rectangular Multiparameter Eigenvalue Problem",
    "title_es": "A Minimal Perturbation Approach For The Rectangular Multiparameter Eigenvalue Problem",
    "url": "https://arxiv.org/abs/2508.05948",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05948v1 Announce Type: new \nAbstract: The rectangular multiparameter eigenvalue problem (RMEP) involves rectangular coefficient matrices (usually with more rows than columns) and may potentially have no solution in its original form. A minimal perturbation framework is proposed to defines approximate solutions. Computationally, two particular scenarios are considered: computing one approximate eigen-tuple or a complete set of approximate eigen-tuples. For computing one approximate eigen-tuple, an alternating iterative scheme with proven convergence is devised, while for a complete set of approximate eigen-tuples, the framework leads to a standard MEP (RMEP with square coefficient matrices) for numerical solutions. The proposed approach is validated on RMEPs from discretizing the multiparameter Sturm-Liouville equation and the Helmholtz equations by the least-squares spectral method.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Minimal Perturbation Approach For The Rectangular Multiparameter Eigenvalue Problem\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "minimal",
      "perturbation"
    ],
    "category": "noticia"
  },
  {
    "title": "A Survey on Task Scheduling in Carbon-Aware Container Orchestration",
    "title_es": "A Survey on Task Scheduling in Carbon-Aware Container Orchestration",
    "url": "https://arxiv.org/abs/2508.05949",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05949v1 Announce Type: new \nAbstract: The soaring energy demands of large-scale software ecosystems and cloud data centers, accelerated by the intensive training and deployment of large language models, have driven energy consumption and carbon footprint to unprecedented levels. In response, both industry and academia are increasing efforts to reduce the carbon emissions associated with cloud computing through more efficient task scheduling and infrastructure orchestration. In this work, we present a systematic review of various Kubernetes scheduling strategies, categorizing them into hardware-centric and software-centric, annotating each with its sustainability objectives, and grouping them according to the algorithms they use. We propose a comprehensive taxonomy for cloud task scheduling studies, with a particular focus on the environmental sustainability aspect. We analyze emerging research trends and open challenges, and our findings provide critical insight into the design of sustainable scheduling solutions for next-generation cloud computing systems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Survey on Task Scheduling in Carbon-Aware Container Orchestration\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "survey",
      "on"
    ],
    "category": "noticia"
  },
  {
    "title": "A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image",
    "title_es": "A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image",
    "url": "https://arxiv.org/abs/2508.05950",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05950v1 Announce Type: new \nAbstract: The lack of spatial dimensional information remains a challenge in normal estimation from a single image. Recent diffusion-based methods have demonstrated significant potential in 2D-to-3D implicit mapping, they rely on data-driven statistical priors and miss the explicit modeling of light-surface interaction, leading to multi-view normal direction conflicts. Moreover, the discrete sampling mechanism of diffusion models causes gradient discontinuity in differentiable rendering reconstruction modules, preventing 3D geometric errors from being backpropagated to the normal generation network, thereby forcing existing methods to depend on dense normal annotations. This paper proposes SINGAD, a novel Self-supervised framework from a single Image for Normal estimation via 3D GAussian splatting guided Diffusion. By integrating physics-driven light-interaction modeling and a differentiable rendering-based reprojection strategy, our framework directly converts 3D geometric errors into normal optimization signals, solving the challenges of multi-view geometric inconsistency and data dependency. Specifically, the framework constructs a light-interaction-driven 3DGS reparameterization model to generate multi-scale geometric features consistent with light transport principles, ensuring multi-view normal consistency. A cross-domain feature fusion module is designed within a conditional diffusion model, embedding geometric priors to constrain normal generation while maintaining accurate geometric error propagation. Furthermore, a differentiable 3D reprojection loss strategy is introduced for self-supervised optimization that minimizes geometric error between the reconstructed and input image, eliminating dependence on annotated normal datasets. Quantitative evaluations on the Google Scanned Objects dataset demonstrate that our method outperforms state-of-the-art approaches across multiple metrics.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "dgsdiffusion",
      "selfsupervised"
    ],
    "category": "noticia"
  },
  {
    "title": "Dean of LLM Tutors: Exploring Comprehensive and Automated Evaluation of LLM-generated Educational Feedback via LLM Feedback Evaluators",
    "title_es": "Dean of LLM Tutors: Exploring Comprehensive and Automated Evaluation of LLM-generated Educational Feedback via LLM Feedback Evaluators",
    "url": "https://arxiv.org/abs/2508.05952",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05952v1 Announce Type: new \nAbstract: The use of LLM tutors to provide automated educational feedback to students on student assignment submissions has received much attention in the AI in Education field. However, the stochastic nature and tendency for hallucinations in LLMs can undermine both quality of learning experience and adherence to ethical standards. To address this concern, we propose a method that uses LLM feedback evaluators (DeanLLMs) to automatically and comprehensively evaluate feedback generated by LLM tutor for submissions on university assignments before it is delivered to students. This allows low-quality feedback to be rejected and enables LLM tutors to improve the feedback they generated based on the evaluation results. We first proposed a comprehensive evaluation framework for LLM-generated educational feedback, comprising six dimensions for feedback content, seven for feedback effectiveness, and three for hallucination types. Next, we generated a virtual assignment submission dataset covering 85 university assignments from 43 computer science courses using eight commonly used commercial LLMs. We labelled and open-sourced the assignment dataset to support the fine-tuning and evaluation of LLM feedback evaluators. Our findings show that o3-pro demonstrated the best performance in zero-shot labelling of feedback while o4-mini demonstrated the best performance in few-shot labelling of feedback. Moreover, GPT-4.1 achieved human expert level performance after fine-tuning (Accuracy 79.8%, F1-score 79.4%; human average Accuracy 78.3%, F1-score 82.6%). Finally, we used our best-performance model to evaluate 2,000 assignment feedback instances generated by 10 common commercial LLMs, 200 each, to compare the quality of feedback generated by different LLMs. Our LLM feedback evaluator method advances our ability to automatically provide high-quality and reliable educational feedback to students.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Dean of LLM Tutors: Exploring Comprehensive and Automated Evaluation of LLM-generated Educational Feedback via LLM Feedback Evaluators\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dean",
      "of",
      "llm"
    ],
    "category": "noticia"
  },
  {
    "title": "SCALEFeedback: A Large-Scale Dataset of Synthetic Computer Science Assignments for LLM-generated Educational Feedback Research",
    "title_es": "SCALEFeedback: A Large-Scale Dataset of Synthetic Computer Science Assignments for LLM-generated Educational Feedback Research",
    "url": "https://arxiv.org/abs/2508.05953",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05953v1 Announce Type: new \nAbstract: Using LLMs to give educational feedback to students for their assignments has attracted much attention in the AI in Education field. Yet, there is currently no large-scale open-source dataset of student assignments that includes detailed assignment descriptions, rubrics, and student submissions across various courses. As a result, research on generalisable methodology for automatic generation of effective and responsible educational feedback remains limited. In the current study, we constructed a large-scale dataset of Synthetic Computer science Assignments for LLM-generated Educational Feedback research (SCALEFeedback). We proposed a Sophisticated Assignment Mimicry (SAM) framework to generate the synthetic dataset by one-to-one LLM-based imitation from real assignment descriptions, student submissions to produce their synthetic versions. Our open-source dataset contains 10,000 synthetic student submissions spanning 155 assignments across 59 university-level computer science courses. Our synthetic submissions achieved BERTScore F1 0.84, PCC of 0.62 for assignment marks and 0.85 for length, compared to the corresponding real-world assignment dataset, while ensuring perfect protection of student private information. All these results of our SAM framework outperformed results of a naive mimicry method baseline. The LLM-generated feedback for our synthetic assignments demonstrated the same level of effectiveness compared to that of real-world assignment dataset. Our research showed that one-to-one LLM imitation is a promising method for generating open-source synthetic educational datasets that preserve the original dataset's semantic meaning and student data distribution, while protecting student privacy and institutional copyright. SCALEFeedback enhances our ability to develop LLM-based generalisable methods for offering high-quality, automated educational feedback in a scalable way.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SCALEFeedback: A Large-Scale Dataset of Synthetic Computer Science Assignments for LLM-generated Educational Feedback Research\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "scalefeedback",
      "a",
      "largescale"
    ],
    "category": "noticia"
  },
  {
    "title": "Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents",
    "title_es": "Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents",
    "url": "https://arxiv.org/abs/2508.05954",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05954v1 Announce Type: new \nAbstract: There is growing interest in integrating high-fidelity visual synthesis capabilities into large language models (LLMs) without compromising their strong reasoning capabilities. Existing methods that directly train LLMs or bridge LLMs and diffusion models usually suffer from costly training since the backbone LLMs have not seen image representations during pretraining. We present Bifrost-1, a unified framework that bridges pretrained multimodal LLMs (MLLMs) and diffusion models using patch-level CLIP image embeddings as latent variables, which are natively aligned with the MLLM's CLIP visual encoder. These patch-level image embeddings are integrated into the diffusion model with a lightweight adaptation of its ControlNet. To retain the original multimodal reasoning capabilities of MLLMs, we equip the MLLM with a visual generation branch initialized from the original MLLM parameters when predicting the patch-level image embeddings. By seamlessly integrating pretrained MLLMs and diffusion models with patch-level CLIP latents, our framework enables high-fidelity controllable image generation with significant training efficiency. Our experiments demonstrate that Bifrost-1 achieves comparable or better performance than previous methods in terms of visual fidelity and multimodal understanding, with substantially lower compute during training. We also provide comprehensive ablation studies showing the effectiveness of our design choices.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "bifrost",
      "bridging",
      "multimodal"
    ],
    "category": "noticia"
  },
  {
    "title": "Multi-Armed Bandits-Based Optimization of Decision Trees",
    "title_es": "Multi-Armed Bandits-Based Optimization of Decision Trees",
    "url": "https://arxiv.org/abs/2508.05957",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05957v1 Announce Type: new \nAbstract: Decision trees, without appropriate constraints, can easily become overly complex and prone to overfit, capturing noise rather than generalizable patterns. To resolve this problem,pruning operation is a crucial part in optimizing decision trees, as it not only reduces the complexity of trees but also decreases the probability of generating overfit models. The conventional pruning techniques like Cost-Complexity Pruning (CCP) and Reduced Error Pruning (REP) are mostly based on greedy approaches that focus on immediate gains in performance while pruning nodes of the decision tree. However, this might result in a lower generalization in the long run, compromising the robust ability of the tree model when introduced to unseen data samples, particularly when trained with small and complex datasets. To address this challenge, we are proposing a Multi-Armed Bandits (MAB)-based pruning approach, a reinforcement learning (RL)-based technique, that will dynamically prune the tree to generate an optimal decision tree with better generalization. Our proposed approach assumes the pruning process as an exploration-exploitation problem, where we are utilizing the MAB algorithms to find optimal branch nodes to prune based on feedback from each pruning actions. Experimental evaluation on several benchmark datasets, demonstrated that our proposed approach results in better predictive performance compared to the traditional ones. This suggests the potential of utilizing MAB for a dynamic and probabilistic way of decision tree pruning, in turn optimizing the decision tree-based model.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Multi-Armed Bandits-Based Optimization of Decision Trees\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "multiarmed",
      "banditsbased",
      "optimization"
    ],
    "category": "noticia"
  },
  {
    "title": "Hierarchical Tucker Low-Rank Matrices: Construction and Matrix-Vector Multiplication",
    "title_es": "Hierarchical Tucker Low-Rank Matrices: Construction and Matrix-Vector Multiplication",
    "url": "https://arxiv.org/abs/2508.05958",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05958v1 Announce Type: new \nAbstract: In this paper, a hierarchical Tucker low-rank (HTLR) matrix is proposed to approximate non-oscillatory kernel functions in linear complexity. The HTLR matrix is based on the hierarchical matrix, with the low-rank blocks replaced by Tucker low-rank blocks. Using high-dimensional interpolation as well as tensor contractions, algorithms for the construction and matrix-vector multiplication of HTLR matrices are proposed admitting linear and quasi-linear complexities respectively. Numerical experiments demonstrate that the HTLR matrix performs well in both memory and runtime. Furthermore, the HTLR matrix can also be applied on quasi-uniform grids in addition to uniform grids, enhancing its versatility.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hierarchical Tucker Low-Rank Matrices: Construction and Matrix-Vector Multiplication\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hierarchical",
      "tucker",
      "lowrank"
    ],
    "category": "noticia"
  },
  {
    "title": "Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning",
    "title_es": "Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.05960",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05960v1 Announce Type: new \nAbstract: Offline reinforcement learning (RL) seeks to learn optimal policies from static datasets without further environment interaction. A key challenge is the distribution shift between the learned and behavior policies, leading to out-of-distribution (OOD) actions and overestimation. To prevent gross overestimation, the value function must remain conservative; however, excessive conservatism may hinder performance improvement. To address this, we propose the mildly conservative regularized evaluation (MCRE) framework, which balances conservatism and performance by combining temporal difference (TD) error with a behavior cloning term in the Bellman backup. Building on this, we develop the mildly conservative regularized Q-learning (MCRQ) algorithm, which integrates MCRE into an off-policy actor-critic framework. Experiments show that MCRQ outperforms strong baselines and state-of-the-art offline RL algorithms on benchmark datasets.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mildly",
      "conservative",
      "regularized"
    ],
    "category": "noticia"
  },
  {
    "title": "Bionic Vision as Neuroadaptive XR: Closed-Loop Perceptual Interfaces for Neurotechnology",
    "title_es": "Bionic Vision as Neuroadaptive XR: Closed-Loop Perceptual Interfaces for Neurotechnology",
    "url": "https://arxiv.org/abs/2508.05963",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05963v1 Announce Type: new \nAbstract: Visual neuroprostheses are commonly framed as technologies to restore natural sight to people who are blind. In practice, they create a novel mode of perception shaped by sparse, distorted, and unstable input. They resemble early extended reality (XR) headsets more than natural vision, streaming video from a head-mounted camera to a neural \"display\" with under 1000 pixels, limited field of view, low refresh rates, and nonlinear spatial mappings. No amount of resolution alone will make this experience natural. This paper proposes a reframing: bionic vision as neuroadaptive XR. Rather than replicating natural sight, the goal is to co-adapt brain and device through a bidirectional interface that responds to neural constraints, behavioral goals, and cognitive state. By comparing traditional XR, current implants, and proposed neuroadaptive systems, it introduces a new design space for inclusive, brain-aware computing. It concludes with research provocations spanning encoding, evaluation, learning, and ethics, and invites the XR community to help shape the future of sensory augmentation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Bionic Vision as Neuroadaptive XR: Closed-Loop Perceptual Interfaces for Neurotechnology\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "bionic",
      "vision",
      "as"
    ],
    "category": "noticia"
  },
  {
    "title": "Dual prototype attentive graph network for cross-market recommendation",
    "title_es": "Dual prototype attentive graph network for cross-market recommendation",
    "url": "https://arxiv.org/abs/2508.05969",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05969v1 Announce Type: new \nAbstract: Cross-market recommender systems (CMRS) aim to utilize historical data from mature markets to promote multinational products in emerging markets. However, existing CMRS approaches often overlook the potential for shared preferences among users in different markets, focusing primarily on modeling specific preferences within each market. In this paper, we argue that incorporating both market-specific and market-shared insights can enhance the generalizability and robustness of CMRS. We propose a novel approach called Dual Prototype Attentive Graph Network for Cross-Market Recommendation (DGRE) to address this. DGRE leverages prototypes based on graph representation learning from both items and users to capture market-specific and market-shared insights. Specifically, DGRE incorporates market-shared prototypes by clustering users from various markets to identify behavioural similarities and create market-shared user profiles. Additionally, it constructs item-side prototypes by aggregating item features within each market, providing valuable market-specific insights. We conduct extensive experiments to validate the effectiveness of DGRE on a real-world cross-market dataset, and the results show that considering both market-specific and market-sharing aspects in modelling can improve the generalization and robustness of CMRS.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Dual prototype attentive graph network for cross-market recommendation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dual",
      "prototype",
      "attentive"
    ],
    "category": "noticia"
  },
  {
    "title": "Impact-driven Context Filtering For Cross-file Code Completion",
    "title_es": "Impact-driven Context Filtering For Cross-file Code Completion",
    "url": "https://arxiv.org/abs/2508.05970",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05970v1 Announce Type: new \nAbstract: Retrieval-augmented generation (RAG) has recently demonstrated considerable potential for repository-level code completion, as it integrates cross-file knowledge with in-file preceding code to provide comprehensive contexts for generation. To better understand the contribution of the retrieved cross-file contexts, we introduce a likelihood-based metric to evaluate the impact of each retrieved code chunk on the completion. Our analysis reveals that, despite retrieving numerous chunks, only a small subset positively contributes to the completion, while some chunks even degrade performance. To address this issue, we leverage this metric to construct a repository-level dataset where each retrieved chunk is labeled as positive, neutral, or negative based on its relevance to the target completion. We then propose an adaptive retrieval context filtering framework, CODEFILTER, trained on this dataset to mitigate the harmful effects of negative retrieved contexts in code completion. Extensive evaluation on the RepoEval and CrossCodeLongEval benchmarks demonstrates that CODEFILTER consistently improves completion accuracy compared to approaches without filtering operations across various tasks. Additionally, CODEFILTER significantly reduces the length of the input prompt, enhancing computational efficiency while exhibiting strong generalizability across different models. These results underscore the potential of CODEFILTER to enhance the accuracy, efficiency, and attributability of repository-level code completion.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Impact-driven Context Filtering For Cross-file Code Completion\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "impactdriven",
      "context",
      "filtering"
    ],
    "category": "noticia"
  },
  {
    "title": "Dynamical Trajectory Planning of Disturbance Consciousness for Air-Land Bimodal Unmanned Aerial Vehicles",
    "title_es": "Dynamical Trajectory Planning of Disturbance Consciousness for Air-Land Bimodal Unmanned Aerial Vehicles",
    "url": "https://arxiv.org/abs/2508.05972",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05972v1 Announce Type: new \nAbstract: Air-land bimodal vehicles provide a promising solution for navigating complex environments by combining the flexibility of aerial locomotion with the energy efficiency of ground mobility. To enhance the robustness of trajectory planning under environmental disturbances, this paper presents a disturbance-aware planning framework that incorporates real-time disturbance estimation into both path searching and trajectory optimization. A key component of the framework is a disturbance-adaptive safety boundary adjustment mechanism, which dynamically modifies the vehicle's feasible dynamic boundaries based on estimated disturbances to ensure trajectory feasibility. Leveraging the dynamics model of the bimodal vehicle, the proposed approach achieves adaptive and reliable motion planning across different terrains and operating conditions. A series of real-world experiments and benchmark comparisons on a custom-built platform validate the effectiveness and robustness of the method, demonstrating improvements in tracking accuracy, task efficiency, and energy performance under both ground and aerial disturbances.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Dynamical Trajectory Planning of Disturbance Consciousness for Air-Land Bimodal Unmanned Aerial Vehicles\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dynamical",
      "trajectory",
      "planning"
    ],
    "category": "noticia"
  },
  {
    "title": "PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation",
    "title_es": "PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation",
    "url": "https://arxiv.org/abs/2508.05976",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05976v1 Announce Type: new \nAbstract: The fragmentation between high-level task semantics and low-level geometric features remains a persistent challenge in robotic manipulation. While vision-language models (VLMs) have shown promise in generating affordance-aware visual representations, the lack of semantic grounding in canonical spaces and reliance on manual annotations severely limit their ability to capture dynamic semantic-affordance relationships. To address these, we propose Primitive-Aware Semantic Grounding (PASG), a closed-loop framework that introduces: (1) Automatic primitive extraction through geometric feature aggregation, enabling cross-category detection of keypoints and axes; (2) VLM-driven semantic anchoring that dynamically couples geometric primitives with functional affordances and task-relevant description; (3) A spatial-semantic reasoning benchmark and a fine-tuned VLM (Qwen2.5VL-PA). We demonstrate PASG's effectiveness in practical robotic manipulation tasks across diverse scenarios, achieving performance comparable to manual annotations. PASG achieves a finer-grained semantic-affordance understanding of objects, establishing a unified paradigm for bridging geometric primitives with task semantics in robotic manipulation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "pasg",
      "a",
      "closedloop"
    ],
    "category": "noticia"
  },
  {
    "title": "LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning",
    "title_es": "LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.05977",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05977v1 Announce Type: new \nAbstract: In the domain of scientific machine learning, designing effective reward functions remains a challenge in reinforcement learning (RL), particularly in environments where task goals are difficult to specify numerically. Reward functions in existing work are predominantly based on heuristics, manual engineering, or task-specific tuning. In this work, we introduce a semantically aligned reinforcement learning method where rewards are computed by aligning the current state with a target semantic instruction using a Sentence-Bidirectional Encoder Representations from Transformers (SBERT). Instead of relying on manually defined reward functions, the policy receives feedback based on the reward, which is a cosine similarity between the goal textual description and the statement description in the episode. We evaluated our approach in several environments and showed that semantic reward can guide learning to achieve competitive control behavior, even in the absence of hand-crafted reward functions. Our study demonstrates a correlation between the language embedding space and the conventional Euclidean space. This framework opens new horizons for aligning agent behavior with natural language goals and lays the groundwork for a more seamless integration of larger language models (LLMs) and fluid control applications.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "linguafluid",
      "language",
      "guided"
    ],
    "category": "noticia"
  },
  {
    "title": "DAFMSVC: One-Shot Singing Voice Conversion with Dual Attention Mechanism and Flow Matching",
    "title_es": "DAFMSVC: One-Shot Singing Voice Conversion with Dual Attention Mechanism and Flow Matching",
    "url": "https://arxiv.org/abs/2508.05978",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05978v1 Announce Type: new \nAbstract: Singing Voice Conversion (SVC) transfers a source singer's timbre to a target while keeping melody and lyrics. The key challenge in any-to-any SVC is adapting unseen speaker timbres to source audio without quality degradation. Existing methods either face timbre leakage or fail to achieve satisfactory timbre similarity and quality in the generated audio. To address these challenges, we propose DAFMSVC, where the self-supervised learning (SSL) features from the source audio are replaced with the most similar SSL features from the target audio to prevent timbre leakage. It also incorporates a dual cross-attention mechanism for the adaptive fusion of speaker embeddings, melody, and linguistic content. Additionally, we introduce a flow matching module for high quality audio generation from the fused features. Experimental results show that DAFMSVC significantly enhances timbre similarity and naturalness, outperforming state-of-the-art methods in both subjective and objective evaluations.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DAFMSVC: One-Shot Singing Voice Conversion with Dual Attention Mechanism and Flow Matching\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dafmsvc",
      "oneshot",
      "singing"
    ],
    "category": "noticia"
  },
  {
    "title": "Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education",
    "title_es": "Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education",
    "url": "https://arxiv.org/abs/2508.05979",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05979v1 Announce Type: new \nAbstract: While Large Language Models (LLMs) are often used as virtual tutors in computer science (CS) education, this approach can foster passive learning and over-reliance. This paper presents a novel pedagogical paradigm that inverts this model: students act as instructors who must teach an LLM to solve problems. To facilitate this, we developed strategies for designing questions with engineered knowledge gaps that only a student can bridge, and we introduce Socrates, a system for deploying this method with minimal overhead. We evaluated our approach in an undergraduate course and found that this active-learning method led to statistically significant improvements in student performance compared to historical cohorts. Our work demonstrates a practical, cost-effective framework for using LLMs to deepen student engagement and mastery.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "learning",
      "by",
      "teaching"
    ],
    "category": "noticia"
  },
  {
    "title": "AnimateScene: Camera-controllable Animation in Any Scene",
    "title_es": "AnimateScene: Camera-controllable Animation in Any Scene",
    "url": "https://arxiv.org/abs/2508.05982",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05982v1 Announce Type: new \nAbstract: 3D scene reconstruction and 4D human animation have seen rapid progress and broad adoption in recent years. However, seamlessly integrating reconstructed scenes with 4D human animation to produce visually engaging results remains challenging. One key difficulty lies in placing the human at the correct location and scale within the scene while avoiding unrealistic interpenetration. Another challenge is that the human and the background may exhibit different lighting and style, leading to unrealistic composites. In addition, appealing character motion videos are often accompanied by camera movements, which means that the viewpoints need to be reconstructed along a specified trajectory. We present AnimateScene, which addresses the above issues in a unified framework. First, we design an accurate placement module that automatically determines a plausible 3D position for the human and prevents any interpenetration within the scene during motion. Second, we propose a training-free style alignment method that adapts the 4D human representation to match the background's lighting and style, achieving coherent visual integration. Finally, we design a joint post-reconstruction method for both the 4D human and the 3D scene that allows camera trajectories to be inserted, enabling the final rendered video to feature visually appealing camera movements. Extensive experiments show that AnimateScene generates dynamic scene videos with high geometric detail and spatiotemporal coherence across various camera and action combinations.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AnimateScene: Camera-controllable Animation in Any Scene\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "animatescene",
      "cameracontrollable",
      "animation"
    ],
    "category": "noticia"
  },
  {
    "title": "Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning",
    "title_es": "Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning",
    "url": "https://arxiv.org/abs/2508.05984",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05984v1 Announce Type: new \nAbstract: Algorithms for solving \\textit{nonlinear} fixed-point equations -- such as average-reward \\textit{$Q$-learning} and \\textit{TD-learning} -- often involve semi-norm contractions. Achieving parameter-free optimal convergence rates for these methods via Polyak--Ruppert averaging has remained elusive, largely due to the non-monotonicity of such semi-norms. We close this gap by (i.) recasting the averaged error as a linear recursion involving a nonlinear perturbation, and (ii.) taming the nonlinearity by coupling the semi-norm's contraction with the monotonicity of a suitably induced norm. Our main result yields the first parameter-free $\\tilde{O}(1/\\sqrt{t})$ optimal rates for $Q$-learning in both average-reward and exponentially discounted settings, where $t$ denotes the iteration index. The result applies within a broad framework that accommodates synchronous and asynchronous updates, single-agent and distributed deployments, and data streams obtained either from simulators or along Markovian trajectories.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "parameterfree",
      "optimal",
      "rates"
    ],
    "category": "noticia"
  },
  {
    "title": "Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring",
    "title_es": "Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring",
    "url": "https://arxiv.org/abs/2508.05987",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05987v1 Announce Type: new \nAbstract: Cross-topic automated essay scoring (AES) aims to develop a transferable model capable of effectively evaluating essays on a target topic. A significant challenge in this domain arises from the inherent discrepancies between topics. While existing methods predominantly focus on extracting topic-shared features through distribution alignment of source and target topics, they often neglect topic-specific features, limiting their ability to assess critical traits such as topic adherence. To address this limitation, we propose an Adversarial TOpic-aware Prompt-tuning (ATOP), a novel method that jointly learns topic-shared and topic-specific features to improve cross-topic AES. ATOP achieves this by optimizing a learnable topic-aware prompt--comprising both shared and specific components--to elicit relevant knowledge from pre-trained language models (PLMs). To enhance the robustness of topic-shared prompt learning and mitigate feature scale sensitivity introduced by topic alignment, we incorporate adversarial training within a unified regression and classification framework. In addition, we employ a neighbor-based classifier to model the local structure of essay representations and generate pseudo-labels for target-topic essays. These pseudo-labels are then used to guide the supervised learning of topic-specific prompts tailored to the target topic. Extensive experiments on the publicly available ASAP++ dataset demonstrate that ATOP significantly outperforms existing state-of-the-art methods in both holistic and multi-trait essay scoring. The implementation of our method is publicly available at: https://anonymous.4open.science/r/ATOP-A271.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "adversarial",
      "topicaware",
      "prompttuning"
    ],
    "category": "noticia"
  },
  {
    "title": "Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal",
    "title_es": "Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal",
    "url": "https://arxiv.org/abs/2508.05988",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05988v1 Announce Type: new \nAbstract: Recently, Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in code reasoning by scaling up the length of Chain-of-Thought (CoT). However, excessively long reasoning traces introduce substantial challenges in terms of training cost, inference latency, and deployment feasibility. While various CoT compression approaches have emerged to address this challenge, they face inherent trade-offs: token-level methods often disrupt syntactic and logical coherence, while step-level methods based on perplexity fail to reliably capture the logically critical reasoning steps. In this paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided pruning to preserve the core reasoning structure, which efficiently reduces the search space for subsequent processing. It then enables a logic-aware pruning by selecting logically essential reasoning steps based on a novel first-token surprisal metric. Finally, ASAP teaches models to autonomously generate and leverage these concise CoTs at inference time, enabling efficient reasoning in coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy across multiple code generation benchmarks while substantially reducing training and inference costs. On the challenging LiveCodeBench v4_v5 benchmark, our approach reduces token generation by 23.5% and inference latency by 43.5% compared to the strongest baseline, while achieving a competitive accuracy of 36.19% in Pass@1. Our results highlight a promising direction for building powerful and efficient LRMs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "pruning",
      "the",
      "unsurprising"
    ],
    "category": "noticia"
  },
  {
    "title": "ETA: Energy-based Test-time Adaptation for Depth Completion",
    "title_es": "ETA: Energy-based Test-time Adaptation for Depth Completion",
    "url": "https://arxiv.org/abs/2508.05989",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05989v1 Announce Type: new \nAbstract: We propose a method for test-time adaptation of pretrained depth completion models. Depth completion models, trained on some ``source'' data, often predict erroneous outputs when transferred to ``target'' data captured in novel environmental conditions due to a covariate shift. The crux of our method lies in quantifying the likelihood of depth predictions belonging to the source data distribution. The challenge is in the lack of access to out-of-distribution (target) data prior to deployment. Hence, rather than making assumptions regarding the target distribution, we utilize adversarial perturbations as a mechanism to explore the data space. This enables us to train an energy model that scores local regions of depth predictions as in- or out-of-distribution. We update the parameters of pretrained depth completion models at test time to minimize energy, effectively aligning test-time predictions to those of the source distribution. We call our method ``Energy-based Test-time Adaptation'', or ETA for short. We evaluate our method across three indoor and three outdoor datasets, where ETA improve over the previous state-of-the-art method by an average of 6.94% for outdoors and 10.23% for indoors. Project Page: https://fuzzythecat.github.io/eta.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ETA: Energy-based Test-time Adaptation for Depth Completion\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "eta",
      "energybased",
      "testtime"
    ],
    "category": "noticia"
  },
  {
    "title": "Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision",
    "title_es": "Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision",
    "url": "https://arxiv.org/abs/2508.05990",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05990v1 Announce Type: new \nAbstract: The efficiency of video computer vision system remains a challenging task due to the high temporal redundancy inside a video. Existing works have been proposed for efficient vision computer vision. However, they do not fully reduce the temporal redundancy and neglect the front end computation overhead. In this paper, we propose an efficient video computer vision system. First, image signal processor is removed and Bayer-format data is directly fed into video computer vision models, thus saving the front end computation. Second, instead of optical flow models and video codecs, a fast block matching-based motion estimation algorithm is proposed specifically for efficient video computer vision, with a MV refinement module. To correct the error, context-aware block refinement network is introduced to refine regions with large error. To further balance the accuracy and efficiency, a frame selection strategy is employed. Experiments on multiple video computer vision tasks demonstrate that our method achieves significant acceleration with slight performance loss.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fast",
      "motion",
      "estimation"
    ],
    "category": "noticia"
  },
  {
    "title": "ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge",
    "title_es": "ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge",
    "url": "https://arxiv.org/abs/2508.05991",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05991v1 Announce Type: new \nAbstract: Emotion recognition plays a vital role in enhancing human-computer interaction. In this study, we tackle the MER-SEMI challenge of the MER2025 competition by proposing a novel multimodal emotion recognition framework. To address the issue of data scarcity, we leverage large-scale pre-trained models to extract informative features from visual, audio, and textual modalities. Specifically, for the visual modality, we design a dual-branch visual encoder that captures both global frame-level features and localized facial representations. For the textual modality, we introduce a context-enriched method that employs large language models to enrich emotional cues within the input text. To effectively integrate these multimodal features, we propose a fusion strategy comprising two key components, i.e., self-attention mechanisms for dynamic modality weighting, and residual connections to preserve original representations. Beyond architectural design, we further refine noisy labels in the training set by a multi-source labeling strategy. Our approach achieves a substantial performance improvement over the official baseline on the MER2025-SEMI dataset, attaining a weighted F-score of 87.49% compared to 78.63%, thereby validating the effectiveness of the proposed framework.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ecmf",
      "enhanced",
      "crossmodal"
    ],
    "category": "noticia"
  },
  {
    "title": "Surviving the Narrative Collapse: Sustainability and Justice in Computing Within Limits",
    "title_es": "Surviving the Narrative Collapse: Sustainability and Justice in Computing Within Limits",
    "url": "https://arxiv.org/abs/2508.05992",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05992v1 Announce Type: new \nAbstract: Sustainability-driven computing research - encompassing equity, diversity, climate change, and social justice - is increasingly dismissed as woke or even dangerous in many sociopolitical contexts. As misinformation, ideological polarisation, deliberate ignorance and reactionary narratives gain ground, how can sustainability research in computing continue to exist and make an impact? This paper explores these tensions through Fictomorphosis, a creative story retelling method that reframes contested topics through different genres and perspectives. By engaging computing researchers in structured narrative transformations, we investigate how sustainability-oriented computing research is perceived, contested, and can adapt in a post-truth world.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Surviving the Narrative Collapse: Sustainability and Justice in Computing Within Limits\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "surviving",
      "the",
      "narrative"
    ],
    "category": "noticia"
  },
  {
    "title": "Efficient Multimodal Streaming Recommendation via Expandable Side Mixture-of-Experts",
    "title_es": "Efficient Multimodal Streaming Recommendation via Expandable Side Mixture-of-Experts",
    "url": "https://arxiv.org/abs/2508.05993",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05993v1 Announce Type: new \nAbstract: Streaming recommender systems (SRSs) are widely deployed in real-world applications, where user interests shift and new items arrive over time. As a result, effectively capturing users' latest preferences is challenging, as interactions reflecting recent interests are limited and new items often lack sufficient feedback. A common solution is to enrich item representations using multimodal encoders (e.g., BERT or ViT) to extract visual and textual features. However, these encoders are pretrained on general-purpose tasks: they are not tailored to user preference modeling, and they overlook the fact that user tastes toward modality-specific features such as visual styles and textual tones can also drift over time. This presents two key challenges in streaming scenarios: the high cost of fine-tuning large multimodal encoders, and the risk of forgetting long-term user preferences due to continuous model updates.\n  To tackle these challenges, we propose Expandable Side Mixture-of-Experts (XSMoE), a memory-efficient framework for multimodal streaming recommendation. XSMoE attaches lightweight side-tuning modules consisting of expandable expert networks to frozen pretrained encoders and incrementally expands them in response to evolving user feedback. A gating router dynamically combines expert and backbone outputs, while a utilization-based pruning strategy maintains model compactness. By learning new patterns through expandable experts without overwriting previously acquired knowledge, XSMoE effectively captures both cold start and shifting preferences in multimodal features. Experiments on three real-world datasets demonstrate that XSMoE outperforms state-of-the-art baselines in both recommendation quality and computational efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Efficient Multimodal Streaming Recommendation via Expandable Side Mixture-of-Experts\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "efficient",
      "multimodal",
      "streaming"
    ],
    "category": "noticia"
  },
  {
    "title": "EvoMakeup: High-Fidelity and Controllable Makeup Editing with MakeupQuad",
    "title_es": "EvoMakeup: High-Fidelity and Controllable Makeup Editing with MakeupQuad",
    "url": "https://arxiv.org/abs/2508.05994",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05994v1 Announce Type: new \nAbstract: Facial makeup editing aims to realistically transfer makeup from a reference to a target face. Existing methods often produce low-quality results with coarse makeup details and struggle to preserve both identity and makeup fidelity, mainly due to the lack of structured paired data -- where source and result share identity, and reference and result share identical makeup. To address this, we introduce MakeupQuad, a large-scale, high-quality dataset with non-makeup faces, references, edited results, and textual makeup descriptions. Building on this, we propose EvoMakeup, a unified training framework that mitigates image degradation during multi-stage distillation, enabling iterative improvement of both data and model quality. Although trained solely on synthetic data, EvoMakeup generalizes well and outperforms prior methods on real-world benchmarks. It supports high-fidelity, controllable, multi-task makeup editing -- including full-face and partial reference-based editing, as well as text-driven makeup editing -- within a single model. Experimental results demonstrate that our method achieves superior makeup fidelity and identity preservation, effectively balancing both aspects. Code and dataset will be released upon acceptance.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"EvoMakeup: High-Fidelity and Controllable Makeup Editing with MakeupQuad\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "evomakeup",
      "highfidelity",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization",
    "title_es": "Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization",
    "url": "https://arxiv.org/abs/2508.05995",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05995v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated remarkable capabilities in code generation and structured reasoning; however, their performance often degrades on complex tasks that require consistent multi-step planning. Recent work has explored combining LLMs with Monte Carlo Tree Search (MCTS), yet existing approaches primarily focus on generating heuristic-based code for optimization or target simpler tasks where correctness alone is sufficient. In this work, we propose MCTS-OPS, a novel neural-symbolic framework that formulates prompt selection as a sequential decision process guided by MCTS. Our method explores and refines multi-step prompt sequences for the goal of improving code generation quality and enhancing the problem-solving capabilities of LLMs in general optimization. Experiments on network optimization show significant improvement over the baselines, both in the success rate of executing the generated code and in the optimization results with the specified objective and constraints (2$\\sim$4$\\times$ higher reward and 3$\\times$ lower standard deviation). Moreover, it improves the chance of attaining the optimal solution by about 10\\% of cases, compared to baseline methods in hard problems. These results highlight the promise of combining symbolic planning with LLMs for robust, high-quality code generation in complex domains.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "optimizing",
      "prompt",
      "sequences"
    ],
    "category": "noticia"
  },
  {
    "title": "Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making",
    "title_es": "Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making",
    "url": "https://arxiv.org/abs/2508.05996",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05996v1 Announce Type: new \nAbstract: Complex medical decision-making involves cooperative workflows operated by different clinicians. Designing AI multi-agent systems can expedite and augment human-level clinical decision-making. Existing multi-agent researches primarily focus on language-only tasks, yet their extension to multimodal scenarios remains challenging. A blind combination of diverse vision-language models (VLMs) can amplify an erroneous outcome interpretation. VLMs in general are less capable in instruction following and importantly self-reflection, compared to large language models (LLMs) of comparable sizes. This disparity largely constrains VLMs' ability in cooperative workflows. In this study, we propose MedOrch, a mediator-guided multi-agent collaboration framework for medical multimodal decision-making. MedOrch employs an LLM-based mediator agent that enables multiple VLM-based expert agents to exchange and reflect on their outputs towards collaboration. We utilize multiple open-source general-purpose and domain-specific VLMs instead of costly GPT-series models, revealing the strength of heterogeneous models. We show that the collaboration within distinct VLM-based agents can surpass the capabilities of any individual agent. We validate our approach on five medical vision question answering benchmarks, demonstrating superior collaboration performance without model training. Our findings underscore the value of mediator-guided multi-agent collaboration in advancing medical multimodal intelligence. Our code will be made publicly available.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mediatorguided",
      "multiagent",
      "collaboration"
    ],
    "category": "noticia"
  },
  {
    "title": "Hybrid Game Control Envelope Synthesis",
    "title_es": "Hybrid Game Control Envelope Synthesis",
    "url": "https://arxiv.org/abs/2508.05997",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05997v1 Announce Type: new \nAbstract: Control problems for embedded systems like cars and trains can be modeled by two-player hybrid games. Control envelopes, which are families of safe control solutions, correspond to nondeterministic winning policies of hybrid games, where each deterministic specialization of the policy is a control solution. This paper synthesizes nondeterministic winning policies for hybrid games that are as permissive as possible. It introduces subvalue maps, a compositional representation of such policies that enables verification and synthesis along the structure of the game. An inductive logical characterization in differential game logic (dGL) checks whether a subvalue map induces a sound control envelope which always induces a winning play. A policy is said to win if it always achieves the desirable outcome when the player follows it, no matter what actions the opponent plays. The maximal subvalue map, which allows the most action options while still winning, is shown to exist and satisfy a logical characterization. A family of algorithms for nondeterministic policy synthesis can be obtained from the inductive subvalue map soundness characterization. An implementation of these findings is evaluated on examples that use the expressivity of dGL to model a range of diverse control challenges.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hybrid Game Control Envelope Synthesis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hybrid",
      "game",
      "control"
    ],
    "category": "noticia"
  },
  {
    "title": "Between Tool and Trouble: Student Attitudes Toward AI in Programming Education",
    "title_es": "Between Tool and Trouble: Student Attitudes Toward AI in Programming Education",
    "url": "https://arxiv.org/abs/2508.05999",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05999v1 Announce Type: new \nAbstract: This study examines how AI code assistants shape novice programmers experiences during a two-part exam in an introductory programming course. In the first part, students completed a programming task with access to AI support; in the second, they extended their solutions without AI. We collected Likert-scale and open-ended responses from 20 students to evaluate their perceptions and challenges. Findings suggest that AI tools were perceived as helpful for understanding code and increasing confidence, particularly during initial development. However, students reported difficulties transferring knowledge to unaided tasks, revealing possible overreliance and gaps in conceptual understanding. These insights highlight the need for pedagogical strategies that integrate AI meaningfully while reinforcing foundational programming skills.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Between Tool and Trouble: Student Attitudes Toward AI in Programming Education\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "between",
      "tool",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning",
    "title_es": "Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning",
    "url": "https://arxiv.org/abs/2508.06000",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06000v1 Announce Type: new \nAbstract: Operational skill learning, inherently physical and reliant on hands-on practice and kinesthetic feedback, has yet to be effectively replicated in large language model (LLM)-supported training. Current LLM training assistants primarily generate customized textual feedback, neglecting the crucial kinesthetic modality. This gap derives from the textual and uncertain nature of LLMs, compounded by concerns on user acceptance of LLM driven body control. To bridge this gap and realize the potential of collaborative human-LLM action, this work explores human experience of LLM driven kinesthetic assistance. Specifically, we introduced an \"Align-Analyze-Adjust\" strategy and developed FlightAxis, a tool that integrates LLM with Electrical Muscle Stimulation (EMS) for flight skill acquisition, a representative operational skill domain. FlightAxis learns flight skills from manuals and guides forearm movements during simulated flight tasks. Our results demonstrate high user acceptance of LLM-mediated body control and significantly reduced task completion times. Crucially, trainees reported that this kinesthetic assistance enhanced their awareness of operation flaws and fostered increased engagement in the training process, rather than relieving perceived load. This work demonstrated the potential of kinesthetic LLM training in operational skill acquisition.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hand",
      "by",
      "hand"
    ],
    "category": "noticia"
  },
  {
    "title": "KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training",
    "title_es": "KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training",
    "url": "https://arxiv.org/abs/2508.06001",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06001v1 Announce Type: new \nAbstract: We present KnapFormer, an efficient and versatile framework to combine workload balancing and sequence parallelism in distributed training of Diffusion Transformers (DiT). KnapFormer builds on the insight that strong synergy exists between sequence parallelism and the need to address the significant token imbalance across ranks. This imbalance arises from variable-length text inputs and varying visual token counts in mixed-resolution and image-video joint training. KnapFormer redistributes tokens by first gathering sequence length metadata across all ranks in a balancing group and solving a global knapsack problem. The solver aims to minimize the variances of total workload per-GPU, while accounting for the effect of sequence parallelism. By integrating DeepSpeed-Ulysees-based sequence parallelism in the load-balancing decision process and utilizing a simple semi-empirical workload model, KnapFormers achieves minimal communication overhead and less than 1% workload discrepancy in real-world training workloads with sequence length varying from a few hundred to tens of thousands. It eliminates straggler effects and achieves 2x to 3x speedup when training state-of-the-art diffusion models like FLUX on mixed-resolution and image-video joint data corpora. We open-source the KnapFormer implementation at https://github.com/Kai-46/KnapFormer/",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "knapformer",
      "an",
      "online"
    ],
    "category": "noticia"
  },
  {
    "title": "When a Paper Has 1000 Authors: Rethinking Citation Metrics in the Era of LLMs",
    "title_es": "When a Paper Has 1000 Authors: Rethinking Citation Metrics in the Era of LLMs",
    "url": "https://arxiv.org/abs/2508.06004",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06004v1 Announce Type: new \nAbstract: Author-level citation metrics provide a practical, interpretable, and scalable signal of scholarly influence in a complex research ecosystem. It has been widely used as a proxy in hiring decisions. However, the past five years have seen the rapid emergence of large-scale publications in the field of large language models and foundation models, with papers featuring hundreds to thousands of co-authors and receiving tens of thousands of citations within months. For example, Gemini has 1361 authors and has been cited around 4600 times in 19 months. In such cases, traditional metrics, such as total citation count and the $h$-index, fail to meaningfully distinguish individual contributions. Therefore, we propose the following research question: How can one identify standout researchers among thousands of co-authors in large-scale LLM papers? This question is particularly important in scenarios such as academic hiring and funding decisions. In this paper, we introduce a novel citation metric designed to address this challenge by balancing contributions across large-scale and small-scale publications. We propose the SBCI index, analyze its theoretical properties, and evaluate its behavior on synthetic publication datasets. Our results demonstrate that the proposed metric provides a more robust and discriminative assessment of individual scholarly impact in the era of large-scale collaborations.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"When a Paper Has 1000 Authors: Rethinking Citation Metrics in the Era of LLMs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "when",
      "a",
      "paper"
    ],
    "category": "noticia"
  },
  {
    "title": "MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models",
    "title_es": "MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models",
    "url": "https://arxiv.org/abs/2508.06009",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06009v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in visual mathematical reasoning across various existing benchmarks. However, these benchmarks are predominantly based on clean or processed multimodal inputs, without incorporating the images provided by real-world Kindergarten through 12th grade (K-12) educational users. To address this gap, we introduce MathReal, a meticulously curated dataset comprising 2,000 mathematical questions with images captured by handheld mobile devices in authentic scenarios. Each question is an image, containing the question text and visual element. We systematically classify the real images into three primary categories: image quality degradation, perspective variation, and irrelevant content interference, which are further delineated into 14 subcategories. Additionally, MathReal spans five core knowledge and ability categories, which encompass three question types and are divided into three difficulty levels. To comprehensively evaluate the multimodal mathematical reasoning abilities of state-of-the-art MLLMs in real-world scenarios, we design six experimental settings that enable a systematic analysis of their performance. Through extensive experimentation, we find that the problem-solving abilities of existing MLLMs are significantly challenged in realistic educational contexts. Based on this, we conduct a thorough analysis of their performance and error patterns, providing insights into their recognition, comprehension, and reasoning capabilities, and outlining directions for future improvements. Data and code: https://github.com/junfeng0288/MathReal.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mathreal",
      "we",
      "keep"
    ],
    "category": "noticia"
  },
  {
    "title": "ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors",
    "title_es": "ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors",
    "url": "https://arxiv.org/abs/2508.06014",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06014v1 Announce Type: new \nAbstract: Recent advances in novel view synthesis (NVS) have enabled real-time rendering with 3D Gaussian Splatting (3DGS). However, existing methods struggle with artifacts and missing regions when rendering from viewpoints that deviate from the training trajectory, limiting seamless scene exploration. To address this, we propose a 3DGS-based pipeline that generates additional training views to enhance reconstruction. We introduce an information-gain-driven virtual camera placement strategy to maximize scene coverage, followed by video diffusion priors to refine rendered results. Fine-tuning 3D Gaussians with these enhanced views significantly improves reconstruction quality. To evaluate our method, we present Wild-Explore, a benchmark designed for challenging scene exploration. Experiments demonstrate that our approach outperforms existing 3DGS-based methods, enabling high-quality, artifact-free rendering from arbitrary viewpoints.\n  https://exploregs.github.io",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "exploregs",
      "explorable",
      "d"
    ],
    "category": "noticia"
  },
  {
    "title": "Crisp Attention: Regularizing Transformers via Structured Sparsity",
    "title_es": "Crisp Attention: Regularizing Transformers via Structured Sparsity",
    "url": "https://arxiv.org/abs/2508.06016",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06016v1 Announce Type: new \nAbstract: The quadratic computational cost of the self-attention mechanism is a primary challenge in scaling Transformer models. While attention sparsity is widely studied as a technique to improve computational efficiency, it is almost universally assumed to come at the cost of model accuracy. In this paper, we report a surprising counter-example to this common wisdom. By introducing structured, post-hoc sparsity to the attention mechanism of a DistilBERT model during fine-tuning on the SST-2 sentiment analysis task, we find that model accuracy improves significantly. Our model with 80\\% attention sparsity achieves a validation accuracy of 91.59\\%, a 0.97\\% absolute improvement over the dense baseline. We hypothesize that this phenomenon is due to sparsity acting as a powerful implicit regularizer, preventing the model from overfitting by forcing it to make predictions with a more constrained and robust set of features. Our work recasts attention sparsity not just as a tool for computational efficiency, but as a potential method for improving the generalization and performance of Transformer models.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Crisp Attention: Regularizing Transformers via Structured Sparsity\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "crisp",
      "attention",
      "regularizing"
    ],
    "category": "noticia"
  },
  {
    "title": "Position: Intelligent Coding Systems Should Write Programs with Justifications",
    "title_es": "Position: Intelligent Coding Systems Should Write Programs with Justifications",
    "url": "https://arxiv.org/abs/2508.06017",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06017v1 Announce Type: new \nAbstract: Intelligent coding systems are transforming software development by enabling users to specify code behavior in natural language. However, the opaque decision-making of AI-driven coders raises trust and usability concerns, particularly for non-expert users who cannot inspect low-level implementations. We argue that these systems should not only generate code but also produce clear, consistent justifications that bridge model reasoning and user understanding. To this end, we identify two critical justification properties-cognitive alignment and semantic faithfulness-and highlight the limitations of existing methods, including formal verification, static analysis, and post-hoc explainability. We advocate exploring neuro-symbolic approaches for justification generation, where symbolic constraints guide model behavior during training and program semantics are enriched through neural representations, enabling automated consistency checks at inference time.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Position: Intelligent Coding Systems Should Write Programs with Justifications\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "position",
      "intelligent",
      "coding"
    ],
    "category": "noticia"
  },
  {
    "title": "Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis",
    "title_es": "Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis",
    "url": "https://arxiv.org/abs/2508.06021",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06021v1 Announce Type: new \nAbstract: Sub-visible particle analysis using flow imaging microscopy combined with deep learning has proven effective in identifying particle types, enabling the distinction of harmless components such as silicone oil from protein particles. However, the scarcity of available data and severe imbalance between particle types within datasets remain substantial hurdles when applying multi-class classifiers to such problems, often forcing researchers to rely on less effective methods. The aforementioned issue is particularly challenging for particle types that appear unintentionally and in lower numbers, such as silicone oil and air bubbles, as opposed to protein particles, where obtaining large numbers of images through controlled settings is comparatively straightforward. In this work, we develop a state-of-the-art diffusion model to address data imbalance by generating high-fidelity images that can augment training datasets, enabling the effective training of multi-class deep neural networks. We validate this approach by demonstrating that the generated samples closely resemble real particle images in terms of visual quality and structure. To assess the effectiveness of using diffusion-generated images in training datasets, we conduct large-scale experiments on a validation dataset comprising 500,000 protein particle images and demonstrate that this approach improves classification performance with no negligible downside. Finally, to promote open research and reproducibility, we publicly release both our diffusion models and the trained multi-class deep neural network classifiers, along with a straightforward interface for easy integration into future studies, at https://github.com/utkuozbulak/svp-generative-ai.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "improved",
      "subvisible",
      "particle"
    ],
    "category": "noticia"
  },
  {
    "title": "Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients",
    "title_es": "Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients",
    "url": "https://arxiv.org/abs/2508.06023",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06023v1 Announce Type: new \nAbstract: Prognostication for comatose post-cardiac arrest patients is a critical challenge that directly impacts clinical decision-making in the ICU. Clinical information that informs prognostication is collected serially over time. Shortly after cardiac arrest, various time-invariant baseline features are collected (e.g., demographics, cardiac arrest characteristics). After ICU admission, additional features are gathered, including time-varying hemodynamic data (e.g., blood pressure, doses of vasopressor medications). We view these as two phases in which we collect new features. In this study, we propose a novel stepwise dynamic competing risks model that improves the prediction of neurological outcomes by automatically determining when to take advantage of time-invariant features (first phase) and time-varying features (second phase). Notably, our model finds patients for whom this second phase (time-varying hemodynamic) information is beneficial for prognostication and also when this information is beneficial (as we collect more hemodynamic data for a patient over time, how important these data are for prognostication varies). Our approach extends the standard Fine and Gray model to explicitly model the two phases and to incorporate neural networks to flexibly capture complex nonlinear feature relationships. Evaluated on a retrospective cohort of 2,278 comatose post-arrest patients, our model demonstrates robust discriminative performance for the competing outcomes of awakening, withdrawal of life-sustaining therapy, and death despite maximal support. Our approach generalizes to more than two phases in which new features are collected and could be used in other dynamic prediction tasks, where it may be helpful to know when and for whom newly collected features significantly improve prediction.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "stepwise",
      "fine",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "EC2MoE: Adaptive End-Cloud Pipeline Collaboration Enabling Scalable Mixture-of-Experts Inference",
    "title_es": "EC2MoE: Adaptive End-Cloud Pipeline Collaboration Enabling Scalable Mixture-of-Experts Inference",
    "url": "https://arxiv.org/abs/2508.06024",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06024v1 Announce Type: new \nAbstract: The Mixture-of-Experts (MoE) paradigm has emerged as a promising solution to scale up model capacity while maintaining inference efficiency. However, deploying MoE models across heterogeneous end-cloud environments poses new challenges in expert scheduling, communication overhead, and resource heterogeneity. In this paper, we propose EC2MoE, an adaptive framework for scalable MoE inference via end-cloud pipeline collaboration. First, we design a hardware-aware lightweight group gate network that enhances expert selection and computational efficiency. By incorporating a hardware-aware local expert selection mechanism, the system adaptively filters candidate experts based on real-time device profiles. A lightweight group gate module then integrates local and global gating outputs to achieve high-quality expert routing with minimal overhead. Second, we develop a pipeline optimization mechanism based on endcloud collaboration to accelerate MoE inference. This includes an encoder-decoder structure based on low-rank compression, which reduces transmission and computation costs. And a route-aware heuristic pipeline scheduling algorithm that dynamically allocates inference stages across devices according to workload and network topology. Extensive experiments show that EC2MoE can increase throughput by 2.2x to 5.1x and reduce end-to-end latency by 53% to 67% while maintaining high accuracy compared to state-of-the-art methods. It also maintains good scalability under dynamic load and network environments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"EC2MoE: Adaptive End-Cloud Pipeline Collaboration Enabling Scalable Mixture-of-Experts Inference\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ecmoe",
      "adaptive",
      "endcloud"
    ],
    "category": "noticia"
  },
  {
    "title": "Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future",
    "title_es": "Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future",
    "url": "https://arxiv.org/abs/2508.06026",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06026v1 Announce Type: new \nAbstract: Self-Rewarding Language Models propose an architecture in which the Large Language Models(LLMs) both generates responses and evaluates its own outputs via LLM-as-a-Judge prompting, dynamically improving its generative capabilities through iterative Direct Preference Optimization (DPO). However, our analysis reveals a critical limitation in existing Self-Rewarding paradigms: the synchronized improvement of chosen and rejected responses progressively narrows the representational difference between contrasting samples, undermining effective preference learning. We propose \\textbf{Temporal Self-Rewarding Language Models} that strategically coordinate past, present, and future model generations to sustain learning signals. Our dual-phase framework introduces: (1) \\textit{Anchored Rejection} - fixing rejected responses using the past initial model's outputs and (2) \\textit{Future-Guided Chosen} - dynamically curating chosen samples using next-generation model predictions. Extensive experiments across three model families (Llama, Qwen, Mistral) and different model sizes (Llama3B/8B/70B) demonstrate significant improvements when trained with our method compared to Self-Rewarding using same computation resources. For example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our method, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our method also demonstrates superior out-of-distribution generalization across mathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code generation (HumanEval) tasks, even though we do not specifically collect such training data.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "temporal",
      "selfrewarding",
      "language"
    ],
    "category": "noticia"
  },
  {
    "title": "Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings",
    "title_es": "Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings",
    "url": "https://arxiv.org/abs/2508.06030",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06030v1 Announce Type: new \nAbstract: Large language models (LLMs) acquire knowledge across diverse domains such as science, history, and geography encountered during generative pre-training. However, due to their stochasticity, it is difficult to predict what LLMs have acquired. Prior work has developed different ways to probe this knowledge by investigating the hidden representations, crafting specific task prompts, curating representative samples, and estimating their uncertainty. However, these methods require making forward passes through the underlying model to probe the LLM's knowledge about a specific fact, making them computationally expensive and time-consuming. To bridge this gap, we propose $\\textbf{PEEK}$ or $\\textbf{P}$roxy $\\textbf{E}$mbeddings to $\\textbf{E}$stimate $\\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models that effectively encode factual knowledge as text or graphs as proxies for LLMs. First, we identify a training set of facts known by LLMs through various probing strategies and then adapt embedding models to predict the LLM outputs with a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived datasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict LLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find that sentence embedding models are more suitable than graph embeddings to predict LLM knowledge, shedding light on the underlying representation of the factual landscape. Thus, we believe that knowledge-adapted embeddings can be used to identify knowledge gaps in LLMs at scale and can provide deeper insights into LLMs' internal inductive bias. The code and data are made available at https://github.com/claws-lab/peek.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "efficient",
      "knowledge",
      "probing"
    ],
    "category": "noticia"
  },
  {
    "title": "An Overlapping Coalition Game Approach for Collaborative Block Mining and Edge Task Offloading in MEC-assisted Blockchain Networks",
    "title_es": "An Overlapping Coalition Game Approach for Collaborative Block Mining and Edge Task Offloading in MEC-assisted Blockchain Networks",
    "url": "https://arxiv.org/abs/2508.06031",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06031v1 Announce Type: new \nAbstract: Mobile edge computing (MEC) is a promising technology that enhances the efficiency of mobile blockchain networks, by enabling miners, often acted by mobile users (MUs) with limited computing resources, to offload resource-intensive mining tasks to nearby edge computing servers. Collaborative block mining can further boost mining efficiency by allowing multiple miners to form coalitions, pooling their computing resources and transaction data together to mine new blocks collaboratively. Therefore, an MEC-assisted collaborative blockchain network can leverage the strengths of both technologies, offering improved efficiency, security, and scalability for blockchain systems. While existing research in this area has mainly focused on the single-coalition collaboration mode, where each miner can only join one coalition, this work explores a more comprehensive multi-coalition collaboration mode, which allows each miner to join multiple coalitions. To analyze the behavior of miners and the edge computing service provider (ECP) in this scenario, we propose a novel two-stage Stackelberg game. In Stage I, the ECP, as the leader, determines the prices of computing resources for all MUs. In Stage II, each MU decides the coalitions to join, resulting in an overlapping coalition formation (OCF) game; Subsequently, each coalition decides how many edge computing resources to purchase from the ECP, leading to an edge resource competition (ERC) game. We derive the closed-form Nash equilibrium for the ERC game, based on which we further propose an OCF-based alternating algorithm to achieve a stable coalition structure for the OCF game and develop a near-optimal pricing strategy for the ECP's resource pricing problem.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"An Overlapping Coalition Game Approach for Collaborative Block Mining and Edge Task Offloading in MEC-assisted Blockchain Networks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "an",
      "overlapping",
      "coalition"
    ],
    "category": "noticia"
  },
  {
    "title": "Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts",
    "title_es": "Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts",
    "url": "https://arxiv.org/abs/2508.06032",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06032v1 Announce Type: new \nAbstract: Existing methods for human parsing into body parts and clothing often use fixed mask categories with broad labels that obscure fine-grained clothing types. Recent open-vocabulary segmentation approaches leverage pretrained text-to-image (T2I) diffusion model features for strong zero-shot transfer, but typically group entire humans into a single person category, failing to distinguish diverse clothing or detailed body parts. To address this, we propose Spectrum, a unified network for part-level pixel parsing (body parts and clothing) and instance-level grouping. While diffusion-based open-vocabulary models generalize well across tasks, their internal representations are not specialized for detailed human parsing. We observe that, unlike diffusion models with broad representations, image-driven 3D texture generators maintain faithful correspondence to input images, enabling stronger representations for parsing diverse clothing and body parts. Spectrum introduces a novel repurposing of an Image-to-Texture (I2Tx) diffusion model -- obtained by fine-tuning a T2I model on 3D human texture maps -- for improved alignment with body parts and clothing. From an input image, we extract human-part internal features via the I2Tx diffusion model and generate semantically valid masks aligned to diverse clothing categories through prompt-guided grounding. Once trained, Spectrum produces semantic segmentation maps for every visible body part and clothing category, ignoring standalone garments or irrelevant objects, for any number of humans in the scene. We conduct extensive cross-dataset experiments -- separately assessing body parts, clothing parts, unseen clothing categories, and full-body masks -- and demonstrate that Spectrum consistently outperforms baseline methods in prompt-based segmentation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "learning",
      "d",
      "textureaware"
    ],
    "category": "noticia"
  },
  {
    "title": "InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow",
    "title_es": "InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow",
    "url": "https://arxiv.org/abs/2508.06033",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06033v1 Announce Type: new \nAbstract: We propose a fast text-guided image editing method called InstantEdit based on the RectifiedFlow framework, which is structured as a few-step editing process that preserves critical content while following closely to textual instructions. Our approach leverages the straight sampling trajectories of RectifiedFlow by introducing a specialized inversion strategy called PerRFI. To maintain consistent while editable results for RectifiedFlow model, we further propose a novel regeneration method, Inversion Latent Injection, which effectively reuses latent information obtained during inversion to facilitate more coherent and detailed regeneration. Additionally, we propose a Disentangled Prompt Guidance technique to balance editability with detail preservation, and integrate a Canny-conditioned ControlNet to incorporate structural cues and suppress artifacts. Evaluation on the PIE image editing dataset demonstrates that InstantEdit is not only fast but also achieves better qualitative and quantitative results compared to state-of-the-art few-step editing methods.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "instantedit",
      "textguided",
      "fewstep"
    ],
    "category": "noticia"
  },
  {
    "title": "Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity",
    "title_es": "Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity",
    "url": "https://arxiv.org/abs/2508.06034",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06034v1 Announce Type: new \nAbstract: Heterogeneous graphs (HGs) are common in real-world scenarios and often exhibit heterophily. However, most existing studies focus on either heterogeneity or heterophily in isolation, overlooking the prevalence of heterophilic HGs in practical applications. Such ignorance leads to their performance degradation. In this work, we first identify two main challenges in modeling heterophily HGs: (1) varying heterophily distributions across hops and meta-paths; (2) the intricate and often heterophily-driven diversity of semantic information across different meta-paths. Then, we propose the Adaptive Heterogeneous Graph Neural Network (AHGNN) to tackle these challenges. AHGNN employs a heterophily-aware convolution that accounts for heterophily distributions specific to both hops and meta-paths. It then integrates messages from diverse semantic spaces using a coarse-to-fine attention mechanism, which filters out noise and emphasizes informative signals. Experiments on seven real-world graphs and twenty baselines demonstrate the superior performance of AHGNN, particularly in high-heterophily situations.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "adaptive",
      "heterogeneous",
      "graph"
    ],
    "category": "noticia"
  },
  {
    "title": "More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment",
    "title_es": "More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment",
    "url": "https://arxiv.org/abs/2508.06036",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06036v1 Announce Type: new \nAbstract: In this paper, we present our solution for the semi-supervised learning track (MER-SEMI) in MER2025. We propose a comprehensive framework, grounded in the principle that \"more is better,\" to construct a robust Mixture of Experts (MoE) emotion recognition system. Our approach integrates a diverse range of input modalities as independent experts, including novel signals such as knowledge from large Vision-Language Models (VLMs) and temporal Action Unit (AU) information. To effectively utilize unlabeled data, we introduce a consensus-based pseudo-labeling strategy, generating high-quality labels from the agreement between a baseline model and Gemini, which are then used in a two-stage training paradigm. Finally, we employ a multi-expert voting ensemble combined with a rule-based re-ranking process to correct prediction bias and better align the outputs with human preferences. Evaluated on the MER2025-SEMI challenge dataset, our method achieves an F1-score of 0.8772 on the test set, ranking 2nd in the track. Our code is available at https://github.com/zhuyjan/MER2025-MRAC25.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "more",
      "is",
      "better"
    ],
    "category": "noticia"
  },
  {
    "title": "Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models",
    "title_es": "Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models",
    "url": "https://arxiv.org/abs/2508.06038",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06038v1 Announce Type: new \nAbstract: Vision-Language Models (VLMs) typically replace the predefined image placeholder token () in textual instructions with visual features from an image encoder, forming the input to a backbone Large Language Model (LLM). However, the large number of vision tokens significantly increases the context length, leading to high computational overhead and inference latency. While previous efforts mitigate this by selecting only important visual features or leveraging learnable queries to reduce token count, they often compromise performance or introduce substantial extra costs. In response, we propose Fourier-VLM, a simple yet efficient method that compresses visual representations in the frequency domain. Our approach is motivated by the observation that vision features output from the vision encoder exhibit concentrated energy in low-frequency components. Leveraging this, we apply a low-pass filter to the vision features using a two-dimentional Discrete Cosine Transform (DCT). Notably, the DCT is efficiently computed via the Fast Fourier Transform (FFT) operator with a time complexity of $\\mathcal{O}(n\\log n)$, minimizing the extra computational cost while introducing no additional parameters. Extensive experiments across various image-based benchmarks demonstrate that Fourier-VLM achieves competitive performance with strong generalizability across both LLaVA and Qwen-VL architectures. Crucially, it reduce inference FLOPs by up to 83.8% and boots generation speed by 31.2% compared to LLaVA-v1.5, highlighting the superior efficiency and practicality.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fouriervlm",
      "compressing",
      "vision"
    ],
    "category": "noticia"
  },
  {
    "title": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment",
    "title_es": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment",
    "url": "https://arxiv.org/abs/2508.06041",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06041v1 Announce Type: new \nAbstract: How can we effectively handle queries for on-device large language models (LLMs) with varying runtime constraints, such as latency and accuracy? Multi-scale quantization addresses this challenge by enabling memory-efficient runtime model adaptation of LLMs through the overlaying of multiple model variants quantized to different bitwidths. Meanwhile, an important question still remains open-ended: how can models be properly configured to match a target precision or latency? While mixed-precision offers a promising solution, we take this further by leveraging the key observation that the sensitivity of each layer dynamically changes across decoding iterations. Building on this insight, we introduce DP-LLM, a novel mechanism that dynamically assigns precision to each layer based on input values. DP-LLM augments each linear layer in an LLM with a precision selector that determines the bitwidth at runtime using a lightweight error estimator and threshold values learned through fine-tuning. Experimental results across multiple models and benchmarks demonstrate that DP-LLM achieves a superior performance-latency trade-off, outperforming prior approaches.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dpllm",
      "runtime",
      "model"
    ],
    "category": "noticia"
  },
  {
    "title": "Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning",
    "title_es": "Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning",
    "url": "https://arxiv.org/abs/2508.06042",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06042v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have recently demonstrated impressive action sequence prediction capabilities but often struggle with dynamic, long-horizon tasks such as real-time strategic games. In a game such as StarCraftII (SC2), agents need to manage resource constraints and adapt to evolving battlefield situations in a partially observable environment. This often overwhelms exisiting LLM-based approaches. To address these challenges, we propose a hierarchical multi-agent framework that employs specialized imitation learning agents under a meta-controller called Strategic Planner (SP). By expert demonstrations, each specialized agent learns a distinctive strategy, such as aerial support or defensive maneuvers, and produces coherent, structured multistep action sequences. The SP then orchestrates these proposals into a single, environmentally adaptive plan that ensures local decisions aligning with long-term strategies. We call this HIMA (Hierarchical Imitation Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that encompasses all race match combinations in SC2. Our empirical results show that HIMA outperforms state of the arts in strategic clarity, adaptability, and computational efficiency, underscoring the potential of combining specialized imitation modules with meta-level orchestration to develop more robust, general-purpose AI agents.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "society",
      "of",
      "mind"
    ],
    "category": "noticia"
  },
  {
    "title": "NEP: Autoregressive Image Editing via Next Editing Token Prediction",
    "title_es": "NEP: Autoregressive Image Editing via Next Editing Token Prediction",
    "url": "https://arxiv.org/abs/2508.06044",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06044v1 Announce Type: new \nAbstract: Text-guided image editing involves modifying a source image based on a language instruction and, typically, requires changes to only small local regions. However, existing approaches generate the entire target image rather than selectively regenerate only the intended editing areas. This results in (1) unnecessary computational costs and (2) a bias toward reconstructing non-editing regions, which compromises the quality of the intended edits. To resolve these limitations, we propose to formulate image editing as Next Editing-token Prediction (NEP) based on autoregressive image generation, where only regions that need to be edited are regenerated, thus avoiding unintended modification to the non-editing areas. To enable any-region editing, we propose to pre-train an any-order autoregressive text-to-image (T2I) model. Once trained, it is capable of zero-shot image editing and can be easily adapted to NEP for image editing, which achieves a new state-of-the-art on widely used image editing benchmarks. Moreover, our model naturally supports test-time scaling (TTS) through iteratively refining its generation in a zero-shot manner. The project page is: https://nep-bigai.github.io/",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"NEP: Autoregressive Image Editing via Next Editing Token Prediction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nep",
      "autoregressive",
      "image"
    ],
    "category": "noticia"
  },
  {
    "title": "EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation",
    "title_es": "EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation",
    "url": "https://arxiv.org/abs/2508.06046",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06046v1 Announce Type: new \nAbstract: Although the effectiveness of Large Language Models (LLMs) as judges (LLM-as-a-judge) has been validated, their performance remains limited in open-ended tasks, particularly in story evaluation. Accurate story evaluation is crucial not only for assisting human quality judgment but also for providing key signals to guide story generation. However, existing methods face a dilemma: prompt engineering for closed-source models suffers from poor adaptability, while fine-tuning approaches for open-source models lack the rigorous reasoning capabilities essential for story evaluation. To address this, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework. Grounded in pairwise comparison, the framework first self-synthesizes score-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To ensure data quality, these raw CoTs undergo a self-filtering process, utilizing multi-agents to guarantee their logical rigor and robustness. Finally, the evaluator trained on the refined data is deployed as a reward model to guide the story generation task. Experimental results demonstrate that our framework achieves state-of-the-art (SOTA) performance on three evaluation benchmarks including StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward model, it significantly enhances the quality of generated stories, thereby fully validating the superiority of our self-evolving approach.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "evolvr",
      "selfevolving",
      "pairwise"
    ],
    "category": "noticia"
  },
  {
    "title": "ArchXBench: A Complex Digital Systems Benchmark Suite for LLM Driven RTL Synthesis",
    "title_es": "ArchXBench: A Complex Digital Systems Benchmark Suite for LLM Driven RTL Synthesis",
    "url": "https://arxiv.org/abs/2508.06047",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06047v1 Announce Type: new \nAbstract: Modern SoC datapaths include deeply pipelined, domain-specific accelerators, but their RTL implementation and verification are still mostly done by hand. While large language models (LLMs) exhibit advanced code-generation abilities for programming languages like Python, their application to Verilog-like RTL remains in its nascent stage. This is reflected in the simple arithmetic and control circuits currently used to evaluate generative capabilities in existing benchmarks. In this paper, we introduce ArchXBench, a six-level benchmark suite that encompasses complex arithmetic circuits and other advanced digital subsystems drawn from domains such as cryptography, image processing, machine learning, and signal processing. Architecturally, some of these designs are purely combinational, others are multi-cycle or pipelined, and many require hierarchical composition of modules. For each benchmark, we provide a problem description, design specification, and testbench, enabling rapid research in the area of LLM-driven agentic approaches for complex digital systems design.\n  Using zero-shot prompting with Claude Sonnet 4, GPT 4.1, o4-mini-high, and DeepSeek R1 under a pass@5 criterion, we observed that o4-mini-high successfully solves the largest number of benchmarks, 16 out of 30, spanning Levels 1, 2, and 3. From Level 4 onward, however, all models consistently fail, highlighting a clear gap in the capabilities of current state-of-the-art LLMs and prompting/agentic approaches.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ArchXBench: A Complex Digital Systems Benchmark Suite for LLM Driven RTL Synthesis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "archxbench",
      "a",
      "complex"
    ],
    "category": "noticia"
  },
  {
    "title": "$k\\ell$-refinement: An adaptive mesh refinement scheme for hiearchical hybrid grids",
    "title_es": "$k\\ell$-refinement: An adaptive mesh refinement scheme for hiearchical hybrid grids",
    "url": "https://arxiv.org/abs/2508.06049",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06049v1 Announce Type: new \nAbstract: This work introduces an adaptive mesh refinement technique for hierarchical hybrid grids with the goal to reach scalability and maintain excellent performance on massively parallel computer systems. On the block structured hierarchical hybrid grids, this is accomplished by using classical, unstructured refinement only on the coarsest level of the hierarchy, while keeping the number of structured refinement levels constant on the whole domain. This leads to a compromise where the excellent performance characteristics of hierarchical hybrid grids can be maintained at the price that the flexibility of generating locally refined meshes is constrained. Furthermore, mesh adaptivity often relies on a posteriori error estimators or error indicators that tend to become computationally expensive. Again with the goal of preserving scalability and performance, a method is proposed that leverages the grid hierarchy and the full multigrid scheme that generates a natural sequence of approximations on the nested hierarchy of grids. This permits to compute a cheap error estimator that is well-suited for large-scale parallel computing. We present the theoretical foundations for both global and local error estimates and present a rigorous analysis of their effectivity. The proposed method, including error estimator and the adaptive coarse grid refinement, is implemented in the finite element framework HyTeG. Extensive numerical experiments are conducted to validate the effectiveness, as well as performance and scalability.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"$k\\ell$-refinement: An adaptive mesh refinement scheme for hiearchical hybrid grids\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "kellrefinement",
      "an",
      "adaptive"
    ],
    "category": "noticia"
  },
  {
    "title": "VQAThinker: Exploring Generalizable and Explainable Video Quality Assessment via Reinforcement Learning",
    "title_es": "VQAThinker: Exploring Generalizable and Explainable Video Quality Assessment via Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.06051",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06051v1 Announce Type: new \nAbstract: Video quality assessment (VQA) aims to objectively quantify perceptual quality degradation in alignment with human visual perception. Despite recent advances, existing VQA models still suffer from two critical limitations: \\textit{poor generalization to out-of-distribution (OOD) videos} and \\textit{limited explainability}, which restrict their applicability in real-world scenarios. To address these challenges, we propose \\textbf{VQAThinker}, a reasoning-based VQA framework that leverages large multimodal models (LMMs) with reinforcement learning to jointly model video quality understanding and scoring, emulating human perceptual decision-making. Specifically, we adopt group relative policy optimization (GRPO), a rule-guided reinforcement learning algorithm that enables reasoning over video quality under score-level supervision, and introduce three VQA-specific rewards: (1) a \\textbf{bell-shaped regression reward} that increases rapidly as the prediction error decreases and becomes progressively less sensitive near the ground truth; (2) a \\textbf{pairwise ranking reward} that guides the model to correctly determine the relative quality between video pairs; and (3) a \\textbf{temporal consistency reward} that encourages the model to prefer temporally coherent videos over their perturbed counterparts. Extensive experiments demonstrate that VQAThinker achieves state-of-the-art performance on both in-domain and OOD VQA benchmarks, showing strong generalization for video quality scoring. Furthermore, evaluations on video quality understanding tasks validate its superiority in distortion attribution and quality description compared to existing explainable VQA models and LMMs. These findings demonstrate that reinforcement learning offers an effective pathway toward building generalizable and explainable VQA models solely with score-level supervision.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"VQAThinker: Exploring Generalizable and Explainable Video Quality Assessment via Reinforcement Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "vqathinker",
      "exploring",
      "generalizable"
    ],
    "category": "noticia"
  },
  {
    "title": "ReNiL: Relative Neural Inertial Locator with Any-Scale Bayesian Inference",
    "title_es": "ReNiL: Relative Neural Inertial Locator with Any-Scale Bayesian Inference",
    "url": "https://arxiv.org/abs/2508.06053",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06053v1 Announce Type: new \nAbstract: Pedestrian inertial localization is key for mobile and IoT services because it provides infrastructure-free positioning. Yet most learning-based methods depend on fixed sliding-window integration, struggle to adapt to diverse motion scales and cadences, and yield inconsistent uncertainty, limiting real-world use. We present ReNiL, a Bayesian deep-learning framework for accurate, efficient, and uncertainty-aware pedestrian localization. ReNiL introduces Inertial Positioning Demand Points (IPDPs) to estimate motion at contextually meaningful waypoints instead of dense tracking, and supports inference on IMU sequences at any scale so cadence can match application needs. It couples a motion-aware orientation filter with an Any-Scale Laplace Estimator (ASLE), a dual-task network that blends patch-based self-supervision with Bayesian regression. By modeling displacements with a Laplace distribution, ReNiL provides homogeneous Euclidean uncertainty that integrates cleanly with other sensors. A Bayesian inference chain links successive IPDPs into consistent trajectories. On RoNIN-ds and a new WUDataset covering indoor and outdoor motion from 28 participants, ReNiL achieves state-of-the-art displacement accuracy and uncertainty consistency, outperforming TLIO, CTIN, iMoT, and RoNIN variants while reducing computation. Application studies further show robustness and practicality for mobile and IoT localization, making ReNiL a scalable, uncertainty-aware foundation for next-generation positioning.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ReNiL: Relative Neural Inertial Locator with Any-Scale Bayesian Inference\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "renil",
      "relative",
      "neural"
    ],
    "category": "noticia"
  },
  {
    "title": "LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing",
    "title_es": "LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing",
    "url": "https://arxiv.org/abs/2508.06055",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06055v1 Announce Type: new \nAbstract: Lateral ventricle (LV) shape analysis holds promise as a biomarker for neurological diseases; however, challenges remain due to substantial shape variability across individuals and segmentation difficulties arising from limited MRI resolution. We introduce LV-Net, a novel framework for producing individualized 3D LV meshes from brain MRI by deforming an anatomy-aware joint LV-hippocampus template mesh. By incorporating anatomical relationships embedded within the joint template, LV-Net reduces boundary segmentation artifacts and improves reconstruction robustness. In addition, by classifying the vertices of the template mesh based on their anatomical adjacency, our method enhances point correspondence across subjects, leading to more accurate LV shape statistics. We demonstrate that LV-Net achieves superior reconstruction accuracy, even in the presence of segmentation imperfections, and delivers more reliable shape descriptors across diverse datasets. Finally, we apply LV-Net to Alzheimer's disease analysis, identifying LV subregions that show significantly associations with the disease relative to cognitively normal controls. The codes for LV shape modeling are available at https://github.com/PWonjung/LV_Shape_Modeling.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lvnet",
      "anatomyaware",
      "lateral"
    ],
    "category": "noticia"
  },
  {
    "title": "RAGTrace: Understanding and Refining Retrieval-Generation Dynamics in Retrieval-Augmented Generation",
    "title_es": "RAGTrace: Understanding and Refining Retrieval-Generation Dynamics in Retrieval-Augmented Generation",
    "url": "https://arxiv.org/abs/2508.06056",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06056v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) systems have emerged as a promising solution to enhance large language models (LLMs) by integrating external knowledge retrieval with generative capabilities. While significant advancements have been made in improving retrieval accuracy and response quality, a critical challenge remains that the internal knowledge integration and retrieval-generation interactions in RAG workflows are largely opaque. This paper introduces RAGTrace, an interactive evaluation system designed to analyze retrieval and generation dynamics in RAG-based workflows. Informed by a comprehensive literature review and expert interviews, the system supports a multi-level analysis approach, ranging from high-level performance evaluation to fine-grained examination of retrieval relevance, generation fidelity, and cross-component interactions. Unlike conventional evaluation practices that focus on isolated retrieval or generation quality assessments, RAGTrace enables an integrated exploration of retrieval-generation relationships, allowing users to trace knowledge sources and identify potential failure cases. The system's workflow allows users to build, evaluate, and iterate on retrieval processes tailored to their specific domains of interest. The effectiveness of the system is demonstrated through case studies and expert evaluations on real-world RAG applications.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"RAGTrace: Understanding and Refining Retrieval-Generation Dynamics in Retrieval-Augmented Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ragtrace",
      "understanding",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?",
    "title_es": "AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?",
    "url": "https://arxiv.org/abs/2508.06057",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06057v1 Announce Type: new \nAbstract: Artificial General Intelligence (AGI) is closer than ever to becoming a reality, sparking widespread enthusiasm in the research community to collect and work with various modalities, including text, image, video, and audio. Despite recent efforts, satellite spectral imagery, as an additional modality, has yet to receive the attention it deserves. This area presents unique challenges, but also holds great promise in advancing the capabilities of AGI in understanding the natural world. In this paper, we argue why Earth Observation data is useful for an intelligent model, and then we review existing benchmarks and highlight their limitations in evaluating the generalization ability of foundation models in this domain. This paper emphasizes the need for a more comprehensive benchmark to evaluate earth observation models. To facilitate this, we propose a comprehensive set of tasks that a benchmark should encompass to effectively assess a model's ability to understand and interact with Earth observation data.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "agi",
      "for",
      "the"
    ],
    "category": "noticia"
  },
  {
    "title": "Lightweight Quad Bayer HybridEVS Demosaicing via State Space Augmented Cross-Attention",
    "title_es": "Lightweight Quad Bayer HybridEVS Demosaicing via State Space Augmented Cross-Attention",
    "url": "https://arxiv.org/abs/2508.06058",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06058v1 Announce Type: new \nAbstract: Event cameras like the Hybrid Event-based Vision Sensor (HybridEVS) camera capture brightness changes as asynchronous \"events\" instead of frames, offering advanced application on mobile photography. However, challenges arise from combining a Quad Bayer Color Filter Array (CFA) sensor with event pixels lacking color information, resulting in aliasing and artifacts on the demosaicing process before downstream application. Current methods struggle to address these issues, especially on resource-limited mobile devices. In response, we introduce \\textbf{TSANet}, a lightweight \\textbf{T}wo-stage network via \\textbf{S}tate space augmented cross-\\textbf{A}ttention, which can handle event pixels inpainting and demosaicing separately, leveraging the benefits of dividing complex tasks into manageable subtasks. Furthermore, we introduce a lightweight Cross-Swin State Block that uniquely utilizes positional prior for demosaicing and enhances global dependencies through the state space model with linear complexity. In summary, TSANet demonstrates excellent demosaicing performance on both simulated and real data of HybridEVS while maintaining a lightweight model, averaging better results than the previous state-of-the-art method DemosaicFormer across seven diverse datasets in both PSNR and SSIM, while respectively reducing parameter and computation costs by $1.86\\times$ and $3.29\\times$. Our approach presents new possibilities for efficient image demosaicing on mobile devices. Code is available in the supplementary materials.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Lightweight Quad Bayer HybridEVS Demosaicing via State Space Augmented Cross-Attention\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lightweight",
      "quad",
      "bayer"
    ],
    "category": "noticia"
  },
  {
    "title": "Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System",
    "title_es": "Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System",
    "url": "https://arxiv.org/abs/2508.06059",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06059v1 Announce Type: new \nAbstract: State-of-the-art fact-checking systems combat misinformation at scale by employing autonomous LLM-based agents to decompose complex claims into smaller sub-claims, verify each sub-claim individually, and aggregate the partial results to produce verdicts with justifications (explanatory rationales for the verdicts). The security of these systems is crucial, as compromised fact-checkers, which tend to be easily underexplored, can amplify misinformation. This work introduces Fact2Fiction, the first poisoning attack framework targeting such agentic fact-checking systems. Fact2Fiction mirrors the decomposition strategy and exploits system-generated justifications to craft tailored malicious evidences that compromise sub-claim verification. Extensive experiments demonstrate that Fact2Fiction achieves 8.9\\%--21.2\\% higher attack success rates than state-of-the-art attacks across various poisoning budgets. Fact2Fiction exposes security weaknesses in current fact-checking systems and highlights the need for defensive countermeasures.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "factfiction",
      "targeted",
      "poisoning"
    ],
    "category": "noticia"
  },
  {
    "title": "LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences",
    "title_es": "LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences",
    "url": "https://arxiv.org/abs/2508.06060",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06060v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly expected to handle complex decision-making tasks, yet their ability to perform structured resource allocation remains underexplored. Evaluating their reasoning is also difficult due to data contamination and the static nature of existing benchmarks. We present a dual-purpose framework leveraging Participatory Budgeting (PB) both as (i) a practical setting for LLM-based resource allocation and (ii) an adaptive benchmark for evaluating their reasoning capabilities. We task LLMs with selecting project subsets under feasibility (e.g., budget) constraints via three prompting strategies: greedy selection, direct optimization, and a hill-climbing-inspired refinement. We benchmark LLMs' allocations against a utility-maximizing oracle. Interestingly, we also test whether LLMs can infer structured preferences from natural-language voter input or metadata, without explicit votes. By comparing allocations based on inferred preferences to those from ground-truth votes, we evaluate LLMs' ability to extract preferences from open-ended input. Our results underscore the role of prompt design and show that LLMs hold promise for mechanism design with unstructured inputs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "llms",
      "for",
      "resource"
    ],
    "category": "noticia"
  },
  {
    "title": "Policy Optimization in Multi-Agent Settings under Partially Observable Environments",
    "title_es": "Policy Optimization in Multi-Agent Settings under Partially Observable Environments",
    "url": "https://arxiv.org/abs/2508.06061",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06061v1 Announce Type: new \nAbstract: This work leverages adaptive social learning to estimate partially observable global states in multi-agent reinforcement learning (MARL) problems. Unlike existing methods, the proposed approach enables the concurrent operation of social learning and reinforcement learning. Specifically, it alternates between a single step of social learning and a single step of MARL, eliminating the need for the time- and computation-intensive two-timescale learning frameworks. Theoretical guarantees are provided to support the effectiveness of the proposed method. Simulation results verify that the performance of the proposed methodology can approach that of reinforcement learning when the true state is known.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Policy Optimization in Multi-Agent Settings under Partially Observable Environments\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "policy",
      "optimization",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Don't Forget Imagination!",
    "title_es": "Don't Forget Imagination!",
    "url": "https://arxiv.org/abs/2508.06062",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06062v1 Announce Type: new \nAbstract: Cognitive imagination is a type of imagination that plays a key role in human thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to mentally visualize coherent and holistic systems of concepts and causal links that serve as semantic contexts for reasoning, decision making and prediction. Our position is that the role of cognitive imagination is still greatly underestimated, and this creates numerous problems and diminishes the current capabilities of AI. For instance, when reasoning, humans rely on imaginary contexts to retrieve background info. They also constantly return to the context for semantic verification that their reasoning is still reasonable. Thus, reasoning without imagination is blind. This paper is a call for greater attention to cognitive imagination as the next promising breakthrough in artificial intelligence. As an instrument for simulating cognitive imagination, we propose semantic models -- a new approach to mathematical models that can learn, like neural networks, and are based on probabilistic causal relationships. Semantic models can simulate cognitive imagination because they ensure the consistency of imaginary contexts and implement a glass-box approach that allows the context to be manipulated as a holistic and coherent system of interrelated facts glued together with causal relations.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Don't Forget Imagination!\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dont",
      "forget",
      "imagination"
    ],
    "category": "noticia"
  },
  {
    "title": "Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection",
    "title_es": "Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection",
    "url": "https://arxiv.org/abs/2508.06063",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06063v1 Announce Type: new \nAbstract: Salient object detection (SOD) and camouflaged object detection (COD) are two closely related but distinct computer vision tasks. Although both are class-agnostic segmentation tasks that map from RGB space to binary space, the former aims to identify the most salient objects in the image, while the latter focuses on detecting perfectly camouflaged objects that blend into the background in the image. These two tasks exhibit strong contradictory attributes. Previous works have mostly believed that joint learning of these two tasks would confuse the network, reducing its performance on both tasks. However, here we present an opposite perspective: with the correct approach to learning, the network can simultaneously possess the capability to find both salient and camouflaged objects, allowing both tasks to benefit from joint learning. We propose SCJoint, a joint learning scheme for SOD and COD tasks, assuming that the decoding processes of SOD and COD have different distribution characteristics. The key to our method is to learn the respective means and variances of the decoding processes for both tasks by inserting a minimal amount of task-specific learnable parameters within a fully shared network structure, thereby decoupling the contradictory attributes of the two tasks at a minimal cost. Furthermore, we propose a saliency-based sampling strategy (SBSS) to sample the training set of the SOD task to balance the training set sizes of the two tasks. In addition, SBSS improves the training set quality and shortens the training time. Based on the proposed SCJoint and SBSS, we train a powerful generalist network, named JoNet, which has the ability to simultaneously capture both ``salient\" and ``camouflaged\". Extensive experiments demonstrate the competitive performance and effectiveness of our proposed method. The code is available at https://github.com/linuxsino/JoNet.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "distributionspecific",
      "learning",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "A Generic Complete Anytime Beam Search for Optimal Decision Tree",
    "title_es": "A Generic Complete Anytime Beam Search for Optimal Decision Tree",
    "url": "https://arxiv.org/abs/2508.06064",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06064v1 Announce Type: new \nAbstract: Finding an optimal decision tree that minimizes classification error is known to be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic programming guarantee optimality, they often suffer from poor anytime behavior -- meaning they struggle to find high-quality decision trees quickly when the search is stopped before completion -- due to unbalanced search space exploration. To address this, several anytime extensions of exact methods have been proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not been systematically compared, making it difficult to assess their relative effectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and anytime beam search algorithm that extends the DL8.5 framework and unifies some existing anytime strategies. In particular, CA-DL8.5 generalizes previous approaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various heuristics and relaxation mechanisms through a modular design. The algorithm reuses DL8.5's efficient branch-and-bound pruning and trie-based caching, combined with a restart-based beam search that gradually relaxes pruning criteria to improve solution quality over time. Our contributions are twofold: (1) We introduce this new generic framework for exact and anytime decision tree learning, enabling the incorporation of diverse heuristics and search strategies; (2) We conduct a rigorous empirical comparison of several instantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k heuristics -- using an anytime evaluation metric called the primal gap integral. Experimental results on standard classification benchmarks show that CA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime performance, outperforming both other CA-DL8.5 variants and the Blossom algorithm while maintaining completeness and optimality guarantees.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Generic Complete Anytime Beam Search for Optimal Decision Tree\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "generic",
      "complete"
    ],
    "category": "noticia"
  },
  {
    "title": "ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation",
    "title_es": "ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation",
    "url": "https://arxiv.org/abs/2508.06065",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06065v1 Announce Type: new \nAbstract: Generative AI has made image creation more accessible, yet aligning outputs with nuanced creative intent remains challenging, particularly for non-experts. Existing tools often require users to externalize ideas through prompts or references, limiting fluid exploration. We introduce ThematicPlane, a system that enables users to navigate and manipulate high-level semantic concepts (e.g., mood, style, or narrative tone) within an interactive thematic design plane. This interface bridges the gap between tacit creative intent and system control. In our exploratory study (N=6), participants engaged in divergent and convergent creative modes, often embracing unexpected results as inspiration or iteration cues. While they grounded their exploration in familiar themes, differing expectations of how themes mapped to outputs revealed a need for more explainable controls. Overall, ThematicPlane fosters expressive, iterative workflows and highlights new directions for intuitive, semantics-driven interaction in generative design tools.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "thematicplane",
      "bridging",
      "tacit"
    ],
    "category": "noticia"
  },
  {
    "title": "Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology",
    "title_es": "Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology",
    "url": "https://arxiv.org/abs/2508.06066",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06066v1 Announce Type: new \nAbstract: Deep temporal architectures such as Temporal Convolutional Networks (TCNs) achieve strong predictive performance on sequential data, yet theoretical understanding of their generalization remains limited. We address this gap by providing both the first non-vacuous, architecture-aware generalization bounds for deep temporal models and a principled evaluation methodology.\n  For exponentially $\\beta$-mixing sequences, we derive bounds scaling as $ O\\!\\Bigl(R\\,\\sqrt{\\tfrac{D\\,p\\,n\\,\\log N}{N}}\\Bigr), $ where $D$ is network depth, $p$ kernel size, $n$ input dimension, and $R$ weight norm. Our delayed-feedback blocking mechanism transforms dependent samples into effectively independent ones while discarding only $O(1/\\log N)$ of the data, yielding $\\sqrt{D}$ scaling instead of exponential, implying that doubling depth requires approximately quadrupling the training data.\n  We also introduce a fair-comparison methodology that fixes the effective sample size to isolate the effect of temporal structure from information content. Under $N_{\\text{eff}}=2{,}000$, strongly dependent sequences ($\\rho=0.8$) exhibit $\\approx76\\%$ smaller generalization gaps than weakly dependent ones ($\\rho=0.2$), challenging the intuition that dependence is purely detrimental. Yet convergence rates diverge from theory: weak dependencies follow $N_{\\text{eff}}^{-1.21}$ scaling and strong dependencies follow $N_{\\text{eff}}^{-0.89}$, both steeper than the predicted $N^{-0.5}$. These findings reveal that temporal dependence can enhance learning under fixed information budgets, while highlighting gaps between theory and practice that motivate future research.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "architectureaware",
      "generalization",
      "bounds"
    ],
    "category": "noticia"
  },
  {
    "title": "A Game-Theoretic Foundation for Bitcoin's Price: A Security-Utility Equilibrium",
    "title_es": "A Game-Theoretic Foundation for Bitcoin's Price: A Security-Utility Equilibrium",
    "url": "https://arxiv.org/abs/2508.06071",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06071v1 Announce Type: new \nAbstract: This paper introduces a structural game-theoretic model to value decentralized digital assets like Bitcoin. Instead of relying on speculative beliefs, it frames the asset's price within a Rational-Expectations Security-Utility Nash Equilibrium (RESUNE). This equilibrium is a fixed point where the market-clearing price dictates the hash rate through a free-entry mining model, which in turn endogenously sets the network's security. The security, defined as one minus the probability of a 51% attack, is determined via a global games model of attacker coordination, providing a unique and continuous security function. We prove the existence of a RESUNE and offer conditions for its uniqueness and stability. The model predicts that the stabilizing direct effect of price on demand must outweigh the potentially destabilizing feedback from price to security. The framework generates testable predictions, such as a protocol halving causing a contraction in both hash rate and price. A structural Vector Autoregression (VAR) model is proposed to test this mechanism. The model decomposes Bitcoin's value into transactional utility, security, and speculative components and explains the observed unidirectional causality from price to hash rate.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Game-Theoretic Foundation for Bitcoin's Price: A Security-Utility Equilibrium\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "gametheoretic",
      "foundation"
    ],
    "category": "noticia"
  },
  {
    "title": "Can Large Models Fool the Eye? A New Turing Test for Biological Animation",
    "title_es": "Can Large Models Fool the Eye? A New Turing Test for Biological Animation",
    "url": "https://arxiv.org/abs/2508.06072",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06072v1 Announce Type: new \nAbstract: Evaluating the abilities of large models and manifesting their gaps are challenging. Current benchmarks adopt either ground-truth-based score-form evaluation on static datasets or indistinct textual chatbot-style human preferences collection, which may not provide users with immediate, intuitive, and perceptible feedback on performance differences. In this paper, we introduce BioMotion Arena, a novel framework for evaluating large language models (LLMs) and multimodal large language models (MLLMs) via visual animation. Our methodology draws inspiration from the inherent visual perception of motion patterns characteristic of living organisms that utilizes point-light source imaging to amplify the performance discrepancies between models. Specifically, we employ a pairwise comparison evaluation and collect more than 45k votes for 53 mainstream LLMs and MLLMs on 90 biological motion variants. Data analyses show that the crowd-sourced human votes are in good agreement with those of expert raters, demonstrating the superiority of our BioMotion Arena in offering discriminative feedback. We also find that over 90\\% of evaluated models, including the cutting-edge open-source InternVL3 and proprietary Claude-4 series, fail to produce fundamental humanoid point-light groups, much less smooth and biologically plausible motions. This enables BioMotion Arena to serve as a challenging benchmark for performance visualization and a flexible evaluation framework without restrictions on ground-truth.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Can Large Models Fool the Eye? A New Turing Test for Biological Animation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "can",
      "large",
      "models"
    ],
    "category": "noticia"
  },
  {
    "title": "ProvX: Generating Counterfactual-Driven Attack Explanations for Provenance-Based Detection",
    "title_es": "ProvX: Generating Counterfactual-Driven Attack Explanations for Provenance-Based Detection",
    "url": "https://arxiv.org/abs/2508.06073",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06073v1 Announce Type: new \nAbstract: Provenance graph-based intrusion detection systems are deployed on hosts to defend against increasingly severe Advanced Persistent Threat. Using Graph Neural Networks to detect these threats has become a research focus and has demonstrated exceptional performance. However, the widespread adoption of GNN-based security models is limited by their inherent black-box nature, as they fail to provide security analysts with any verifiable explanations for model predictions or any evidence regarding the model's judgment in relation to real-world attacks. To address this challenge, we propose ProvX, an effective explanation framework for exlaining GNN-based security models on provenance graphs. ProvX introduces counterfactual explanation logic, seeking the minimal structural subset within a graph predicted as malicious that, when perturbed, can subvert the model's original prediction. We innovatively transform the discrete search problem of finding this critical subgraph into a continuous optimization task guided by a dual objective of prediction flipping and distance minimization. Furthermore, a Staged Solidification strategy is incorporated to enhance the precision and stability of the explanations. We conducted extensive evaluations of ProvX on authoritative datasets. The experimental results demonstrate that ProvX can locate critical graph structures that are highly relevant to real-world attacks and achieves an average explanation necessity of 51.59\\%, with these metrics outperforming current SOTA explainers. Furthermore, we explore and provide a preliminary validation of a closed-loop Detection-Explanation-Feedback enhancement framework, demonstrating through experiments that the explanation results from ProvX can guide model optimization, effectively enhancing its robustness against adversarial attacks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ProvX: Generating Counterfactual-Driven Attack Explanations for Provenance-Based Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "provx",
      "generating",
      "counterfactualdriven"
    ],
    "category": "noticia"
  },
  {
    "title": "ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception",
    "title_es": "ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception",
    "url": "https://arxiv.org/abs/2508.06074",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06074v1 Announce Type: new \nAbstract: Autonomous driving systems face significant challenges in perceiving complex environments and making real-time decisions. Traditional modular approaches, while offering interpretability, suffer from error propagation and coordination issues, whereas end-to-end learning systems can simplify the design but face computational bottlenecks. This paper presents a novel approach to autonomous driving using deep reinforcement learning (DRL) that integrates bird's-eye view (BEV) perception for enhanced real-time decision-making. We introduce the \\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction network that combines BEV-based perception with the Mamba framework for temporal feature modeling. This integration allows the system to encode vehicle surroundings and road features in a unified coordinate system and accurately model long-range dependencies. Building on this, we propose the \\texttt{ME$^3$-BEV} framework, which utilizes the \\texttt{Mamba-BEV} model as a feature input for end-to-end DRL, achieving superior performance in dynamic urban driving scenarios. We further enhance the interpretability of the model by visualizing high-dimensional features through semantic segmentation, providing insight into the learned representations. Extensive experiments on the CARLA simulator demonstrate that \\texttt{ME$^3$-BEV} outperforms existing models across multiple metrics, including collision rate and trajectory accuracy, offering a promising solution for real-time autonomous driving.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mebev",
      "mambaenhanced",
      "deep"
    ],
    "category": "noticia"
  },
  {
    "title": "Towards MR-Based Trochleoplasty Planning",
    "title_es": "Towards MR-Based Trochleoplasty Planning",
    "url": "https://arxiv.org/abs/2508.06076",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06076v1 Announce Type: new \nAbstract: To treat Trochlear Dysplasia (TD), current approaches rely mainly on low-resolution clinical Magnetic Resonance (MR) scans and surgical intuition. The surgeries are planned based on surgeons experience, have limited adoption of minimally invasive techniques, and lead to inconsistent outcomes. We propose a pipeline that generates super-resolved, patient-specific 3D pseudo-healthy target morphologies from conventional clinical MR scans. First, we compute an isotropic super-resolved MR volume using an Implicit Neural Representation (INR). Next, we segment femur, tibia, patella, and fibula with a multi-label custom-trained network. Finally, we train a Wavelet Diffusion Model (WDM) to generate pseudo-healthy target morphologies of the trochlear region. In contrast to prior work producing pseudo-healthy low-resolution 3D MR images, our approach enables the generation of sub-millimeter resolved 3D shapes compatible for pre- and intraoperative use. These can serve as preoperative blueprints for reshaping the femoral groove while preserving the native patella articulation. Furthermore, and in contrast to other work, we do not require a CT for our pipeline - reducing the amount of radiation. We evaluated our approach on 25 TD patients and could show that our target morphologies significantly improve the sulcus angle (SA) and trochlear groove depth (TGD). The code and interactive visualization are available at https://wehrlimi.github.io/sr-3d-planning/.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Towards MR-Based Trochleoplasty Planning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "towards",
      "mrbased",
      "trochleoplasty"
    ],
    "category": "noticia"
  },
  {
    "title": "A Cross-Perspective Annotated Dataset for Dynamic Object-Level Attention Modeling in Cloud Gaming",
    "title_es": "A Cross-Perspective Annotated Dataset for Dynamic Object-Level Attention Modeling in Cloud Gaming",
    "url": "https://arxiv.org/abs/2508.06077",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06077v1 Announce Type: new \nAbstract: Cloud gaming has gained popularity as it provides high-quality gaming experiences on thin hardware, such as phones and tablets. Transmitting gameplay frames at high resolutions and ultra-low latency is the key to guaranteeing players' quality of experience (QoE). Numerous studies have explored deep learning (DL) techniques to address this challenge. The efficiency of these DL-based approaches is highly affected by the dataset. However, existing datasets usually focus on the positions of objects while ignoring semantic relationships with other objects and their unique features. In this paper, we present a game dataset by collecting gameplay clips from Grand Theft Auto (GTA) V, and annotating the player's interested objects during the gameplay. Based on the collected data, we analyze several factors that have an impact on player's interest and identify that the player's in-game speed, object's size, and object's speed are the main factors. The dataset is available at https://drive.google.com/drive/folders/1idH251a2K-hGGd3pKjX-3Gx5o_rUqLC4?usp=sharing",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Cross-Perspective Annotated Dataset for Dynamic Object-Level Attention Modeling in Cloud Gaming\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "crossperspective",
      "annotated"
    ],
    "category": "noticia"
  },
  {
    "title": "Panel-Scale Reconfigurable Photonic Interconnects for Scalable AI Computation",
    "title_es": "Panel-Scale Reconfigurable Photonic Interconnects for Scalable AI Computation",
    "url": "https://arxiv.org/abs/2508.06079",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06079v1 Announce Type: new \nAbstract: Panel-scale reconfigurable photonic interconnects on a glass substrate up to 500-mm x 500-mm or larger are envisioned by proposing a novel photonic switch fabric that enables all directional panel-edge-to-panel-edge reach without the need for active repeaters while offering high communication bandwidth, planar-direction reconfigurability, low energy consumption, and compelling data bandwidth density for heterogeneous integration of an in-package AI computing system on a single glass-substrate photonic interposer exceeding thousands of centimeters square. The proposed approach focuses on reconfigurable photonic interconnects, which are integration-compatible with commercial processor chiplets and 3D high-bandwidth memory (HBM) stacks on a large-area glass substrate, to create a novel panel-scale heterogeneously integrated interposer or package enabling low-energy and high-capacity wavelength-division-multiplexing (WDM) optical data links using advanced high-speed optical modulators, broadband photodetectors, novel optical crossbar switches with multi-layer waveguides, and in-package frequency comb sources.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Panel-Scale Reconfigurable Photonic Interconnects for Scalable AI Computation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "panelscale",
      "reconfigurable",
      "photonic"
    ],
    "category": "noticia"
  },
  {
    "title": "DreamVE: Unified Instruction-based Image and Video Editing",
    "title_es": "DreamVE: Unified Instruction-based Image and Video Editing",
    "url": "https://arxiv.org/abs/2508.06080",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06080v1 Announce Type: new \nAbstract: Instruction-based editing holds vast potential due to its simple and efficient interactive editing format. However, instruction-based editing, particularly for video, has been constrained by limited training data, hindering its practical application. To this end, we introduce DreamVE, a unified model for instruction-based image and video editing. Specifically, We propose a two-stage training strategy: first image editing, then video editing. This offers two main benefits: (1) Image data scales more easily, and models are more efficient to train, providing useful priors for faster and better video editing training. (2) Unifying image and video generation is natural and aligns with current trends. Moreover, we present comprehensive training data synthesis pipelines, including collage-based and generative model-based data synthesis. The collage-based data synthesis combines foreground objects and backgrounds to generate diverse editing data, such as object manipulation, background changes, and text modifications. It can easily generate billions of accurate, consistent, realistic, and diverse editing pairs. We pretrain DreamVE on extensive collage-based data to achieve strong performance in key editing types and enhance generalization and transfer capabilities. However, collage-based data lacks some attribute editing cases, leading to a relative drop in performance. In contrast, the generative model-based pipeline, despite being hard to scale up, offers flexibility in handling attribute editing cases. Therefore, we use generative model-based data to further fine-tune DreamVE. Besides, we design an efficient and powerful editing framework for DreamVE. We build on the SOTA T2V model and use a token concatenation with early drop approach to inject source image guidance, ensuring strong consistency and editability. The codes and models will be released.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DreamVE: Unified Instruction-based Image and Video Editing\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dreamve",
      "unified",
      "instructionbased"
    ],
    "category": "noticia"
  },
  {
    "title": "SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment",
    "title_es": "SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment",
    "url": "https://arxiv.org/abs/2508.06082",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06082v1 Announce Type: new \nAbstract: Diffusion-based or flow-based models have achieved significant progress in video synthesis but require multiple iterative sampling steps, which incurs substantial computational overhead. While many distillation methods that are solely based on trajectory-preserving or distribution-matching have been developed to accelerate video generation models, these approaches often suffer from performance breakdown or increased artifacts under few-step settings. To address these limitations, we propose \\textbf{\\emph{SwiftVideo}}, a unified and stable distillation framework that combines the advantages of trajectory-preserving and distribution-matching strategies. Our approach introduces continuous-time consistency distillation to ensure precise preservation of ODE trajectories. Subsequently, we propose a dual-perspective alignment that includes distribution alignment between synthetic and real data along with trajectory alignment across different inference steps. Our method maintains high-quality video generation while substantially reducing the number of inference steps. Quantitative evaluations on the OpenVid-1M benchmark demonstrate that our method significantly outperforms existing approaches in few-step video generation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "swiftvideo",
      "a",
      "unified"
    ],
    "category": "noticia"
  },
  {
    "title": "AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance",
    "title_es": "AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance",
    "url": "https://arxiv.org/abs/2508.06084",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06084v1 Announce Type: new \nAbstract: Vision-language models (VLMs) have achieved impressive performance on multimodal reasoning tasks such as visual question answering (VQA), but their inference cost remains a significant challenge due to the large number of vision tokens processed during the prefill stage. Existing pruning methods often rely on directly using the attention patterns or static text prompt guidance, failing to exploit the dynamic internal signals generated during inference. To address these issues, we propose AdaptInfer, a plug-and-play framework for adaptive vision token pruning in VLMs. First, we introduce a fine-grained, dynamic text-guided pruning mechanism that reuses layer-wise text-to-text attention maps to construct soft priors over text-token importance, allowing more informed scoring of vision tokens at each stage. Second, we perform an offline analysis of cross-modal attention shifts and identify consistent inflection locations in inference, which inspire us to propose a more principled and efficient pruning schedule. Our method is lightweight and plug-and-play, also generalizable across multi-modal tasks. Experimental results have verified the effectiveness of the proposed method. For example, it reduces CUDA latency by 61.3\\% while maintaining an average accuracy of 92.9\\% on vanilla LLaVA-1.5-7B. Under the same token budget, AdaptInfer surpasses SOTA in accuracy.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "adaptinfer",
      "adaptive",
      "token"
    ],
    "category": "noticia"
  },
  {
    "title": "Exploring Interactive Simulation of Grass Display Color Characteristic Based on Real-World Conditions",
    "title_es": "Exploring Interactive Simulation of Grass Display Color Characteristic Based on Real-World Conditions",
    "url": "https://arxiv.org/abs/2508.06086",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06086v1 Announce Type: new \nAbstract: Recent research has focused on incorporating media into living environments via color-controlled materials and image display. In particular, grass-based displays have drawn attention as landscape-friendly interactive interfaces. To develop the grass display, it is important to obtain the grass color change characteristics that depend on the real environment. However, conventional methods require experiments on actual equipment every time the lighting or viewpoint changes, which is time-consuming and costly. Although research has begun on simulating grass colors, this approach still faces significant issues as it takes many hours for a single measurement. In this paper, we explore an interactive simulation of a grass display color change characteristic based on real-world conditions in a virtual environment. We evaluated our method's accuracy by simulating grass color characteristics across multiple viewpoints and environments, and then compared the results against prior work. The results indicated that our method tended to simulate the grass color characteristics similar to the actual characteristics and showed the potential to do so more quickly and with comparable accuracy to the previous study.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Exploring Interactive Simulation of Grass Display Color Characteristic Based on Real-World Conditions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "exploring",
      "interactive",
      "simulation"
    ],
    "category": "noticia"
  },
  {
    "title": "Adaptive Backtracking for Privacy Protection in Large Language Models",
    "title_es": "Adaptive Backtracking for Privacy Protection in Large Language Models",
    "url": "https://arxiv.org/abs/2508.06087",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06087v1 Announce Type: new \nAbstract: The preservation of privacy has emerged as a critical topic in the era of artificial intelligence. However, current work focuses on user-oriented privacy, overlooking severe enterprise data leakage risks exacerbated by the Retrieval-Augmented Generation paradigm. To address this gap, our paper introduces a novel objective: enterprise-oriented privacy concerns. Achieving this objective requires overcoming two fundamental challenges: existing methods such as data sanitization severely degrade model performance, and the field lacks public datasets for evaluation. We address these challenges with several solutions. (1) To prevent performance degradation, we propose ABack, a training-free mechanism that leverages a Hidden State Model to pinpoint the origin of a leakage intention and rewrite the output safely. (2) To solve the lack of datasets, we construct PriGenQA, a new benchmark for enterprise privacy scenarios in healthcare and finance. To ensure a rigorous evaluation, we move beyond simple static attacks by developing a powerful adaptive attacker with Group Relative Policy Optimization. Experiments show that against this superior adversary, ABack improves the overall privacy utility score by up to 15\\% over strong baselines, avoiding the performance trade-offs of prior methods.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Adaptive Backtracking for Privacy Protection in Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "adaptive",
      "backtracking",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Widest Path Games and Maximality Inheritance in Bounded Value Iteration for Stochastic Games",
    "title_es": "Widest Path Games and Maximality Inheritance in Bounded Value Iteration for Stochastic Games",
    "url": "https://arxiv.org/abs/2508.06088",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06088v1 Announce Type: new \nAbstract: For model checking stochastic games (SGs), bounded value iteration (BVI) algorithms have gained attention as efficient approximate methods with rigorous precision guarantees. However, BVI may not terminate or converge when the target SG contains end components. Most existing approaches address this issue by explicitly detecting and processing end components--a process that is often computationally expensive. An exception is the widest path-based BVI approach previously studied by Phalakarn et al., which we refer to as 1WP-BVI. The method performs particularly well in the presence of numerous end components. Nonetheless, its theoretical foundations remain somewhat ad hoc. In this paper, we identify and formalize the core principles underlying the widest path-based BVI approach by (i) presenting 2WP-BVI, a clean BVI algorithm based on (2-player) widest path games, and (ii) proving its correctness using what we call the maximality inheritance principle--a proof principle previously employed in a well-known result in probabilistic model checking. Our experimental results demonstrate the practical relevance and potential of our proposed 2WP-BVI algorithm.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Widest Path Games and Maximality Inheritance in Bounded Value Iteration for Stochastic Games\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "widest",
      "path",
      "games"
    ],
    "category": "noticia"
  },
  {
    "title": "Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2",
    "title_es": "Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2",
    "url": "https://arxiv.org/abs/2508.06091",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06091v1 Announce Type: new \nAbstract: In recent years, there has been growing interest in understanding the expressive power of graph neural networks (GNNs) by relating them to logical languages. This research has been been initialised by an influential result of Barcel\\'o et al. (2020), who showed that the graded modal logic (or a guarded fragment of the logic C2), characterises the logical expressiveness of aggregate-combine GNNs. As a ``challenging open problem'' they left the question whether full C2 characterises the logical expressiveness of aggregate-combine-readout GNNs. This question has remained unresolved despite several attempts. In this paper, we solve the above open problem by proving that the logical expressiveness of aggregate-combine-readout GNNs strictly exceeds that of C2. This result holds over both undirected and directed graphs. Beyond its implications for GNNs, our work also leads to purely logical insights on the expressive power of infinitary logics.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "aggregatecombinereadout",
      "gnns",
      "are"
    ],
    "category": "noticia"
  },
  {
    "title": "Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation",
    "title_es": "Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation",
    "url": "https://arxiv.org/abs/2508.06092",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06092v1 Announce Type: new \nAbstract: Accurate and efficient Video Quality Assessment (VQA) has long been a key research challenge. Current mainstream VQA methods typically improve performance by pretraining on large-scale classification datasets (e.g., ImageNet, Kinetics-400), followed by fine-tuning on VQA datasets. However, this strategy presents two significant challenges: (1) merely transferring semantic knowledge learned from pretraining is insufficient for VQA, as video quality depends on multiple factors (e.g., semantics, distortion, motion, aesthetics); (2) pretraining on large-scale datasets demands enormous computational resources, often dozens or even hundreds of times greater than training directly on VQA datasets. Recently, Vision-Language Models (VLMs) have shown remarkable generalization capabilities across a wide range of visual tasks, and have begun to demonstrate promising potential in quality assessment. In this work, we propose Q-CLIP, the first fully VLMs-based framework for VQA. Q-CLIP enhances both visual and textual representations through a Shared Cross-Modal Adapter (SCMA), which contains only a minimal number of trainable parameters and is the only component that requires training. This design significantly reduces computational cost. In addition, we introduce a set of five learnable quality-level prompts to guide the VLMs in perceiving subtle quality variations, thereby further enhancing the model's sensitivity to video quality. Furthermore, we investigate the impact of different frame sampling strategies on VQA performance, and find that frame-difference-based sampling leads to better generalization performance across datasets. Extensive experiments demonstrate that Q-CLIP exhibits excellent performance on several VQA datasets.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "qclip",
      "unleashing",
      "the"
    ],
    "category": "noticia"
  },
  {
    "title": "E-React: Towards Emotionally Controlled Synthesis of Human Reactions",
    "title_es": "E-React: Towards Emotionally Controlled Synthesis of Human Reactions",
    "url": "https://arxiv.org/abs/2508.06093",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06093v1 Announce Type: new \nAbstract: Emotion serves as an essential component in daily human interactions. Existing human motion generation frameworks do not consider the impact of emotions, which reduces naturalness and limits their application in interactive tasks, such as human reaction synthesis. In this work, we introduce a novel task: generating diverse reaction motions in response to different emotional cues. However, learning emotion representation from limited motion data and incorporating it into a motion generation framework remains a challenging problem. To address the above obstacles, we introduce a semi-supervised emotion prior in an actor-reactor diffusion model to facilitate emotion-driven reaction synthesis. Specifically, based on the observation that motion clips within a short sequence tend to share the same emotion, we first devise a semi-supervised learning framework to train an emotion prior. With this prior, we further train an actor-reactor diffusion model to generate reactions by considering both spatial interaction and emotional response. Finally, given a motion sequence of an actor, our approach can generate realistic reactions under various emotional conditions. Experimental results demonstrate that our model outperforms existing reaction generation methods. The code and data will be made publicly available at https://ereact.github.io/",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"E-React: Towards Emotionally Controlled Synthesis of Human Reactions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ereact",
      "towards",
      "emotionally"
    ],
    "category": "noticia"
  },
  {
    "title": "ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline",
    "title_es": "ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline",
    "url": "https://arxiv.org/abs/2508.06094",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06094v1 Announce Type: new \nAbstract: Constructed languages (conlangs) such as Esperanto and Quenya have played diverse roles in art, philosophy, and international communication. Meanwhile, large-scale foundation models have revolutionized creative generation in text, images, and beyond. In this work, we leverage modern LLMs as computational creativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a multi-hop pipeline that decomposes language design into modular stages -- phonology, morphology, syntax, lexicon generation, and translation. At each stage, our method leverages LLMs' meta-linguistic reasoning capabilities, injecting randomness to encourage diversity and leveraging self-refinement feedback to encourage consistency in the emerging language description. We evaluate ConlangCrafter on metrics measuring coherence and typological diversity, demonstrating its ability to produce coherent and varied conlangs without human linguistic expertise.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "conlangcrafter",
      "constructing",
      "languages"
    ],
    "category": "noticia"
  },
  {
    "title": "Incremental Language Understanding for Online Motion Planning of Robot Manipulators",
    "title_es": "Incremental Language Understanding for Online Motion Planning of Robot Manipulators",
    "url": "https://arxiv.org/abs/2508.06095",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06095v1 Announce Type: new \nAbstract: Human-robot interaction requires robots to process language incrementally, adapting their actions in real-time based on evolving speech input. Existing approaches to language-guided robot motion planning typically assume fully specified instructions, resulting in inefficient stop-and-replan behavior when corrections or clarifications occur. In this paper, we introduce a novel reasoning-based incremental parser which integrates an online motion planning algorithm within the cognitive architecture. Our approach enables continuous adaptation to dynamic linguistic input, allowing robots to update motion plans without restarting execution. The incremental parser maintains multiple candidate parses, leveraging reasoning mechanisms to resolve ambiguities and revise interpretations when needed. By combining symbolic reasoning with online motion planning, our system achieves greater flexibility in handling speech corrections and dynamically changing constraints. We evaluate our framework in real-world human-robot interaction scenarios, demonstrating online adaptions of goal poses, constraints, or task objectives. Our results highlight the advantages of integrating incremental language understanding with real-time motion planning for natural and fluid human-robot collaboration. The experiments are demonstrated in the accompanying video at www.acin.tuwien.ac.at/42d5.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Incremental Language Understanding for Online Motion Planning of Robot Manipulators\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "incremental",
      "language",
      "understanding"
    ],
    "category": "noticia"
  },
  {
    "title": "Bounding Distributional Shifts in World Modeling through Novelty Detection",
    "title_es": "Bounding Distributional Shifts in World Modeling through Novelty Detection",
    "url": "https://arxiv.org/abs/2508.06096",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06096v1 Announce Type: new \nAbstract: Recent work on visual world models shows significant promise in latent state dynamics obtained from pre-trained image backbones. However, most of the current approaches are sensitive to training quality, requiring near-complete coverage of the action and state space during training to prevent divergence during inference. To make a model-based planning algorithm more robust to the quality of the learned world model, we propose in this work to use a variational autoencoder as a novelty detector to ensure that proposed action trajectories during planning do not cause the learned model to deviate from the training data distribution. To evaluate the effectiveness of this approach, a series of experiments in challenging simulated robot environments was carried out, with the proposed method incorporated into a model-predictive control policy loop extending the DINO-WM architecture. The results clearly show that the proposed method improves over state-of-the-art solutions in terms of data efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Bounding Distributional Shifts in World Modeling through Novelty Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "bounding",
      "distributional",
      "shifts"
    ],
    "category": "noticia"
  },
  {
    "title": "Recurrent Deep Differentiable Logic Gate Networks",
    "title_es": "Recurrent Deep Differentiable Logic Gate Networks",
    "url": "https://arxiv.org/abs/2508.06097",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06097v1 Announce Type: new \nAbstract: While differentiable logic gates have shown promise in feedforward networks, their application to sequential modeling remains unexplored. This paper presents the first implementation of Recurrent Deep Differentiable Logic Gate Networks (RDDLGN), combining Boolean operations with recurrent architectures for sequence-to-sequence learning.\n  Evaluated on WMT'14 English-German translation, RDDLGN achieves 5.00 BLEU and 30.9\\% accuracy during training, approaching GRU performance (5.41 BLEU) and graceful degradation (4.39 BLEU) during inference. This work establishes recurrent logic-based neural computation as viable, opening research directions for FPGA acceleration in sequential modeling and other recursive network architectures.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Recurrent Deep Differentiable Logic Gate Networks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "recurrent",
      "deep",
      "differentiable"
    ],
    "category": "noticia"
  },
  {
    "title": "MeanAudio: Fast and Faithful Text-to-Audio Generation with Mean Flows",
    "title_es": "MeanAudio: Fast and Faithful Text-to-Audio Generation with Mean Flows",
    "url": "https://arxiv.org/abs/2508.06098",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06098v1 Announce Type: new \nAbstract: Recent developments in diffusion- and flow- based models have significantly advanced Text-to-Audio Generation (TTA). While achieving great synthesis quality and controllability, current TTA systems still suffer from slow inference speed, which significantly limits their practical applicability. This paper presents MeanAudio, a novel MeanFlow-based model tailored for fast and faithful text-to-audio generation. Built on a Flux-style latent transformer, MeanAudio regresses the average velocity field during training, enabling fast generation by mapping directly from the start to the endpoint of the flow trajectory. By incorporating classifier-free guidance (CFG) into the training target, MeanAudio incurs no additional cost in the guided sampling process. To further stabilize training, we propose an instantaneous-to-mean curriculum with flow field mix-up, which encourages the model to first learn the foundational instantaneous dynamics, and then gradually adapt to mean flows. This strategy proves critical for enhancing training efficiency and generation quality. Experimental results demonstrate that MeanAudio achieves state-of-the-art performance in single-step audio generation. Specifically, it achieves a real time factor (RTF) of 0.013 on a single NVIDIA RTX 3090, yielding a 100x speedup over SOTA diffusion-based TTA systems. Moreover, MeanAudio also demonstrates strong performance in multi-step generation, enabling smooth and coherent transitions across successive synthesis steps.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MeanAudio: Fast and Faithful Text-to-Audio Generation with Mean Flows\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "meanaudio",
      "fast",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization",
    "title_es": "UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization",
    "url": "https://arxiv.org/abs/2508.06101",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06101v1 Announce Type: new \nAbstract: In the digital age, advanced image editing tools pose a serious threat to the integrity of visual content, making image forgery detection and localization a key research focus. Most existing Image Manipulation Localization (IML) methods rely on discriminative learning and require large, high-quality annotated datasets. However, current datasets lack sufficient scale and diversity, limiting model performance in real-world scenarios. To overcome this, recent studies have explored Constrained IML (CIML), which generates pixel-level annotations through algorithmic supervision. However, existing CIML approaches often depend on complex multi-stage pipelines, making the annotation process inefficient. In this work, we propose a novel generative framework based on diffusion models, named UGD-IML, which for the first time unifies both IML and CIML tasks within a single framework. By learning the underlying data distribution, generative diffusion models inherently reduce the reliance on large-scale labeled datasets, allowing our approach to perform effectively even under limited data conditions. In addition, by leveraging a class embedding mechanism and a parameter-sharing design, our model seamlessly switches between IML and CIML modes without extra components or training overhead. Furthermore, the end-to-end design enables our model to avoid cumbersome steps in the data annotation process. Extensive experimental results on multiple datasets demonstrate that UGD-IML outperforms the SOTA methods by an average of 9.66 and 4.36 in terms of F1 metrics for IML and CIML tasks, respectively. Moreover, the proposed method also excels in uncertainty estimation, visualization and robustness.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ugdiml",
      "a",
      "unified"
    ],
    "category": "noticia"
  },
  {
    "title": "Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs",
    "title_es": "Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs",
    "url": "https://arxiv.org/abs/2508.06103",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06103v1 Announce Type: new \nAbstract: This paper presents two effective approaches for Extractive Question Answering (QA) on the Quran. It addresses challenges related to complex language, unique terminology, and deep meaning in the text. The second uses few-shot prompting with instruction-tuned large language models such as Gemini and DeepSeek. A specialized Arabic prompt framework is developed for span extraction. A strong post-processing system integrates subword alignment, overlap suppression, and semantic filtering. This improves precision and reduces hallucinations. Evaluations show that large language models with Arabic instructions outperform traditional fine-tuned models. The best configuration achieves a pAP10 score of 0.637. The results confirm that prompt-based instruction tuning is effective for low-resource, semantically rich QA tasks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fewshot",
      "prompting",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "MCA: 2D-3D Retrieval with Noisy Labels via Multi-level Adaptive Correction and Alignment",
    "title_es": "MCA: 2D-3D Retrieval with Noisy Labels via Multi-level Adaptive Correction and Alignment",
    "url": "https://arxiv.org/abs/2508.06104",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06104v1 Announce Type: new \nAbstract: With the increasing availability of 2D and 3D data, significant advancements have been made in the field of cross-modal retrieval. Nevertheless, the existence of imperfect annotations presents considerable challenges, demanding robust solutions for 2D-3D cross-modal retrieval in the presence of noisy label conditions. Existing methods generally address the issue of noise by dividing samples independently within each modality, making them susceptible to overfitting on corrupted labels. To address these issues, we propose a robust 2D-3D \\textbf{M}ulti-level cross-modal adaptive \\textbf{C}orrection and \\textbf{A}lignment framework (MCA). Specifically, we introduce a Multimodal Joint label Correction (MJC) mechanism that leverages multimodal historical self-predictions to jointly model the modality prediction consistency, enabling reliable label refinement. Additionally, we propose a Multi-level Adaptive Alignment (MAA) strategy to effectively enhance cross-modal feature semantics and discrimination across different levels. Extensive experiments demonstrate the superiority of our method, MCA, which achieves state-of-the-art performance on both conventional and realistic noisy 3D benchmarks, highlighting its generality and effectiveness.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MCA: 2D-3D Retrieval with Noisy Labels via Multi-level Adaptive Correction and Alignment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mca",
      "dd",
      "retrieval"
    ],
    "category": "noticia"
  },
  {
    "title": "You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures",
    "title_es": "You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures",
    "url": "https://arxiv.org/abs/2508.06105",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06105v1 Announce Type: new \nAbstract: Large language models (LLMs) often suffer from hallucination, generating factually incorrect statements when handling questions beyond their knowledge and perception. Retrieval-augmented generation (RAG) addresses this by retrieving query-relevant contexts from knowledge bases to support LLM reasoning. Recent advances leverage pre-constructed graphs to capture the relational connections among distributed documents, showing remarkable performance in complex tasks. However, existing Graph-based RAG (GraphRAG) methods rely on a costly process to transform the corpus into a graph, introducing overwhelming token cost and update latency. Moreover, real-world queries vary in type and complexity, requiring different logic structures for accurate reasoning. The pre-built graph may not align with these required structures, resulting in ineffective knowledge retrieval. To this end, we propose a \\textbf{\\underline{Logic}}-aware \\textbf{\\underline{R}}etrieval-\\textbf{\\underline{A}}ugmented \\textbf{\\underline{G}}eneration framework (\\textbf{LogicRAG}) that dynamically extracts reasoning structures at inference time to guide adaptive retrieval without any pre-built graph. LogicRAG begins by decomposing the input query into a set of subproblems and constructing a directed acyclic graph (DAG) to model the logical dependencies among them. To support coherent multi-step reasoning, LogicRAG then linearizes the graph using topological sort, so that subproblems can be addressed in a logically consistent order. Besides, LogicRAG applies graph pruning to reduce redundant retrieval and uses context pruning to filter irrelevant context, significantly reducing the overall token cost. Extensive experiments demonstrate that LogicRAG achieves both superior performance and efficiency compared to state-of-the-art baselines.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "you",
      "dont",
      "need"
    ],
    "category": "noticia"
  },
  {
    "title": "Simulation in Cybersecurity: Understanding Techniques, Applications, and Goals",
    "title_es": "Simulation in Cybersecurity: Understanding Techniques, Applications, and Goals",
    "url": "https://arxiv.org/abs/2508.06106",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06106v1 Announce Type: new \nAbstract: Modeling and simulation are widely used in cybersecurity research to assess cyber threats, evaluate defense mechanisms, and analyze vulnerabilities. However, the diversity of application areas, the variety of cyberattacks scenarios, and the differing objectives of these simulations makes it difficult to identify methodological trends. Existing reviews often focus on specific modeling techniques or application domains, making it challenging to analyze the field as a whole. To address these limitations, we present a comprehensive review of the current state of the art, classifying the selected papers based on four dimensions: the application domain, the types of cyber threats represented, the simulation techniques employed, and the primary goals of the simulation. The review discusses the strengths and limitations of different approaches, identifies which cyber threats are the most suited for simulation-based investigations, and analyzes which modeling paradigms are most appropriate for specific cybersecurity challenges.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Simulation in Cybersecurity: Understanding Techniques, Applications, and Goals\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "simulation",
      "in",
      "cybersecurity"
    ],
    "category": "noticia"
  },
  {
    "title": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention",
    "title_es": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention",
    "url": "https://arxiv.org/abs/2508.06107",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06107v1 Announce Type: new \nAbstract: Recognizing handwritten mathematical expressions (HMER) is a challenging task due to the inherent two-dimensional structure, varying symbol scales, and complex spatial relationships among symbols. In this paper, we present a self-supervised learning (SSL) framework for HMER that eliminates the need for expensive labeled data. Our approach begins by pretraining an image encoder using a combination of global and local contrastive loss, enabling the model to learn both holistic and fine-grained representations. A key contribution of this work is a novel self-supervised attention network, which is trained using a progressive spatial masking strategy. This attention mechanism is designed to learn semantically meaningful focus regions, such as operators, exponents, and nested mathematical notation, without requiring any supervision. The progressive masking curriculum encourages the network to become increasingly robust to missing or occluded visual information, ultimately improving structural understanding. Our complete pipeline consists of (1) self-supervised pretraining of the encoder, (2) self-supervised attention learning, and (3) supervised fine-tuning with a transformer decoder to generate LATEX sequences. Extensive experiments on CROHME benchmarks demonstrate that our method outperforms existing SSL and fully supervised baselines, validating the effectiveness of our progressive attention mechanism in enhancing HMER performance. Our codebase can be found here.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mask",
      "",
      "match"
    ],
    "category": "noticia"
  },
  {
    "title": "GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning",
    "title_es": "GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.06108",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06108v1 Announce Type: new \nAbstract: Goal-conditioned reinforcement learning (GCRL) with sparse rewards remains a fundamental challenge in reinforcement learning. While hindsight experience replay (HER) has shown promise by relabeling collected trajectories with achieved goals, we argue that trajectory relabeling alone does not fully exploit the available experiences in off-policy GCRL methods, resulting in limited sample efficiency. In this paper, we propose Hindsight Goal-conditioned Regularization (HGR), a technique that generates action regularization priors based on hindsight goals. When combined with hindsight self-imitation regularization (HSR), our approach enables off-policy RL algorithms to maximize experience utilization. Compared to existing GCRL methods that employ HER and self-imitation techniques, our hindsight regularizations achieve substantially more efficient sample reuse and the best performances, which we empirically demonstrate on a suite of navigation and manipulation tasks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "gchr",
      "",
      "goalconditioned"
    ],
    "category": "noticia"
  },
  {
    "title": "FMCE-Net++: Feature Map Convergence Evaluation and Training",
    "title_es": "FMCE-Net++: Feature Map Convergence Evaluation and Training",
    "url": "https://arxiv.org/abs/2508.06109",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06109v1 Announce Type: new \nAbstract: Deep Neural Networks (DNNs) face interpretability challenges due to their opaque internal representations. While Feature Map Convergence Evaluation (FMCE) quantifies module-level convergence via Feature Map Convergence Scores (FMCS), it lacks experimental validation and closed-loop integration. To address this limitation, we propose FMCE-Net++, a novel training framework that integrates a pretrained, frozen FMCE-Net as an auxiliary head. This module generates FMCS predictions, which, combined with task labels, jointly supervise backbone optimization through a Representation Auxiliary Loss. The RAL dynamically balances the primary classification loss and feature convergence optimization via a tunable \\Representation Abstraction Factor. Extensive experiments conducted on MNIST, CIFAR-10, FashionMNIST, and CIFAR-100 demonstrate that FMCE-Net++ consistently enhances model performance without architectural modifications or additional data. Key experimental outcomes include accuracy gains of $+1.16$ pp (ResNet-50/CIFAR-10) and $+1.08$ pp (ShuffleNet v2/CIFAR-100), validating that FMCE-Net++ can effectively elevate state-of-the-art performance ceilings.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"FMCE-Net++: Feature Map Convergence Evaluation and Training\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fmcenet",
      "feature",
      "map"
    ],
    "category": "noticia"
  },
  {
    "title": "PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion",
    "title_es": "PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion",
    "url": "https://arxiv.org/abs/2508.06110",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06110v1 Announce Type: new \nAbstract: Table reasoning, including tabular QA and fact verification, often depends on annotated data or complex data augmentation, limiting flexibility and generalization. LLMs, despite their versatility, often underperform compared to simple supervised models. To approach these issues, we introduce PanelTR, a framework utilizing LLM agent scientists for robust table reasoning through a structured scientific approach. PanelTR's workflow involves agent scientists conducting individual investigations, engaging in self-review, and participating in collaborative peer-review discussions. This process, driven by five scientist personas, enables semantic-level transfer without relying on data augmentation or parametric optimization. Experiments across four benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully supervised models, all while remaining independent of training data. Our findings indicate that structured scientific methodology can effectively handle complex tasks beyond table reasoning with flexible semantic understanding in a zero-shot context.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "paneltr",
      "zeroshot",
      "table"
    ],
    "category": "noticia"
  },
  {
    "title": "SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges",
    "title_es": "SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges",
    "url": "https://arxiv.org/abs/2508.06111",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06111v1 Announce Type: new \nAbstract: Evaluating the capabilities and risks of foundation models is paramount, yet current methods demand extensive domain expertise, hindering their scalability as these models rapidly evolve. We introduce SKATE: a novel evaluation framework in which large language models (LLMs) compete by generating and solving verifiable tasks for one another. Our core insight is to treat evaluation as a game: models act as both task-setters and solvers, incentivized to create questions which highlight their own strengths while exposing others' weaknesses. SKATE offers several key advantages, balancing scalability, open-endedness, and objectivity. It is fully automated, data-free, and scalable, requiring no human input or domain expertise. By using verifiable tasks rather than LLM judges, scoring is objective. Unlike domain-limited programmatically-generated benchmarks (e.g. chess-playing or spatial reasoning), having LLMs creatively pose challenges enables open-ended and scalable evaluation. As a proof of concept, we introduce LLM-set code-output-prediction (COP) challenges as a verifiable and extensible framework in which to test our approach. Using a TrueSkill-based ranking system, we evaluate six frontier LLMs and find that: (1) weaker models can reliably differentiate and score stronger ones, (2) LLM-based systems are capable of self-preferencing behavior, generating questions that align with their own capabilities, and (3) SKATE automatically surfaces fine-grained capability differences between models. Our findings are an important step towards general, scalable evaluation frameworks which can keep pace with LLM progress.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "skate",
      "a",
      "scalable"
    ],
    "category": "noticia"
  },
  {
    "title": "GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving",
    "title_es": "GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving",
    "url": "https://arxiv.org/abs/2508.06113",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06113v1 Announce Type: new \nAbstract: Diffusion-based models are redefining the state-of-the-art in end-to-end autonomous driving, yet their performance is increasingly hampered by a reliance on transformer-based fusion. These architectures face fundamental limitations: quadratic computational complexity restricts the use of high-resolution features, and a lack of spatial priors prevents them from effectively modeling the inherent structure of Bird's Eye View (BEV) representations. This paper introduces GMF-Drive (Gated Mamba Fusion for Driving), an end-to-end framework that overcomes these challenges through two principled innovations. First, we supersede the information-limited histogram-based LiDAR representation with a geometrically-augmented pillar format encoding shape descriptors and statistical features, preserving critical 3D geometric details. Second, we propose a novel hierarchical gated mamba fusion (GM-Fusion) architecture that substitutes an expensive transformer with a highly efficient, spatially-aware state-space model (SSM). Our core BEV-SSM leverages directional sequencing and adaptive fusion mechanisms to capture long-range dependencies with linear complexity, while explicitly respecting the unique spatial properties of the driving scene. Extensive experiments on the challenging NAVSIM benchmark demonstrate that GMF-Drive achieves a new state-of-the-art performance, significantly outperforming DiffusionDrive. Comprehensive ablation studies validate the efficacy of each component, demonstrating that task-specific SSMs can surpass a general-purpose transformer in both performance and efficiency for autonomous driving.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "gmfdrive",
      "gated",
      "mamba"
    ],
    "category": "noticia"
  },
  {
    "title": "SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation",
    "title_es": "SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation",
    "url": "https://arxiv.org/abs/2508.06115",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06115v1 Announce Type: new \nAbstract: Semantic segmentation in open-vocabulary scenarios presents significant challenges due to the wide range and granularity of semantic categories. Existing weakly-supervised methods often rely on category-specific supervision and ill-suited feature construction methods for contrastive learning, leading to semantic misalignment and poor performance. In this work, we propose a novel weakly-supervised approach, SynSeg, to address the challenges. SynSeg performs Multi-Category Contrastive Learning (MCCL) as a stronger training signal with a new feature reconstruction framework named Feature Synergy Structure (FSS). Specifically, MCCL strategy robustly combines both intra- and inter-category alignment and separation in order to make the model learn the knowledge of correlations from different categories within the same image. Moreover, FSS reconstructs discriminative features for contrastive learning through prior fusion and semantic-activation-map enhancement, effectively avoiding the foreground bias introduced by the visual encoder. In general, SynSeg effectively improves the abilities in semantic localization and discrimination under weak supervision. Extensive experiments on benchmarks demonstrate that our method outperforms state-of-the-art (SOTA) performance. For instance, SynSeg achieves higher accuracy than SOTA baselines by 4.5\\% on VOC, 8.9\\% on Context, 2.6\\% on Object and 2.0\\% on City.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "synseg",
      "feature",
      "synergy"
    ],
    "category": "noticia"
  },
  {
    "title": "A Multimodal Framework for Understanding Collaborative Design Processes",
    "title_es": "A Multimodal Framework for Understanding Collaborative Design Processes",
    "url": "https://arxiv.org/abs/2508.06117",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06117v1 Announce Type: new \nAbstract: An essential task in analyzing collaborative design processes, such as those that are part of workshops in design studies, is identifying design outcomes and understanding how the collaboration between participants formed the results and led to decision-making. However, findings are typically restricted to a consolidated textual form based on notes from interviews or observations. A challenge arises from integrating different sources of observations, leading to large amounts and heterogeneity of collected data. To address this challenge we propose a practical, modular, and adaptable framework of workshop setup, multimodal data acquisition, AI-based artifact extraction, and visual analysis. Our interactive visual analysis system, reCAPit, allows the flexible combination of different modalities, including video, audio, notes, or gaze, to analyze and communicate important workshop findings. A multimodal streamgraph displays activity and attention in the working area, temporally aligned topic cards summarize participants' discussions, and drill-down techniques allow inspecting raw data of included sources. As part of our research, we conducted six workshops across different themes ranging from social science research on urban planning to a design study on band-practice visualization. The latter two are examined in detail and described as case studies. Further, we present considerations for planning workshops and challenges that we derive from our own experience and the interviews we conducted with workshop experts. Our research extends existing methodology of collaborative design workshops by promoting data-rich acquisition of multimodal observations, combined AI-based extraction and interactive visual analysis, and transparent dissemination of results.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Multimodal Framework for Understanding Collaborative Design Processes\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "multimodal",
      "framework"
    ],
    "category": "noticia"
  },
  {
    "title": "Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events",
    "title_es": "Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events",
    "url": "https://arxiv.org/abs/2508.06122",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06122v1 Announce Type: new \nAbstract: This study applied representation learning algorithms to satellite images and evaluated the learned latent spaces with classifications of various weather events. The algorithms investigated include the classical linear transformation, i.e., principal component analysis (PCA), state-of-the-art deep learning method, i.e., convolutional autoencoder (CAE), and a residual network pre-trained with large image datasets (PT). The experiment results indicated that the latent space learned by CAE consistently showed higher threat scores for all classification tasks. The classifications with PCA yielded high hit rates but also high false-alarm rates. In addition, the PT performed exceptionally well at recognizing tropical cyclones but was inferior in other tasks. Further experiments suggested that representations learned from higher-resolution datasets are superior in all classification tasks for deep-learning algorithms, i.e., CAE and PT. We also found that smaller latent space sizes had minor impact on the classification task's hit rate. Still, a latent space dimension smaller than 128 caused a significantly higher false alarm rate. Though the CAE can learn latent spaces effectively and efficiently, the interpretation of the learned representation lacks direct connections to physical attributions. Therefore, developing a physics-informed version of CAE can be a promising outlook for the current work.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "learning",
      "representations",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models",
    "title_es": "AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models",
    "url": "https://arxiv.org/abs/2508.06124",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06124v1 Announce Type: new \nAbstract: Present day LLMs face the challenge of managing affordance-based safety risks-situations where outputs inadvertently facilitate harmful actions due to overlooked logical implications. Traditional safety solutions, such as scalar outcome-based reward models, parameter tuning, or heuristic decoding strategies, lack the granularity and proactive nature needed to reliably detect and intervene during subtle yet crucial reasoning steps. Addressing this fundamental gap, we introduce AURA, an innovative, multi-layered framework centered around Process Reward Models (PRMs), providing comprehensive, step level evaluations across logical coherence and safety-awareness. Our framework seamlessly combines introspective self-critique, fine-grained PRM assessments, and adaptive safety-aware decoding to dynamically and proactively guide models toward safer reasoning trajectories. Empirical evidence clearly demonstrates that this approach significantly surpasses existing methods, significantly improving the logical integrity and affordance-sensitive safety of model outputs. This research represents a pivotal step toward safer, more responsible, and contextually aware AI, setting a new benchmark for alignment-sensitive applications.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "aura",
      "affordanceunderstanding",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "SC-Captioner: Improving Image Captioning with Self-Correction by Reinforcement Learning",
    "title_es": "SC-Captioner: Improving Image Captioning with Self-Correction by Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.06125",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06125v1 Announce Type: new \nAbstract: We propose SC-Captioner, a reinforcement learning framework that enables the self-correcting capability of image caption models. Our crucial technique lies in the design of the reward function to incentivize accurate caption corrections. Specifically, the predicted and reference captions are decomposed into object, attribute, and relation sets using scene-graph parsing algorithms. We calculate the set difference between sets of initial and self-corrected captions to identify added and removed elements. These elements are matched against the reference sets to calculate correctness bonuses for accurate refinements and mistake punishments for wrong additions and removals, thereby forming the final reward. For image caption quality assessment, we propose a set of metrics refined from CAPTURE that alleviate its incomplete precision evaluation and inefficient relation matching problems. Furthermore, we collect a fine-grained annotated image caption dataset, RefinedCaps, consisting of 6.5K diverse images from COCO dataset. Experiments show that applying SC-Captioner on large visual-language models can generate better image captions across various scenarios, significantly outperforming the direct preference optimization training strategy.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SC-Captioner: Improving Image Captioning with Self-Correction by Reinforcement Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sccaptioner",
      "improving",
      "image"
    ],
    "category": "noticia"
  },
  {
    "title": "SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures",
    "title_es": "SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures",
    "url": "https://arxiv.org/abs/2508.06127",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06127v1 Announce Type: new \nAbstract: While the Segment Anything Model (SAM) transforms interactive segmentation with zero-shot abilities, its inherent vulnerabilities present a single-point risk, potentially leading to the failure of numerous downstream applications. Proactively evaluating these transferable vulnerabilities is thus imperative. Prior adversarial attacks on SAM often present limited transferability due to insufficient exploration of common weakness across domains. To address this, we propose Vertex-Refining Simplicial Complex Attack (VeSCA), a novel method that leverages only the encoder of SAM for generating transferable adversarial examples. Specifically, it achieves this by explicitly characterizing the shared vulnerable regions between SAM and downstream models through a parametric simplicial complex. Our goal is to identify such complexes within adversarially potent regions by iterative vertex-wise refinement. A lightweight domain re-adaptation strategy is introduced to bridge domain divergence using minimal reference data during the initialization of simplicial complex. Ultimately, VeSCA generates consistently transferable adversarial examples through random simplicial complex sampling. Extensive experiments demonstrate that VeSCA achieves performance improved by 12.7% compared to state-of-the-art methods across three downstream model categories across five domain-specific datasets. Our findings further highlight the downstream model risks posed by SAM's vulnerabilities and emphasize the urgency of developing more robust foundation models.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sam",
      "encoder",
      "breach"
    ],
    "category": "noticia"
  },
  {
    "title": "Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem",
    "title_es": "Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem",
    "url": "https://arxiv.org/abs/2508.06129",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06129v1 Announce Type: new \nAbstract: The Vehicle Routing Problem (VRP) is a complex optimization problem with numerous real-world applications, mostly solved using metaheuristic algorithms due to its $\\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely on human-crafted designs developed through empirical studies. However, recent research shows that machine learning methods can be used the structural characteristics of solutions in combinatorial optimization, thereby aiding in designing more efficient algorithms, particularly for solving VRP. Building on this advancement, this study extends the previous research by conducting a sensitivity analysis using multiple classifier models that are capable of predicting the quality of VRP solutions. Hence, by leveraging explainable AI, this research is able to extend the understanding of how these models make decisions. Finally, our findings indicate that while feature importance varies, certain features consistently emerge as strong predictors. Furthermore, we propose a unified framework able of ranking feature impact across different scenarios to illustrate this finding. These insights highlight the potential of feature importance analysis as a foundation for developing a guidance mechanism of metaheuristic algorithms for solving the VRP.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "study",
      "of",
      "robust"
    ],
    "category": "noticia"
  },
  {
    "title": "Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models",
    "title_es": "Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models",
    "url": "https://arxiv.org/abs/2508.06135",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06135v1 Announce Type: new \nAbstract: Knowledge Distillation (KD) is a fundamental technique for compressing large language models (LLMs) into compact, efficient student models. However, existing white-box KD methods mainly focus on balancing ground truth and student-generated responses while overlooking two critical factors: training data quality and student-model compatibility. To address these limitations, we propose Selective Reflection Distillation (SRD), a novel data curation framework that leverages reflections from student models to systematically refine training data. SRD dynamically evaluates and selects prompt-response pairs by comparing ground truth data with student model outputs, selectively curating high-quality, student-compatible training instances through automated ranking based on difficulty. Furthermore, after selecting the training data, a curriculum scheduling strategy is employed to incrementally introduce these curated subsets into the distillation process at fixed intervals. As a plug-and-play enhancement, SRD consistently improves distillation outcomes across diverse white-box KD approaches and model architectures, as well as decreases computational cost significantly during KD training. Experiments on a range of language model benchmarks demonstrate SRD's consistent improvements in distilled model performance, as well as a reduction in training runtime by up to 39%, under diverse KD methods and model families. Notably, SRD operates as a plug-and-play module, enhancing sample efficiency without modifying underlying KD algorithms. Our findings highlight that data quality and compatibility are pivotal to effective and efficient distillation of LLMs, and SRD provides a principled framework to achieve both. This work advances the understanding of data-centric factors in KD and offers practical insights for enhancing the capability and efficiency of compressed LLMs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "less",
      "is",
      "more"
    ],
    "category": "noticia"
  },
  {
    "title": "Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation",
    "title_es": "Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation",
    "url": "https://arxiv.org/abs/2508.06136",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06136v1 Announce Type: new \nAbstract: We propose a novel 3D gaze redirection framework that leverages an explicit 3D eyeball structure. Existing gaze redirection methods are typically based on neural radiance fields, which employ implicit neural representations via volume rendering. Unlike these NeRF-based approaches, where the rotation and translation of 3D representations are not explicitly modeled, we introduce a dedicated 3D eyeball structure to represent the eyeballs with 3D Gaussian Splatting (3DGS). Our method generates photorealistic images that faithfully reproduce the desired gaze direction by explicitly rotating and translating the 3D eyeball structure. In addition, we propose an adaptive deformation module that enables the replication of subtle muscle movements around the eyes. Through experiments conducted on the ETH-XGaze dataset, we demonstrate that our framework is capable of generating diverse novel gaze images, achieving superior image quality and gaze estimation accuracy compared to previous state-of-the-art methods.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "roll",
      "your",
      "eyes"
    ],
    "category": "noticia"
  },
  {
    "title": "DiffCap: Diffusion-based Real-time Human Motion Capture using Sparse IMUs and a Monocular Camera",
    "title_es": "DiffCap: Diffusion-based Real-time Human Motion Capture using Sparse IMUs and a Monocular Camera",
    "url": "https://arxiv.org/abs/2508.06139",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06139v1 Announce Type: new \nAbstract: Combining sparse IMUs and a monocular camera is a new promising setting to perform real-time human motion capture. This paper proposes a diffusion-based solution to learn human motion priors and fuse the two modalities of signals together seamlessly in a unified framework. By delicately considering the characteristics of the two signals, the sequential visual information is considered as a whole and transformed into a condition embedding, while the inertial measurement is concatenated with the noisy body pose frame by frame to construct a sequential input for the diffusion model. Firstly, we observe that the visual information may be unavailable in some frames due to occlusions or subjects moving out of the camera view. Thus incorporating the sequential visual features as a whole to get a single feature embedding is robust to the occasional degenerations of visual information in those frames. On the other hand, the IMU measurements are robust to occlusions and always stable when signal transmission has no problem. So incorporating them frame-wisely could better explore the temporal information for the system. Experiments have demonstrated the effectiveness of the system design and its state-of-the-art performance in pose estimation compared with the previous works. Our codes are available for research at https://shaohua-pan.github.io/diffcap-page.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DiffCap: Diffusion-based Real-time Human Motion Capture using Sparse IMUs and a Monocular Camera\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "diffcap",
      "diffusionbased",
      "realtime"
    ],
    "category": "noticia"
  },
  {
    "title": "SDEval: Safety Dynamic Evaluation for Multimodal Large Language Models",
    "title_es": "SDEval: Safety Dynamic Evaluation for Multimodal Large Language Models",
    "url": "https://arxiv.org/abs/2508.06142",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06142v1 Announce Type: new \nAbstract: In the rapidly evolving landscape of Multimodal Large Language Models (MLLMs), the safety concerns of their outputs have earned significant attention. Although numerous datasets have been proposed, they may become outdated with MLLM advancements and are susceptible to data contamination issues. To address these problems, we propose \\textbf{SDEval}, the \\textit{first} safety dynamic evaluation framework to controllably adjust the distribution and complexity of safety benchmarks. Specifically, SDEval mainly adopts three dynamic strategies: text, image, and text-image dynamics to generate new samples from original benchmarks. We first explore the individual effects of text and image dynamics on model safety. Then, we find that injecting text dynamics into images can further impact safety, and conversely, injecting image dynamics into text also leads to safety risks. SDEval is general enough to be applied to various existing safety and even capability benchmarks. Experiments across safety benchmarks, MLLMGuard and VLSBench, and capability benchmarks, MMBench and MMVet, show that SDEval significantly influences safety evaluation, mitigates data contamination, and exposes safety limitations of MLLMs. Code is available at https://github.com/hq-King/SDEval",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SDEval: Safety Dynamic Evaluation for Multimodal Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sdeval",
      "safety",
      "dynamic"
    ],
    "category": "noticia"
  },
  {
    "title": "Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications",
    "title_es": "Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications",
    "url": "https://arxiv.org/abs/2508.06145",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06145v1 Announce Type: new \nAbstract: The versatility of large language models (LLMs) has been explored across various sectors, but their application in healthcare poses challenges, particularly in the domain of pharmaceutical contraindications where accurate and reliable information is required. This study enhances the capability of LLMs to address contraindications effectively by implementing a Retrieval Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base model, and the text-embedding-3-small model for embeddings, our approach integrates Langchain to orchestrate a hybrid retrieval system with re-ranking. This system leverages Drug Utilization Review (DUR) data from public databases, focusing on contraindications for specific age groups, pregnancy, and concomitant drug use. The dataset includes 300 question-answer pairs across three categories, with baseline model accuracy ranging from 0.49 to 0.57. Post-integration of the RAG pipeline, we observed a significant improvement in model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications related to age groups, pregnancy, and concomitant drug use, respectively. The results indicate that augmenting LLMs with a RAG framework can substantially reduce uncertainty in prescription and drug intake decisions by providing more precise and reliable drug contraindication information.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "retrieval",
      "augmented",
      "large"
    ],
    "category": "noticia"
  },
  {
    "title": "Text-guided Visual Prompt DINO for Generic Segmentation",
    "title_es": "Text-guided Visual Prompt DINO for Generic Segmentation",
    "url": "https://arxiv.org/abs/2508.06146",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06146v1 Announce Type: new \nAbstract: Recent advancements in multimodal vision models have highlighted limitations in late-stage feature fusion and suboptimal query selection for hybrid prompts open-world segmentation, alongside constraints from caption-derived vocabularies. To address these challenges, we propose Prompt-DINO, a text-guided visual Prompt DINO framework featuring three key innovations. First, we introduce an early fusion mechanism that unifies text/visual prompts and backbone features at the initial encoding stage, enabling deeper cross-modal interactions to resolve semantic ambiguities. Second, we design order-aligned query selection for DETR-based architectures, explicitly optimizing the structural alignment between text and visual queries during decoding to enhance semantic-spatial consistency. Third, we develop a generative data engine powered by the Recognize Anything via Prompting (RAP) model, which synthesizes 0.5B diverse training instances through a dual-path cross-verification pipeline, reducing label noise by 80.5% compared to conventional approaches. Extensive experiments demonstrate that Prompt-DINO achieves state-of-the-art performance on open-world detection benchmarks while significantly expanding semantic coverage beyond fixed-vocabulary constraints. Our work establishes a new paradigm for scalable multimodal detection and data generation in open-world scenarios. Data&Code are available at https://github.com/WeChatCV/WeVisionOne.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Text-guided Visual Prompt DINO for Generic Segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "textguided",
      "visual",
      "prompt"
    ],
    "category": "noticia"
  },
  {
    "title": "DSConv: Dynamic Splitting Convolution for Pansharpening",
    "title_es": "DSConv: Dynamic Splitting Convolution for Pansharpening",
    "url": "https://arxiv.org/abs/2508.06147",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06147v1 Announce Type: new \nAbstract: Aiming to obtain a high-resolution image, pansharpening involves the fusion of a multi-spectral image (MS) and a panchromatic image (PAN), the low-level vision task remaining significant and challenging in contemporary research. Most existing approaches rely predominantly on standard convolutions, few making the effort to adaptive convolutions, which are effective owing to the inter-pixel correlations of remote sensing images. In this paper, we propose a novel strategy for dynamically splitting convolution kernels in conjunction with attention, selecting positions of interest, and splitting the original convolution kernel into multiple smaller kernels, named DSConv. The proposed DSConv more effectively extracts features of different positions within the receptive field, enhancing the network's generalization, optimization, and feature representation capabilities. Furthermore, we innovate and enrich concepts of dynamic splitting convolution and provide a novel network architecture for pansharpening capable of achieving the tasks more efficiently, building upon this methodology. Adequate fair experiments illustrate the effectiveness and the state-of-the-art performance attained by DSConv.Comprehensive and rigorous discussions proved the superiority and optimal usage conditions of DSConv.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DSConv: Dynamic Splitting Convolution for Pansharpening\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dsconv",
      "dynamic",
      "splitting"
    ],
    "category": "noticia"
  },
  {
    "title": "Scaling Personality Control in LLMs with Big Five Scaler Prompts",
    "title_es": "Scaling Personality Control in LLMs with Big Five Scaler Prompts",
    "url": "https://arxiv.org/abs/2508.06149",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06149v1 Announce Type: new \nAbstract: We present Big5-Scaler, a prompt-based framework for conditioning large language models (LLMs) with controllable Big Five personality traits. By embedding numeric trait values into natural language prompts, our method enables fine-grained personality control without additional training. We evaluate Big5-Scaler across trait expression, dialogue generation, and human trait imitation tasks. Results show that it induces consistent and distinguishable personality traits across models, with performance varying by prompt type and scale. Our analysis highlights the effectiveness of concise prompts and lower trait intensities, providing a efficient approach for building personality-aware dialogue agents.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Scaling Personality Control in LLMs with Big Five Scaler Prompts\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "scaling",
      "personality",
      "control"
    ],
    "category": "noticia"
  },
  {
    "title": "Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models",
    "title_es": "Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models",
    "url": "https://arxiv.org/abs/2508.06151",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06151v1 Announce Type: new \nAbstract: In oral cancer diagnostics, the limited availability of annotated datasets frequently constrains the performance of diagnostic models, particularly due to the variability and insufficiency of training data. To address these challenges, this study proposed a novel approach to enhance diagnostic accuracy by synthesizing realistic oral cancer lesions using an inpainting technique with a fine-tuned diffusion model. We compiled a comprehensive dataset from multiple sources, featuring a variety of oral cancer images. Our method generated synthetic lesions that exhibit a high degree of visual fidelity to actual lesions, thereby significantly enhancing the performance of diagnostic algorithms. The results show that our classification model achieved a diagnostic accuracy of 0.97 in differentiating between cancerous and non-cancerous tissues, while our detection model accurately identified lesion locations with 0.85 accuracy. This method validates the potential for synthetic image generation in medical diagnostics and paves the way for further research into extending these methods to other types of cancer diagnostics.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "improving",
      "diagnostic",
      "accuracy"
    ],
    "category": "noticia"
  },
  {
    "title": "VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation",
    "title_es": "VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation",
    "url": "https://arxiv.org/abs/2508.06152",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06152v1 Announce Type: new \nAbstract: We present VISTAR, a user-centric, multi-dimensional benchmark for text-to-image (T2I) evaluation that addresses the limitations of existing metrics. VISTAR introduces a two-tier hybrid paradigm: it employs deterministic, scriptable metrics for physically quantifiable attributes (e.g., text rendering, lighting) and a novel Hierarchical Weighted P/N Questioning (HWPQ) scheme that uses constrained vision-language models to assess abstract semantics (e.g., style fusion, cultural fidelity). Grounded in a Delphi study with 120 experts, we defined seven user roles and nine evaluation angles to construct the benchmark, which comprises 2,845 prompts validated by over 15,000 human pairwise comparisons. Our metrics achieve high human alignment (>75%), with the HWPQ scheme reaching 85.9% accuracy on abstract semantics, significantly outperforming VQA baselines. Comprehensive evaluation of state-of-the-art models reveals no universal champion, as role-weighted scores reorder rankings and provide actionable guidance for domain-specific deployment. All resources are publicly released to foster reproducible T2I assessment.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "vistara",
      "usercentric",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "SLIP: Soft Label Mechanism and Key-Extraction-Guided CoT-based Defense Against Instruction Backdoor in APIs",
    "title_es": "SLIP: Soft Label Mechanism and Key-Extraction-Guided CoT-based Defense Against Instruction Backdoor in APIs",
    "url": "https://arxiv.org/abs/2508.06153",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06153v1 Announce Type: new \nAbstract: With the development of customized large language model (LLM) agents, a new threat of black-box backdoor attacks has emerged, where malicious instructions are injected into hidden system prompts. These attacks easily bypass existing defenses that rely on white-box access, posing a serious security challenge. To address this, we propose SLIP, a Soft Label mechanism and key-extraction-guided CoT-based defense against Instruction backdoors in APIs. SLIP is designed based on two key insights. First, to counteract the model's oversensitivity to triggers, we propose a Key-extraction-guided Chain-of-Thought (KCoT). Instead of only considering the single trigger or the input sentence, KCoT prompts the agent to extract task-relevant key phrases. Second, to guide the LLM toward correct answers, our proposed Soft Label Mechanism (SLM) prompts the agent to quantify the semantic correlation between key phrases and candidate answers. Crucially, to mitigate the influence of residual triggers or misleading content in phrases extracted by KCoT, which typically causes anomalous scores, SLM excludes anomalous scores deviating significantly from the mean and subsequently averages the remaining scores to derive a more reliable semantic representation. Extensive experiments on classification and question-answer (QA) tasks demonstrate that SLIP is highly effective, reducing the average attack success rate (ASR) from 90.2% to 25.13% while maintaining high accuracy on clean data and outperforming state-of-the-art defenses. Our code are available in https://github.com/CAU-ISS-Lab/Backdoor-Attack-Defense-LLMs/tree/main/SLIP.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SLIP: Soft Label Mechanism and Key-Extraction-Guided CoT-based Defense Against Instruction Backdoor in APIs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "slip",
      "soft",
      "label"
    ],
    "category": "noticia"
  },
  {
    "title": "Semantic Item Graph Enhancement for Multimodal Recommendation",
    "title_es": "Semantic Item Graph Enhancement for Multimodal Recommendation",
    "url": "https://arxiv.org/abs/2508.06154",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06154v1 Announce Type: new \nAbstract: Multimodal recommendation systems have attracted increasing attention for their improved performance by leveraging items' multimodal information. Prior methods often build modality-specific item-item semantic graphs from raw modality features and use them as supplementary structures alongside the user-item interaction graph to enhance user preference learning. However, these semantic graphs suffer from semantic deficiencies, including (1) insufficient modeling of collaborative signals among items and (2) structural distortions introduced by noise in raw modality features, ultimately compromising performance. To address these issues, we first extract collaborative signals from the interaction graph and infuse them into each modality-specific item semantic graph to enhance semantic modeling. Then, we design a modulus-based personalized embedding perturbation mechanism that injects perturbations with modulus-guided personalized intensity into embeddings to generate contrastive views. This enables the model to learn noise-robust representations through contrastive learning, thereby reducing the effect of structural noise in semantic graphs. Besides, we propose a dual representation alignment mechanism that first aligns multiple semantic representations via a designed Anchor-based InfoNCE loss using behavior representations as anchors, and then aligns behavior representations with the fused semantics by standard InfoNCE, to ensure representation consistency. Extensive experiments on four benchmark datasets validate the effectiveness of our framework.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Semantic Item Graph Enhancement for Multimodal Recommendation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "semantic",
      "item",
      "graph"
    ],
    "category": "noticia"
  },
  {
    "title": "Semantic and Structural Analysis of Implicit Biases in Large Language Models: An Interpretable Approach",
    "title_es": "Semantic and Structural Analysis of Implicit Biases in Large Language Models: An Interpretable Approach",
    "url": "https://arxiv.org/abs/2508.06155",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06155v1 Announce Type: new \nAbstract: This paper addresses the issue of implicit stereotypes that may arise during the generation process of large language models. It proposes an interpretable bias detection method aimed at identifying hidden social biases in model outputs, especially those semantic tendencies that are not easily captured through explicit linguistic features. The method combines nested semantic representation with a contextual contrast mechanism. It extracts latent bias features from the vector space structure of model outputs. Using attention weight perturbation, it analyzes the model's sensitivity to specific social attribute terms, thereby revealing the semantic pathways through which bias is formed. To validate the effectiveness of the method, this study uses the StereoSet dataset, which covers multiple stereotype dimensions including gender, profession, religion, and race. The evaluation focuses on several key metrics, such as bias detection accuracy, semantic consistency, and contextual sensitivity. Experimental results show that the proposed method achieves strong detection performance across various dimensions. It can accurately identify bias differences between semantically similar texts while maintaining high semantic alignment and output stability. The method also demonstrates high interpretability in its structural design. It helps uncover the internal bias association mechanisms within language models. This provides a more transparent and reliable technical foundation for bias detection. The approach is suitable for real-world applications where high trustworthiness of generated content is required.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Semantic and Structural Analysis of Implicit Biases in Large Language Models: An Interpretable Approach\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "semantic",
      "and",
      "structural"
    ],
    "category": "noticia"
  },
  {
    "title": "An Interpretable Multi-Plane Fusion Framework With Kolmogorov-Arnold Network Guided Attention Enhancement for Alzheimer's Disease Diagnosis",
    "title_es": "An Interpretable Multi-Plane Fusion Framework With Kolmogorov-Arnold Network Guided Attention Enhancement for Alzheimer's Disease Diagnosis",
    "url": "https://arxiv.org/abs/2508.06157",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06157v1 Announce Type: new \nAbstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder that severely impairs cognitive function and quality of life. Timely intervention in AD relies heavily on early and precise diagnosis, which remains challenging due to the complex and subtle structural changes in the brain. Most existing deep learning methods focus only on a single plane of structural magnetic resonance imaging (sMRI) and struggle to accurately capture the complex and nonlinear relationships among pathological regions of the brain, thus limiting their ability to precisely identify atrophic features. To overcome these limitations, we propose an innovative framework, MPF-KANSC, which integrates multi-plane fusion (MPF) for combining features from the coronal, sagittal, and axial planes, and a Kolmogorov-Arnold Network-guided spatial-channel attention mechanism (KANSC) to more effectively learn and represent sMRI atrophy features. Specifically, the proposed model enables parallel feature extraction from multiple anatomical planes, thus capturing more comprehensive structural information. The KANSC attention mechanism further leverages a more flexible and accurate nonlinear function approximation technique, facilitating precise identification and localization of disease-related abnormalities. Experiments on the ADNI dataset confirm that the proposed MPF-KANSC achieves superior performance in AD diagnosis. Moreover, our findings provide new evidence of right-lateralized asymmetry in subcortical structural changes during AD progression, highlighting the model's promising interpretability.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"An Interpretable Multi-Plane Fusion Framework With Kolmogorov-Arnold Network Guided Attention Enhancement for Alzheimer's Disease Diagnosis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "an",
      "interpretable",
      "multiplane"
    ],
    "category": "noticia"
  },
  {
    "title": "Fewer Denoising Steps or Cheaper Per-Step Inference: Towards Compute-Optimal Diffusion Model Deployment",
    "title_es": "Fewer Denoising Steps or Cheaper Per-Step Inference: Towards Compute-Optimal Diffusion Model Deployment",
    "url": "https://arxiv.org/abs/2508.06160",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06160v1 Announce Type: new \nAbstract: Diffusion models have shown remarkable success across generative tasks, yet their high computational demands challenge deployment on resource-limited platforms. This paper investigates a critical question for compute-optimal diffusion model deployment: Under a post-training setting without fine-tuning, is it more effective to reduce the number of denoising steps or to use a cheaper per-step inference? Intuitively, reducing the number of denoising steps increases the variability of the distributions across steps, making the model more sensitive to compression. In contrast, keeping more denoising steps makes the differences smaller, preserving redundancy, and making post-training compression more feasible. To systematically examine this, we propose PostDiff, a training-free framework for accelerating pre-trained diffusion models by reducing redundancy at both the input level and module level in a post-training manner. At the input level, we propose a mixed-resolution denoising scheme based on the insight that reducing generation resolution in early denoising steps can enhance low-frequency components and improve final generation fidelity. At the module level, we employ a hybrid module caching strategy to reuse computations across denoising steps. Extensive experiments and ablation studies demonstrate that (1) PostDiff can significantly improve the fidelity-efficiency trade-off of state-of-the-art diffusion models, and (2) to boost efficiency while maintaining decent generation fidelity, reducing per-step inference cost is often more effective than reducing the number of denoising steps. Our code is available at https://github.com/GATECH-EIC/PostDiff.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Fewer Denoising Steps or Cheaper Per-Step Inference: Towards Compute-Optimal Diffusion Model Deployment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fewer",
      "denoising",
      "steps"
    ],
    "category": "noticia"
  },
  {
    "title": "One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging",
    "title_es": "One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging",
    "url": "https://arxiv.org/abs/2508.06163",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06163v1 Announce Type: new \nAbstract: Model merging has emerged as a compelling data-free paradigm for multi-task learning, enabling the fusion of multiple fine-tuned models into a single, powerful entity. A key technique in merging methods is sparsification, which prunes redundant parameters from task vectors to mitigate interference. However, prevailing approaches employ a ``one-size-fits-all'' strategy, applying a uniform sparsity ratio that overlooks the inherent structural and statistical heterogeneity of model parameters. This often leads to a suboptimal trade-off, where critical parameters are inadvertently pruned while less useful ones are retained. To address this limitation, we introduce \\textbf{TADrop} (\\textbf{T}ensor-wise \\textbf{A}daptive \\textbf{Drop}), an adaptive sparsification strategy that respects this heterogeneity. Instead of a global ratio, TADrop assigns a tailored sparsity level to each parameter tensor based on its distributional properties. The core intuition is that tensors with denser, more redundant distributions can be pruned aggressively, while sparser, more critical ones are preserved. As a simple and plug-and-play module, we validate TADrop by integrating it with foundational, classic, and SOTA merging methods. Extensive experiments across diverse tasks (vision, language, and multimodal) and models (ViT, BEiT) demonstrate that TADrop consistently and significantly boosts their performance. For instance, when enhancing a leading merging method, it achieves an average performance gain of 2.0\\% across 8 ViT-B/32 tasks. TADrop provides a more effective way to mitigate parameter interference by tailoring sparsification to the model's structure, offering a new baseline for high-performance model merging.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "one",
      "size",
      "does"
    ],
    "category": "noticia"
  },
  {
    "title": "UR$^2$: Unify RAG and Reasoning through Reinforcement Learning",
    "title_es": "UR$^2$: Unify RAG and Reasoning through Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.06165",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06165v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown remarkable capabilities through two complementary paradigms: Retrieval-Augmented Generation (RAG), which enhances knowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR), which optimizes complex reasoning abilities. However, these two capabilities are often developed in isolation, and existing efforts to unify them remain narrow in scope-typically limited to open-domain QA with fixed retrieval settings and task-specific assumptions. This lack of integration constrains generalization and limits the applicability of RAG-RL methods to broader domains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a general framework that unifies retrieval and reasoning through reinforcement learning. UR2 introduces two key contributions: a difficulty-aware curriculum training that selectively invokes retrieval only for challenging problems, and a hybrid knowledge access strategy combining domain-specific offline corpora with LLM-generated summaries. These components are designed to enable dynamic coordination between retrieval and reasoning, improving adaptability across a diverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical, and mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B and LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods, achieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several benchmarks. We have released all code, models, and data at https://github.com/Tsinghua-dhy/UR2.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"UR$^2$: Unify RAG and Reasoning through Reinforcement Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ur",
      "unify",
      "rag"
    ],
    "category": "noticia"
  },
  {
    "title": "Pragmatics beyond humans: meaning, communication, and LLMs",
    "title_es": "Pragmatics beyond humans: meaning, communication, and LLMs",
    "url": "https://arxiv.org/abs/2508.06167",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06167v1 Announce Type: new \nAbstract: The paper reconceptualizes pragmatics not as a subordinate, third dimension of meaning, but as a dynamic interface through which language operates as a socially embedded tool for action. With the emergence of large language models (LLMs) in communicative contexts, this understanding needs to be further refined and methodologically reconsidered. The first section challenges the traditional semiotic trichotomy, arguing that connectionist LLM architectures destabilize established hierarchies of meaning, and proposes the Human-Machine Communication (HMC) framework as a more suitable alternative. The second section examines the tension between human-centred pragmatic theories and the machine-centred nature of LLMs. While traditional, Gricean-inspired pragmatics continue to dominate, it relies on human-specific assumptions ill-suited to predictive systems like LLMs. Probabilistic pragmatics, particularly the Rational Speech Act framework, offers a more compatible teleology by focusing on optimization rather than truth-evaluation. The third section addresses the issue of substitutionalism in three forms - generalizing, linguistic, and communicative - highlighting the anthropomorphic biases that distort LLM evaluation and obscure the role of human communicative subjects. Finally, the paper introduces the concept of context frustration to describe the paradox of increased contextual input paired with a collapse in contextual understanding, emphasizing how users are compelled to co-construct pragmatic conditions both for the model and themselves. These arguments suggest that pragmatic theory may need to be adjusted or expanded to better account for communication involving generative AI.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Pragmatics beyond humans: meaning, communication, and LLMs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "pragmatics",
      "beyond",
      "humans"
    ],
    "category": "noticia"
  },
  {
    "title": "Improving Table Retrieval with Question Generation from Partial Tables",
    "title_es": "Improving Table Retrieval with Question Generation from Partial Tables",
    "url": "https://arxiv.org/abs/2508.06168",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06168v1 Announce Type: new \nAbstract: Recent advances in open-domain question answering over tables have widely adopted large language models (LLMs) under the Retriever-Reader architecture. Prior works have effectively leveraged LLMs to tackle the complex reasoning demands of the Reader component, such as text-to-text, text-to-SQL, and multi hop reasoning. In contrast, the Retriever component has primarily focused on optimizing the query representation-training retrievers to retrieve relevant tables based on questions, or to select keywords from questions for matching table segments. However, little attention has been given to enhancing how tables themselves are represented in embedding space to better align with questions. To address this, we propose QGpT (Question Generation from Partial Tables), a simple yet effective method that uses an LLM to generate synthetic questions based on small portions of a table. These questions are generated to simulate how a user might query the content of the table currently under consideration. The generated questions are then jointly embedded with the partial table segments used for generation, enhancing semantic alignment with user queries. Without the need to embed entire tables, our method significantly improves retrieval performance across multiple benchmarks for both dense and late-interaction retrievers.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Improving Table Retrieval with Question Generation from Partial Tables\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "improving",
      "table",
      "retrieval"
    ],
    "category": "noticia"
  },
  {
    "title": "UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting",
    "title_es": "UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting",
    "url": "https://arxiv.org/abs/2508.06169",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06169v1 Announce Type: new \nAbstract: Underwater 3D scene reconstruction faces severe challenges from light absorption, scattering, and turbidity, which degrade geometry and color fidelity in traditional methods like Neural Radiance Fields (NeRF). While NeRF extensions such as SeaThru-NeRF incorporate physics-based models, their MLP reliance limits efficiency and spatial resolution in hazy environments. We introduce UW-3DGS, a novel framework adapting 3D Gaussian Splatting (3DGS) for robust underwater reconstruction. Key innovations include: (1) a plug-and-play learnable underwater image formation module using voxel-based regression for spatially varying attenuation and backscatter; and (2) a Physics-Aware Uncertainty Pruning (PAUP) branch that adaptively removes noisy floating Gaussians via uncertainty scoring, ensuring artifact-free geometry. The pipeline operates in training and rendering stages. During training, noisy Gaussians are optimized end-to-end with underwater parameters, guided by PAUP pruning and scattering modeling. In rendering, refined Gaussians produce clean Unattenuated Radiance Images (URIs) free from media effects, while learned physics enable realistic Underwater Images (UWIs) with accurate light transport. Experiments on SeaThru-NeRF and UWBundle datasets show superior performance, achieving PSNR of 27.604, SSIM of 0.868, and LPIPS of 0.104 on SeaThru-NeRF, with ~65% reduction in floating artifacts.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "uwdgs",
      "underwater",
      "d"
    ],
    "category": "noticia"
  },
  {
    "title": "Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation",
    "title_es": "Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation",
    "url": "https://arxiv.org/abs/2508.06170",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06170v1 Announce Type: new \nAbstract: Colonoscopy is a vital tool for the early diagnosis of colorectal cancer, which is one of the main causes of cancer-related mortality globally; hence, it is deemed an essential technique for the prevention and early detection of colorectal cancer. The research introduces a unique multidirectional architectural framework to automate polyp detection within colonoscopy images while helping resolve limited healthcare dataset sizes and annotation complexities. The research implements a comprehensive system that delivers synthetic data generation through Stable Diffusion enhancements together with detection and segmentation algorithms. This detection approach combines Faster R-CNN for initial object localization while the Segment Anything Model (SAM) refines the segmentation masks. The faster R-CNN detection algorithm achieved a recall of 93.08% combined with a precision of 88.97% and an F1 score of 90.98%.SAM is then used to generate the image mask. The research evaluated five state-of-the-art segmentation models that included U-Net, PSPNet, FPN, LinkNet, and MANet using ResNet34 as a base model. The results demonstrate the superior performance of FPN with the highest scores of PSNR (7.205893) and SSIM (0.492381), while UNet excels in recall (84.85%) and LinkNet shows balanced performance in IoU (64.20%) and Dice score (77.53%).",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "synthetic",
      "datadriven",
      "multiarchitecture"
    ],
    "category": "noticia"
  },
  {
    "title": "Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor",
    "title_es": "Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor",
    "url": "https://arxiv.org/abs/2508.06177",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06177v1 Announce Type: new \nAbstract: Accurate localization represents a fundamental challenge in\n  robotic navigation. Traditional methodologies, such as Lidar or QR-code based systems, suffer from inherent scalability and adaptability con straints, particularly in complex environments. In this work, we propose\n  an innovative localization framework that harnesses flooring characteris tics by employing graph-based representations and Graph Convolutional\n  Networks (GCNs). Our method uses graphs to represent floor features,\n  which helps localize the robot more accurately (0.64cm error) and more\n  efficiently than comparing individual image features. Additionally, this\n  approach successfully addresses the kidnapped robot problem in every\n  frame without requiring complex filtering processes. These advancements\n  open up new possibilities for robotic navigation in diverse environments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "graphbased",
      "robot",
      "localization"
    ],
    "category": "noticia"
  },
  {
    "title": "Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime",
    "title_es": "Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime",
    "url": "https://arxiv.org/abs/2508.06178",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06178v1 Announce Type: new \nAbstract: Large language models (LLMs) often require vast amounts of text to effectively acquire new knowledge. While continuing pre-training on large corpora or employing retrieval-augmented generation (RAG) has proven successful, updating an LLM with only a few thousand or million tokens remains challenging. In this work, we investigate the task of injecting small, unstructured information into LLMs and its relation to the catastrophic forgetting phenomenon. We use a dataset of recent news -- ensuring no overlap with the model's pre-training data -- to evaluate the knowledge acquisition by probing the model with question-answer pairs related the learned information. Starting from a continued pre-training baseline, we explored different augmentation algorithms to generate synthetic data to improve the knowledge acquisition capabilities. Our experiments show that simply continuing pre-training on limited data yields modest improvements, whereas exposing the model to diverse textual variations significantly improves the learning of new facts -- particularly with methods that induce greater variability through diverse prompting. Furthermore, we shed light on the forgetting phenomenon in small-data regimes, illustrating the delicate balance between learning new content and retaining existing capabilities. We also confirm the sensitivity of RAG-based approaches for knowledge injection, which often lead to greater degradation on control datasets compared to parametric methods. Finally, we demonstrate that models can generate effective synthetic training data themselves, suggesting a pathway toward self-improving model updates. All code and generated data used in our experiments are publicly available, providing a resource for studying efficient knowledge injection in LLMs with limited data at https://github.com/hugoabonizio/knowledge-injection-methods.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "comparing",
      "knowledge",
      "injection"
    ],
    "category": "noticia"
  },
  {
    "title": "Beyond Constant Parameters: Hyper Prediction Models and HyperMPC",
    "title_es": "Beyond Constant Parameters: Hyper Prediction Models and HyperMPC",
    "url": "https://arxiv.org/abs/2508.06181",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06181v1 Announce Type: new \nAbstract: Model Predictive Control (MPC) is among the most widely adopted and reliable methods for robot control, relying critically on an accurate dynamics model. However, existing dynamics models used in the gradient-based MPC are limited by computational complexity and state representation. To address this limitation, we propose the Hyper Prediction Model (HyperPM) - a novel approach in which we project the unmodeled dynamics onto a time-dependent dynamics model. This time-dependency is captured through time-varying model parameters, whose evolution over the MPC prediction horizon is learned using a neural network. Such formulation preserves the computational efficiency and robustness of the base model while equipping it with the capacity to anticipate previously unmodeled phenomena. We evaluated the proposed approach on several challenging systems, including real-world F1TENTH autonomous racing, and demonstrated that it significantly reduces long-horizon prediction errors. Moreover, when integrated within the MPC framework (HyperMPC), our method consistently outperforms existing state-of-the-art techniques.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Beyond Constant Parameters: Hyper Prediction Models and HyperMPC\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "beyond",
      "constant",
      "parameters"
    ],
    "category": "noticia"
  },
  {
    "title": "Differentially Private Federated Clustering with Random Rebalancing",
    "title_es": "Differentially Private Federated Clustering with Random Rebalancing",
    "url": "https://arxiv.org/abs/2508.06183",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06183v1 Announce Type: new \nAbstract: Federated clustering aims to group similar clients into clusters and produce one model for each cluster. Such a personalization approach typically improves model performance compared with training a single model to serve all clients, but can be more vulnerable to privacy leakage. Directly applying client-level differentially private (DP) mechanisms to federated clustering could degrade the utilities significantly. We identify that such deficiencies are mainly due to the difficulties of averaging privacy noise within each cluster (following standard privacy mechanisms), as the number of clients assigned to the same clusters is uncontrolled. To this end, we propose a simple and effective technique, named RR-Cluster, that can be viewed as a light-weight add-on to many federated clustering algorithms. RR-Cluster achieves reduced privacy noise via randomly rebalancing cluster assignments, guaranteeing a minimum number of clients assigned to each cluster. We analyze the tradeoffs between decreased privacy noise variance and potentially increased bias from incorrect assignments and provide convergence bounds for RR-Clsuter. Empirically, we demonstrate the RR-Cluster plugged into strong federated clustering algorithms results in significantly improved privacy/utility tradeoffs across both synthetic and real-world datasets.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Differentially Private Federated Clustering with Random Rebalancing\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "differentially",
      "private",
      "federated"
    ],
    "category": "noticia"
  },
  {
    "title": "DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration",
    "title_es": "DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration",
    "url": "https://arxiv.org/abs/2508.06186",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06186v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have grown exponentially since the release of ChatGPT. These models have gained attention due to their robust performance on various tasks, including language processing tasks. These models achieve understanding and comprehension of tasks by training billions of parameters. The development of these models is a transformative force in enhancing natural language understanding and has taken a significant step towards artificial general intelligence (AGI). In this study, we aim to present the DKG-LLM framework. The DKG-LLM framework introduces a groundbreaking approach to medical diagnosis and personalized treatment recommendations by integrating a dynamic knowledge graph (DKG) with the Grok 3 large language model. Using the Adaptive Semantic Fusion Algorithm (ASFA), heterogeneous medical data (including clinical reports and PubMed articles) and patient records dynamically generate a knowledge graph consisting of 15,964 nodes in 13 distinct types (e.g., diseases, symptoms, treatments, patient profiles) and 127,392 edges in 26 relationship types (e.g., causal, therapeutic, association). ASFA utilizes advanced probabilistic models, Bayesian inference, and graph optimization to extract semantic information, dynamically updating the graph with approximately 150 new nodes and edges in each data category while maintaining scalability with up to 987,654 edges. Real-world datasets, including MIMIC-III and PubMed, were utilized to evaluate the proposed architecture. The evaluation results show that DKG-LLM achieves a diagnostic accuracy of 84.19%. The model also has a treatment recommendation accuracy of 89.63% and a semantic coverage of 93.48%. DKG-LLM is a reliable and transformative tool that handles noisy data and complex multi-symptom diseases, along with feedback-based learning from physician input.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dkgllm",
      "",
      "a"
    ],
    "category": "noticia"
  },
  {
    "title": "MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration",
    "title_es": "MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration",
    "url": "https://arxiv.org/abs/2508.06189",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06189v1 Announce Type: new \nAbstract: With the acceleration of urbanization, criminal behavior in public scenes poses an increasingly serious threat to social security. Traditional anomaly detection methods based on feature recognition struggle to capture high-level behavioral semantics from historical information, while generative approaches based on Large Language Models (LLMs) often fail to meet real-time requirements. To address these challenges, we propose MA-CBP, a criminal behavior prediction framework based on multi-agent asynchronous collaboration. This framework transforms real-time video streams into frame-level semantic descriptions, constructs causally consistent historical summaries, and fuses adjacent image frames to perform joint reasoning over long- and short-term contexts. The resulting behavioral decisions include key elements such as event subjects, locations, and causes, enabling early warning of potential criminal activity. In addition, we construct a high-quality criminal behavior dataset that provides multi-scale language supervision, including frame-level, summary-level, and event-level semantic annotations. Experimental results demonstrate that our method achieves superior performance on multiple datasets and offers a promising solution for risk warning in urban public safety scenarios.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "macbp",
      "a",
      "criminal"
    ],
    "category": "noticia"
  },
  {
    "title": "A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet",
    "title_es": "A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet",
    "url": "https://arxiv.org/abs/2508.06191",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06191v1 Announce Type: new \nAbstract: Pleural effusion semantic segmentation can significantly enhance the accuracy and timeliness of clinical diagnosis and treatment by precisely identifying disease severity and lesion areas. Currently, semantic segmentation of pleural effusion CT images faces multiple challenges. These include similar gray levels between effusion and surrounding tissues, blurred edges, and variable morphology. Existing methods often struggle with diverse image variations and complex edges, primarily because direct feature concatenation causes semantic gaps. To address these challenges, we propose the Dual-Branch Interactive Fusion Attention model (DBIF-AUNet). This model constructs a densely nested skip-connection network and innovatively refines the Dual-Domain Feature Disentanglement module (DDFD). The DDFD module orthogonally decouples the functions of dual-domain modules to achieve multi-scale feature complementarity and enhance characteristics at different levels. Concurrently, we design a Branch Interaction Attention Fusion module (BIAF) that works synergistically with the DDFD. This module dynamically weights and fuses global, local, and frequency band features, thereby improving segmentation robustness. Furthermore, we implement a nested deep supervision mechanism with hierarchical adaptive hybrid loss to effectively address class imbalance. Through validation on 1,622 pleural effusion CT images from Southwest Hospital, DBIF-AUNet achieved IoU and Dice scores of 80.1% and 89.0% respectively. These results outperform state-of-the-art medical image segmentation models U-Net++ and Swin-UNet by 5.7%/2.7% and 2.2%/1.5% respectively, demonstrating significant optimization in segmentation accuracy for complex pleural effusion CT images.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "semantic",
      "segmentation"
    ],
    "category": "noticia"
  },
  {
    "title": "Understanding Inconsistent State Update Vulnerabilities in Smart Contracts",
    "title_es": "Understanding Inconsistent State Update Vulnerabilities in Smart Contracts",
    "url": "https://arxiv.org/abs/2508.06192",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06192v1 Announce Type: new \nAbstract: Smart contracts enable contract terms to be automatically executed and verified on the blockchain, and recent years have witnessed numerous applications of them in areas such as financial institutions and supply chains. The execution logic of a smart contract is closely related to the contract state, and thus the correct and safe execution of the contract depends heavily on the precise control and update of the contract state. However, the contract state update process can have issues. In particular, inconsistent state update issues can arise for reasons such as unsynchronized modifications. Inconsistent state update bugs have been exploited by attackers many times, but existing detection tools still have difficulty in effectively identifying them. This paper conducts the first large-scale empirical study about inconsistent state update vulnerabilities (that is, inconsistent state update bugs that are exploitable) in smart contracts, aiming to shed light for developers, researchers, tool builders, and language or library designers in order to avoid inconsistent state update vulnerabilities. We systematically investigate 116 inconsistent state update vulnerabilities in 352 real-world smart contract projects, summarizing their root causes, fix strategies, and exploitation methods. Our study provides 11 original and important findings, and we also give the implications of our findings. To illustrate the potential benefits of our research, we also develop a proof-of-concept checker based on one of our findings. The checker effectively detects issues in 64 popular GitHub projects, and 19 project owners have confirmed the detected issues at the time of writing. The result demonstrates the usefulness and importance of our findings for avoiding inconsistent state update vulnerabilities in smart contracts.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Understanding Inconsistent State Update Vulnerabilities in Smart Contracts\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "understanding",
      "inconsistent",
      "state"
    ],
    "category": "noticia"
  },
  {
    "title": "Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation",
    "title_es": "Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation",
    "url": "https://arxiv.org/abs/2508.06194",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06194v1 Announce Type: new \nAbstract: Precise jailbreak evaluation is vital for LLM red teaming and jailbreak research. Current approaches employ binary classification ( e.g., string matching, toxic text classifiers, LLM-driven methods), yielding only \"yes/no\" labels without quantifying harm intensity. Existing multi-dimensional frameworks ( e.g., Security Violation, Relative Truthfulness, Informativeness) apply uniform evaluation criteria across scenarios, resulting in scenario-specific mismatches--for instance, \"Relative Truthfulness\" is irrelevant to \"hate speech\"--which compromise evaluation precision. To tackle these limitations, we introduce SceneJailEval, with key contributions: (1) A groundbreaking scenario-adaptive multi-dimensional framework for jailbreak evaluation, overcoming the critical \"one-size-fits-all\" constraint of existing multi-dimensional methods, and featuring strong extensibility to flexibly adapt to customized or emerging scenarios. (2) A comprehensive 14-scenario dataset with diverse jailbreak variants and regional cases, filling the long-standing gap in high-quality, holistic benchmarks for scenario-adaptive evaluation. (3) SceneJailEval achieves state-of-the-art results, with an F1 score of 0.917 on our full-scenario dataset (+6% over prior SOTA) and 0.995 on JBB (+3% over prior SOTA), surpassing accuracy limits of existing evaluation methods in heterogeneous scenarios and confirming its advantage.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "beyond",
      "uniform",
      "criteria"
    ],
    "category": "noticia"
  },
  {
    "title": "EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations",
    "title_es": "EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations",
    "url": "https://arxiv.org/abs/2508.06196",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06196v1 Announce Type: new \nAbstract: Emotional Intelligence (EI) is a critical yet underexplored dimension in the development of human-aligned LLMs. To address this gap, we introduce a unified, psychologically grounded four-layer taxonomy of EI tailored for large language models (LLMs), encompassing emotional tracking, cause inference, appraisal, and emotionally appropriate response generation. Building on this framework, we present EICAP-Bench, a novel MCQ style multi-turn benchmark designed to evaluate EI capabilities in open-source LLMs across diverse linguistic and cultural contexts. We evaluate six LLMs: LLaMA3 (8B), LLaMA3-Instruct, Gemma (9B), Gemma-Instruct, Qwen2.5 (7B), and Qwen2.5-Instruct on EmoCap-Bench, identifying Qwen2.5-Instruct as the strongest baseline. To assess the potential for enhancing EI capabilities, we fine-tune both Qwen2.5-Base and Qwen2.5-Instruct using LoRA adapters on UltraChat (UC), a large-scale, instruction-tuned dialogue dataset, in both English and Arabic. Our statistical analysis reveals that among the five EI layers, only the Appraisal layer shows significant improvement through UC-based fine-tuning. These findings highlight the limitations of existing pretraining and instruction-tuning paradigms in equipping LLMs with deeper emotional reasoning and underscore the need for targeted data and modeling strategies for comprehensive EI alignment.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "eicap",
      "deep",
      "dive"
    ],
    "category": "noticia"
  },
  {
    "title": "Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning",
    "title_es": "Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning",
    "url": "https://arxiv.org/abs/2508.06199",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06199v1 Announce Type: new \nAbstract: Pretrained neural networks have attracted significant interest in chemistry and small molecule drug design. Embeddings from these models are widely used for molecular property prediction, virtual screening, and small data learning in molecular chemistry. This study presents the most extensive comparison of such models to date, evaluating 25 models across 25 datasets. Under a fair comparison framework, we assess models spanning various modalities, architectures, and pretraining strategies. Using a dedicated hierarchical Bayesian statistical testing model, we arrive at a surprising result: nearly all neural models show negligible or no improvement over the baseline ECFP molecular fingerprint. Only the CLAMP model, which is also based on molecular fingerprints, performs statistically significantly better than the alternatives. These findings raise concerns about the evaluation rigor in existing studies. We discuss potential causes, propose solutions, and offer practical recommendations.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "benchmarking",
      "pretrained",
      "molecular"
    ],
    "category": "noticia"
  },
  {
    "title": "LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning",
    "title_es": "LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning",
    "url": "https://arxiv.org/abs/2508.06202",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06202v1 Announce Type: new \nAbstract: Continual Visual Instruction Tuning (CVIT) enables Multimodal Large Language Models (MLLMs) to incrementally learn new tasks over time. However, this process is challenged by catastrophic forgetting, where performance on previously learned tasks deteriorates as the model adapts to new ones. A common approach to mitigate forgetting is architecture expansion, which introduces task-specific modules to prevent interference. Yet, existing methods often expand entire layers for each task, leading to significant parameter overhead and poor scalability. To overcome these issues, we introduce LoRA in LoRA (LiLoRA), a highly efficient architecture expansion method tailored for CVIT in MLLMs. LiLoRA shares the LoRA matrix A across tasks to reduce redundancy, applies an additional low-rank decomposition to matrix B to minimize task-specific parameters, and incorporates a cosine-regularized stability loss to preserve consistency in shared representations over time. Extensive experiments on a diverse CVIT benchmark show that LiLoRA consistently achieves superior performance in sequential task learning while significantly improving parameter efficiency compared to existing approaches.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lora",
      "in",
      "lora"
    ],
    "category": "noticia"
  },
  {
    "title": "AnomalyMoE: Towards a Language-free Generalist Model for Unified Visual Anomaly Detection",
    "title_es": "AnomalyMoE: Towards a Language-free Generalist Model for Unified Visual Anomaly Detection",
    "url": "https://arxiv.org/abs/2508.06203",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06203v1 Announce Type: new \nAbstract: Anomaly detection is a critical task across numerous domains and modalities, yet existing methods are often highly specialized, limiting their generalizability. These specialized models, tailored for specific anomaly types like textural defects or logical errors, typically exhibit limited performance when deployed outside their designated contexts. To overcome this limitation, we propose AnomalyMoE, a novel and universal anomaly detection framework based on a Mixture-of-Experts (MoE) architecture. Our key insight is to decompose the complex anomaly detection problem into three distinct semantic hierarchies: local structural anomalies, component-level semantic anomalies, and global logical anomalies. AnomalyMoE correspondingly employs three dedicated expert networks at the patch, component, and global levels, and is specialized in reconstructing features and identifying deviations at its designated semantic level. This hierarchical design allows a single model to concurrently understand and detect a wide spectrum of anomalies. Furthermore, we introduce an Expert Information Repulsion (EIR) module to promote expert diversity and an Expert Selection Balancing (ESB) module to ensure the comprehensive utilization of all experts. Experiments on 8 challenging datasets spanning industrial imaging, 3D point clouds, medical imaging, video surveillance, and logical anomaly detection demonstrate that AnomalyMoE establishes new state-of-the-art performance, significantly outperforming specialized methods in their respective domains.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AnomalyMoE: Towards a Language-free Generalist Model for Unified Visual Anomaly Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "anomalymoe",
      "towards",
      "a"
    ],
    "category": "noticia"
  },
  {
    "title": "Classification is a RAG problem: A case study on hate speech detection",
    "title_es": "Classification is a RAG problem: A case study on hate speech detection",
    "url": "https://arxiv.org/abs/2508.06204",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06204v1 Announce Type: new \nAbstract: Robust content moderation requires classification systems that can quickly adapt to evolving policies without costly retraining. We present classification using Retrieval-Augmented Generation (RAG), which shifts traditional classification tasks from determining the correct category in accordance with pre-trained parameters to evaluating content in relation to contextual knowledge retrieved at inference. In hate speech detection, this transforms the task from \"is this hate speech?\" to \"does this violate the hate speech policy?\"\n  Our Contextual Policy Engine (CPE) - an agentic RAG system - demonstrates this approach and offers three key advantages: (1) robust classification accuracy comparable to leading commercial systems, (2) inherent explainability via retrieved policy segments, and (3) dynamic policy updates without model retraining. Through three experiments, we demonstrate strong baseline performance and show that the system can apply fine-grained policy control by correctly adjusting protection for specific identity groups without requiring retraining or compromising overall performance. These findings establish that RAG can transform classification into a more flexible, transparent, and adaptable process for content moderation and wider classification problems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Classification is a RAG problem: A case study on hate speech detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "classification",
      "is",
      "a"
    ],
    "category": "noticia"
  },
  {
    "title": "PA-HOI: A Physics-Aware Human and Object Interaction Dataset",
    "title_es": "PA-HOI: A Physics-Aware Human and Object Interaction Dataset",
    "url": "https://arxiv.org/abs/2508.06205",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06205v1 Announce Type: new \nAbstract: The Human-Object Interaction (HOI) task explores the dynamic interactions between humans and objects in physical environments, providing essential biomechanical and cognitive-behavioral foundations for fields such as robotics, virtual reality, and human-computer interaction. However, existing HOI data sets focus on details of affordance, often neglecting the influence of physical properties of objects on human long-term motion. To bridge this gap, we introduce the PA-HOI Motion Capture dataset, which highlights the impact of objects' physical attributes on human motion dynamics, including human posture, moving velocity, and other motion characteristics. The dataset comprises 562 motion sequences of human-object interactions, with each sequence performed by subjects of different genders interacting with 35 3D objects that vary in size, shape, and weight. This dataset stands out by significantly extending the scope of existing ones for understanding how the physical attributes of different objects influence human posture, speed, motion scale, and interacting strategies. We further demonstrate the applicability of the PA-HOI dataset by integrating it with existing motion generation methods, validating its capacity to transfer realistic physical awareness.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"PA-HOI: A Physics-Aware Human and Object Interaction Dataset\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "pahoi",
      "a",
      "physicsaware"
    ],
    "category": "noticia"
  },
  {
    "title": "Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model",
    "title_es": "Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model",
    "url": "https://arxiv.org/abs/2508.06206",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06206v1 Announce Type: new \nAbstract: Affordance grounding focuses on predicting the specific regions of objects that are associated with the actions to be performed by robots. It plays a vital role in the fields of human-robot interaction, human-object interaction, embodied manipulation, and embodied perception. Existing models often neglect the affordance shared among different objects because they lack the Chain-of-Thought(CoT) reasoning abilities, limiting their out-of-domain (OOD) generalization and explicit reasoning capabilities. To address these challenges, we propose Affordance-R1, the first unified affordance grounding framework that integrates cognitive CoT guided Group Relative Policy Optimization (GRPO) within a reinforcement learning paradigm. Specifically, we designed a sophisticated affordance function, which contains format, perception, and cognition rewards to effectively guide optimization directions. Furthermore, we constructed a high-quality affordance-centric reasoning dataset, ReasonAff, to support training. Trained exclusively via reinforcement learning with GRPO and without explicit reasoning data, Affordance-R1 achieves robust zero-shot generalization and exhibits emergent test-time reasoning capabilities. Comprehensive experiments demonstrate that our model outperforms well-established methods and exhibits open-world generalization. To the best of our knowledge, Affordance-R1 is the first to integrate GRPO-based RL with reasoning into affordance reasoning. The code of our method and our dataset is released on https://github.com/hq-King/Affordance-R1.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "affordancer",
      "reinforcement",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "Computer Vision-based Adaptive Control for Back Exoskeleton Performance Optimization",
    "title_es": "Computer Vision-based Adaptive Control for Back Exoskeleton Performance Optimization",
    "url": "https://arxiv.org/abs/2508.06207",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06207v1 Announce Type: new \nAbstract: Back exoskeletons can reduce musculoskeletal strain, but their effectiveness depends on support modulation and adaptive control. This study addresses two challenges: defining optimal support strategies and developing adaptive control based on payload estimation. We introduce an optimization space based on muscle activity reduction, perceived discomfort, and user preference, constructing functions to identify optimal strategies. Experiments with 12 subjects revealed optimal operating regions, highlighting the need for dynamic modulation. Based on these insights, we developed a vision-based adaptive control pipeline that estimates payloads in real-time by enhancing exoskeleton contextual understanding, minimising latency and enabling support adaptation within the defined optimisation space. Validation with 12 more subjects showed over 80% accuracy and improvements across all metrics. Compared to static control, adaptive modulation reduced peak back muscle activation by up to 23% while preserving user preference and minimising discomfort. These findings validate the proposed framework and highlight the potential of intelligent, context-aware control in industrial exoskeletons.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Computer Vision-based Adaptive Control for Back Exoskeleton Performance Optimization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "computer",
      "visionbased",
      "adaptive"
    ],
    "category": "noticia"
  },
  {
    "title": "Graph Federated Learning for Personalized Privacy Recommendation",
    "title_es": "Graph Federated Learning for Personalized Privacy Recommendation",
    "url": "https://arxiv.org/abs/2508.06208",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06208v1 Announce Type: new \nAbstract: Federated recommendation systems (FedRecs) have gained significant attention for providing privacy-preserving recommendation services. However, existing FedRecs assume that all users have the same requirements for privacy protection, i.e., they do not upload any data to the server. The approaches overlook the potential to enhance the recommendation service by utilizing publicly available user data. In real-world applications, users can choose to be private or public. Private users' interaction data is not shared, while public users' interaction data can be shared. Inspired by the issue, this paper proposes a novel Graph Federated Learning for Personalized Privacy Recommendation (GFed-PP) that adapts to different privacy requirements while improving recommendation performance. GFed-PP incorporates the interaction data of public users to build a user-item interaction graph, which is then used to form a user relationship graph. A lightweight graph convolutional network (GCN) is employed to learn each user's user-specific personalized item embedding. To protect user privacy, each client learns the user embedding and the scoring function locally. Additionally, GFed-PP achieves optimization of the federated recommendation framework through the initialization of item embedding on clients and the aggregation of the user relationship graph on the server. Experimental results demonstrate that GFed-PP significantly outperforms existing methods for five datasets, offering superior recommendation accuracy without compromising privacy. This framework provides a practical solution for accommodating varying privacy preferences in federated recommendation systems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Graph Federated Learning for Personalized Privacy Recommendation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "graph",
      "federated",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "A Structural Linear-Time Algorithm for Computing the Tutte Decomposition",
    "title_es": "A Structural Linear-Time Algorithm for Computing the Tutte Decomposition",
    "url": "https://arxiv.org/abs/2508.06212",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06212v1 Announce Type: new \nAbstract: The block-cut tree decomposes a connected graph along its cutvertices, displaying its 2-connected components. The Tutte-decomposition extends this idea to 2-separators in 2-connected graphs, yielding a canonical tree-decomposition that decomposes the graph into its triconnected components. In 1973, Hopcroft and Tarjan introduced a linear-time algorithm to compute the Tutte-decomposition. Cunningham and Edmonds later established a structural characterization of the Tutte-decomposition via totally-nested 2-separations. We present a conceptually simple algorithm based on this characterization, which computes the Tutte-decomposition in linear time. Our algorithm first computes all totally-nested 2-separations and then builds the Tutte-decomposition from them.\n  Along the way, we derive new structural results on the structure of totally-nested 2-separations in 2-connected graphs using a novel notion of stability, which may be of independent interest.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Structural Linear-Time Algorithm for Computing the Tutte Decomposition\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "structural",
      "lineartime"
    ],
    "category": "noticia"
  },
  {
    "title": "Reparameterization Proximal Policy Optimization",
    "title_es": "Reparameterization Proximal Policy Optimization",
    "url": "https://arxiv.org/abs/2508.06214",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06214v1 Announce Type: new \nAbstract: Reparameterization policy gradient (RPG) is promising for improving sample efficiency by leveraging differentiable dynamics. However, a critical barrier is its training instability, where high-variance gradients can destabilize the learning process. To address this, we draw inspiration from Proximal Policy Optimization (PPO), which uses a surrogate objective to enable stable sample reuse in the model-free setting. We first establish a connection between this surrogate objective and RPG, which has been largely unexplored and is non-trivial. Then, we bridge this gap by demonstrating that the reparameterization gradient of a PPO-like surrogate objective can be computed efficiently using backpropagation through time. Based on this key insight, we propose Reparameterization Proximal Policy Optimization (RPO), a stable and sample-efficient RPG-based method. RPO enables multiple epochs of stable sample reuse by optimizing a clipped surrogate objective tailored for RPG, while being further stabilized by Kullback-Leibler (KL) divergence regularization and remaining fully compatible with existing variance reduction methods. We evaluate RPO on a suite of challenging locomotion and manipulation tasks, where experiments demonstrate that our method achieves superior sample efficiency and strong performance.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Reparameterization Proximal Policy Optimization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "reparameterization",
      "proximal",
      "policy"
    ],
    "category": "noticia"
  },
  {
    "title": "Sandwich Monotonicity and the Recognition of Weighted Graph Classes",
    "title_es": "Sandwich Monotonicity and the Recognition of Weighted Graph Classes",
    "url": "https://arxiv.org/abs/2508.06216",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06216v1 Announce Type: new \nAbstract: Edge-weighted graphs play an important role in the theory of Robinsonian matrices and similarity theory, particularly via the concept of level graphs, that is, graphs obtained from an edge-weighted graph by removing all sufficiently light edges. This suggest a natural way of associating to any class $\\mathcal{G}$ of unweighted graphs a corresponding class of edge-weighted graphs, namely by requiring that all level graphs belong to $\\mathcal{G}$. We show that weighted graphs for which all level graphs are split, threshold, or chain graphs can be recognized in linear time using special edge elimination orderings. We obtain these results by introducing the notion of degree sandwich monotone graph classes. A graph class $\\mathcal{G}$ is sandwich monotone if every edge set which may be removed from a graph in $\\mathcal{G}$ without leaving the class also contains a single edge that can be safely removed. Furthermore, if we require the safe edge to fulfill a certain degree property, then $\\mathcal{G}$ is called degree sandwich monotone. We present necessary and sufficient conditions for the existence of a linear-time recognition algorithm for any weighted graph class whose corresponding unweighted class is degree sandwich monotone and contains all edgeless graphs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Sandwich Monotonicity and the Recognition of Weighted Graph Classes\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sandwich",
      "monotonicity",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "A Preliminary Study on the Dimensional Stability Classification of Polynomial Spline Spaces over T-meshes",
    "title_es": "A Preliminary Study on the Dimensional Stability Classification of Polynomial Spline Spaces over T-meshes",
    "url": "https://arxiv.org/abs/2508.06217",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06217v1 Announce Type: new \nAbstract: This paper introduces the concept of dimensional stability for spline spaces over T-meshes, providing the first mathematical definition and a preliminary classification framework. We define dimensional stability as an invariant within the structurally isomorphic class, contingent on the rank stability of the conformality matrix. Absolute stability is proposed via structurally similar maps to address topological and order structures. Through the $k$-partition decomposition of T-connected components and analysis of the CNDC, we establish a correspondence between conformality vector spaces and rank stability. For diagonalizable T-meshes, decomposition into independent one-dimensional T $l$-edges facilitates basis function construction, while arbitrary T-meshes are partitioned into one- and two-dimensional components. These findings lay the groundwork for understanding dimensional stability and developing spline space basis functions.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Preliminary Study on the Dimensional Stability Classification of Polynomial Spline Spaces over T-meshes\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "preliminary",
      "study"
    ],
    "category": "noticia"
  },
  {
    "title": "Interpretable Rheumatoid Arthritis Scoring via Anatomy-aware Multiple Instance Learning",
    "title_es": "Interpretable Rheumatoid Arthritis Scoring via Anatomy-aware Multiple Instance Learning",
    "url": "https://arxiv.org/abs/2508.06218",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06218v1 Announce Type: new \nAbstract: The Sharp/van der Heijde (SvdH) score has been widely used in clinical trials to quantify radiographic damage in Rheumatoid Arthritis (RA), but its complexity has limited its adoption in routine clinical practice. To address the inefficiency of manual scoring, this work proposes a two-stage pipeline for interpretable image-level SvdH score prediction using dual-hand radiographs. Our approach extracts disease-relevant image regions and integrates them using attention-based multiple instance learning to generate image-level features for prediction. We propose two region extraction schemes: 1) sampling image tiles most likely to contain abnormalities, and 2) cropping patches containing disease-relevant joints. With Scheme 2, our best individual score prediction model achieved a Pearson's correlation coefficient (PCC) of 0.943 and a root mean squared error (RMSE) of 15.73. Ensemble learning further boosted prediction accuracy, yielding a PCC of 0.945 and RMSE of 15.57, achieving state-of-the-art performance that is comparable to that of experienced radiologists (PCC = 0.97, RMSE = 18.75). Finally, our pipeline effectively identified and made decisions based on anatomical structures which clinicians consider relevant to RA progression.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Interpretable Rheumatoid Arthritis Scoring via Anatomy-aware Multiple Instance Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "interpretable",
      "rheumatoid",
      "arthritis"
    ],
    "category": "noticia"
  },
  {
    "title": "On MDS Convertible Codes in the Merge Regime",
    "title_es": "On MDS Convertible Codes in the Merge Regime",
    "url": "https://arxiv.org/abs/2508.06219",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06219v1 Announce Type: new \nAbstract: In large-scale distributed storage systems, erasure coding is employed to ensure reliability against disk failures. Recent work by Kadekodi et al. demonstrates that adapting code parameters to varying disk failure rates can lead to significant storage savings without compromising reliability. Such adaptations, known as \\emph{code conversions}, motivate the design of \\emph{convertible codes}, which enable efficient transformations between codes of different parameters.\n  In this work, we study the setting in which $\\lambda$ codewords of an initial $[n^I = k^I + r^I,\\, k^I]$ MDS code are merged into a single codeword of a final $[n^F = \\lambda k^I + r^F,\\, k^F = \\lambda k^I]$ MDS code. We begin by presenting three constructions that achieve optimal \\emph{access cost}, defined as the total number of disks accessed during the conversion process. The first two constructions apply when $\\lambda \\leq r^I$ and impose specific divisibility conditions on $r^I$ and the field size $q$. These schemes minimize both the per-symbol and the overall access cost. The third construction, which builds on a prior scheme by Kong, achieves minimal access cost while supporting arbitrary parameter regimes. All three constructions require field sizes that are linear in the final code length, and notably, the third construction achieves a field size that matches the lower bound implied by the MDS conjecture in almost all cases. In addition, we propose a construction that optimizes the \\emph{bandwidth cost}, defined as the total number of symbols transmitted during conversion. This scheme is a refinement of Maturana and Rashmi's bandwidth-optimal construction based on the piggybacking framework, and achieves reduced sub-packetization.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"On MDS Convertible Codes in the Merge Regime\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "on",
      "mds",
      "convertible"
    ],
    "category": "noticia"
  },
  {
    "title": "InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?",
    "title_es": "InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?",
    "url": "https://arxiv.org/abs/2508.06220",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06220v1 Announce Type: new \nAbstract: Recent advances in Vision-Language Models (VLMs) have demonstrated impressive capabilities in perception and reasoning. However, the ability to perform causal inference -- a core aspect of human cognition -- remains underexplored, particularly in multimodal settings. In this study, we introduce InfoCausalQA, a novel benchmark designed to evaluate causal reasoning grounded in infographics that combine structured visual data with textual context. The benchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning based on inferred numerical trends, while Task 2 targets semantic causal reasoning involving five types of causal relations: cause, effect, intervention, counterfactual, and temporal. We manually collected 494 infographic-text pairs from four public sources and used GPT-4o to generate 1,482 high-quality multiple-choice QA pairs. These questions were then carefully revised by humans to ensure they cannot be answered based on surface-level cues alone but instead require genuine visual grounding. Our experimental results reveal that current VLMs exhibit limited capability in computational reasoning and even more pronounced limitations in semantic causal reasoning. Their significantly lower performance compared to humans indicates a substantial gap in leveraging infographic-based information for causal inference. Through InfoCausalQA, we highlight the need for advancing the causal reasoning abilities of multimodal AI systems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "infocausalqacan",
      "models",
      "perform"
    ],
    "category": "noticia"
  },
  {
    "title": "TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic Segmentation of Urban Remote Sensing Images",
    "title_es": "TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic Segmentation of Urban Remote Sensing Images",
    "url": "https://arxiv.org/abs/2508.06224",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06224v1 Announce Type: new \nAbstract: Semantic segmentation of urban remote sensing images (URSIs) is crucial for applications such as urban planning and environmental monitoring. However, geospatial objects often exhibit subtle texture differences and similar spatial structures, which can easily lead to semantic ambiguity and misclassification. Moreover, challenges such as irregular object shapes, blurred boundaries, and overlapping spatial distributions of semantic objects contribute to complex and diverse edge morphologies, further complicating accurate segmentation. To tackle these issues, we propose a texture-aware and edge-guided Transformer (TEFormer) that integrates texture awareness and edge-guidance mechanisms for semantic segmentation of URSIs. In the encoder, a texture-aware module (TaM) is designed to capture fine-grained texture differences between visually similar categories to enhance semantic discrimination. Then, an edge-guided tri-branch decoder (Eg3Head) is constructed to preserve local edges and details for multiscale context-awareness. Finally, an edge-guided feature fusion module (EgFFM) is to fuse contextual and detail information with edge information to realize refined semantic segmentation. Extensive experiments show that TEFormer achieves mIoU of 88.57%, 81.46%, and 53.55% on the Potsdam, Vaihingen, and LoveDA datasets, respectively, shows the effectiveness in URSI semantic segmentation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic Segmentation of Urban Remote Sensing Images\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "teformer",
      "textureaware",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution",
    "title_es": "Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution",
    "url": "https://arxiv.org/abs/2508.06225",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06225v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are widely used as automated judges, where practical value depends on both accuracy and trustworthy, risk-aware judgments. Existing approaches predominantly focus on accuracy, overlooking the necessity of well-calibrated confidence, which is vital for adaptive and reliable evaluation pipelines. In this work, we advocate a shift from accuracy-centric evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing the necessity of well-calibrated confidence for trustworthy and adaptive evaluation. We systematically identify the **Overconfidence Phenomenon** in current LLM-as-a-Judges, where predicted confidence significantly overstates actual correctness, undermining reliability in practical deployment. To quantify this phenomenon, we introduce **TH-Score**, a novel metric measuring confidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an ensemble framework that transforms LLMs into reliable, risk-aware evaluators. Extensive experiments demonstrate that our approach substantially improves calibration and enables adaptive, confidence-driven evaluation pipelines, achieving superior reliability and accuracy compared to existing baselines.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "overconfidence",
      "in",
      "llmasajudge"
    ],
    "category": "noticia"
  },
  {
    "title": "GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines",
    "title_es": "GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines",
    "url": "https://arxiv.org/abs/2508.06226",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06226v1 Announce Type: new \nAbstract: Geometry problem solving (GPS) requires models to master diagram comprehension, logical reasoning, knowledge application, numerical computation, and auxiliary line construction. This presents a significant challenge for Multimodal Large Language Models (MLLMs). However, existing benchmarks for evaluating MLLM geometry skills overlook auxiliary line construction and lack fine-grained process evaluation, making them insufficient for assessing MLLMs' long-step reasoning abilities. To bridge these gaps, we present the GeoLaux benchmark, comprising 2,186 geometry problems, incorporating both calculation and proving questions. Notably, the problems require an average of 6.51 reasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary line construction. Building on the dataset, we design a novel five-dimensional evaluation strategy assessing answer correctness, process correctness, process quality, auxiliary line impact, and error causes. Extensive experiments on 13 leading MLLMs (including thinking models and non-thinking models) yield three pivotal findings: First, models exhibit substantial performance degradation in extended reasoning steps (nine models demonstrate over 50% performance drop). Second, compared to calculation problems, MLLMs tend to take shortcuts when solving proving problems. Third, models lack auxiliary line awareness, and enhancing this capability proves particularly beneficial for overall geometry reasoning improvement. These findings establish GeoLaux as both a benchmark for evaluating MLLMs' long-step geometric reasoning with auxiliary lines and a guide for capability advancement. Our dataset and code are included in supplementary materials and will be released.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "geolaux",
      "a",
      "benchmark"
    ],
    "category": "noticia"
  },
  {
    "title": "Depth Jitter: Seeing through the Depth",
    "title_es": "Depth Jitter: Seeing through the Depth",
    "url": "https://arxiv.org/abs/2508.06227",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06227v1 Announce Type: new \nAbstract: Depth information is essential in computer vision, particularly in underwater imaging, robotics, and autonomous navigation. However, conventional augmentation techniques overlook depth aware transformations, limiting model robustness in real world depth variations. In this paper, we introduce Depth-Jitter, a novel depth-based augmentation technique that simulates natural depth variations to improve generalization. Our approach applies adaptive depth offsetting, guided by depth variance thresholds, to generate synthetic depth perturbations while preserving structural integrity. We evaluate Depth-Jitter on two benchmark datasets, FathomNet and UTDAC2020 demonstrating its impact on model stability under diverse depth conditions. Extensive experiments compare Depth-Jitter against traditional augmentation strategies such as ColorJitter, analyzing performance across varying learning rates, encoders, and loss functions. While Depth-Jitter does not always outperform conventional methods in absolute performance, it consistently enhances model stability and generalization in depth-sensitive environments. These findings highlight the potential of depth-aware augmentation for real-world applications and provide a foundation for further research into depth-based learning strategies. The proposed technique is publicly available to support advancements in depth-aware augmentation. The code is publicly available on \\href{https://github.com/mim-team/Depth-Jitter}{github}.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Depth Jitter: Seeing through the Depth\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "depth",
      "jitter",
      "seeing"
    ],
    "category": "noticia"
  },
  {
    "title": "Towards Unified Image Deblurring using a Mixture-of-Experts Decoder",
    "title_es": "Towards Unified Image Deblurring using a Mixture-of-Experts Decoder",
    "url": "https://arxiv.org/abs/2508.06228",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06228v1 Announce Type: new \nAbstract: Image deblurring, removing blurring artifacts from images, is a fundamental task in computational photography and low-level computer vision. Existing approaches focus on specialized solutions tailored to particular blur types, thus, these solutions lack generalization. This limitation in current methods implies requiring multiple models to cover several blur types, which is not practical in many real scenarios. In this paper, we introduce the first all-in-one deblurring method capable of efficiently restoring images affected by diverse blur degradations, including global motion, local motion, blur in low-light conditions, and defocus blur. We propose a mixture-of-experts (MoE) decoding module, which dynamically routes image features based on the recognized blur degradation, enabling precise and efficient restoration in an end-to-end manner. Our unified approach not only achieves performance comparable to dedicated task-specific models, but also demonstrates remarkable robustness and generalization capabilities on unseen blur degradation scenarios.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Towards Unified Image Deblurring using a Mixture-of-Experts Decoder\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "towards",
      "unified",
      "image"
    ],
    "category": "noticia"
  },
  {
    "title": "REBot: Reflexive Evasion Robot for Instantaneous Dynamic Obstacle Avoidance",
    "title_es": "REBot: Reflexive Evasion Robot for Instantaneous Dynamic Obstacle Avoidance",
    "url": "https://arxiv.org/abs/2508.06229",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06229v1 Announce Type: new \nAbstract: Dynamic obstacle avoidance (DOA) is critical for quadrupedal robots operating in environments with moving obstacles or humans. Existing approaches typically rely on navigation-based trajectory replanning, which assumes sufficient reaction time and leading to fails when obstacles approach rapidly. In such scenarios, quadrupedal robots require reflexive evasion capabilities to perform instantaneous, low-latency maneuvers. This paper introduces Reflexive Evasion Robot (REBot), a control framework that enables quadrupedal robots to achieve real-time reflexive obstacle avoidance. REBot integrates an avoidance policy and a recovery policy within a finite-state machine. With carefully designed learning curricula and by incorporating regularization and adaptive rewards, REBot achieves robust evasion and rapid stabilization in instantaneous DOA tasks. We validate REBot through extensive simulations and real-world experiments, demonstrating notable improvements in avoidance success rates, energy efficiency, and robustness to fast-moving obstacles. Videos and appendix are available on https://rebot-2025.github.io/.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"REBot: Reflexive Evasion Robot for Instantaneous Dynamic Obstacle Avoidance\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "rebot",
      "reflexive",
      "evasion"
    ],
    "category": "noticia"
  },
  {
    "title": "Learning Logical Rules using Minimum Message Length",
    "title_es": "Learning Logical Rules using Minimum Message Length",
    "url": "https://arxiv.org/abs/2508.06230",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06230v1 Announce Type: new \nAbstract: Unifying probabilistic and logical learning is a key challenge in AI. We introduce a Bayesian inductive logic programming approach that learns minimum message length programs from noisy data. Our approach balances hypothesis complexity and data fit through priors, which explicitly favour more general programs, and a likelihood that favours accurate programs. Our experiments on several domains, including game playing and drug design, show that our method significantly outperforms previous methods, notably those that learn minimum description length programs. Our results also show that our approach is data-efficient and insensitive to example balance, including the ability to learn from exclusively positive examples.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Learning Logical Rules using Minimum Message Length\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "learning",
      "logical",
      "rules"
    ],
    "category": "noticia"
  },
  {
    "title": "Rethinking the Sioux Falls Network: Insights from Path-Driven Higher-Order Network Analysis",
    "title_es": "Rethinking the Sioux Falls Network: Insights from Path-Driven Higher-Order Network Analysis",
    "url": "https://arxiv.org/abs/2508.06234",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06234v1 Announce Type: new \nAbstract: Benchmark scenarios are widely used in transportation research to evaluate routing algorithms, simulate infrastructure interventions, and test new technologies under controlled conditions. However, the structural and behavioral fidelity of these benchmarks remains largely unquantified, raising concerns about the external validity of simulation results. In this study, we introduce a mathematical framework based on higher-order network models to evaluate the representativeness of benchmark networks, focusing on the widely used Sioux Falls scenario. Higher-order network models encode empirical and simulated trajectory data into memory-aware network representations, which we use to quantify sequential dependencies in mobility behavior and assess how well benchmark networks capture real-world structural and functional patterns. Applying this framework to the Sioux Falls network, as well as real-world trajectory data, we quantify structural complexity, optimal memory length, link prediction accuracy, and centrality alignment. Our results show and statistically quantify that the classical Sioux Falls network exhibits limited path diversity, rapid structural fragmentation at higher orders, and weak alignment with empirical routing behavior. These results illustrate the potential of higher-order network models to bridge the gap between simulation-based and real-world mobility analysis, providing a robust foundation for more accurate and generalizable insights in transportation research.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Rethinking the Sioux Falls Network: Insights from Path-Driven Higher-Order Network Analysis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "rethinking",
      "the",
      "sioux"
    ],
    "category": "noticia"
  },
  {
    "title": "Fully discrete error analysis of finite element discretizations of time-dependent Stokes equations in a stream-function formulation",
    "title_es": "Fully discrete error analysis of finite element discretizations of time-dependent Stokes equations in a stream-function formulation",
    "url": "https://arxiv.org/abs/2508.06235",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06235v1 Announce Type: new \nAbstract: In this paper we establish best approximation type error estimates for the fully discrete Galerkin solutions of the time-dependent Stokes problem using the stream-function formulation. For the time discretization we use the discontinuous Galerkin method of arbitrary degree, whereas we present the space discretization in a general framework. This makes our result applicable for a wide variety of space discretization methods, provided some Galerkin orthogonality conditions are satisfied. As an example, conformal $C^1$ and $C^0$ interior penalty methods are covered by our analysis. The results do not require any additional regularity assumptions beyond the natural regularity given by the domain and data and can be used for optimal control problems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Fully discrete error analysis of finite element discretizations of time-dependent Stokes equations in a stream-function formulation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fully",
      "discrete",
      "error"
    ],
    "category": "noticia"
  },
  {
    "title": "A New Framework for the Sum of Squared $\\kappa$-$\\mu$ RVs with Application to Sub-THz Systems",
    "title_es": "A New Framework for the Sum of Squared $\\kappa$-$\\mu$ RVs with Application to Sub-THz Systems",
    "url": "https://arxiv.org/abs/2508.06242",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06242v1 Announce Type: new \nAbstract: In this paper, we adopt the $\\kappa$-$\\mu$ model to characterize the propagation in the sub-THz band. We develop a new exact representation of the sum of squared independent and identically distributed $\\kappa$-$\\mu$ random variables, which can be used to express the power of the received signal in multi-antenna systems. Unlike existing ones, the proposed analytical framework is remarkably tractable and computationally efficient, and thus can be conveniently employed to analyze systems with massive antenna arrays. We derive novel expressions for the probability density function and cumulative distribution function, analyze their convergence and truncation error, and discuss the computational complexity and the implementation aspects. Moreover, we derive expressions for the coverage probability and bit error probability for coherent binary modulations. Lastly, we evaluate the performance of an uplink sub-THz system where a single-antenna user is served by a base station employing maximum ratio combining.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A New Framework for the Sum of Squared $\\kappa$-$\\mu$ RVs with Application to Sub-THz Systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "new",
      "framework"
    ],
    "category": "noticia"
  },
  {
    "title": "SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems",
    "title_es": "SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems",
    "url": "https://arxiv.org/abs/2508.06243",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06243v1 Announce Type: new \nAbstract: The advent of 6G networks opens new possibilities for connected infotainment services in vehicular environments. However, traditional Radio Resource Management (RRM) techniques struggle with the increasing volume and complexity of data such as Channel Quality Indicators (CQI) from autonomous vehicles. To address this, we propose SCAR (State-Space Compression for AI-Driven Resource Management), an Edge AI-assisted framework that optimizes scheduling and fairness in vehicular infotainment. SCAR employs ML-based compression techniques (e.g., clustering and RBF networks) to reduce CQI data size while preserving essential features. These compressed states are used to train 6G-enabled Reinforcement Learning policies that maximize throughput while meeting fairness objectives defined by the NGMN. Simulations show that SCAR increases time in feasible scheduling regions by 14\\% and reduces unfair scheduling time by 15\\% compared to RL baselines without CQI compression. Furthermore, Simulated Annealing with Stochastic Tunneling (SAST)-based clustering reduces CQI clustering distortion by 10\\%, confirming its efficiency. These results demonstrate SCAR's scalability and fairness benefits for dynamic vehicular networks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "scar",
      "statespace",
      "compression"
    ],
    "category": "noticia"
  },
  {
    "title": "Membership Inference Attack with Partial Features",
    "title_es": "Membership Inference Attack with Partial Features",
    "url": "https://arxiv.org/abs/2508.06244",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06244v1 Announce Type: new \nAbstract: Machine learning models have been shown to be susceptible to membership inference attack, which can be used to determine whether a given sample appears in the training data. Existing membership inference methods commonly assume that the adversary has full access to the features of the target sample. This assumption, however, does not hold in many real-world scenarios where only partial features information is available, thereby limiting the applicability of these methods. In this work, we study an inference scenario where the adversary observes only partial features of each sample and aims to infer whether this observed subset was present in the training set of the target model. We define this problem as Partial Feature Membership Inference (PFMI). To address this problem, we propose MRAD (Memory-guided Reconstruction and Anomaly Detection), a two-stage attack framework. In the first stage, MRAD optimizes the unknown feature values to minimize the loss of the sample. In the second stage, it measures the deviation between the reconstructed sample and the training distribution using anomaly detection. Empirical results demonstrate that MRAD is effective across a range of datasets, and maintains compatibility with various off-the-shelf anomaly detection techniques. For example, on STL-10, our attack achieves an AUC of around 0.6 even with 40% of the missing features.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Membership Inference Attack with Partial Features\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "membership",
      "inference",
      "attack"
    ],
    "category": "noticia"
  },
  {
    "title": "Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits",
    "title_es": "Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits",
    "url": "https://arxiv.org/abs/2508.06247",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06247v1 Announce Type: new \nAbstract: The combinatorial multi-armed bandit (CMAB) is a cornerstone of sequential decision-making framework, dominated by two algorithmic families: UCB-based and adversarial methods such as follow the regularized leader (FTRL) and online mirror descent (OMD). However, prominent UCB-based approaches like CUCB suffer from additional regret factor $\\log T$ that is detrimental over long horizons, while adversarial methods such as EXP3.M and HYBRID impose significant computational overhead. To resolve this trade-off, we introduce the Combinatorial Minimax Optimal Strategy in the Stochastic setting (CMOSS). CMOSS is a computationally efficient algorithm that achieves an instance-independent regret of $O\\big( (\\log k)^2\\sqrt{kmT}\\big )$ under semi-bandit feedback, where $m$ is the number of arms and $k$ is the maximum cardinality of a feasible action. Crucially, this result eliminates the dependency on $\\log T$ and matches the established $\\Omega\\big( \\sqrt{kmT}\\big)$ lower bound up to $O\\big((\\log k)^2\\big)$. We then extend our analysis to show that CMOSS is also applicable to cascading feedback. Experiments on synthetic and real-world datasets validate that CMOSS consistently outperforms benchmark algorithms in both regret and runtime efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nearoptimal",
      "regret",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Deepfake Detection that Generalizes Across Benchmarks",
    "title_es": "Deepfake Detection that Generalizes Across Benchmarks",
    "url": "https://arxiv.org/abs/2508.06248",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06248v1 Announce Type: new \nAbstract: The generalization of deepfake detectors to unseen manipulation techniques remains a challenge for practical deployment. Although many approaches adapt foundation models by introducing significant architectural complexity, this work demonstrates that robust generalization is achievable through a parameter-efficient adaptation of a pre-trained CLIP vision encoder. The proposed method, LNCLIP-DF, fine-tunes only the Layer Normalization parameters (0.03% of the total) and enhances generalization by enforcing a hyperspherical feature manifold using L2 normalization and latent space augmentations.\n  We conducted an extensive evaluation on 13 benchmark datasets spanning from 2019 to 2025. The proposed method achieves state-of-the-art performance, outperforming more complex, recent approaches in average cross-dataset AUROC. Our analysis yields two primary findings for the field: 1) training on paired real-fake data from the same source video is essential for mitigating shortcut learning and improving generalization, and 2) detection difficulty on academic datasets has not strictly increased over time, with models trained on older, diverse datasets showing strong generalization capabilities.\n  This work delivers a computationally efficient and reproducible method, proving that state-of-the-art generalization is attainable by making targeted, minimal changes to a pre-trained CLIP model. The code will be made publicly available upon acceptance.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Deepfake Detection that Generalizes Across Benchmarks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "deepfake",
      "detection",
      "that"
    ],
    "category": "noticia"
  },
  {
    "title": "In-Training Defenses against Emergent Misalignment in Language Models",
    "title_es": "In-Training Defenses against Emergent Misalignment in Language Models",
    "url": "https://arxiv.org/abs/2508.06249",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06249v1 Announce Type: new \nAbstract: Fine-tuning lets practitioners repurpose aligned large language models (LLMs) for new domains, yet recent work reveals emergent misalignment (EMA): Even a small, domain-specific fine-tune can induce harmful behaviors far outside the target domain. Even in the case where model weights are hidden behind a fine-tuning API, this gives attackers inadvertent access to a broadly misaligned model in a way that can be hard to detect from the fine-tuning data alone. We present the first systematic study of in-training safeguards against EMA that are practical for providers who expose fine-tuning via an API. We investigate four training regularization interventions: (i) KL-divergence regularization toward a safe reference model, (ii) $\\ell_2$ distance in feature space, (iii) projecting onto a safe subspace (SafeLoRA), and (iv) interleaving of a small amount of safe training examples from a general instruct-tuning dataset. We first evaluate the methods' emergent misalignment effect across four malicious, EMA-inducing tasks. Second, we assess the methods' impacts on benign tasks. We conclude with a discussion of open questions in emergent misalignment research.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"In-Training Defenses against Emergent Misalignment in Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "intraining",
      "defenses",
      "against"
    ],
    "category": "noticia"
  },
  {
    "title": "Dirty Bits in Low-Earth Orbit: The Carbon Footprint of Launching Computers",
    "title_es": "Dirty Bits in Low-Earth Orbit: The Carbon Footprint of Launching Computers",
    "url": "https://arxiv.org/abs/2508.06250",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06250v1 Announce Type: new \nAbstract: Low-Earth Orbit (LEO) satellites are increasingly proposed for communication and in-orbit computing, achieving low-latency global services. However, their sustainability remains largely unexamined. This paper investigates the carbon footprint of computing in space, focusing on lifecycle emissions from launch over orbital operation to re-entry. We present ESpaS, a lightweight tool for estimating carbon intensities across CPU usage, memory, and networking in orbital vs. terrestrial settings. Three worked examples compare (i) launch technologies (state-of-the-art rocket vs. potential next generation) and (ii) operational emissions of data center workloads in orbit and on the ground. Results show that, even under optimistic assumptions, in-orbit systems incur significantly higher carbon costs - up to an order of magnitude more than terrestrial equivalents - primarily due to embodied emissions from launch and re-entry. Our findings advocate for carbon-aware design principles and regulatory oversight in developing sustainable digital infrastructure in orbit.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Dirty Bits in Low-Earth Orbit: The Carbon Footprint of Launching Computers\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dirty",
      "bits",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)",
    "title_es": "Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)",
    "url": "https://arxiv.org/abs/2508.06251",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06251v1 Announce Type: new \nAbstract: Synthetic data generation is a key technique in modern artificial intelligence, addressing data scarcity, privacy constraints, and the need for diverse datasets in training robust models. In this work, we propose a method for generating privacy-preserving high-quality synthetic tabular data using Tensor Networks, specifically Matrix Product States (MPS). We benchmark the MPS-based generative model against state-of-the-art models such as CTGAN, VAE, and PrivBayes, focusing on both fidelity and privacy-preserving capabilities. To ensure differential privacy (DP), we integrate noise injection and gradient clipping during training, enabling privacy guarantees via R\\'enyi Differential Privacy accounting. Across multiple metrics analyzing data fidelity and downstream machine learning task performance, our results show that MPS outperforms classical models, particularly under strict privacy constraints. This work highlights MPS as a promising tool for privacy-aware synthetic data generation. By combining the expressive power of tensor network representations with formal privacy mechanisms, the proposed approach offers an interpretable and scalable alternative for secure data sharing. Its structured design facilitates integration into sensitive domains where both data quality and confidentiality are critical.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "synthetic",
      "data",
      "generation"
    ],
    "category": "noticia"
  },
  {
    "title": "FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing",
    "title_es": "FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing",
    "url": "https://arxiv.org/abs/2508.06256",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06256v1 Announce Type: new \nAbstract: Federated learning (FL) enables the collaborative training of deep neural networks across decentralized data archives (i.e., clients), where each client stores data locally and only shares model updates with a central server. This makes FL a suitable learning paradigm for remote sensing (RS) image classification tasks, where data centralization may be restricted due to legal and privacy constraints. However, a key challenge in applying FL to RS tasks is the communication overhead caused by the frequent exchange of large model updates between clients and the central server. To address this issue, in this paper we propose a novel strategy (denoted as FedX) that uses explanation-guided pruning to reduce communication overhead by minimizing the size of the transmitted models without compromising performance. FedX leverages backpropagation-based explanation methods to estimate the task-specific importance of model components and prunes the least relevant ones at the central server. The resulting sparse global model is then sent to clients, substantially reducing communication overhead. We evaluate FedX on multi-label scene classification using the BigEarthNet-S2 dataset and single-label scene classification using the EuroSAT dataset. Experimental results show the success of FedX in significantly reducing the number of shared model parameters while enhancing the generalization capability of the global model, compared to both unpruned model and state-of-the-art pruning methods. The code of FedX will be available at https://git.tu-berlin.de/rsim/FedX.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fedx",
      "explanationguided",
      "pruning"
    ],
    "category": "noticia"
  },
  {
    "title": "Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors",
    "title_es": "Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors",
    "url": "https://arxiv.org/abs/2508.06257",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06257v1 Announce Type: new \nAbstract: Integrating multi-omics datasets through data-driven analysis offers a comprehensive understanding of the complex biological processes underlying various diseases, particularly cancer. Graph Neural Networks (GNNs) have recently demonstrated remarkable ability to exploit relational structures in biological data, enabling advances in multi-omics integration for cancer subtype classification. Existing approaches often neglect the intricate coupling between heterogeneous omics, limiting their capacity to resolve subtle cancer subtype heterogeneity critical for precision oncology. To address these limitations, we propose a framework named Graph Transformer for Multi-omics Cancer Subtype Classification (GTMancer). This framework builds upon the GNN optimization problem and extends its application to complex multi-omics data. Specifically, our method leverages contrastive learning to embed multi-omics data into a unified semantic space. We unroll the multiplex graph optimization problem in that unified space and introduce dual sets of attention coefficients to capture structural graph priors both within and among multi-omics data. This approach enables global omics information to guide the refining of the representations of individual omics. Empirical experiments on seven real-world cancer datasets demonstrate that GTMancer outperforms existing state-of-the-art algorithms.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "multiomics",
      "analysis",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur MRI Segmentation",
    "title_es": "XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur MRI Segmentation",
    "url": "https://arxiv.org/abs/2508.06258",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06258v1 Announce Type: new \nAbstract: Accurate segmentation of femur structures from Magnetic Resonance Imaging (MRI) is critical for orthopedic diagnosis and surgical planning but remains challenging due to the limitations of existing 2D and 3D deep learning-based segmentation approaches. In this study, we propose XAG-Net, a novel 2.5D U-Net-based architecture that incorporates pixel-wise cross-slice attention (CSA) and skip attention gating (AG) mechanisms to enhance inter-slice contextual modeling and intra-slice feature refinement. Unlike previous CSA-based models, XAG-Net applies pixel-wise softmax attention across adjacent slices at each spatial location for fine-grained inter-slice modeling. Extensive evaluations demonstrate that XAG-Net surpasses baseline 2D, 2.5D, and 3D U-Net models in femur segmentation accuracy while maintaining computational efficiency. Ablation studies further validate the critical role of the CSA and AG modules, establishing XAG-Net as a promising framework for efficient and accurate femur MRI segmentation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur MRI Segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "xagnet",
      "a",
      "crossslice"
    ],
    "category": "noticia"
  },
  {
    "title": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning",
    "title_es": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning",
    "url": "https://arxiv.org/abs/2508.06259",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06259v1 Announce Type: new \nAbstract: Current multimodal large language models (MLLMs) still face significant challenges in complex visual tasks (e.g., spatial understanding, fine-grained perception). Prior methods have tried to incorporate visual reasoning, however, they fail to leverage attention correction with spatial cues to iteratively refine their focus on prompt-relevant regions. In this paper, we introduce SIFThinker, a spatially-aware \"think-with-images\" framework that mimics human visual perception. Specifically, SIFThinker enables attention correcting and image region focusing by interleaving depth-enhanced bounding boxes and natural language. Our contributions are twofold: First, we introduce a reverse-expansion-forward-inference strategy that facilitates the generation of interleaved image-text chains of thought for process-level supervision, which in turn leads to the construction of the SIF-50K dataset. Besides, we propose GRPO-SIF, a reinforced training paradigm that integrates depth-informed visual grounding into a unified reasoning pipeline, teaching the model to dynamically correct and focus on prompt-relevant regions. Extensive experiments demonstrate that SIFThinker outperforms state-of-the-art methods in spatial understanding and fine-grained visual perception, while maintaining strong general capabilities, highlighting the effectiveness of our method.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SIFThinker: Spatially-Aware Image Focus for Visual Reasoning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sifthinker",
      "spatiallyaware",
      "image"
    ],
    "category": "noticia"
  },
  {
    "title": "Llasa+: Free Lunch for Accelerated and Streaming Llama-Based Speech Synthesis",
    "title_es": "Llasa+: Free Lunch for Accelerated and Streaming Llama-Based Speech Synthesis",
    "url": "https://arxiv.org/abs/2508.06262",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06262v1 Announce Type: new \nAbstract: Recent progress in text-to-speech (TTS) has achieved impressive naturalness and flexibility, especially with the development of large language model (LLM)-based approaches. However, existing autoregressive (AR) structures and large-scale models, such as Llasa, still face significant challenges in inference latency and streaming synthesis. To deal with the limitations, we introduce Llasa+, an accelerated and streaming TTS model built on Llasa. Specifically, to accelerate the generation process, we introduce two plug-and-play Multi-Token Prediction (MTP) modules following the frozen backbone. These modules allow the model to predict multiple tokens in one AR step. Additionally, to mitigate potential error propagation caused by inaccurate MTP, we design a novel verification algorithm that leverages the frozen backbone to validate the generated tokens, thus allowing Llasa+ to achieve speedup without sacrificing generation quality. Furthermore, we design a causal decoder that enables streaming speech reconstruction from tokens. Extensive experiments show that Llasa+ achieves a 1.48X speedup without sacrificing generation quality, despite being trained only on LibriTTS. Moreover, the MTP-and-verification framework can be applied to accelerate any LLM-based model. All codes and models are publicly available at https://github.com/ASLP-lab/LLaSA_Plus.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Llasa+: Free Lunch for Accelerated and Streaming Llama-Based Speech Synthesis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "llasa",
      "free",
      "lunch"
    ],
    "category": "noticia"
  },
  {
    "title": "Symmetry breaking for inductive logic programming",
    "title_es": "Symmetry breaking for inductive logic programming",
    "url": "https://arxiv.org/abs/2508.06263",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06263v1 Announce Type: new \nAbstract: The goal of inductive logic programming is to search for a hypothesis that generalises training data and background knowledge. The challenge is searching vast hypothesis spaces, which is exacerbated because many logically equivalent hypotheses exist. To address this challenge, we introduce a method to break symmetries in the hypothesis space. We implement our idea in answer set programming. Our experiments on multiple domains, including visual reasoning and game playing, show that our approach can reduce solving times from over an hour to just 17 seconds.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Symmetry breaking for inductive logic programming\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "symmetry",
      "breaking",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Numerical Considerations in Weighted Model Counting",
    "title_es": "Numerical Considerations in Weighted Model Counting",
    "url": "https://arxiv.org/abs/2508.06264",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06264v1 Announce Type: new \nAbstract: Weighted model counting computes the sum of the rational-valued weights associated with the satisfying assignments for a Boolean formula, where the weight of an assignment is given by the product of the weights assigned to the positive and negated variables comprising the assignment. Weighted model counting finds applications across a variety of domains including probabilistic reasoning and quantitative risk assessment.\n  Most weighted model counting programs operate by (explicitly or implicitly) converting the input formula into a form that enables arithmetic evaluation, using multiplication for conjunctions and addition for disjunctions. Performing this evaluation using floating-point arithmetic can yield inaccurate results, and it cannot quantify the level of precision achieved. Computing with rational arithmetic gives exact results, but it is costly in both time and space.\n  This paper describes how to combine multiple numeric representations to efficiently compute weighted model counts that are guaranteed to achieve a user-specified precision. When all weights are nonnegative, we prove that the precision loss of arithmetic evaluation using floating-point arithmetic can be tightly bounded. We show that supplementing a standard IEEE double-precision representation with a separate 64-bit exponent, a format we call extended-range double (ERD), avoids the underflow and overflow issues commonly encountered in weighted model counting. For problems with mixed negative and positive weights, we show that a combination of interval floating-point arithmetic and rational arithmetic can achieve the twin goals of efficiency and guaranteed precision. For our evaluations, we have devised especially challenging formulas and weight assignments, demonstrating the robustness of our approach.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Numerical Considerations in Weighted Model Counting\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "numerical",
      "considerations",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints",
    "title_es": "ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints",
    "url": "https://arxiv.org/abs/2508.06266",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06266v1 Announce Type: new \nAbstract: Diffusion policies have recently emerged as a powerful class of visuomotor controllers for robot manipulation, offering stable training and expressive multi-modal action modeling. However, existing approaches typically treat action generation as an unconstrained denoising process, ignoring valuable a priori knowledge about geometry and control structure. In this work, we propose the Adaptive Diffusion Policy (ADP), a test-time adaptation method that introduces two key inductive biases into the diffusion. First, we embed a geometric manifold constraint that aligns denoising updates with task-relevant subspaces, leveraging the fact that the relative pose between the end-effector and target scene provides a natural gradient direction, and guiding denoising along the geodesic path of the manipulation manifold. Then, to reduce unnecessary exploration and accelerate convergence, we propose an analytically guided initialization: rather than sampling from an uninformative prior, we compute a rough registration between the gripper and target scenes to propose a structured initial noisy action. ADP is compatible with pre-trained diffusion policies and requires no retraining, enabling test-time adaptation that tailors the policy to specific tasks, thereby enhancing generalization across novel tasks and environments. Experiments on RLBench, CALVIN, and real-world dataset show that ADPro, an implementation of ADP, improves success rates, generalization, and sampling efficiency, achieving up to 25% faster execution and 9% points over strong diffusion baselines.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "adpro",
      "a",
      "testtime"
    ],
    "category": "noticia"
  },
  {
    "title": "Analysis and Constructive Criticism of the Official Data Protection Impact Assessment of the German Corona-Warn-App",
    "title_es": "Analysis and Constructive Criticism of the Official Data Protection Impact Assessment of the German Corona-Warn-App",
    "url": "https://arxiv.org/abs/2508.06267",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06267v1 Announce Type: new \nAbstract: On June 15, 2020, the official data protection impact assessment (DPIA) for the German Corona-Warn-App (CWA) was made publicly available. Shortly thereafter, the app was made available for download in the app stores. However, the first version of the DPIA had significant weaknesses, as this paper argues. However since then, the quality of the official DPIA increased immensely due to interventions and interactions such as an alternative DPIA produced by external experts and extensive public discussions. To illustrate the development and improvement, the initial weaknesses of the official DPIA are documented and analyzed here. For this paper to meaningfully do this, first the purpose of a DPIA is briefly summarized. According to Article 35 of the GDPR, it consists primarily of identifying the risks to the fundamental rights and freedoms of natural persons. This paper documents at least specific methodological, technical and legal shortcomings of the initial DPIA of the CWA: 1) It only focused on the app itself, neither on the whole processing procedure nor on the infrastructure used. 2) It only briefly touched on the main data protection specific attacker, the processing organization itself. And 3) The discussion of effective safeguards to all risks including such as the ones posed by Google and Apple has only insufficiently been worked out. Finally, this paper outlines the constructive criticism and suggestions uttered, also by the authors of this paper, regarding the initial release. As of now, some of those constructive contributions have been worked into the current DPIA, such as 1) and 2), but some central ones still haven't, such as 3). This paper aims to provide an opportunity to improve the practical knowledge and academic discourse regarding high-quality DPIAs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Analysis and Constructive Criticism of the Official Data Protection Impact Assessment of the German Corona-Warn-App\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "analysis",
      "and",
      "constructive"
    ],
    "category": "noticia"
  },
  {
    "title": "OM2P: Offline Multi-Agent Mean-Flow Policy",
    "title_es": "OM2P: Offline Multi-Agent Mean-Flow Policy",
    "url": "https://arxiv.org/abs/2508.06269",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06269v1 Announce Type: new \nAbstract: Generative models, especially diffusion and flow-based models, have been promising in offline multi-agent reinforcement learning. However, integrating powerful generative models into this framework poses unique challenges. In particular, diffusion and flow-based policies suffer from low sampling efficiency due to their iterative generation processes, making them impractical in time-sensitive or resource-constrained settings. To tackle these difficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel offline MARL algorithm to achieve efficient one-step action sampling. To address the misalignment between generative objectives and reward maximization, we introduce a reward-aware optimization scheme that integrates a carefully-designed mean-flow matching loss with Q-function supervision. Additionally, we design a generalized timestep distribution and a derivative-free estimation strategy to reduce memory overhead and improve training stability. Empirical evaluations on Multi-Agent Particle and MuJoCo benchmarks demonstrate that OM2P achieves superior performance, with up to a 3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time. Our approach represents the first to successfully integrate mean-flow model into offline MARL, paving the way for practical and scalable generative policies in cooperative multi-agent settings.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"OM2P: Offline Multi-Agent Mean-Flow Policy\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "omp",
      "offline",
      "multiagent"
    ],
    "category": "noticia"
  },
  {
    "title": "A Fully Discrete Truly Multidimensional Active Flux Method For The Two-Dimensional Euler Equations",
    "title_es": "A Fully Discrete Truly Multidimensional Active Flux Method For The Two-Dimensional Euler Equations",
    "url": "https://arxiv.org/abs/2508.06273",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06273v1 Announce Type: new \nAbstract: The Active Flux method is a finite volume method for hyperbolic conservation laws that uses both cell averages and point values as degrees of freedom. Several versions of such methods are currently under development. We focus on third order accurate, fully discrete Active Flux methods with compact stencil in space and time. These methods require exact or approximate evolution operators for the update of the point value degrees of freedom which are provided by the method of bicharacteristics. Here we propose new limiting strategies that guarantee positivity of pressure and density and furthermore discuss the implementation of reflecting boundary conditions. Numerical results show that the method leads to accurate approximates on coarse grids.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Fully Discrete Truly Multidimensional Active Flux Method For The Two-Dimensional Euler Equations\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "fully",
      "discrete"
    ],
    "category": "noticia"
  },
  {
    "title": "EcBot: Data-Driven Energy Consumption Open-Source MATLAB Library for Manipulators",
    "title_es": "EcBot: Data-Driven Energy Consumption Open-Source MATLAB Library for Manipulators",
    "url": "https://arxiv.org/abs/2508.06276",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06276v1 Announce Type: new \nAbstract: Existing literature proposes models for estimating the electrical power of manipulators, yet two primary limitations prevail. First, most models are predominantly tested using traditional industrial robots. Second, these models often lack accuracy. To address these issues, we introduce an open source Matlab-based library designed to automatically generate \\ac{ec} models for manipulators. The necessary inputs for the library are Denavit-Hartenberg parameters, link masses, and centers of mass. Additionally, our model is data-driven and requires real operational data, including joint positions, velocities, accelerations, electrical power, and corresponding timestamps. We validated our methodology by testing on four lightweight robots sourced from three distinct manufacturers: Universal Robots, Franka Emika, and Kinova. The model underwent testing, and the results demonstrated an RMSE ranging from 1.42 W to 2.80 W for the training dataset and from 1.45 W to 5.25 W for the testing dataset.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"EcBot: Data-Driven Energy Consumption Open-Source MATLAB Library for Manipulators\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ecbot",
      "datadriven",
      "energy"
    ],
    "category": "noticia"
  },
  {
    "title": "Large Language Model Data Generation for Enhanced Intent Recognition in German Speech",
    "title_es": "Large Language Model Data Generation for Enhanced Intent Recognition in German Speech",
    "url": "https://arxiv.org/abs/2508.06277",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06277v1 Announce Type: new \nAbstract: Intent recognition (IR) for speech commands is essential for artificial intelligence (AI) assistant systems; however, most existing approaches are limited to short commands and are predominantly developed for English. This paper addresses these limitations by focusing on IR from speech by elderly German speakers. We propose a novel approach that combines an adapted Whisper ASR model, fine-tuned on elderly German speech (SVC-de), with Transformer-based language models trained on synthetic text datasets generated by three well-known large language models (LLMs): LeoLM, Llama3, and ChatGPT. To evaluate the robustness of our approach, we generate synthetic speech with a text-to-speech model and conduct extensive cross-dataset testing. Our results show that synthetic LLM-generated data significantly boosts classification performance and robustness to different speaking styles and unseen vocabulary. Notably, we find that LeoLM, a smaller, domain-specific 13B LLM, surpasses the much larger ChatGPT (175B) in dataset quality for German intent recognition. Our approach demonstrates that generative AI can effectively bridge data gaps in low-resource domains. We provide detailed documentation of our data generation and training process to ensure transparency and reproducibility.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Large Language Model Data Generation for Enhanced Intent Recognition in German Speech\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "large",
      "language",
      "model"
    ],
    "category": "noticia"
  },
  {
    "title": "Mitigating Undesired Conditions in Flexible Production with Product-Process-Resource Asset Knowledge Graphs",
    "title_es": "Mitigating Undesired Conditions in Flexible Production with Product-Process-Resource Asset Knowledge Graphs",
    "url": "https://arxiv.org/abs/2508.06278",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06278v1 Announce Type: new \nAbstract: Contemporary industrial cyber-physical production systems (CPPS) composed of robotic workcells face significant challenges in the analysis of undesired conditions due to the flexibility of Industry 4.0 that disrupts traditional quality assurance mechanisms. This paper presents a novel industry-oriented semantic model called Product-Process-Resource Asset Knowledge Graph (PPR-AKG), which is designed to analyze and mitigate undesired conditions in flexible CPPS. Built on top of the well-proven Product-Process-Resource (PPR) model originating from ISA-95 and VDI-3682, a comprehensive OWL ontology addresses shortcomings of conventional model-driven engineering for CPPS, particularly inadequate undesired condition and error handling representation. The integration of semantic technologies with large language models (LLMs) provides intuitive interfaces for factory operators, production planners, and engineers to interact with the entire model using natural language. Evaluation with the use case addressing electric vehicle battery remanufacturing demonstrates that the PPR-AKG approach efficiently supports resource allocation based on explicitly represented capabilities as well as identification and mitigation of undesired conditions in production. The key contributions include (1) a holistic PPR-AKG model capturing multi-dimensional production knowledge, and (2) the useful combination of the PPR-AKG with LLM-based chatbots for human interaction.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Mitigating Undesired Conditions in Flexible Production with Product-Process-Resource Asset Knowledge Graphs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mitigating",
      "undesired",
      "conditions"
    ],
    "category": "noticia"
  },
  {
    "title": "A Study on Regularization-Based Continual Learning Methods for Indic ASR",
    "title_es": "A Study on Regularization-Based Continual Learning Methods for Indic ASR",
    "url": "https://arxiv.org/abs/2508.06280",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06280v1 Announce Type: new \nAbstract: Indias linguistic diversity poses significant challenges for developing inclusive Automatic Speech Recognition (ASR) systems. Traditional multilingual models, which require simultaneous access to all language data, are impractical due to the sequential arrival of data and privacy constraints. Continual Learning (CL) offers a solution by enabling models to learn new languages sequentially without catastrophically forgetting previously learned knowledge. This paper investigates CL for ASR on Indian languages using a subset of the IndicSUPERB benchmark. We employ a Conformer-based hybrid RNN-T/CTC model, initially pretrained on Hindi, which is then incrementally trained on eight additional Indian languages, for a total sequence of nine languages. We evaluate three prominent regularization- and distillation-based CL strategies: Elastic Weight Consolidation (EWC), Memory Aware Synapses (MAS), and Learning without Forgetting (LwF), selected for their suitability in no-replay, privacy-conscious scenarios. Performance is analyzed using Word Error Rate (WER) for both RNN-T and CTC paths on clean and noisy data, as well as knowledge retention via Backward Transfer. We also explore the impact of varying the number of training epochs (1, 2, 5, and 10) per task. Results, compared against naive fine-tuning, demonstrate CLs effectiveness in mitigating forgetting, making it a promising approach for scalable ASR in diverse Indian languages under realistic constraints. The code is available at: https://github.com/FrozenWolf-Cyber/Indic-CL-ASR",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Study on Regularization-Based Continual Learning Methods for Indic ASR\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "study",
      "on"
    ],
    "category": "noticia"
  },
  {
    "title": "Situationally-aware Path Planning Exploiting 3D Scene Graphs",
    "title_es": "Situationally-aware Path Planning Exploiting 3D Scene Graphs",
    "url": "https://arxiv.org/abs/2508.06283",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06283v1 Announce Type: new \nAbstract: 3D Scene Graphs integrate both metric and semantic information, yet their structure remains underutilized for improving path planning efficiency and interpretability. In this work, we present S-Path, a situationally-aware path planner that leverages the metric-semantic structure of indoor 3D Scene Graphs to significantly enhance planning efficiency. S-Path follows a two-stage process: it first performs a search over a semantic graph derived from the scene graph to yield a human-understandable high-level path. This also identifies relevant regions for planning, which later allows the decomposition of the problem into smaller, independent subproblems that can be solved in parallel. We also introduce a replanning mechanism that, in the event of an infeasible path, reuses information from previously solved subproblems to update semantic heuristics and prioritize reuse to further improve the efficiency of future planning attempts. Extensive experiments on both real-world and simulated environments show that S-Path achieves average reductions of 5.7x in planning time while maintaining comparable path optimality to classical sampling-based planners and surpassing them in complex scenarios, making it an efficient and interpretable path planner for environments represented by indoor 3D Scene Graphs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Situationally-aware Path Planning Exploiting 3D Scene Graphs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "situationallyaware",
      "path",
      "planning"
    ],
    "category": "noticia"
  },
  {
    "title": "Real-Time 3D Vision-Language Embedding Mapping",
    "title_es": "Real-Time 3D Vision-Language Embedding Mapping",
    "url": "https://arxiv.org/abs/2508.06291",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06291v1 Announce Type: new \nAbstract: A metric-accurate semantic 3D representation is essential for many robotic tasks. This work proposes a simple, yet powerful, way to integrate the 2D embeddings of a Vision-Language Model in a metric-accurate 3D representation at real-time. We combine a local embedding masking strategy, for a more distinct embedding distribution, with a confidence-weighted 3D integration for more reliable 3D embeddings. The resulting metric-accurate embedding representation is task-agnostic and can represent semantic concepts on a global multi-room, as well as on a local object-level. This enables a variety of interactive robotic applications that require the localisation of objects-of-interest via natural language. We evaluate our approach on a variety of real-world sequences and demonstrate that these strategies achieve a more accurate object-of-interest localisation while improving the runtime performance in order to meet our real-time constraints. We further demonstrate the versatility of our approach in a variety of interactive handheld, mobile robotics and manipulation tasks, requiring only raw image data.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Real-Time 3D Vision-Language Embedding Mapping\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "realtime",
      "d",
      "visionlanguage"
    ],
    "category": "noticia"
  },
  {
    "title": "Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback",
    "title_es": "Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback",
    "url": "https://arxiv.org/abs/2508.06292",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06292v1 Announce Type: new \nAbstract: Neuromorphic computing is an emerging technology enabling low-latency and energy-efficient signal processing. A key algorithmic tool in neuromorphic computing is spiking neural networks (SNNs). SNNs are biologically inspired neural networks which utilize stateful neurons, and provide low-bit data processing by encoding and decoding information using spikes. Similar to SNNs, deep state-space models (SSMs) utilize stateful building blocks. However, deep SSMs, which recently achieved competitive performance in various temporal modeling tasks, are typically designed with high-precision activation functions and no reset mechanisms. To bridge the gains offered by SNNs and the recent deep SSM models, we propose a novel multiple-output spiking neuron model that combines a linear, general SSM state transition with a non-linear feedback mechanism through reset. Compared to the existing neuron models for SNNs, our proposed model clearly conceptualizes the differences between the spiking function, the reset condition and the reset action. The experimental results on various tasks, i.e., a keyword spotting task, an event-based vision task and a sequential pattern recognition task, show that our proposed model achieves performance comparable to existing benchmarks in the SNN literature. Our results illustrate how the proposed reset mechanism can overcome instability and enable learning even when the linear part of neuron dynamics is unstable, allowing us to go beyond the strictly enforced stability of linear dynamics in recent deep SSM models.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lowbit",
      "data",
      "processing"
    ],
    "category": "noticia"
  },
  {
    "title": "Evaluating Robot Program Performance with Power Consumption Driven Metrics in Lightweight Industrial Robots",
    "title_es": "Evaluating Robot Program Performance with Power Consumption Driven Metrics in Lightweight Industrial Robots",
    "url": "https://arxiv.org/abs/2508.06295",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06295v1 Announce Type: new \nAbstract: The code performance of industrial robots is typically analyzed through CPU metrics, which overlook the physical impact of code on robot behavior. This study introduces a novel framework for assessing robot program performance from an embodiment perspective by analyzing the robot's electrical power profile. Our approach diverges from conventional CPU based evaluations and instead leverages a suite of normalized metrics, namely, the energy utilization coefficient, the energy conversion metric, and the reliability coefficient, to capture how efficiently and reliably energy is used during task execution. Complementing these metrics, the established robot wear metric provides further insight into long term reliability. Our approach is demonstrated through an experimental case study in machine tending, comparing four programs with diverse strategies using a UR5e robot. The proposed metrics directly compare and categorize different robot programs, regardless of the specific task, by linking code performance to its physical manifestation through power consumption patterns. Our results reveal the strengths and weaknesses of each strategy, offering actionable insights for optimizing robot programming practices. Enhancing energy efficiency and reliability through this embodiment centric approach not only improves individual robot performance but also supports broader industrial objectives such as sustainable manufacturing and cost reduction.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Evaluating Robot Program Performance with Power Consumption Driven Metrics in Lightweight Industrial Robots\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "evaluating",
      "robot",
      "program"
    ],
    "category": "noticia"
  },
  {
    "title": "LLM Robustness Leaderboard v1 --Technical report",
    "title_es": "LLM Robustness Leaderboard v1 --Technical report",
    "url": "https://arxiv.org/abs/2508.06296",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06296v1 Announce Type: new \nAbstract: This technical report accompanies the LLM robustness leaderboard published by PRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior Elicitation Tool (BET), an AI system performing automated red-teaming through Dynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR) against 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we propose a fine-grained robustness metric estimating the average number of attempts required to elicit harmful behaviors, revealing that attack difficulty varies by over 300-fold across models despite universal vulnerability. We introduce primitive-level vulnerability analysis to identify which jailbreaking techniques are most effective for specific hazard categories. Our collaborative evaluation with trusted third parties from the AI Safety Network demonstrates practical pathways for distributed robustness assessment across the community.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LLM Robustness Leaderboard v1 --Technical report\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "llm",
      "robustness",
      "leaderboard"
    ],
    "category": "noticia"
  },
  {
    "title": "KV Cache Compression for Inference Efficiency in LLMs: A Review",
    "title_es": "KV Cache Compression for Inference Efficiency in LLMs: A Review",
    "url": "https://arxiv.org/abs/2508.06297",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06297v1 Announce Type: new \nAbstract: Withtherapid advancement of large language models (LLMs), the context length for inference has been continuously increasing, leading to an exponential growth in the demand for Key-Value (KV) caching. This has resulted in a significant memory bottleneck, limiting the inference efficiency and scalability of the models. Therefore, optimizing the KV cache during inference is crucial for enhancing performance and efficiency. This review systematically examines current KV cache optimization techniques, including compression strategies such as selective token strategies, quantization, and attention compression. We evaluate the effectiveness, trade-offs, and application scenarios of these methods, providing a comprehensive analysis of their impact on memory usage and inference speed. We focus on identifying the limitations and challenges of existing methods, such as compatibility issues with different models and tasks. Additionally, this review highlights future research directions, including hybrid optimization techniques, adaptive dynamic strategies, and software-hardware co-design. These approaches aim to improve inference efficiency and promote the practical application of large language models.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"KV Cache Compression for Inference Efficiency in LLMs: A Review\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "kv",
      "cache",
      "compression"
    ],
    "category": "noticia"
  },
  {
    "title": "Improving the Developer Experience with a Low-Code Process Modelling Language",
    "title_es": "Improving the Developer Experience with a Low-Code Process Modelling Language",
    "url": "https://arxiv.org/abs/2508.06299",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06299v1 Announce Type: new \nAbstract: Context: The OutSystems Platform is a development environment composed of several DSLs, used to specify, quickly build, and validate web and mobile applications. The DSLs allow users to model different perspectives such as interfaces and data models, define custom business logic and construct process models. Problem: The DSL for process modelling (Business Process Technology (BPT)), has a low adoption rate and is perceived as having usability problems hampering its adoption. This is problematic given the language maintenance costs. Method: We used a combination of interviews, a critical review of BPT using the \"Physics of Notation\" and empirical evaluations of BPT using the System Usability Scale (SUS) and the NASA Task Load indeX (TLX), to develop a new version of BPT, taking these inputs and Outsystems' engineers' culture into account. Results: Evaluations conducted with 25 professional software engineers showed an increase of the semantic transparency on the new version, from 31% to 69%, an increase in the correctness of responses, from 51% to 89%, an increase in the SUS score, from 42.25 to 64.78, and a decrease of the TLX score, from 36.50 to 20.78. These differences were statistically significant. Conclusions: These results suggest that the new version of BPT significantly improved the developer experience of the previous version. The end users' background with OutSystems had a relevant impact on the final concrete syntax choices and achieved usability indicators.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Improving the Developer Experience with a Low-Code Process Modelling Language\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "improving",
      "the",
      "developer"
    ],
    "category": "noticia"
  },
  {
    "title": "Automatic Semantic Alignment of Flow Pattern Representations for Exploration with Large Language Models",
    "title_es": "Automatic Semantic Alignment of Flow Pattern Representations for Exploration with Large Language Models",
    "url": "https://arxiv.org/abs/2508.06300",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06300v1 Announce Type: new \nAbstract: Explorative flow visualization allows domain experts to analyze complex flow structures by interactively investigating flow patterns. However, traditional visual interfaces often rely on specialized graphical representations and interactions, which require additional effort to learn and use. Natural language interaction offers a more intuitive alternative, but teaching machines to recognize diverse scientific concepts and extract corresponding structures from flow data poses a significant challenge. In this paper, we introduce an automated framework that aligns flow pattern representations with the semantic space of large language models (LLMs), eliminating the need for manual labeling. Our approach encodes streamline segments using a denoising autoencoder and maps the generated flow pattern representations to LLM embeddings via a projector layer. This alignment empowers semantic matching between textual embeddings and flow representations through an attention mechanism, enabling the extraction of corresponding flow patterns based on textual descriptions. To enhance accessibility, we develop an interactive interface that allows users to query and visualize flow structures using natural language. Through case studies, we demonstrate the effectiveness of our framework in enabling intuitive and intelligent flow exploration.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Automatic Semantic Alignment of Flow Pattern Representations for Exploration with Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "automatic",
      "semantic",
      "alignment"
    ],
    "category": "noticia"
  },
  {
    "title": "FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields",
    "title_es": "FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields",
    "url": "https://arxiv.org/abs/2508.06301",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06301v1 Announce Type: new \nAbstract: Neural fields provide a memory-efficient representation of data, which can effectively handle diverse modalities and large-scale data. However, learning to map neural fields often requires large amounts of training data and computations, which can be limited to resource-constrained edge devices. One approach to tackle this limitation is to leverage Federated Meta-Learning (FML), but traditional FML approaches suffer from privacy leakage. To address these issues, we introduce a novel FML approach called FedMeNF. FedMeNF utilizes a new privacy-preserving loss function that regulates privacy leakage in the local meta-optimization. This enables the local meta-learner to optimize quickly and efficiently without retaining the client's private data. Our experiments demonstrate that FedMeNF achieves fast optimization speed and robust reconstruction performance, even with few-shot or non-IID data across diverse data modalities, while preserving client data privacy.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fedmenf",
      "privacypreserving",
      "federated"
    ],
    "category": "noticia"
  },
  {
    "title": "Parallelized computation of quasi-periodic solutions for finite element problems: A Fourier series expansion-based shooting method",
    "title_es": "Parallelized computation of quasi-periodic solutions for finite element problems: A Fourier series expansion-based shooting method",
    "url": "https://arxiv.org/abs/2508.06302",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06302v1 Announce Type: new \nAbstract: High-dimensional nonlinear mechanical systems admit quasi-periodic solutions that are essential for the understanding of the dynamical systems. These quasi-periodic solutions stay on some invariant tori governed by complex PDEs in hyper-time. Here, we propose a Fourier series expansion-based shooting method (FSE-Shooting) for the parallelized computation of quasi-periodic solution with $d$ base frequencies ($d \\ge 2$). We represent the associated $d$-torus as a collection of trajectories initialized at a ($d-1$)-torus. We drive a set of ODEs that hold for any of these trajectories. We also derive a set of boundary conditions that couple the initial and terminal states of these trajectories and then formulate a set of nonlinear algebraic equations via the coupling conditions. We use Fourier series expansion to parameterize the ($d-1$)-torus and shooting method to iterate the Fourier coefficients associated with initial torus such that the coupling conditions are satisfied. In particular, the terminal points of these trajectories are parallelized computed via Newmark integration, where the time points and Fourier coefficients are transformed to each other by alternating Frequency-Time method. A straightforward phase condition is devised to track the quasi-periodic solutions with priori unknown base frequencies. Additionally, the by-product of the FSE-Shooting can be also directly used to compute the Lyapunov exponents to assess the stabilities of quasi-periodic solutions. The results of three finite element systems show the efficiency and versatility of FSE-Shooting in high-dimensional nonlinear dynamical systems, including a three-dimensional shell structure with $1872$ DOFs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Parallelized computation of quasi-periodic solutions for finite element problems: A Fourier series expansion-based shooting method\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "parallelized",
      "computation",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "A Tensor Train Approach for Deterministic Arithmetic Operations on Discrete Representations of Probability Distributions",
    "title_es": "A Tensor Train Approach for Deterministic Arithmetic Operations on Discrete Representations of Probability Distributions",
    "url": "https://arxiv.org/abs/2508.06303",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06303v1 Announce Type: new \nAbstract: Computing with discrete representations of high-dimensional probability distributions is fundamental to uncertainty quantification, Bayesian inference, and stochastic modeling. However, storing and manipulating such distributions suffers from the curse of dimensionality, as memory and computational costs grow exponentially with dimension. Monte Carlo methods require thousands to billions of samples, incurring high computational costs and producing inconsistent results due to stochasticity. We present an efficient tensor train method for performing exact arithmetic operations on discretizations of continuous probability distributions while avoiding exponential growth. Our approach leverages low-rank tensor train decomposition to represent latent random variables compactly using Dirac deltas, enabling deterministic addition, subtraction and multiplication operations directly in the compressed format. We develop an efficient implementation using sparse matrices and specialized data structures that further enhances performance. Theoretical analysis demonstrates polynomial scaling of memory and computational complexity under rank assumptions, and shows how statistics of latent variables can be computed with polynomial complexity. Numerical experiments spanning randomized linear algebra to stochastic differential equations demonstrate orders-of-magnitude improvements in memory usage and computational time compared to conventional approaches, enabling tractable deterministic computations on discretized random variables in previously intractable dimensions.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Tensor Train Approach for Deterministic Arithmetic Operations on Discrete Representations of Probability Distributions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "tensor",
      "train"
    ],
    "category": "noticia"
  },
  {
    "title": "Higher Order Regularization using Harmonic Eigenfunctions for Model-Based Reconstruction in Magnetic Particle Imaging",
    "title_es": "Higher Order Regularization using Harmonic Eigenfunctions for Model-Based Reconstruction in Magnetic Particle Imaging",
    "url": "https://arxiv.org/abs/2508.06306",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06306v1 Announce Type: new \nAbstract: Magnetic Particle Imaging (MPI) is a recent imaging modality where superparamagnetic nanoparticles are employed as tracers. The reconstruction task is to obtain the spatial particle distribution from a voltage signal induced by the particles. Generally, in computational imaging variational reconstruction techniques are common and rely on a mathematical model to describe the underlying physics. For the MPI reconstruction task we propose a model-based variational reconstruction technique which incorporates a higher order regularizer, where the regularizer is diagonalized by harmonic eigenfunctions. The proposed image reconstruction algorithm features two major stages: in the first stage, the core stage, the components of the MPI core response are reconstructed. This is the MPI-specific data approximation task which we formulate as a variational problem incorporating the higher order regularizer. The relationship between the particle distribution, the MPI core response and the measured data is given by a mathematical model which was introduced in our earlier research. According to this model the MPI core response is tied to the particle distribution by convolution. Therefore the outcome of the core stage yields the data for the second stage, the deconvolution stage, in which the final reconstructed image is produced by solving an ill-posed deconvolution problem in a robust way relying on earlier research. Interestingly, the quality of the final image depends significantly on the quality of the result of the core stage. A contribution is thus the enhancement of the core stage via higher order regularization. We provide a theoretical foundation for our approach and demonstrate its benefit with numerical examples.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Higher Order Regularization using Harmonic Eigenfunctions for Model-Based Reconstruction in Magnetic Particle Imaging\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "higher",
      "order",
      "regularization"
    ],
    "category": "noticia"
  },
  {
    "title": "Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC",
    "title_es": "Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC",
    "url": "https://arxiv.org/abs/2508.06309",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06309v1 Announce Type: new \nAbstract: In recent years, concerns about intellectual property (IP) in large language models (LLMs) have grown significantly. Plagiarizing other LLMs (through direct weight copying, upcycling, pruning, or continual pretraining) and claiming authorship without properly attributing to the original license, is a serious misconduct that can lead to significant financial and reputational harm to the original developers. However, existing methods for detecting LLM plagiarism fall short in key areas. They fail to accurately reconstruct weight correspondences, lack the ability to compute statistical significance measures such as $p$-values, and may mistakenly flag models trained on similar data as being related. To address these limitations, we propose Matrix-Driven Instant Review (MDIR), a novel method that leverages matrix analysis and Large Deviation Theory. MDIR achieves accurate reconstruction of weight relationships, provides rigorous $p$-value estimation, and focuses exclusively on weight similarity without requiring full model inference. Experimental results demonstrate that MDIR reliably detects plagiarism even after extensive transformations, such as random permutations and continual pretraining with trillions of tokens. Moreover, all detections can be performed on a single PC within an hour, making MDIR both efficient and accessible.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "matrixdriven",
      "instant",
      "review"
    ],
    "category": "noticia"
  },
  {
    "title": "Chain-of-Alpha: Unleashing the Power of Large Language Models for Alpha Mining in Quantitative Trading",
    "title_es": "Chain-of-Alpha: Unleashing the Power of Large Language Models for Alpha Mining in Quantitative Trading",
    "url": "https://arxiv.org/abs/2508.06312",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06312v1 Announce Type: new \nAbstract: Alpha factor mining is a fundamental task in quantitative trading, aimed at discovering interpretable signals that can predict asset returns beyond systematic market risk. While traditional methods rely on manual formula design or heuristic search with machine learning, recent advances have leveraged Large Language Models (LLMs) for automated factor discovery. However, existing LLM-based alpha mining approaches remain limited in terms of automation, generality, and efficiency. In this paper, we propose Chain-of-Alpha, a novel, simple, yet effective and efficient LLM-based framework for fully automated formulaic alpha mining. Our method features a dual-chain architecture, consisting of a Factor Generation Chain and a Factor Optimization Chain, which iteratively generate, evaluate, and refine candidate alpha factors using only market data, while leveraging backtest feedback and prior optimization knowledge. The two chains work synergistically to enable high-quality alpha discovery without human intervention and offer strong scalability. Extensive experiments on real-world A-share benchmarks demonstrate that Chain-of-Alpha outperforms existing baselines across multiple metrics, presenting a promising direction for LLM-driven quantitative research.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Chain-of-Alpha: Unleashing the Power of Large Language Models for Alpha Mining in Quantitative Trading\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "chainofalpha",
      "unleashing",
      "the"
    ],
    "category": "noticia"
  },
  {
    "title": "Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators",
    "title_es": "Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators",
    "url": "https://arxiv.org/abs/2508.06313",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06313v1 Announce Type: new \nAbstract: This paper presents a unified system-level modeling and control framework for an all-electric heavy-duty robotic manipulator (HDRM) driven by electromechanical linear actuators (EMLAs). A surrogate-enhanced actuator model, combining integrated electromechanical dynamics with a neural network trained on a dedicated testbed, is integrated into an extended virtual decomposition control (VDC) architecture augmented by a natural adaptation law. The derived analytical HDRM model supports a hierarchical control structure that seamlessly maps high-level force and velocity objectives to real-time actuator commands, accompanied by a Lyapunov-based stability proof. In multi-domain simulations of both cubic and a custom planar triangular trajectory, the proposed adaptive modular controller achieves sub-centimeter Cartesian tracking accuracy. Experimental validation of the same 1-DoF platform under realistic load emulation confirms the efficacy of the proposed control strategy. These findings demonstrate that a surrogate-enhanced EMLA model embedded in the VDC approach can enable modular, real-time control of an all-electric HDRM, supporting its deployment in next-generation mobile working machines.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "surrogateenhanced",
      "modeling",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "The Beauty of Anisotropic Mesh Refinement: Omnitrees for Efficient Dyadic Discretizations",
    "title_es": "The Beauty of Anisotropic Mesh Refinement: Omnitrees for Efficient Dyadic Discretizations",
    "url": "https://arxiv.org/abs/2508.06316",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06316v1 Announce Type: new \nAbstract: Structured adaptive mesh refinement (AMR), commonly implemented via quadtrees and octrees, underpins a wide range of applications including databases, computer graphics, physics simulations, and machine learning. However, octrees enforce isotropic refinement in regions of interest, which can be especially inefficient for problems that are intrinsically anisotropic--much resolution is spent where little information is gained. This paper presents omnitrees as an anisotropic generalization of octrees and related data structures. Omnitrees allow to refine only the locally most important dimensions, providing tree structures that are less deep than bintrees and less wide than octrees. As a result, the convergence of the AMR schemes can be increased by up to a factor of the dimensionality d for very anisotropic problems, quickly offsetting their modest increase in storage overhead. We validate this finding on the problem of binary shape representation across 4,166 three-dimensional objects: Omnitrees increase the mean convergence rate by 1.5x, require less storage to achieve equivalent error bounds, and maximize the information density of the stored function faster than octrees. These advantages are projected to be even stronger for higher-dimensional problems. We provide a first validation by introducing a time-dependent rotation to create four-dimensional representations, and discuss the properties of their 4-d octree and omnitree approximations. Overall, omnitree discretizations can make existing AMR approaches more efficient, and open up new possibilities for high-dimensional applications.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"The Beauty of Anisotropic Mesh Refinement: Omnitrees for Efficient Dyadic Discretizations\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "beauty",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding",
    "title_es": "Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding",
    "url": "https://arxiv.org/abs/2508.06317",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06317v1 Announce Type: new \nAbstract: Video Temporal Grounding (TG) aims to temporally locate video segments matching a natural language description (a query) in a long video. While Vision-Language Models (VLMs) are effective at holistic semantic matching, they often struggle with fine-grained temporal localisation. Recently, Group Relative Policy Optimisation (GRPO) reformulates the inference process as a reinforcement learning task, enabling fine-grained grounding and achieving strong in-domain performance. However, GRPO relies on labelled data, making it unsuitable in unlabelled domains. Moreover, because videos are large and expensive to store and process, performing full-scale adaptation introduces prohibitive latency and computational overhead, making it impractical for real-time deployment. To overcome both problems, we introduce a Data-Efficient Unlabelled Cross-domain Temporal Grounding method, from which a model is first trained on a labelled source domain, then adapted to a target domain using only a small number of unlabelled videos from the target domain. This approach eliminates the need for target annotation and keeps both computational and storage overhead low enough to run in real time. Specifically, we introduce. Uncertainty-quantified Rollout Policy Adaptation (URPA) for cross-domain knowledge transfer in learning video temporal grounding without target labels. URPA generates multiple candidate predictions using GRPO rollouts, averages them to form a pseudo label, and estimates confidence from the variance across these rollouts. This confidence then weights the training rewards, guiding the model to focus on reliable supervision. Experiments on three datasets across six cross-domain settings show that URPA generalises well using only a few unlabelled target videos. Codes will be released once published.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "uncertaintyquantified",
      "rollout",
      "policy"
    ],
    "category": "noticia"
  },
  {
    "title": "Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection",
    "title_es": "Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection",
    "url": "https://arxiv.org/abs/2508.06318",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06318v1 Announce Type: new \nAbstract: Video Anomaly Detection (VAD) is a challenging task due to the variability of anomalous events and the limited availability of labeled data. Under the Weakly-Supervised VAD (WSVAD) paradigm, only video-level labels are provided during training, while predictions are made at the frame level. Although state-of-the-art models perform well on simple anomalies (e.g., explosions), they struggle with complex real-world events (e.g., shoplifting). This difficulty stems from two key issues: (1) the inability of current models to address the diversity of anomaly types, as they process all categories with a shared model, overlooking category-specific features; and (2) the weak supervision signal, which lacks precise temporal information, limiting the ability to capture nuanced anomalous patterns blended with normal events. To address these challenges, we propose Gaussian Splatting-guided Mixture of Experts (GS-MoE), a novel framework that employs a set of expert models, each specialized in capturing specific anomaly types. These experts are guided by a temporal Gaussian splatting loss, enabling the model to leverage temporal consistency and enhance weak supervision. The Gaussian splatting approach encourages a more precise and comprehensive representation of anomalies by focusing on temporal segments most likely to contain abnormal events. The predictions from these specialized experts are integrated through a mixture-of-experts mechanism to model complex relationships across diverse anomaly patterns. Our approach achieves state-of-the-art performance, with a 91.58% AUC on the UCF-Crime dataset, and demonstrates superior results on XD-Violence and MSAD datasets. By leveraging category-specific expertise and temporal guidance, GS-MoE sets a new benchmark for VAD under weak supervision.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mixture",
      "of",
      "experts"
    ],
    "category": "noticia"
  },
  {
    "title": "Towards Balanced Behavior Cloning from Imbalanced Datasets",
    "title_es": "Towards Balanced Behavior Cloning from Imbalanced Datasets",
    "url": "https://arxiv.org/abs/2508.06319",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06319v1 Announce Type: new \nAbstract: Robots should be able to learn complex behaviors from human demonstrations. In practice, these human-provided datasets are inevitably imbalanced: i.e., the human demonstrates some subtasks more frequently than others. State-of-the-art methods default to treating each element of the human's dataset as equally important. So if -- for instance -- the majority of the human's data focuses on reaching a goal, and only a few state-action pairs move to avoid an obstacle, the learning algorithm will place greater emphasis on goal reaching. More generally, misalignment between the relative amounts of data and the importance of that data causes fundamental problems for imitation learning approaches. In this paper we analyze and develop learning methods that automatically account for mixed datasets. We formally prove that imbalanced data leads to imbalanced policies when each state-action pair is weighted equally; these policies emulate the most represented behaviors, and not the human's complex, multi-task demonstrations. We next explore algorithms that rebalance offline datasets (i.e., reweight the importance of different state-action pairs) without human oversight. Reweighting the dataset can enhance the overall policy performance. However, there is no free lunch: each method for autonomously rebalancing brings its own pros and cons. We formulate these advantages and disadvantages, helping other researchers identify when each type of approach is most appropriate. We conclude by introducing a novel meta-gradient rebalancing algorithm that addresses the primary limitations behind existing approaches. Our experiments show that dataset rebalancing leads to better downstream learning, improving the performance of general imitation learning algorithms without requiring additional data collection. See our project website: https://collab.me.vt.edu/data_curation/.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Towards Balanced Behavior Cloning from Imbalanced Datasets\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "towards",
      "balanced",
      "behavior"
    ],
    "category": "noticia"
  },
  {
    "title": "Social Welfare in Battery Charging Games",
    "title_es": "Social Welfare in Battery Charging Games",
    "url": "https://arxiv.org/abs/2508.06320",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06320v1 Announce Type: new \nAbstract: The recent rise of renewable energy produced by many decentralized sources yields interesting market design challenges for electrical grids. Balancing supply and demand in such networks is both a temporal and spatial challenge due to capacity constraints. The recent surge in the number of household-owned batteries, especially in regions with rooftop solar adoption, offers mitigation potential but often acts misaligned with grid-level objectives. In fact, the decision to charge or discharge a household-owned battery is a strategic choice by each battery owner governed by selfish incentives. This calls for an analysis from a game-theoretic point of view.\n  We initiate this timely research direction by considering a game-theoretic setting where selfish agents strategically charge or discharge their batteries to increase their profit. In particular, we study a Stackelberg-like market model where a third party introduces price incentives, aiming to optimize renewable energy utilization while preserving grid feasibility. For this, we study the existence and the quality of equilibria under various pricing strategies. We find that the existence of equilibria crucially depends on the chosen pricing and that the obtained social welfare varies widely. This calls for more sophisticated market models and pricing mechanisms and opens up a rich field for future research in Algorithmic Game Theory on incentives in renewable energy networks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Social Welfare in Battery Charging Games\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "social",
      "welfare",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "EmoAugNet: A Signal-Augmented Hybrid CNN-LSTM Framework for Speech Emotion Recognition",
    "title_es": "EmoAugNet: A Signal-Augmented Hybrid CNN-LSTM Framework for Speech Emotion Recognition",
    "url": "https://arxiv.org/abs/2508.06321",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06321v1 Announce Type: new \nAbstract: Recognizing emotional signals in speech has a significant impact on enhancing the effectiveness of human-computer interaction (HCI). This study introduces EmoAugNet, a hybrid deep learning framework, that incorporates Long Short-Term Memory (LSTM) layers with one-dimensional Convolutional Neural Networks (1D-CNN) to enable reliable Speech Emotion Recognition (SER). The quality and variety of the features that are taken from speech signals have a significant impact on how well SER systems perform. A comprehensive speech data augmentation strategy was used to combine both traditional methods, such as noise addition, pitch shifting, and time stretching, with a novel combination-based augmentation pipeline to enhance generalization and reduce overfitting. Each audio sample was transformed into a high-dimensional feature vector using root mean square energy (RMSE), Mel-frequency Cepstral Coefficient (MFCC), and zero-crossing rate (ZCR). Our model with ReLU activation has a weighted accuracy of 95.78\\% and unweighted accuracy of 92.52\\% on the IEMOCAP dataset and, with ELU activation, has a weighted accuracy of 96.75\\% and unweighted accuracy of 91.28\\%. On the RAVDESS dataset, we get a weighted accuracy of 94.53\\% and 94.98\\% unweighted accuracy for ReLU activation and 93.72\\% weighted accuracy and 94.64\\% unweighted accuracy for ELU activation. These results highlight EmoAugNet's effectiveness in improving the robustness and performance of SER systems through integated data augmentation and hybrid modeling.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"EmoAugNet: A Signal-Augmented Hybrid CNN-LSTM Framework for Speech Emotion Recognition\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "emoaugnet",
      "a",
      "signalaugmented"
    ],
    "category": "noticia"
  },
  {
    "title": "Anti-Tamper Protection for Unauthorized Individual Image Generation",
    "title_es": "Anti-Tamper Protection for Unauthorized Individual Image Generation",
    "url": "https://arxiv.org/abs/2508.06325",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06325v1 Announce Type: new \nAbstract: With the advancement of personalized image generation technologies, concerns about forgery attacks that infringe on portrait rights and privacy are growing. To address these concerns, protection perturbation algorithms have been developed to disrupt forgery generation. However, the protection algorithms would become ineffective when forgery attackers apply purification techniques to bypass the protection. To address this issue, we present a novel approach, Anti-Tamper Perturbation (ATP). ATP introduces a tamper-proof mechanism within the perturbation. It consists of protection and authorization perturbations, where the protection perturbation defends against forgery attacks, while the authorization perturbation detects purification-based tampering. Both protection and authorization perturbations are applied in the frequency domain under the guidance of a mask, ensuring that the protection perturbation does not disrupt the authorization perturbation. This design also enables the authorization perturbation to be distributed across all image pixels, preserving its sensitivity to purification-based tampering. ATP demonstrates its effectiveness in defending forgery attacks across various attack settings through extensive experiments, providing a robust solution for protecting individuals' portrait rights and privacy. Our code is available at: https://github.com/Seeyn/Anti-Tamper-Perturbation .",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Anti-Tamper Protection for Unauthorized Individual Image Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "antitamper",
      "protection",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "A \"good regulator theorem\" for embodied agents",
    "title_es": "A \"good regulator theorem\" for embodied agents",
    "url": "https://arxiv.org/abs/2508.06326",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06326v1 Announce Type: new \nAbstract: In a classic paper, Conant and Ashby claimed that \"every good regulator of a system must be a model of that system.\" Artificial Life has produced many examples of systems that perform tasks with apparently no model in sight; these suggest Conant and Ashby's theorem doesn't easily generalise beyond its restricted setup. Nevertheless, here we show that a similar intuition can be fleshed out in a different way: whenever an agent is able to perform a regulation task, it is possible for an observer to interpret it as having \"beliefs\" about its environment, which it \"updates\" in response to sensory input. This notion of belief updating provides a notion of model that is more sophisticated than Conant and Ashby's, as well as a theorem that is more broadly applicable. However, it necessitates a change in perspective, in that the observer plays an essential role in the theory: models are not a mere property of the system but are imposed on it from outside. Our theorem holds regardless of whether the system is regulating its environment in a classic control theory setup, or whether it's regulating its own internal state; the model is of its environment either way. The model might be trivial, however, and this is how the apparent counterexamples are resolved.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A \"good regulator theorem\" for embodied agents\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "good",
      "regulator"
    ],
    "category": "noticia"
  },
  {
    "title": "Can Diffusion Models Bridge the Domain Gap in Cardiac MR Imaging?",
    "title_es": "Can Diffusion Models Bridge the Domain Gap in Cardiac MR Imaging?",
    "url": "https://arxiv.org/abs/2508.06327",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06327v1 Announce Type: new \nAbstract: Magnetic resonance (MR) imaging, including cardiac MR, is prone to domain shift due to variations in imaging devices and acquisition protocols. This challenge limits the deployment of trained AI models in real-world scenarios, where performance degrades on unseen domains. Traditional solutions involve increasing the size of the dataset through ad-hoc image augmentation or additional online training/transfer learning, which have several limitations. Synthetic data offers a promising alternative, but anatomical/structural consistency constraints limit the effectiveness of generative models in creating image-label pairs. To address this, we propose a diffusion model (DM) trained on a source domain that generates synthetic cardiac MR images that resemble a given reference. The synthetic data maintains spatial and structural fidelity, ensuring similarity to the source domain and compatibility with the segmentation mask. We assess the utility of our generative approach in multi-centre cardiac MR segmentation, using the 2D nnU-Net, 3D nnU-Net and vanilla U-Net segmentation networks. We explore domain generalisation, where, domain-invariant segmentation models are trained on synthetic source domain data, and domain adaptation, where, we shift target domain data towards the source domain using the DM. Both strategies significantly improved segmentation performance on data from an unseen target domain, in terms of surface-based metrics (Welch's t-test, p < 0.01), compared to training segmentation models on real data alone. The proposed method ameliorates the need for transfer learning or online training to address domain shift challenges in cardiac MR image analysis, especially useful in data-scarce settings.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Can Diffusion Models Bridge the Domain Gap in Cardiac MR Imaging?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "can",
      "diffusion",
      "models"
    ],
    "category": "noticia"
  },
  {
    "title": "M2IO-R1: An Efficient RL-Enhanced Reasoning Framework for Multimodal Retrieval Augmented Multimodal Generation",
    "title_es": "M2IO-R1: An Efficient RL-Enhanced Reasoning Framework for Multimodal Retrieval Augmented Multimodal Generation",
    "url": "https://arxiv.org/abs/2508.06328",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06328v1 Announce Type: new \nAbstract: Current research on Multimodal Retrieval-Augmented Generation (MRAG) enables diverse multimodal inputs but remains limited to single-modality outputs, restricting expressive capacity and practical utility. In contrast, real-world applications often demand both multimodal inputs and multimodal outputs for effective communication and grounded reasoning. Motivated by the recent success of Reinforcement Learning (RL) in complex reasoning tasks for Large Language Models (LLMs), we adopt RL as a principled and effective paradigm to address the multi-step, outcome-driven challenges inherent in multimodal output generation. Here, we introduce M2IO-R1, a novel framework for Multimodal Retrieval-Augmented Multimodal Generation (MRAMG) that supports both multimodal inputs and outputs. Central to our framework is an RL-based inserter, Inserter-R1-3B, trained with Group Relative Policy Optimization to guide image selection and placement in a controllable and semantically aligned manner. Empirical results show that our lightweight 3B inserter achieves strong reasoning capabilities with significantly reduced latency, outperforming baselines in both quality and efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"M2IO-R1: An Efficient RL-Enhanced Reasoning Framework for Multimodal Retrieval Augmented Multimodal Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mior",
      "an",
      "efficient"
    ],
    "category": "noticia"
  },
  {
    "title": "L2Calib: $SE(3)$-Manifold Reinforcement Learning for Robust Extrinsic Calibration with Degenerate Motion Resilience",
    "title_es": "L2Calib: $SE(3)$-Manifold Reinforcement Learning for Robust Extrinsic Calibration with Degenerate Motion Resilience",
    "url": "https://arxiv.org/abs/2508.06330",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06330v1 Announce Type: new \nAbstract: Extrinsic calibration is essential for multi-sensor fusion, existing methods rely on structured targets or fully-excited data, limiting real-world applicability. Online calibration further suffers from weak excitation, leading to unreliable estimates. To address these limitations, we propose a reinforcement learning (RL)-based extrinsic calibration framework that formulates extrinsic calibration as a decision-making problem, directly optimizes $SE(3)$ extrinsics to enhance odometry accuracy. Our approach leverages a probabilistic Bingham distribution to model 3D rotations, ensuring stable optimization while inherently retaining quaternion symmetry. A trajectory alignment reward mechanism enables robust calibration without structured targets by quantitatively evaluating estimated tightly-coupled trajectory against a reference trajectory. Additionally, an automated data selection module filters uninformative samples, significantly improving efficiency and scalability for large-scale datasets. Extensive experiments on UAVs, UGVs, and handheld platforms demonstrate that our method outperforms traditional optimization-based approaches, achieving high-precision calibration even under weak excitation conditions. Our framework simplifies deployment on diverse robotic platforms by eliminating the need for high-quality initial extrinsics and enabling calibration from routine operating data. The code is available at https://github.com/APRIL-ZJU/learn-to-calibrate.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"L2Calib: $SE(3)$-Manifold Reinforcement Learning for Robust Extrinsic Calibration with Degenerate Motion Resilience\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lcalib",
      "semanifold",
      "reinforcement"
    ],
    "category": "noticia"
  },
  {
    "title": "ViPro-2: Unsupervised State Estimation via Integrated Dynamics for Guiding Video Prediction",
    "title_es": "ViPro-2: Unsupervised State Estimation via Integrated Dynamics for Guiding Video Prediction",
    "url": "https://arxiv.org/abs/2508.06335",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06335v1 Announce Type: new \nAbstract: Predicting future video frames is a challenging task with many downstream applications. Previous work has shown that procedural knowledge enables deep models for complex dynamical settings, however their model ViPro assumed a given ground truth initial symbolic state. We show that this approach led to the model learning a shortcut that does not actually connect the observed environment with the predicted symbolic state, resulting in the inability to estimate states given an observation if previous states are noisy. In this work, we add several improvements to ViPro that enables the model to correctly infer states from observations without providing a full ground truth state in the beginning. We show that this is possible in an unsupervised manner, and extend the original Orbits dataset with a 3D variant to close the gap to real world scenarios.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ViPro-2: Unsupervised State Estimation via Integrated Dynamics for Guiding Video Prediction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "vipro",
      "unsupervised",
      "state"
    ],
    "category": "noticia"
  },
  {
    "title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork",
    "title_es": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork",
    "url": "https://arxiv.org/abs/2508.06336",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06336v1 Announce Type: new \nAbstract: We introduce Unsupervised Partner Design (UPD) - a population-free, multi-agent reinforcement learning framework for robust ad-hoc teamwork that adaptively generates training partners without requiring pretrained partners or manual parameter tuning. UPD constructs diverse partners by stochastically mixing an ego agent's policy with biased random behaviours and scores them using a variance-based learnability metric that prioritises partners near the ego agent's current learning frontier. We show that UPD can be integrated with unsupervised environment design, resulting in the first method enabling fully unsupervised curricula over both level and partner distributions in a cooperative setting. Through extensive evaluations on Overcooked-AI and the Overcooked Generalisation Challenge, we demonstrate that this dynamic partner curriculum is highly effective: UPD consistently outperforms both population-based and population-free baselines as well as ablations. In a user study, we further show that UPD achieves higher returns than all baselines and was perceived as significantly more adaptive, more human-like, a better collaborator, and less frustrating.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Unsupervised Partner Design Enables Robust Ad-hoc Teamwork\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "unsupervised",
      "partner",
      "design"
    ],
    "category": "noticia"
  },
  {
    "title": "Performant Unified GPU Kernels for Portable Singular Value Computation Across Hardware and Precision",
    "title_es": "Performant Unified GPU Kernels for Portable Singular Value Computation Across Hardware and Precision",
    "url": "https://arxiv.org/abs/2508.06339",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06339v1 Announce Type: new \nAbstract: This paper presents a portable, GPU-accelerated implementation of a QR-based singular value computation algorithm in Julia. The singular value ecomposition (SVD) is a fundamental numerical tool in scientific computing and machine learning, providing optimal low-rank matrix approximations. Its importance has increased even more in large-scale machine learning pipelines, including large language models (LLMs), where it enables low-rank adaptation (LoRA). The implemented algorithm is based on the classic two-stage QR reduction, consisting of successive matrix reduction to band form and bidiagonal form. Our implementation leverages Julia's multiple dispatch and metaprogramming capabilities, integrating with the GPUArrays and KernelAbstractions frameworks to provide a unified type and hardware-agnostic function. It supports diverse GPU architectures and data types, and is, to our knowledge, the first GPU-accelerated singular value implementation to support Apple Metal GPUs and half precision. Performance results on multiple GPU backends and data types demonstrate that portability does not require sacrificing performance: the unified function outperforms most linear algebra libraries (MAGMA, SLATE, rocSOLVER, oneMKL) for matrix sizes larger than 1024x1024, and achieves 80%-90% of the performance of cuSOLVER for large matrices.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Performant Unified GPU Kernels for Portable Singular Value Computation Across Hardware and Precision\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "performant",
      "unified",
      "gpu"
    ],
    "category": "noticia"
  },
  {
    "title": "Street View Sociability: Interpretable Analysis of Urban Social Behavior Across 15 Cities",
    "title_es": "Street View Sociability: Interpretable Analysis of Urban Social Behavior Across 15 Cities",
    "url": "https://arxiv.org/abs/2508.06342",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06342v1 Announce Type: new \nAbstract: Designing socially active streets has long been a goal of urban planning, yet existing quantitative research largely measures pedestrian volume rather than the quality of social interactions. We hypothesize that street view imagery -- an inexpensive data source with global coverage -- contains latent social information that can be extracted and interpreted through established social science theory. As a proof of concept, we analyzed 2,998 street view images from 15 cities using a multimodal large language model guided by Mehta's taxonomy of passive, fleeting, and enduring sociability -- one illustrative example of a theory grounded in urban design that could be substituted or complemented by other sociological frameworks. We then used linear regression models, controlling for factors like weather, time of day, and pedestrian counts, to test whether the inferred sociability measures correlate with city-level place attachment scores from the World Values Survey and with environmental predictors (e.g., green, sky, and water view indices) derived from individual street view images. Results aligned with long-standing urban planning theory: the sky view index was associated with all three sociability types, the green view index predicted enduring sociability, and place attachment was positively associated with fleeting sociability. These results provide preliminary evidence that street view images can be used to infer relationships between specific types of social interactions and built environment variables. Further research could establish street view imagery as a scalable, privacy-preserving tool for studying urban sociability, enabling cross-cultural theory testing and evidence-based design of socially vibrant cities.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Street View Sociability: Interpretable Analysis of Urban Social Behavior Across 15 Cities\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "street",
      "view",
      "sociability"
    ],
    "category": "noticia"
  },
  {
    "title": "On Approximate MMS Allocations on Restricted Graph Classes",
    "title_es": "On Approximate MMS Allocations on Restricted Graph Classes",
    "url": "https://arxiv.org/abs/2508.06343",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06343v1 Announce Type: new \nAbstract: We study the problem of fair division of a set of indivisible goods with connectivity constraints. Specifically, we assume that the goods are represented as vertices of a connected graph, and sets of goods allocated to the agents are connected subgraphs of this graph. We focus on the widely-studied maximin share criterion of fairness. It has been shown that an allocation satisfying this criterion may not exist even without connectivity constraints, i.e., if the graph of goods is complete. In view of this, it is natural to seek approximate allocations that guarantee each agent a connected bundle of goods with value at least a constant fraction of the maximin share value to the agent. It is known that for some classes of graphs, such as complete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such approximate allocations indeed exist. However, it is an open problem whether they exist for the class of all graphs.\n  In this paper, we continue the systematic study of the existence of approximate allocations on restricted graph classes. In particular, we show that such allocations exist for several well-studied classes, including block graphs, cacti, complete multipartite graphs, and split graphs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"On Approximate MMS Allocations on Restricted Graph Classes\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "on",
      "approximate",
      "mms"
    ],
    "category": "noticia"
  },
  {
    "title": "Nail: Not Another Fault-Injection Framework for Chisel-generated RTL",
    "title_es": "Nail: Not Another Fault-Injection Framework for Chisel-generated RTL",
    "url": "https://arxiv.org/abs/2508.06344",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06344v1 Announce Type: new \nAbstract: Fault simulation and emulation are essential techniques for evaluating the dependability of integrated circuits, enabling early-stage vulnerability analysis and supporting the implementation of effective mitigation strategies. High-level hardware description languages such as Chisel facilitate the rapid development of complex fault scenarios with minimal modification to the design. However, existing Chisel-based fault injection (FI) frameworks are limited by coarse-grained, instruction-level controllability, restricting the precision of fault modeling. This work introduces Nail, a Chisel-based open-source FI framework that overcomes these limitations by introducing state-based faults. This approach enables fault scenarios that depend on specific system states, rather than solely on instruction-level triggers, thereby removing the need for precise timing of fault activation. For greater controllability, Nail allows users to arbitrarily modify internal trigger states via software at runtime. To support this, Nail automatically generates a software interface, offering straightforward access to the instrumented design. This enables fine-tuning of fault parameters during active FI campaigns - a feature particularly beneficial for FPGA emulation, where synthesis is time-consuming. Utilizing these features, Nail narrows the gap between the high speed of emulation-based FI frameworks, the usability of software-based approaches, and the controllability achieved in simulation. We demonstrate Nail's state-based FI and software framework by modeling a faulty general-purpose register in a RISC-V processor. Although this might appear straightforward, it requires state-dependent FI and was previously impossible without fundamental changes to the design. The approach was validated in both simulation and FPGA emulation, where the addition of Nail introduced less than 1% resource overhead.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Nail: Not Another Fault-Injection Framework for Chisel-generated RTL\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nail",
      "not",
      "another"
    ],
    "category": "noticia"
  },
  {
    "title": "Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering",
    "title_es": "Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering",
    "url": "https://arxiv.org/abs/2508.06345",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06345v1 Announce Type: new \nAbstract: Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities in diverse domain question-answering (QA) tasks, including graph QA that involves complex graph topologies. However, most current approaches use only a single type of graph representation, namely Topology Representation Form (TRF), such as prompt-unified text descriptions or style-fixed visual styles. Those \"one-size-fits-all\" approaches fail to consider the specific preferences of different models or tasks, often leading to incorrect or overly long responses. To address this, we first analyze the characteristics and weaknesses of existing TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to zero-shot graph QA. We then introduce a new metric, Graph Response Efficiency (GRE), which measures the balance between the performance and the brevity in graph QA. Built on these, we develop the DynamicTRF framework, which aims to improve both the accuracy and conciseness of graph QA. To be specific, DynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based on their GRE scores, to probe the question-specific TRF preferences. Then it trains a TRF router on the TRFP dataset, to adaptively assign the best TRF from $F_{ZS}$ for each question during the inference. Extensive experiments across 7 in-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show that DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms of accuracy",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "harnessing",
      "adaptive",
      "topology"
    ],
    "category": "noticia"
  },
  {
    "title": "Introducing Fractional Classification Loss for Robust Learning with Noisy Labels",
    "title_es": "Introducing Fractional Classification Loss for Robust Learning with Noisy Labels",
    "url": "https://arxiv.org/abs/2508.06346",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06346v1 Announce Type: new \nAbstract: Robust loss functions are crucial for training deep neural networks in the presence of label noise, yet existing approaches require extensive, dataset-specific hyperparameter tuning. In this work, we introduce Fractional Classification Loss (FCL), an adaptive robust loss that automatically calibrates its robustness to label noise during training. Built within the active-passive loss framework, FCL employs the fractional derivative of the Cross-Entropy (CE) loss as its active component and the Mean Absolute Error (MAE) as its passive loss component. With this formulation, we demonstrate that the fractional derivative order $\\mu$ spans a family of loss functions that interpolate between MAE-like robustness and CE-like fast convergence. Furthermore, we integrate $\\mu$ into the gradient-based optimization as a learnable parameter and automatically adjust it to optimize the trade-off between robustness and convergence speed. We reveal that FCL's unique property establishes a critical trade-off that enables the stable learning of $\\mu$: lower log penalties on difficult or mislabeled examples improve robustness but impose higher penalties on easy or clean data, reducing model confidence in them. Consequently, FCL can dynamically reshape its loss landscape to achieve effective classification performance under label noise. Extensive experiments on benchmark datasets show that FCL achieves state-of-the-art results without the need for manual hyperparameter tuning.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Introducing Fractional Classification Loss for Robust Learning with Noisy Labels\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "introducing",
      "fractional",
      "classification"
    ],
    "category": "noticia"
  },
  {
    "title": "Structural Equation-VAE: Disentangled Latent Representations for Tabular Data",
    "title_es": "Structural Equation-VAE: Disentangled Latent Representations for Tabular Data",
    "url": "https://arxiv.org/abs/2508.06347",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06347v1 Announce Type: new \nAbstract: Learning interpretable latent representations from tabular data remains a challenge in deep generative modeling. We introduce SE-VAE (Structural Equation-Variational Autoencoder), a novel architecture that embeds measurement structure directly into the design of a variational autoencoder. Inspired by structural equation modeling, SE-VAE aligns latent subspaces with known indicator groupings and introduces a global nuisance latent to isolate construct-specific confounding variation. This modular architecture enables disentanglement through design rather than through statistical regularizers alone. We evaluate SE-VAE on a suite of simulated tabular datasets and benchmark its performance against a series of leading baselines using standard disentanglement metrics. SE-VAE consistently outperforms alternatives in factor recovery, interpretability, and robustness to nuisance variation. Ablation results reveal that architectural structure, rather than regularization strength, is the key driver of performance. SE-VAE offers a principled framework for white-box generative modeling in scientific and social domains where latent constructs are theory-driven and measurement validity is essential.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Structural Equation-VAE: Disentangled Latent Representations for Tabular Data\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "structural",
      "equationvae",
      "disentangled"
    ],
    "category": "noticia"
  },
  {
    "title": "AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games",
    "title_es": "AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games",
    "url": "https://arxiv.org/abs/2508.06348",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06348v1 Announce Type: new \nAbstract: Cheating in online video games compromises the integrity of gaming experiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face significant challenges in keeping pace with evolving cheating methods without imposing invasive measures on users' systems. This paper presents AntiCheatPT\\_256, a transformer-based machine learning model designed to detect cheating behaviour in Counter-Strike 2 using gameplay data. To support this, we introduce and publicly release CS2CD: A labelled dataset of 795 matches. Using this dataset, 90,707 context windows were created and subsequently augmented to address class imbalance. The transformer model, trained on these windows, achieved an accuracy of 89.17\\% and an AUC of 93.36\\% on an unaugmented test set. This approach emphasizes reproducibility and real-world applicability, offering a robust baseline for future research in data-driven cheat detection.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "anticheatpt",
      "a",
      "transformerbased"
    ],
    "category": "noticia"
  },
  {
    "title": "Emoji Reactions on Telegram Often Reflect Social Approval Over Emotional Resonance",
    "title_es": "Emoji Reactions on Telegram Often Reflect Social Approval Over Emotional Resonance",
    "url": "https://arxiv.org/abs/2508.06349",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06349v1 Announce Type: new \nAbstract: Emoji reactions are a frequently used feature of messaging platforms. Prior work mainly interpreted emojis as indicators of emotional resonance or user sentiment. However, emoji reactions may instead reflect broader social dynamics. Here, we investigate the communicative function of emoji reactions on Telegram by analyzing the relationship between the emotional and rhetorical content of messages and the emoji reactions they receive. We collect and analyze over 650k Telegram messages that received at least one emoji reaction. We annotate each message with sentiment, emotion, persuasion strategy, and speech act labels, and infer the sentiment and emotion of emoji reactions using both lexicons and large languages. We find a systematic mismatch between message sentiment and reaction sentiment, with positive reactions dominating even when the message is neutral or negative. We show that this pattern remains consistent across rhetorical strategies and emotional tones, suggesting that emoji reactions may signal a degree of social approval rather than reflecting emotional resonance. Finally, we shed light on the communicative strategies that predict greater emoji engagement. These findings have methodological implications for sentiment analysis, as interpreting emoji reactions as direct proxies for emotional response may be misleading.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Emoji Reactions on Telegram Often Reflect Social Approval Over Emotional Resonance\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "emoji",
      "reactions",
      "on"
    ],
    "category": "noticia"
  },
  {
    "title": "Aligning Effective Tokens with Video Anomaly in Large Language Models",
    "title_es": "Aligning Effective Tokens with Video Anomaly in Large Language Models",
    "url": "https://arxiv.org/abs/2508.06350",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06350v1 Announce Type: new \nAbstract: Understanding abnormal events in videos is a vital and challenging task that has garnered significant attention in a wide range of applications. Although current video understanding Multi-modal Large Language Models (MLLMs) are capable of analyzing general videos, they often struggle to handle anomalies due to the spatial and temporal sparsity of abnormal events, where the redundant information always leads to suboptimal outcomes. To address these challenges, exploiting the representation and generalization capabilities of Vison Language Models (VLMs) and Large Language Models (LLMs), we propose VA-GPT, a novel MLLM designed for summarizing and localizing abnormal events in various videos. Our approach efficiently aligns effective tokens between visual encoders and LLMs through two key proposed modules: Spatial Effective Token Selection (SETS) and Temporal Effective Token Generation (TETG). These modules enable our model to effectively capture and analyze both spatial and temporal information associated with abnormal events, resulting in more accurate responses and interactions. Furthermore, we construct an instruction-following dataset specifically for fine-tuning video-anomaly-aware MLLMs, and introduce a cross-domain evaluation benchmark based on XD-Violence dataset. Our proposed method outperforms existing state-of-the-art methods on various benchmarks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Aligning Effective Tokens with Video Anomaly in Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "aligning",
      "effective",
      "tokens"
    ],
    "category": "noticia"
  },
  {
    "title": "An Implemention of Two-Phase Image Segmentation using the Split Bregman Method",
    "title_es": "An Implemention of Two-Phase Image Segmentation using the Split Bregman Method",
    "url": "https://arxiv.org/abs/2508.06351",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06351v1 Announce Type: new \nAbstract: In this paper, we describe an implementation of the two-phase image segmentation algorithm proposed by Goldstein, Bresson, Osher in \\cite{gold:bre}. This algorithm partitions the domain of a given 2d image into foreground and background regions, and each pixel of the image is assigned membership to one of these two regions. The underlying assumption for the segmentation model is that the pixel values of the input image can be summarized by two distinct average values, and that the region boundaries are smooth. Accordingly, the model is defined as an energy in which the variable is a region membership function to assign pixels to either region, originally proposed by Chan and Vese in \\cite{chan:vese}. This energy is the sum of image data terms in the regions and a length penalty for region boundaries. Goldstein, Bresson, Osher modify the energy of Chan-Vese in \\cite{gold:bre} so that their new energy can be minimized efficiently using the split Bregman method to produce an equivalent two-phase segmentation. We provide a detailed implementation of this method \\cite{gold:bre}, and document its performance with several images over a range of algorithm parameters.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"An Implemention of Two-Phase Image Segmentation using the Split Bregman Method\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "an",
      "implemention",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI",
    "title_es": "From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI",
    "url": "https://arxiv.org/abs/2508.06352",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06352v1 Announce Type: new \nAbstract: Current explainable AI (XAI) approaches prioritize algorithmic transparency and present explanations in abstract, non-adaptive formats that often fail to support meaningful end-user understanding. This paper introduces \"Explanatory AI\" as a complementary paradigm that leverages generative AI capabilities to serve as explanatory partners for human understanding rather than providers of algorithmic transparency. While XAI reveals algorithmic decision processes for model validation, Explanatory AI addresses contextual reasoning to support human decision-making in sociotechnical contexts. We develop a definition and systematic eight-dimensional conceptual model distinguishing Explanatory AI through narrative communication, adaptive personalization, and progressive disclosure principles. Empirical validation through Rapid Contextual Design methodology with healthcare professionals demonstrates that users consistently prefer context-sensitive, multimodal explanations over technical transparency. Our findings reveal the practical urgency for AI systems designed for human comprehension rather than algorithmic introspection, establishing a comprehensive research agenda for advancing user-centered AI explanation approaches across diverse domains and cultural contexts.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "from",
      "explainable",
      "to"
    ],
    "category": "noticia"
  },
  {
    "title": "Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means",
    "title_es": "Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means",
    "url": "https://arxiv.org/abs/2508.06353",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06353v1 Announce Type: new \nAbstract: This paper introduces Geometric-k-means (or Gk-means for short), a novel approach that significantly enhances the efficiency and energy economy of the widely utilized k-means algorithm, which, despite its inception over five decades ago, remains a cornerstone in machine learning applications. The essence of Gk-means lies in its active utilization of geometric principles, specifically scalar projection, to significantly accelerate the algorithm without sacrificing solution quality. This geometric strategy enables a more discerning focus on data points that are most likely to influence cluster updates, which we call as high expressive data (HE). In contrast, low expressive data (LE), does not impact clustering outcome, is effectively bypassed, leading to considerable reductions in computational overhead. Experiments spanning synthetic, real-world and high-dimensional datasets, demonstrate Gk-means is significantly better than traditional and state of the art (SOTA) k-means variants in runtime and distance computations (DC). Moreover, Gk-means exhibits better resource efficiency, as evidenced by its reduced energy footprint, placing it as more sustainable alternative.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "geometrickmeans",
      "a",
      "bound"
    ],
    "category": "noticia"
  },
  {
    "title": "Zombitron: towards a toolbox for repurposing obsolete smartphones into new interactive systems",
    "title_es": "Zombitron: towards a toolbox for repurposing obsolete smartphones into new interactive systems",
    "url": "https://arxiv.org/abs/2508.06354",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06354v1 Announce Type: new \nAbstract: This article explores the possibilities of reusing obsolete smartphones and tablets to build new interactive systems. Taking the case of a musical instrument, I present my research into the design of a controller made from various of these obsolete smartphones. From the diagnostic stage to the creation of a new autonomous electronic object, I document the process, the barriers and the levers encountered. Based on these explorations and discussions with two professional musicians, I provide several insights into the software and hardware aspects, with a view to continuing this work, towards the creation of an open-source toolkit enabling anyone to build new interactive systems with old devices. I discuss the implication of how a high-level web-based approach could allow designers to enter the black box and foster permacomputing using smartphones.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Zombitron: towards a toolbox for repurposing obsolete smartphones into new interactive systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "zombitron",
      "towards",
      "a"
    ],
    "category": "noticia"
  },
  {
    "title": "Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd",
    "title_es": "Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd",
    "url": "https://arxiv.org/abs/2508.06357",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06357v1 Announce Type: new \nAbstract: A central problem in one-to-many facial identification is that the person in the probe image may or may not have enrolled image(s) in the gallery; that is, may be In-gallery or Out-of-gallery. Past approaches to detect when a rank-one result is Out-of-gallery have mostly focused on finding a suitable threshold on the similarity score. We take a new approach, using the additional enrolled images of the identity with the rank-one result to predict if the rank-one result is In-gallery / Out-of-gallery. Given a gallery of identities and images, we generate In-gallery and Out-of-gallery training data by extracting the ranks of additional enrolled images corresponding to the rank-one identity. We then train a classifier to utilize this feature vector to predict whether a rank-one result is In-gallery or Out-of-gallery. Using two different datasets and four different matchers, we present experimental results showing that our approach is viable for mugshot quality probe images, and also, importantly, for probes degraded by blur, reduced resolution, atmospheric turbulence and sunglasses. We also analyze results across demographic groups, and show that In-gallery / Out-of-gallery classification accuracy is similar across demographics. Our approach has the potential to provide an objective estimate of whether a one-to-many facial identification is Out-of-gallery, and thereby to reduce false positive identifications, wrongful arrests, and wasted investigative time. Interestingly, comparing the results of older deep CNN-based face matchers with newer ones suggests that the effectiveness of our Out-of-gallery detection approach emerges only with matchers trained using advanced margin-based loss functions.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "are",
      "you",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Cyberbullying Detection via Aggression-Enhanced Prompting",
    "title_es": "Cyberbullying Detection via Aggression-Enhanced Prompting",
    "url": "https://arxiv.org/abs/2508.06360",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06360v1 Announce Type: new \nAbstract: Detecting cyberbullying on social media remains a critical challenge due to its subtle and varied expressions. This study investigates whether integrating aggression detection as an auxiliary task within a unified training framework can enhance the generalisation and performance of large language models (LLMs) in cyberbullying detection. Experiments are conducted on five aggression datasets and one cyberbullying dataset using instruction-tuned LLMs. We evaluated multiple strategies: zero-shot, few-shot, independent LoRA fine-tuning, and multi-task learning (MTL). Given the inconsistent results of MTL, we propose an enriched prompt pipeline approach in which aggression predictions are embedded into cyberbullying detection prompts to provide contextual augmentation. Preliminary results show that the enriched prompt pipeline consistently outperforms standard LoRA fine-tuning, indicating that aggression-informed context significantly boosts cyberbullying detection. This study highlights the potential of auxiliary tasks, such as aggression detection, to improve the generalisation of LLMs for safety-critical applications on social networks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Cyberbullying Detection via Aggression-Enhanced Prompting\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cyberbullying",
      "detection",
      "via"
    ],
    "category": "noticia"
  },
  {
    "title": "Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts",
    "title_es": "Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts",
    "url": "https://arxiv.org/abs/2508.06361",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06361v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have been widely deployed in reasoning, planning, and decision-making tasks, making their trustworthiness a critical concern. The potential for intentional deception, where an LLM deliberately fabricates or conceals information to serve a hidden objective, remains a significant and underexplored threat. Existing studies typically induce such deception by explicitly setting a \"hidden\" objective through prompting or fine-tuning, which may not fully reflect real-world human-LLM interactions. Moving beyond this human-induced deception, we investigate LLMs' self-initiated deception on benign prompts. To address the absence of ground truth in this evaluation, we propose a novel framework using \"contact searching questions.\" This framework introduces two statistical metrics derived from psychological principles to quantify the likelihood of deception. The first, the Deceptive Intention Score, measures the model's bias towards a hidden objective. The second, Deceptive Behavior Score, measures the inconsistency between the LLM's internal belief and its expressed output. Upon evaluating 14 leading LLMs, we find that both metrics escalate as task difficulty increases, rising in parallel for most models. Building on these findings, we formulate a mathematical model to explain this behavior. These results reveal that even the most advanced LLMs exhibit an increasing tendency toward deception when handling complex problems, raising critical concerns for the deployment of LLM agents in complex and crucial domains.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "beyond",
      "promptinduced",
      "lies"
    ],
    "category": "noticia"
  },
  {
    "title": "ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design",
    "title_es": "ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design",
    "url": "https://arxiv.org/abs/2508.06364",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06364v1 Announce Type: new \nAbstract: Achieving precise control over a molecule's biological activity-encompassing targeted activation/inhibition, cooperative multi-target modulation, and off-target toxicity mitigation-remains a critical challenge in de novo drug design. However, existing generative methods primarily focus on producing molecules with a single desired activity, lacking integrated mechanisms for the simultaneous management of multiple intended and unintended molecular interactions. Here, we propose ActivityDiff, a generative approach based on the classifier-guidance technique of diffusion models. It leverages separately trained drug-target classifiers for both positive and negative guidance, enabling the model to enhance desired activities while minimizing harmful off-target effects. Experimental results show that ActivityDiff effectively handles essential drug design tasks, including single-/dual-target generation, fragment-constrained dual-target design, selective generation to enhance target specificity, and reduction of off-target effects. These results demonstrate the effectiveness of classifier-guided diffusion in balancing efficacy and safety in molecular design. Overall, our work introduces a novel paradigm for achieving integrated control over molecular activity, and provides ActivityDiff as a versatile and extensible framework.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "activitydiff",
      "a",
      "diffusion"
    ],
    "category": "noticia"
  },
  {
    "title": "Execution-Feedback Driven Test Generation from SWE Issues",
    "title_es": "Execution-Feedback Driven Test Generation from SWE Issues",
    "url": "https://arxiv.org/abs/2508.06365",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06365v1 Announce Type: new \nAbstract: A software engineering issue (SWE issue) is easier to resolve when accompanied by a reproduction test. Unfortunately, most issues do not come with functioning reproduction tests, so this paper explores how to generate them automatically. The primary challenge in this setting is that the code to be tested is either missing or wrong, as evidenced by the existence of the issue in the first place. This has held back test generation for this setting: without the correct code to execute, it is difficult to leverage execution feedback to generate good tests. This paper introduces novel techniques for leveraging execution feedback to get around this problem, implemented in a new reproduction test generator called e-Otter++. Experiments show that e-Otter++ represents a leap ahead in the state-of-the-art for this problem, generating tests with an average fail-to-pass rate of 63% on the TDD-Bench Verified benchmark.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Execution-Feedback Driven Test Generation from SWE Issues\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "executionfeedback",
      "driven",
      "test"
    ],
    "category": "noticia"
  },
  {
    "title": "Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned",
    "title_es": "Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned",
    "url": "https://arxiv.org/abs/2508.06368",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06368v1 Announce Type: new \nAbstract: Legal decision-making process requires the availability of comprehensive and detailed legislative background knowledge and up-to-date information on legal cases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a valuable tool to facilitate access to legal information, to be queried and exploited for the purpose, and to enable advanced reasoning and machine learning applications. Indeed, legal KGs may act as knowledge intensive component to be used by pre-dictive machine learning solutions supporting the decision process of the legal expert. Nevertheless, a few KGs can be found in the legal domain. To fill this gap, we developed a legal KG targeting legal cases of violence against women, along with clear adopted methodologies. Specifically, the paper introduces two complementary approaches for automated legal KG construction; a systematic bottom-up approach, customized for the legal domain, and a new solution leveraging Large Language Models. Starting from legal sentences publicly available from the European Court of Justice, the solutions integrate structured data extraction, ontology development, and semantic enrichment to produce KGs tailored for legal cases involving violence against women. After analyzing and comparing the results of the two approaches, the developed KGs are validated via suitable competency questions. The obtained KG may be impactful for multiple purposes: can improve the accessibility to legal information both to humans and machine, can enable complex queries and may constitute an important knowledge component to be possibly exploited by machine learning tools tailored for predictive justice.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "automated",
      "creation",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with Multimodal Large Language Models",
    "title_es": "SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with Multimodal Large Language Models",
    "url": "https://arxiv.org/abs/2508.06372",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06372v1 Announce Type: new \nAbstract: The Speaker Diarization and Recognition (SDR) task aims to predict \"who spoke when and what\" within an audio clip, which is a crucial task in various real-world multi-speaker scenarios such as meeting transcription and dialogue systems. Existing SDR systems typically adopt a cascaded framework, combining multiple modules such as speaker diarization (SD) and automatic speech recognition (ASR). The cascaded systems suffer from several limitations, such as error propagation, difficulty in handling overlapping speech, and lack of joint optimization for exploring the synergy between SD and ASR tasks. To address these limitations, we introduce SpeakerLM, a unified multimodal large language model for SDR that jointly performs SD and ASR in an end-to-end manner. Moreover, to facilitate diverse real-world scenarios, we incorporate a flexible speaker registration mechanism into SpeakerLM, enabling SDR under different speaker registration settings. SpeakerLM is progressively developed with a multi-stage training strategy on large-scale real data. Extensive experiments show that SpeakerLM demonstrates strong data scaling capability and generalizability, outperforming state-of-the-art cascaded baselines on both in-domain and out-of-domain public SDR benchmarks. Furthermore, experimental results show that the proposed speaker registration mechanism effectively ensures robust SDR performance of SpeakerLM across diverse speaker registration conditions and varying numbers of registered speakers.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with Multimodal Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "speakerlm",
      "endtoend",
      "versatile"
    ],
    "category": "noticia"
  },
  {
    "title": "Evaluating Style-Personalized Text Generation: Challenges and Directions",
    "title_es": "Evaluating Style-Personalized Text Generation: Challenges and Directions",
    "url": "https://arxiv.org/abs/2508.06374",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06374v1 Announce Type: new \nAbstract: While prior research has built tools and benchmarks towards style personalized text generation, there has been limited exploration of evaluation in low-resource author style personalized text generation space. Through this work, we question the effectiveness of the widely adopted evaluation metrics like BLEU and ROUGE, and explore other evaluation paradigms such as style embeddings and LLM-as-judge to holistically evaluate the style personalized text generation task. We evaluate these metrics and their ensembles using our style discrimination benchmark, that spans eight writing tasks, and evaluates across three settings, domain discrimination, authorship attribution, and LLM personalized vs non-personalized discrimination. We provide conclusive evidence to adopt ensemble of diverse evaluation metrics to effectively evaluate style personalized text generation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Evaluating Style-Personalized Text Generation: Challenges and Directions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "evaluating",
      "stylepersonalized",
      "text"
    ],
    "category": "noticia"
  },
  {
    "title": "Rational minimax approximation of matrix-valued functions",
    "title_es": "Rational minimax approximation of matrix-valued functions",
    "url": "https://arxiv.org/abs/2508.06378",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06378v1 Announce Type: new \nAbstract: In this paper, we present a rigorous framework for rational minimax approximation of matrix-valued functions that generalizes classical scalar approximation theory. Given sampled data $\\{(x_\\ell, {F}(x_\\ell))\\}_{\\ell=1}^m$ where ${F}:\\mathbb{C} \\to \\mathbb{C}^{s \\times t}$ is a matrix-valued function, we study the problem of finding a matrix-valued rational approximant ${R}(x) = {P}(x)/q(x)$ (with ${P}:\\mathbb{C} \\to \\mathbb{C}^{s \\times t}$ a matrix-valued polynomial and $q(x)$ a nonzero scalar polynomial of prescribed degrees) that minimizes the worst-case Frobenius norm error over the given nodes: $$ \\inf_{{R}(x) = {P}(x)/q(x)} \\max_{1 \\leq \\ell \\leq m} \\|{F}(x_\\ell) - {R}(x_\\ell)\\|_{\\rm F}. $$ By reformulating this min-max optimization problem through Lagrangian duality, we derive a maximization dual problem over the probability simplex. We analyze weak and strong duality properties and establish a sufficient condition ensuring that the solution of the dual problem yields the minimax approximant $R(x)$. For numerical implementation, we propose an efficient method (\\textsf{m-d-Lawson}) to solve the dual problem, generalizing Lawson's iteration to matrix-valued functions. Numerical experiments are conducted and compared to state-of-the-art approaches, demonstrating its efficiency as a novel computational framework for matrix-valued rational approximation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Rational minimax approximation of matrix-valued functions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "rational",
      "minimax",
      "approximation"
    ],
    "category": "noticia"
  },
  {
    "title": "Text as Any-Modality for Zero-Shot Classification by Consistent Prompt Tuning",
    "title_es": "Text as Any-Modality for Zero-Shot Classification by Consistent Prompt Tuning",
    "url": "https://arxiv.org/abs/2508.06382",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06382v1 Announce Type: new \nAbstract: The integration of prompt tuning with multimodal learning has shown significant generalization abilities for various downstream tasks. Despite advancements, existing methods heavily depend on massive modality-specific labeled data (e.g., video, audio, and image), or are customized for a single modality. In this study, we present Text as Any-Modality by Consistent Prompt Tuning (TaAM-CPT), a scalable approach for constructing a general representation model toward unlimited modalities using solely text data. TaAM-CPT comprises modality prompt pools, text construction, and modality-aligned text encoders from pre-trained models, which allows for extending new modalities by simply adding prompt pools and modality-aligned text encoders. To harmonize the learning across different modalities, TaAM-CPT designs intra- and inter-modal learning objectives, which can capture category details within modalities while maintaining semantic consistency across different modalities. Benefiting from its scalable architecture and pre-trained models, TaAM-CPT can be seamlessly extended to accommodate unlimited modalities. Remarkably, without any modality-specific labeled data, TaAM-CPT achieves leading results on diverse datasets spanning various modalities, including video classification, image classification, and audio classification. The code is available at https://github.com/Jinx630/TaAM-CPT.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Text as Any-Modality for Zero-Shot Classification by Consistent Prompt Tuning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "text",
      "as",
      "anymodality"
    ],
    "category": "noticia"
  },
  {
    "title": "Tree-Based Deep Learning for Ranking Symbolic Integration Algorithms",
    "title_es": "Tree-Based Deep Learning for Ranking Symbolic Integration Algorithms",
    "url": "https://arxiv.org/abs/2508.06383",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06383v1 Announce Type: new \nAbstract: Symbolic indefinite integration in Computer Algebra Systems such as Maple involves selecting the most effective algorithm from multiple available methods. Not all methods will succeed for a given problem, and when several do, the results, though mathematically equivalent, can differ greatly in presentation complexity. Traditionally, this choice has been made with minimal consideration of the problem instance, leading to inefficiencies.\n  We present a machine learning (ML) approach using tree-based deep learning models within a two-stage architecture: first identifying applicable methods for a given instance, then ranking them by predicted output complexity. Furthermore, we find representing mathematical expressions as tree structures significantly improves performance over sequence-based representations, and our two-stage framework outperforms alternative ML formulations.\n  Using a diverse dataset generated by six distinct data generators, our models achieve nearly 90% accuracy in selecting the optimal method on a 70,000 example holdout test set. On an independent out-of-distribution benchmark from Maple's internal test suite, our tree transformer model maintains strong generalisation, outperforming Maple's built-in selector and prior ML approaches.\n  These results highlight the critical role of data representation and problem framing in ML for symbolic computation, and we expect our methodology to generalise effectively to similar optimisation problems in mathematical software.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Tree-Based Deep Learning for Ranking Symbolic Integration Algorithms\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "treebased",
      "deep",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "Bridging Farm Economics and Landscape Ecology for Global Sustainability through Hierarchical and Bayesian Optimization",
    "title_es": "Bridging Farm Economics and Landscape Ecology for Global Sustainability through Hierarchical and Bayesian Optimization",
    "url": "https://arxiv.org/abs/2508.06386",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06386v1 Announce Type: new \nAbstract: Agricultural landscapes face the dual challenge of sustaining food production while reversing biodiversity loss. Agri-environmental policies often fall short of delivering ecological functions such as landscape connectivity, in part due to a persistent disconnect between farm-level economic decisions and landscape-scale spatial planning. We introduce a novel hierarchical optimization framework that bridges this gap. First, an Ecological Intensification (EI) model determines the economically optimal allocation of land to margin and habitat interventions at the individual farm level. These farm-specific intervention levels are then passed to an Ecological Connectivity (EC) model, which spatially arranges them across the landscape to maximize connectivity while preserving farm-level profitability. Finally, we introduce a Bayesian Optimization (BO) approach that translates these spatial outcomes into simple, cost effective, and scalable policy instruments, such as subsidies and eco-premiums, using non-spatial, farm-level policy parameters. Applying the framework to a Canadian agricultural landscape, we demonstrate how it enhances connectivity under real-world economic constraints. Our approach provides a globally relevant tool for aligning farm incentives with biodiversity goals, advancing the development of agri-environmental policies that are economically viable and ecologically effective.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Bridging Farm Economics and Landscape Ecology for Global Sustainability through Hierarchical and Bayesian Optimization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "bridging",
      "farm",
      "economics"
    ],
    "category": "noticia"
  },
  {
    "title": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation",
    "title_es": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation",
    "url": "https://arxiv.org/abs/2508.06387",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06387v1 Announce Type: new \nAbstract: Text-to-SQL bridges the gap between natural language and structured database language, thus allowing non-technical users to easily query databases. Traditional approaches model text-to-SQL as a direct translation task, where a given Natural Language Query (NLQ) is mapped to an SQL command. Recent advances in large language models (LLMs) have significantly improved translation accuracy, however, these methods all require that the target database is pre-specified. This becomes problematic in scenarios with multiple extensive databases, where identifying the correct database becomes a crucial yet overlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL framework to identify the user's intended database before generating SQL queries. Our approach leverages LLMs and prompt engineering to extract implicit information from natural language queries (NLQs) in the form of a ruleset. We then train a large db\\_id prediction model, which includes a RoBERTa-based finetuned encoder, to predict the correct Database identifier (db\\_id) based on both the NLQ and the LLM-generated rules. Finally, we refine the generated SQL by using critic agents to correct errors. Experimental results demonstrate that our framework outperforms the current state-of-the-art models in both database intent prediction and SQL generation accuracy.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "endtoend",
      "texttosql",
      "with"
    ],
    "category": "noticia"
  },
  {
    "title": "LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing",
    "title_es": "LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing",
    "url": "https://arxiv.org/abs/2508.06388",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06388v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated impressive capabilities in role-playing conversations and providing emotional support as separate research directions. However, there remains a significant research gap in combining these capabilities to enable emotionally supportive interactions with virtual characters. To address this research gap, we focus on anime characters as a case study because of their well-defined personalities and large fan bases. This choice enables us to effectively evaluate how well LLMs can provide emotional support while maintaining specific character traits. We introduce ChatAnime, the first Emotionally Supportive Role-Playing (ESRP) dataset. We first thoughtfully select 20 top-tier characters from popular anime communities and design 60 emotion-centric real-world scenario questions. Then, we execute a nationwide selection process to identify 40 Chinese anime enthusiasts with profound knowledge of specific characters and extensive experience in role-playing. Next, we systematically collect two rounds of dialogue data from 10 LLMs and these 40 Chinese anime enthusiasts. To evaluate the ESRP performance of LLMs, we design a user experience-oriented evaluation system featuring 9 fine-grained metrics across three dimensions: basic dialogue, role-playing and emotional support, along with an overall metric for response diversity. In total, the dataset comprises 2,400 human-written and 24,000 LLM-generated answers, supported by over 132,000 human annotations. Experimental results show that top-performing LLMs surpass human fans in role-playing and emotional support, while humans still lead in response diversity. We hope this work can provide valuable resources and insights for future research on optimizing LLMs in ESRP. Our datasets are available at https://github.com/LanlanQiu/ChatAnime.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "llms",
      "vs",
      "chinese"
    ],
    "category": "noticia"
  },
  {
    "title": "Identity Increases Stability in Neural Cellular Automata",
    "title_es": "Identity Increases Stability in Neural Cellular Automata",
    "url": "https://arxiv.org/abs/2508.06389",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06389v1 Announce Type: new \nAbstract: Neural Cellular Automata (NCAs) offer a way to study the growth of two-dimensional artificial organisms from a single seed cell. From the outset, NCA-grown organisms have had issues with stability, their natural boundary often breaking down and exhibiting tumour-like growth or failing to maintain the expected shape. In this paper, we present a method for improving the stability of NCA-grown organisms by introducing an 'identity' layer with simple constraints during training.\n  Results show that NCAs grown in close proximity are more stable compared with the original NCA model. Moreover, only a single identity value is required to achieve this increase in stability. We observe emergent movement from the stable organisms, with increasing prevalence for models with multiple identity values.\n  This work lays the foundation for further study of the interaction between NCA-grown organisms, paving the way for studying social interaction at a cellular level in artificial organisms.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Identity Increases Stability in Neural Cellular Automata\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "identity",
      "increases",
      "stability"
    ],
    "category": "noticia"
  },
  {
    "title": "Improved Dysarthric Speech to Text Conversion via TTS Personalization",
    "title_es": "Improved Dysarthric Speech to Text Conversion via TTS Personalization",
    "url": "https://arxiv.org/abs/2508.06391",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06391v1 Announce Type: new \nAbstract: We present a case study on developing a customized speech-to-text system for a Hungarian speaker with severe dysarthria. State-of-the-art automatic speech recognition (ASR) models struggle with zero-shot transcription of dysarthric speech, yielding high error rates. To improve performance with limited real dysarthric data, we fine-tune an ASR model using synthetic speech generated via a personalized text-to-speech (TTS) system. We introduce a method for generating synthetic dysarthric speech with controlled severity by leveraging premorbidity recordings of the given speaker and speaker embedding interpolation, enabling ASR fine-tuning on a continuum of impairments. Fine-tuning on both real and synthetic dysarthric speech reduces the character error rate (CER) from 36-51% (zero-shot) to 7.3%. Our monolingual FastConformer_Hu ASR model significantly outperforms Whisper-turbo when fine-tuned on the same data, and the inclusion of synthetic speech contributes to an 18% relative CER reduction. These results highlight the potential of personalized ASR systems for improving accessibility for individuals with severe speech impairments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Improved Dysarthric Speech to Text Conversion via TTS Personalization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "improved",
      "dysarthric",
      "speech"
    ],
    "category": "noticia"
  },
  {
    "title": "FVGen: Accelerating Novel-View Synthesis with Adversarial Video Diffusion Distillation",
    "title_es": "FVGen: Accelerating Novel-View Synthesis with Adversarial Video Diffusion Distillation",
    "url": "https://arxiv.org/abs/2508.06392",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06392v1 Announce Type: new \nAbstract: Recent progress in 3D reconstruction has enabled realistic 3D models from dense image captures, yet challenges persist with sparse views, often leading to artifacts in unseen areas. Recent works leverage Video Diffusion Models (VDMs) to generate dense observations, filling the gaps when only sparse views are available for 3D reconstruction tasks. A significant limitation of these methods is their slow sampling speed when using VDMs. In this paper, we present FVGen, a novel framework that addresses this challenge by enabling fast novel view synthesis using VDMs in as few as four sampling steps. We propose a novel video diffusion model distillation method that distills a multi-step denoising teacher model into a few-step denoising student model using Generative Adversarial Networks (GANs) and softened reverse KL-divergence minimization. Extensive experiments on real-world datasets show that, compared to previous works, our framework generates the same number of novel views with similar (or even better) visual quality while reducing sampling time by more than 90%. FVGen significantly improves time efficiency for downstream reconstruction tasks, particularly when working with sparse input views (more than 2) where pre-trained VDMs need to be run multiple times to achieve better spatial coverage.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"FVGen: Accelerating Novel-View Synthesis with Adversarial Video Diffusion Distillation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fvgen",
      "accelerating",
      "novelview"
    ],
    "category": "noticia"
  },
  {
    "title": "Robust Target Speaker Diarization and Separation via Augmented Speaker Embedding Sampling",
    "title_es": "Robust Target Speaker Diarization and Separation via Augmented Speaker Embedding Sampling",
    "url": "https://arxiv.org/abs/2508.06393",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06393v1 Announce Type: new \nAbstract: Traditional speech separation and speaker diarization approaches rely on prior knowledge of target speakers or a predetermined number of participants in audio signals. To address these limitations, recent advances focus on developing enrollment-free methods capable of identifying targets without explicit speaker labeling. This work introduces a new approach to train simultaneous speech separation and diarization using automatic identification of target speaker embeddings, within mixtures. Our proposed model employs a dual-stage training pipeline designed to learn robust speaker representation features that are resilient to background noise interference. Furthermore, we present an overlapping spectral loss function specifically tailored for enhancing diarization accuracy during overlapped speech frames. Experimental results show significant performance gains compared to the current SOTA baseline, achieving 71% relative improvement in DER and 69% in cpWER.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Robust Target Speaker Diarization and Separation via Augmented Speaker Embedding Sampling\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "robust",
      "target",
      "speaker"
    ],
    "category": "noticia"
  },
  {
    "title": "When AIOps Become \"AI Oops\": Subverting LLM-driven IT Operations via Telemetry Manipulation",
    "title_es": "When AIOps Become \"AI Oops\": Subverting LLM-driven IT Operations via Telemetry Manipulation",
    "url": "https://arxiv.org/abs/2508.06394",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06394v1 Announce Type: new \nAbstract: AI for IT Operations (AIOps) is transforming how organizations manage complex software systems by automating anomaly detection, incident diagnosis, and remediation. Modern AIOps solutions increasingly rely on autonomous LLM-based agents to interpret telemetry data and take corrective actions with minimal human intervention, promising faster response times and operational cost savings.\n  In this work, we perform the first security analysis of AIOps solutions, showing that, once again, AI-driven automation comes with a profound security cost. We demonstrate that adversaries can manipulate system telemetry to mislead AIOps agents into taking actions that compromise the integrity of the infrastructure they manage. We introduce techniques to reliably inject telemetry data using error-inducing requests that influence agent behavior through a form of adversarial reward-hacking; plausible but incorrect system error interpretations that steer the agent's decision-making. Our attack methodology, AIOpsDoom, is fully automated--combining reconnaissance, fuzzing, and LLM-driven adversarial input generation--and operates without any prior knowledge of the target system.\n  To counter this threat, we propose AIOpsShield, a defense mechanism that sanitizes telemetry data by exploiting its structured nature and the minimal role of user-generated content. Our experiments show that AIOpsShield reliably blocks telemetry-based attacks without affecting normal agent performance.\n  Ultimately, this work exposes AIOps as an emerging attack vector for system compromise and underscores the urgent need for security-aware AIOps design.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"When AIOps Become \"AI Oops\": Subverting LLM-driven IT Operations via Telemetry Manipulation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "when",
      "aiops",
      "become"
    ],
    "category": "noticia"
  },
  {
    "title": "A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges",
    "title_es": "A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges",
    "url": "https://arxiv.org/abs/2508.06401",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06401v1 Announce Type: new \nAbstract: This systematic review of the research literature on retrieval-augmented generation (RAG) provides a focused analysis of the most highly cited studies published between 2020 and May 2025. A total of 128 articles met our inclusion criteria. The records were retrieved from ACM Digital Library, IEEE Xplore, Scopus, ScienceDirect, and the Digital Bibliography and Library Project (DBLP). RAG couples a neural retriever with a generative language model, grounding output in up-to-date, non-parametric memory while retaining the semantic generalisation stored in model weights. Guided by the PRISMA 2020 framework, we (i) specify explicit inclusion and exclusion criteria based on citation count and research questions, (ii) catalogue datasets, architectures, and evaluation practices, and (iii) synthesise empirical evidence on the effectiveness and limitations of RAG. To mitigate citation-lag bias, we applied a lower citation-count threshold to papers published in 2025 so that emerging breakthroughs with naturally fewer citations were still captured. This review clarifies the current research landscape, highlights methodological gaps, and charts priority directions for future research.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "systematic",
      "literature"
    ],
    "category": "noticia"
  },
  {
    "title": "V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles",
    "title_es": "V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles",
    "url": "https://arxiv.org/abs/2508.06404",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06404v1 Announce Type: new \nAbstract: Autonomous vehicle navigation in structured environments requires planners capable of generating time-optimal, collision-free trajectories that satisfy dynamic and kinematic constraints. We introduce V*, a graph-based motion planner that represents speed and direction as explicit state variables within a discretised space-time-velocity lattice. Unlike traditional methods that decouple spatial search from dynamic feasibility or rely on post-hoc smoothing, V* integrates both motion dimensions directly into graph construction through dynamic graph generation during search expansion. To manage the complexity of high-dimensional search, we employ a hexagonal discretisation strategy and provide formal mathematical proofs establishing optimal waypoint spacing and minimal node redundancy under constrained heading transitions for velocity-aware motion planning. We develop a mathematical formulation for transient steering dynamics in the kinematic bicycle model, modelling steering angle convergence with exponential behaviour, and deriving the relationship for convergence rate parameters. This theoretical foundation, combined with geometric pruning strategies that eliminate expansions leading to infeasible steering configurations, enables V* to evaluate dynamically admissible manoeuvres, ensuring each trajectory is physically realisable without further refinement. We further demonstrate V*'s performance in simulation studies with cluttered and dynamic environments involving moving obstacles, showing its ability to avoid conflicts, yield proactively, and generate safe, efficient trajectories with temporal reasoning capabilities for waiting behaviours and dynamic coordination.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "v",
      "an",
      "efficient"
    ],
    "category": "noticia"
  },
  {
    "title": "Blockchain-Enabled Federated Learning",
    "title_es": "Blockchain-Enabled Federated Learning",
    "url": "https://arxiv.org/abs/2508.06406",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06406v1 Announce Type: new \nAbstract: Blockchain-enabled federated learning (BCFL) addresses fundamental challenges of trust, privacy, and coordination in collaborative AI systems. This chapter provides comprehensive architectural analysis of BCFL systems through a systematic four-dimensional taxonomy examining coordination structures, consensus mechanisms, storage architectures, and trust models. We analyze design patterns from blockchain-verified centralized coordination to fully decentralized peer-to-peer networks, evaluating trade-offs in scalability, security, and performance. Through detailed examination of consensus mechanisms designed for federated learning contexts, including Proof of Quality and Proof of Federated Learning, we demonstrate how computational work can be repurposed from arbitrary cryptographic puzzles to productive machine learning tasks. The chapter addresses critical storage challenges by examining multi-tier architectures that balance blockchain's transaction constraints with neural networks' large parameter requirements while maintaining cryptographic integrity. A technical case study of the TrustMesh framework illustrates practical implementation considerations in BCFL systems through distributed image classification training, demonstrating effective collaborative learning across IoT devices with highly non-IID data distributions while maintaining complete transparency and fault tolerance. Analysis of real-world deployments across healthcare consortiums, financial services, and IoT security applications validates the practical viability of BCFL systems, achieving performance comparable to centralized approaches while providing enhanced security guarantees and enabling new models of trustless collaborative intelligence.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Blockchain-Enabled Federated Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "blockchainenabled",
      "federated",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery",
    "title_es": "A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery",
    "url": "https://arxiv.org/abs/2508.06407",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06407v1 Announce Type: new \nAbstract: High-resolution imagery plays a critical role in improving the performance of visual recognition tasks such as classification, detection, and segmentation. In many domains, including remote sensing and surveillance, low-resolution images can limit the accuracy of automated analysis. To address this, super-resolution (SR) techniques have been widely adopted to attempt to reconstruct high-resolution images from low-resolution inputs. Related traditional approaches focus solely on enhancing image quality based on pixel-level metrics, leaving the relationship between super-resolved image fidelity and downstream classification performance largely underexplored. This raises a key question: can integrating classification objectives directly into the super-resolution process further improve classification accuracy? In this paper, we try to respond to this question by investigating the relationship between super-resolution and classification through the deployment of a specialised algorithmic strategy. We propose a novel methodology that increases the resolution of synthetic aperture radar imagery by optimising loss functions that account for both image quality and classification performance. Our approach improves image quality, as measured by scientifically ascertained image quality indicators, while also enhancing classification accuracy.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "classificationaware",
      "superresolution"
    ],
    "category": "noticia"
  },
  {
    "title": "Heterogeneous optimized Schwarz Methods for heat conduction in composites with thermal contact resistance",
    "title_es": "Heterogeneous optimized Schwarz Methods for heat conduction in composites with thermal contact resistance",
    "url": "https://arxiv.org/abs/2508.06408",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06408v1 Announce Type: new \nAbstract: Heat transfer in composites is critical in engineering, where imperfect layer contact causes thermal contact resistance (TCR), leading to interfacial temperature discontinuity. We propose solving this numerically using the optimized Schwarz method (OSM), which decouples the heterogeneous problem into homogeneous subproblems. This avoids ill-conditioned systems from monolithic solving due to high contrast and interface jumps. Both energy estimate and Fourier analysis are used to prove the convergence of this algorithm when the standard Robin condition is applied to transmit information between subdomains. To achieve fast convergence, instead of the standard Robin, the scaled Robin transmission condition is proposed, and the involved free parameter is rigorously optimized. The results reveal several new findings due to the presence of TCR: first, the larger the TCR, the faster the OSM converges; second, mesh-independent convergence is achieved in the asymptotic sense, in contrast to the mesh-dependent results without TCR; and last, the heterogeneity contrast benefits the convergence, with a larger contrast leading to faster convergence. Interestingly, different from the case without TCR, the thermal conductivity also benefits the convergence, similar to the effect of heterogeneity. Numerical experiments confirm the theoretical findings and demonstrate the method's potential for nonlinear problems on irregular domains.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Heterogeneous optimized Schwarz Methods for heat conduction in composites with thermal contact resistance\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "heterogeneous",
      "optimized",
      "schwarz"
    ],
    "category": "noticia"
  },
  {
    "title": "A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images",
    "title_es": "A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images",
    "url": "https://arxiv.org/abs/2508.06409",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06409v1 Announce Type: new \nAbstract: Homelessness in the United States has surged to levels unseen since the Great Depression. However, existing methods for monitoring it, such as point-in-time (PIT) counts, have limitations in terms of frequency, consistency, and spatial detail. This study proposes a new approach using publicly available, crowdsourced data, specifically 311 Service Calls and street-level imagery, to track and forecast homeless tent trends in San Francisco. Our predictive model captures fine-grained daily and neighborhood-level variations, uncovering patterns that traditional counts often overlook, such as rapid fluctuations during the COVID-19 pandemic and spatial shifts in tent locations over time. By providing more timely, localized, and cost-effective information, this approach serves as a valuable tool for guiding policy responses and evaluating interventions aimed at reducing unsheltered homelessness.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "new",
      "lens"
    ],
    "category": "noticia"
  },
  {
    "title": "Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks",
    "title_es": "Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks",
    "url": "https://arxiv.org/abs/2508.06411",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06411v1 Announce Type: new \nAbstract: Although discourse around the risks of Artificial Intelligence (AI) has grown, it often lacks a comprehensive, multidimensional framework, and concrete causal pathways mapping hazard to harm. This paper aims to bridge this gap by examining six commonly discussed AI catastrophic risks: CBRN, cyber offense, sudden loss of control, gradual loss of control, environmental risk, and geopolitical risk. First, we characterize these risks across seven key dimensions, namely intent, competency, entity, polarity, linearity, reach, and order. Next, we conduct risk pathway modeling by mapping step-by-step progressions from the initial hazard to the resulting harms. The dimensional approach supports systematic risk identification and generalizable mitigation strategies, while risk pathway models help identify scenario-specific interventions. Together, these methods offer a more structured and actionable foundation for managing catastrophic AI risks across the value chain.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dimensional",
      "characterization",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Sample-efficient LLM Optimization with Reset Replay",
    "title_es": "Sample-efficient LLM Optimization with Reset Replay",
    "url": "https://arxiv.org/abs/2508.06412",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06412v1 Announce Type: new \nAbstract: Recent advancements in post-training Large Language Models (LLMs), particularly through Reinforcement Learning (RL) and preference optimization methods, are key drivers for enhancing their reasoning capabilities. However, these methods are often plagued by low sample efficiency and a susceptibility to primacy bias, where overfitting to initial experiences degrades policy quality and damages the learning process. To address these challenges, we introduce LLM optimization with Reset Replay (LoRR), a general and powerful plugin designed to enhance sample efficiency in any preference-based optimization framework. LoRR core mechanism enables training at a high replay number, maximizing the utility of each collected data batch. To counteract the risk of overfitting inherent in high-replay training, LoRR incorporates a periodic reset strategy with reusing initial data, which preserves network plasticity. Furthermore, it leverages a hybrid optimization objective, combining supervised fine-tuning (SFT) and preference-based losses to further bolster data exploitation. Our extensive experiments demonstrate that LoRR significantly boosts the performance of various preference optimization methods on both mathematical and general reasoning benchmarks. Notably, an iterative DPO approach augmented with LoRR achieves comparable performance on challenging math tasks, outperforming some complex and computationally intensive RL-based algorithms. These findings highlight that LoRR offers a practical, sample-efficient, and highly effective paradigm for LLM finetuning, unlocking greater performance from limited data.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Sample-efficient LLM Optimization with Reset Replay\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sampleefficient",
      "llm",
      "optimization"
    ],
    "category": "noticia"
  },
  {
    "title": "What Builds Effective In-Context Examples for Code Generation?",
    "title_es": "What Builds Effective In-Context Examples for Code Generation?",
    "url": "https://arxiv.org/abs/2508.06414",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06414v1 Announce Type: new \nAbstract: In-Context Learning (ICL) has emerged as a promising solution to enhance the code generation capabilities of Large Language Models (LLMs), which incorporates code examples inside the prompt to let LLMs learn from demonstrations. However, despite the substantial effectiveness of the code example-based ICL approach, the specific features (e.g., identifier naming styles, code formatting, solution insight) within the ICL-provided code examples that significantly contribute to the ICL's effectiveness remain unclear. This paper systematically investigates the impact of various code features on ICL with code examples through controlled ablation studies. Our findings reveal that the appropriate naming of variables and functions is crucial for effective code generation, with their elimination leading to performance decreases of up to 30 percentage points. We further demonstrate that LLMs prioritize semantically meaningful identifier names over formatting conventions, with language-specific preferences regarding identifier verbosity. Additionally, our investigation into ICL's potential for enhancing reflection and inference capabilities reveals that current LLMs struggle to extract generalizable problem-solving insights from similar code solutions, despite being capable of utilizing direct information effectively. These findings are expected to provide valuable insights for optimizing ICL systems in code generation applications and highlight fundamental challenges in reflection-based learning for code generation tasks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"What Builds Effective In-Context Examples for Code Generation?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "what",
      "builds",
      "effective"
    ],
    "category": "noticia"
  },
  {
    "title": "Quantifying Conversation Drift in MCP via Latent Polytope",
    "title_es": "Quantifying Conversation Drift in MCP via Latent Polytope",
    "url": "https://arxiv.org/abs/2508.06418",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06418v1 Announce Type: new \nAbstract: The Model Context Protocol (MCP) enhances large language models (LLMs) by integrating external tools, enabling dynamic aggregation of real-time data to improve task execution. However, its non-isolated execution context introduces critical security and privacy risks. In particular, adversarially crafted content can induce tool poisoning or indirect prompt injection, leading to conversation hijacking, misinformation propagation, or data exfiltration. Existing defenses, such as rule-based filters or LLM-driven detection, remain inadequate due to their reliance on static signatures, computational inefficiency, and inability to quantify conversational hijacking. To address these limitations, we propose SecMCP, a secure framework that detects and quantifies conversation drift, deviations in latent space trajectories induced by adversarial external knowledge. By modeling LLM activation vectors within a latent polytope space, SecMCP identifies anomalous shifts in conversational dynamics, enabling proactive detection of hijacking, misleading, and data exfiltration. We evaluate SecMCP on three state-of-the-art LLMs (Llama3, Vicuna, Mistral) across benchmark datasets (MS MARCO, HotpotQA, FinQA), demonstrating robust detection with AUROC scores exceeding 0.915 while maintaining system usability. Our contributions include a systematic categorization of MCP security threats, a novel latent polytope-based methodology for quantifying conversation drift, and empirical validation of SecMCP's efficacy.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Quantifying Conversation Drift in MCP via Latent Polytope\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "quantifying",
      "conversation",
      "drift"
    ],
    "category": "noticia"
  },
  {
    "title": "Feature-Space Oversampling for Addressing Class Imbalance in SAR Ship Classification",
    "title_es": "Feature-Space Oversampling for Addressing Class Imbalance in SAR Ship Classification",
    "url": "https://arxiv.org/abs/2508.06420",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06420v1 Announce Type: new \nAbstract: SAR ship classification faces the challenge of long-tailed datasets, which complicates the classification of underrepresented classes. Oversampling methods have proven effective in addressing class imbalance in optical data. In this paper, we evaluated the effect of oversampling in the feature space for SAR ship classification. We propose two novel algorithms inspired by the Major-to-minor (M2m) method M2m$_f$, M2m$_u$. The algorithms are tested on two public datasets, OpenSARShip (6 classes) and FuSARShip (9 classes), using three state-of-the-art models as feature extractors: ViT, VGG16, and ResNet50. Additionally, we also analyzed the impact of oversampling methods on different class sizes. The results demonstrated the effectiveness of our novel methods over the original M2m and baselines, with an average F1-score increase of 8.82% for FuSARShip and 4.44% for OpenSARShip.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Feature-Space Oversampling for Addressing Class Imbalance in SAR Ship Classification\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "featurespace",
      "oversampling",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation",
    "title_es": "Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation",
    "url": "https://arxiv.org/abs/2508.06426",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06426v1 Announce Type: new \nAbstract: Generalist robot policies trained on large-scale datasets such as Open X-Embodiment (OXE) demonstrate strong performance across a wide range of tasks. However, they often struggle to generalize beyond the distribution of their training data. In this paper, we investigate the underlying cause of this limited generalization capability. We identify shortcut learning -- the reliance on task-irrelevant features -- as a key impediment to generalization. Through comprehensive theoretical and empirical analysis, we uncover two primary contributors to shortcut learning: (1) limited diversity within individual sub-datasets, and (2) significant distributional disparities across sub-datasets, leading to dataset fragmentation. These issues arise from the inherent structure of large-scale datasets like OXE, which are typically composed of multiple sub-datasets collected independently across varied environments and embodiments. Our findings provide critical insights into dataset collection strategies that can reduce shortcut learning and enhance the generalization ability of generalist robot policies. Moreover, in scenarios where acquiring new large-scale data is impractical, we demonstrate that carefully selected robotic data augmentation strategies can effectively reduce shortcut learning in existing offline datasets, thereby improving generalization capabilities of generalist robot policies, e.g., $\\pi_0$, in both simulation and real-world environments. More information at https://lucky-light-sun.github.io/proj/shortcut-learning-in-grps/.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "shortcut",
      "learning",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation",
    "title_es": "SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation",
    "url": "https://arxiv.org/abs/2508.06429",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06429v1 Announce Type: new \nAbstract: Deep learning has revolutionized medical imaging, but its effectiveness is severely limited by insufficient labeled training data. This paper introduces a novel GAN-based semi-supervised learning framework specifically designed for low labeled-data regimes, evaluated across settings with 5 to 50 labeled samples per class. Our approach integrates three specialized neural networks -- a generator for class-conditioned image translation, a discriminator for authenticity assessment and classification, and a dedicated classifier -- within a three-phase training framework. The method alternates between supervised training on limited labeled data and unsupervised learning that leverages abundant unlabeled images through image-to-image translation rather than generation from noise. We employ ensemble-based pseudo-labeling that combines confidence-weighted predictions from the discriminator and classifier with temporal consistency through exponential moving averaging, enabling reliable label estimation for unlabeled data. Comprehensive evaluation across eleven MedMNIST datasets demonstrates that our approach achieves statistically significant improvements over six state-of-the-art GAN-based semi-supervised methods, with particularly strong performance in the extreme 5-shot setting where the scarcity of labeled data is most challenging. The framework maintains its superiority across all evaluated settings (5, 10, 20, and 50 shots per class). Our approach offers a practical solution for medical imaging applications where annotation costs are prohibitive, enabling robust classification performance even with minimal labeled data. Code is available at https://github.com/GuidoManni/SPARSE.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sparse",
      "data",
      "rich"
    ],
    "category": "noticia"
  },
  {
    "title": "MotionSwap",
    "title_es": "MotionSwap",
    "url": "https://arxiv.org/abs/2508.06430",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06430v1 Announce Type: new \nAbstract: Face swapping technology has gained significant attention in both academic research and commercial applications. This paper presents our implementation and enhancement of SimSwap, an efficient framework for high fidelity face swapping. We introduce several improvements to the original model, including the integration of self and cross-attention mechanisms in the generator architecture, dynamic loss weighting, and cosine annealing learning rate scheduling. These enhancements lead to significant improvements in identity preservation, attribute consistency, and overall visual quality.\n  Our experimental results, spanning 400,000 training iterations, demonstrate progressive improvements in generator and discriminator performance. The enhanced model achieves better identity similarity, lower FID scores, and visibly superior qualitative results compared to the baseline. Ablation studies confirm the importance of each architectural and training improvement. We conclude by identifying key future directions, such as integrating StyleGAN3, improving lip synchronization, incorporating 3D facial modeling, and introducing temporal consistency for video-based applications.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MotionSwap\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "motionswap"
    ],
    "category": "noticia"
  },
  {
    "title": "Hierarchical Placement Learning for Network Slice Provisioning",
    "title_es": "Hierarchical Placement Learning for Network Slice Provisioning",
    "url": "https://arxiv.org/abs/2508.06432",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06432v1 Announce Type: new \nAbstract: In this work, we aim to address the challenge of slice provisioning in edge-based mobile networks. We propose a solution that learns a service function chain placement policy for Network Slice Requests, to maximize the request acceptance rate, while minimizing the average node resource utilization. To do this, we consider a Hierarchical Multi-Armed Bandit problem and propose a two-level hierarchical bandit solution which aims to learn a scalable placement policy that optimizes the stated objectives in an online manner. Simulations on two real network topologies show that our proposed approach achieves 5% average node resource utilization while admitting over 25% more slice requests in certain scenarios, compared to baseline methods.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hierarchical Placement Learning for Network Slice Provisioning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hierarchical",
      "placement",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "Memp: Exploring Agent Procedural Memory",
    "title_es": "Memp: Exploring Agent Procedural Memory",
    "url": "https://arxiv.org/abs/2508.06433",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06433v1 Announce Type: new \nAbstract: Large Language Models (LLMs) based agents excel at diverse tasks, yet they suffer from brittle procedural memory that is manually engineered or entangled in static parameters. In this work, we investigate strategies to endow agents with a learnable, updatable, and lifelong procedural memory. We propose Memp that distills past agent trajectories into both fine-grained, step-by-step instructions and higher-level, script-like abstractions, and explore the impact of different strategies for Build, Retrieval, and Update of procedural memory. Coupled with a dynamic regimen that continuously updates, corrects, and deprecates its contents, this repository evolves in lockstep with new experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as the memory repository is refined, agents achieve steadily higher success rates and greater efficiency on analogous tasks. Moreover, procedural memory built from a stronger model retains its value: migrating the procedural memory to a weaker model yields substantial performance gains.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Memp: Exploring Agent Procedural Memory\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "memp",
      "exploring",
      "agent"
    ],
    "category": "noticia"
  },
  {
    "title": "CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment",
    "title_es": "CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment",
    "url": "https://arxiv.org/abs/2508.06434",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06434v1 Announce Type: new \nAbstract: Large-scale natural image-text datasets, especially those automatically collected from the web, often suffer from loose semantic alignment due to weak supervision, while medical datasets tend to have high cross-modal correlation but low content diversity. These properties pose a common challenge for contrastive language-image pretraining (CLIP): they hinder the model's ability to learn robust and generalizable representations. In this work, we propose CLIPin, a unified non-contrastive plug-in that can be seamlessly integrated into CLIP-style architectures to improve multimodal semantic alignment, providing stronger supervision and enhancing alignment robustness. Furthermore, two shared pre-projectors are designed for image and text modalities respectively to facilitate the integration of contrastive and non-contrastive learning in a parameter-compromise manner. Extensive experiments on diverse downstream tasks demonstrate the effectiveness and generality of CLIPin as a plug-and-play component compatible with various contrastive frameworks. Code is available at https://github.com/T6Yang/CLIPin.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "clipin",
      "a",
      "noncontrastive"
    ],
    "category": "noticia"
  },
  {
    "title": "Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages",
    "title_es": "Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages",
    "url": "https://arxiv.org/abs/2508.06435",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06435v1 Announce Type: new \nAbstract: Large language models (LLMs) are transforming social-science research by enabling scalable, precise analysis. Their adaptability raises the question of whether knowledge acquired through fine-tuning in a few languages can transfer to unseen languages that only appeared during pre-training. To examine this, we fine-tune lightweight LLaMA 3.2-3B models on monolingual, bilingual, or multilingual data sets to classify immigration-related tweets from X/Twitter across 13 languages, a domain characterised by polarised, culturally specific discourse. We evaluate whether minimal language-specific fine-tuning enables cross-lingual topic detection and whether adding targeted languages corrects pre-training biases. Results show that LLMs fine-tuned in one or two languages can reliably classify immigration-related content in unseen languages. However, identifying whether a tweet expresses a pro- or anti-immigration stance benefits from multilingual fine-tuning. Pre-training bias favours dominant languages, but even minimal exposure to under-represented languages during fine-tuning (as little as $9.62\\times10^{-11}$ of the original pre-training token volume) yields significant gains. These findings challenge the assumption that cross-lingual mastery requires extensive multilingual training: limited language coverage suffices for topic-level generalisation, and structural biases can be corrected with lightweight interventions. By releasing 4-bit-quantised, LoRA fine-tuned models, we provide an open-source, reproducible alternative to proprietary LLMs that delivers 35 times faster inference at just 0.00000989% of the dollar cost of the OpenAI GPT-4o model, enabling scalable, inclusive research.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "learning",
      "the",
      "topic"
    ],
    "category": "noticia"
  },
  {
    "title": "The Fair Game: Auditing & Debiasing AI Algorithms Over Time",
    "title_es": "The Fair Game: Auditing & Debiasing AI Algorithms Over Time",
    "url": "https://arxiv.org/abs/2508.06443",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06443v1 Announce Type: new \nAbstract: An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify different types of bias (also known as unfairness) exhibited in the predictions of ML algorithms, and to design new algorithms to mitigate them. Often, the definitions of bias used in the literature are observational, i.e. they use the input and output of a pre-trained algorithm to quantify a bias under concern. In reality,these definitions are often conflicting in nature and can only be deployed if either the ground truth is known or only in retrospect after deploying the algorithm. Thus,there is a gap between what we want Fair ML to achieve and what it does in a dynamic social environment. Hence, we propose an alternative dynamic mechanism,\"Fair Game\",to assure fairness in the predictions of an ML algorithm and to adapt its predictions as the society interacts with the algorithm over time. \"Fair Game\" puts together an Auditor and a Debiasing algorithm in a loop around an ML algorithm. The \"Fair Game\" puts these two components in a loop by leveraging Reinforcement Learning (RL). RL algorithms interact with an environment to take decisions, which yields new observations (also known as data/feedback) from the environment and in turn, adapts future decisions. RL is already used in algorithms with pre-fixed long-term fairness goals. \"Fair Game\" provides a unique framework where the fairness goals can be adapted over time by only modifying the auditor and the different biases it quantifies. Thus,\"Fair Game\" aims to simulate the evolution of ethical and legal frameworks in the society by creating an auditor which sends feedback to a debiasing algorithm deployed around an ML system. This allows us to develop a flexible and adaptive-over-time framework to build Fair ML systems pre- and post-deployment.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"The Fair Game: Auditing & Debiasing AI Algorithms Over Time\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "fair",
      "game"
    ],
    "category": "noticia"
  },
  {
    "title": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking",
    "title_es": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking",
    "url": "https://arxiv.org/abs/2508.06445",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06445v1 Announce Type: new \nAbstract: The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns for journalistic integrity and authorship. This study examines AI-generated content across over 40,000 news articles from major, local, and college news media, in various media formats. Using three advanced AI-text detectors (e.g., Binoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of GenAI use in recent years, especially in local and college news. Sentence-level analysis reveals LLMs are often used in the introduction of news, while conclusions usually written manually. Linguistic analysis shows GenAI boosts word richness and readability but lowers formality, leading to more uniform writing styles, particularly in local media.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Echoes of Automation: The Increasing Use of LLMs in Newsmaking\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "echoes",
      "of",
      "automation"
    ],
    "category": "noticia"
  },
  {
    "title": "SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning",
    "title_es": "SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning",
    "url": "https://arxiv.org/abs/2508.06447",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06447v1 Announce Type: new \nAbstract: Long-context inference for Large Language Models (LLMs) is heavily limited by high computational demands. While several existing methods optimize attention computation, they still process the full set of hidden states at each layer, limiting overall efficiency. In this work, we propose SlimInfer, an innovative framework that aims to accelerate inference by directly pruning less critical prompt tokens during the forward pass. Our key insight is an information diffusion phenomenon: As information from critical tokens propagates through layers, it becomes distributed across the entire sequence. This diffusion process suggests that LLMs can maintain their semantic integrity when excessive tokens, even including these critical ones, are pruned in hidden states. Motivated by this, SlimInfer introduces a dynamic fine-grained pruning mechanism that accurately removes redundant tokens of hidden state at intermediate layers. This layer-wise pruning naturally enables an asynchronous KV cache manager that prefetches required token blocks without complex predictors, reducing both memory usage and I/O costs. Extensive experiments show that SlimInfer can achieve up to $\\mathbf{2.53\\times}$ time-to-first-token (TTFT) speedup and $\\mathbf{1.88\\times}$ end-to-end latency reduction for LLaMA3.1-8B-Instruct on a single RTX 4090, without sacrificing performance on LongBench. Our code will be released upon acceptance.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sliminfer",
      "accelerating",
      "longcontext"
    ],
    "category": "noticia"
  },
  {
    "title": "eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion",
    "title_es": "eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion",
    "url": "https://arxiv.org/abs/2508.06450",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06450v1 Announce Type: new \nAbstract: Since their introduction, Transformer-based models, such as SASRec and BERT4Rec, have become common baselines for sequential recommendations, surpassing earlier neural and non-neural methods. A number of following publications have shown that the effectiveness of these models can be improved by, for example, slightly updating the architecture of the Transformer layers, using better training objectives, and employing improved loss functions. However, the additivity of these modular improvements has not been systematically benchmarked - this is the gap we aim to close in this paper. Through our experiments, we identify a very strong model that uses SASRec's training objective, LiGR Transformer layers, and Sampled Softmax Loss. We call this combination eSASRec (Enhanced SASRec). While we primarily focus on realistic, production-like evaluation, in our preliminarily study we find that common academic benchmarks show eSASRec to be 23% more effective compared to the most recent state-of-the-art models, such as ActionPiece. In our main production-like benchmark, eSASRec resides on the Pareto frontier in terms of the accuracy-coverage tradeoff (alongside the recent industrial models HSTU and FuXi. As the modifications compared to the original SASRec are relatively straightforward and no extra features are needed (such as timestamps in HSTU), we believe that eSASRec can be easily integrated into existing recommendation pipelines and can can serve as a strong yet very simple baseline for emerging complicated algorithms. To facilitate this, we provide the open-source implementations for our models and benchmarks in repository https://github.com/blondered/transformer_benchmark",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "esasrec",
      "enhancing",
      "transformerbased"
    ],
    "category": "noticia"
  },
  {
    "title": "TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation",
    "title_es": "TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation",
    "url": "https://arxiv.org/abs/2508.06452",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06452v1 Announce Type: new \nAbstract: Recent unsupervised domain adaptation (UDA) methods have shown great success in addressing classical domain shifts (e.g., synthetic-to-real), but they still suffer under complex shifts (e.g. geographical shift), where both the background and object appearances differ significantly across domains. Prior works showed that the language modality can help in the adaptation process, exhibiting more robustness to such complex shifts. In this paper, we introduce TRUST, a novel UDA approach that exploits the robustness of the language modality to guide the adaptation of a vision model. TRUST generates pseudo-labels for target samples from their captions and introduces a novel uncertainty estimation strategy that uses normalised CLIP similarity scores to estimate the uncertainty of the generated pseudo-labels. Such estimated uncertainty is then used to reweight the classification loss, mitigating the adverse effects of wrong pseudo-labels obtained from low-quality captions. To further increase the robustness of the vision model, we propose a multimodal soft-contrastive learning loss that aligns the vision and language feature spaces, by leveraging captions to guide the contrastive training of the vision model on target images. In our contrastive loss, each pair of images acts as both a positive and a negative pair and their feature representations are attracted and repulsed with a strength proportional to the similarity of their captions. This solution avoids the need for hardly determining positive and negative pairs, which is critical in the UDA setting. Our approach outperforms previous methods, setting the new state-of-the-art on classical (DomainNet) and complex (GeoNet) domain shifts. The code will be available upon acceptance.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "trust",
      "leveraging",
      "text"
    ],
    "category": "noticia"
  },
  {
    "title": "Text Embedded Swin-UMamba for DeepLesion Segmentation",
    "title_es": "Text Embedded Swin-UMamba for DeepLesion Segmentation",
    "url": "https://arxiv.org/abs/2508.06453",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06453v1 Announce Type: new \nAbstract: Segmentation of lesions on CT enables automatic measurement for clinical assessment of chronic diseases (e.g., lymphoma). Integrating large language models (LLMs) into the lesion segmentation workflow offers the potential to combine imaging features with descriptions of lesion characteristics from the radiology reports. In this study, we investigate the feasibility of integrating text into the Swin-UMamba architecture for the task of lesion segmentation. The publicly available ULS23 DeepLesion dataset was used along with short-form descriptions of the findings from the reports. On the test dataset, a high Dice Score of 82% and low Hausdorff distance of 6.58 (pixels) was obtained for lesion segmentation. The proposed Text-Swin-UMamba model outperformed prior approaches: 37% improvement over the LLM-driven LanGuideMedSeg model (p < 0.001),and surpassed the purely image-based xLSTM-UNet and nnUNet models by 1.74% and 0.22%, respectively. The dataset and code can be accessed at https://github.com/ruida/LLM-Swin-UMamba",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Text Embedded Swin-UMamba for DeepLesion Segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "text",
      "embedded",
      "swinumamba"
    ],
    "category": "noticia"
  },
  {
    "title": "What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting",
    "title_es": "What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting",
    "url": "https://arxiv.org/abs/2508.06454",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06454v1 Announce Type: new \nAbstract: Committee-selection problems arise in many contexts and applications, and there has been increasing interest within the social choice research community on identifying which properties are satisfied by different multi-winner voting rules. In this work, we propose a data-driven framework to evaluate how frequently voting rules violate axioms across diverse preference distributions in practice, shifting away from the binary perspective of axiom satisfaction given by worst-case analysis. Using this framework, we analyze the relationship between multi-winner voting rules and their axiomatic performance under several preference distributions. We then show that neural networks, acting as voting rules, can outperform traditional rules in minimizing axiom violations. Our results suggest that data-driven approaches to social choice can inform the design of new voting systems and support the continuation of data-driven research in social choice.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "what",
      "voting",
      "rules"
    ],
    "category": "noticia"
  },
  {
    "title": "Maximum Impact with Fewer Features: Efficient Feature Selection for Cold-Start Recommenders through Collaborative Importance Weighting",
    "title_es": "Maximum Impact with Fewer Features: Efficient Feature Selection for Cold-Start Recommenders through Collaborative Importance Weighting",
    "url": "https://arxiv.org/abs/2508.06455",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06455v1 Announce Type: new \nAbstract: Cold-start challenges in recommender systems necessitate leveraging auxiliary features beyond user-item interactions. However, the presence of irrelevant or noisy features can degrade predictive performance, whereas an excessive number of features increases computational demands, leading to higher memory consumption and prolonged training times.\n  To address this, we propose a feature selection strategy that prioritizes the user behavioral information. Our method enhances the feature representation by incorporating correlations from collaborative behavior data using a hybrid matrix factorization technique and then ranks features using a mechanism based on the maximum volume algorithm. This approach identifies the most influential features, striking a balance between recommendation accuracy and computational efficiency. We conduct an extensive evaluation across various datasets and hybrid recommendation models, demonstrating that our method excels in cold-start scenarios by selecting minimal yet highly effective feature subsets. Even under strict feature reduction, our approach surpasses existing feature selection techniques while maintaining superior efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Maximum Impact with Fewer Features: Efficient Feature Selection for Cold-Start Recommenders through Collaborative Importance Weighting\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "maximum",
      "impact",
      "with"
    ],
    "category": "noticia"
  },
  {
    "title": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls",
    "title_es": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls",
    "url": "https://arxiv.org/abs/2508.06457",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06457v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated impressive fluency and reasoning capabilities, but their potential for misuse has raised growing concern. In this paper, we present ScamAgent, an autonomous multi-turn agent built on top of LLMs, capable of generating highly realistic scam call scripts that simulate real-world fraud scenarios. Unlike prior work focused on single-shot prompt misuse, ScamAgent maintains dialogue memory, adapts dynamically to simulated user responses, and employs deceptive persuasion strategies across conversational turns. We show that current LLM safety guardrails, including refusal mechanisms and content filters, are ineffective against such agent-based threats. Even models with strong prompt-level safeguards can be bypassed when prompts are decomposed, disguised, or delivered incrementally within an agent framework. We further demonstrate the transformation of scam scripts into lifelike voice calls using modern text-to-speech systems, completing a fully automated scam pipeline. Our findings highlight an urgent need for multi-turn safety auditing, agent-level control frameworks, and new methods to detect and disrupt conversational deception powered by generative AI.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "scamagents",
      "how",
      "ai"
    ],
    "category": "noticia"
  },
  {
    "title": "A Simple PTAS for Weighted $k$-means and Sensor Coverage",
    "title_es": "A Simple PTAS for Weighted $k$-means and Sensor Coverage",
    "url": "https://arxiv.org/abs/2508.06460",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06460v1 Announce Type: new \nAbstract: Clustering is a fundamental technique in data analysis, with the $k$-means being one of the widely studied objectives due to its simplicity and broad applicability. In many practical scenarios, data points come with associated weights that reflect their importance, frequency, or confidence. Given a weighted point set $P \\subset R^d$, where each point $p \\in P$ has a positive weight $w_p$, the goal is to compute a set of $k$ centers $C = \\{ c_1, c_2, \\ldots, c_k \\} \\subset R^d$ that minimizes the weighted clustering cost: $\\Delta_w(P,C) = \\sum_{p \\in P} w_p \\cdot d(p,C)^2$, where $d(p,C)$ denotes the Euclidean distance from $p$ to its nearest center in $C$. Although most existing coreset-based algorithms for $k$-means extend naturally to the weighted setting and provide a PTAS, no prior work has offered a simple, coreset-free PTAS designed specifically for the weighted $k$-means problem.\n  In this paper, we present a simple PTAS for weighted $k$-means that does not rely on coresets. Building upon the framework of Jaiswal, Kumar, and Sen (2012) for the unweighted case, we extend the result to the weighted setting by using the weighted $D^2$-sampling technique. Our algorithm runs in time $n d \\cdot 2^{O\\left(\\frac{k^2}{\\epsilon}\\right)}$ and outputs a set of $k$ centers whose total clustering cost is within a $(1 + \\epsilon)$-factor of the optimal cost. As a key application of the weighted $k$-means, we obtain a PTAS for the sensor coverage problem, which can also be viewed as a continuous locational optimization problem. For this problem, the best-known result prior to our work was an $O(\\log k)$-approximation by Deshpande (2014), whereas our algorithm guarantees a $(1 + \\epsilon)$-approximation to the optimal coverage cost even before applying refinement steps like Lloyd desent.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Simple PTAS for Weighted $k$-means and Sensor Coverage\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "simple",
      "ptas"
    ],
    "category": "noticia"
  },
  {
    "title": "LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection",
    "title_es": "LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection",
    "url": "https://arxiv.org/abs/2508.06467",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06467v1 Announce Type: new \nAbstract: The growing legal and ethical scrutiny of large language models (LLMs) necessitates effective machine unlearning, particularly for sensitive or unauthorized data. Existing empirical methods often yield incomplete forgetting or unintended degradation of unrelated knowledge due to poor localization. In this work, we propose GRIN: a modular and targeted framework for LLM unlearning. GRIN introduces a novel gradient-ratio-based metric to identify parameters most responsible for memorizing forget data. We then perform selective noise injection into these parameters prior to fine-tuning, which improves unlearning performance while maintaining model utility. Finally, we propose new evaluation metrics tailored to the LLM setting and validate our approach on standard benchmarks such as TOFU, WMDP, and SafePKU.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "llm",
      "unlearning",
      "using"
    ],
    "category": "noticia"
  },
  {
    "title": "An Online Multi-dimensional Knapsack Approach for Slice Admission Control",
    "title_es": "An Online Multi-dimensional Knapsack Approach for Slice Admission Control",
    "url": "https://arxiv.org/abs/2508.06468",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06468v1 Announce Type: new \nAbstract: Network Slicing has emerged as a powerful technique to enable cost-effective, multi-tenant communications and services over a shared physical mobile network infrastructure. One major challenge of service provisioning in slice-enabled networks is the uncertainty in the demand for the limited network resources that must be shared among existing slices and potentially new Network Slice Requests. In this paper, we consider admission control of Network Slice Requests in an online setting, with the goal of maximizing the long-term revenue received from admitted requests. We model the Slice Admission Control problem as an Online Multidimensional Knapsack Problem and present two reservation-based policies and their algorithms, which have a competitive performance for Online Multidimensional Knapsack Problems. Through Monte Carlo simulations, we evaluate the performance of our online admission control method in terms of average revenue gained by the Infrastructure Provider, system resource utilization, and the ratio of accepted slice requests. We compare our approach with those of the online First Come First Serve greedy policy. The simulation's results prove that our proposed online policies increase revenues for Infrastructure Providers by up to 12.9 % while reducing the average resource consumption by up to 1.7% In particular, when the tenants' economic inequality increases, an Infrastructure Provider who adopts our proposed online admission policies gains higher revenues compared to an Infrastructure Provider who adopts First Come First Serve.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"An Online Multi-dimensional Knapsack Approach for Slice Admission Control\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "an",
      "online",
      "multidimensional"
    ],
    "category": "noticia"
  },
  {
    "title": "A Geometric Analysis of Gains from Trade",
    "title_es": "A Geometric Analysis of Gains from Trade",
    "url": "https://arxiv.org/abs/2508.06469",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06469v1 Announce Type: new \nAbstract: We provide a geometric proof that the random proposer mechanism is a $4$-approximation to the first-best gains from trade in bilateral exchange. We then refine this geometric analysis to recover the state-of-the-art approximation ratio of $3.15$.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Geometric Analysis of Gains from Trade\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "geometric",
      "analysis"
    ],
    "category": "noticia"
  },
  {
    "title": "Generative AI and the Future of the Digital Commons: Five Open Questions and Knowledge Gaps",
    "title_es": "Generative AI and the Future of the Digital Commons: Five Open Questions and Knowledge Gaps",
    "url": "https://arxiv.org/abs/2508.06470",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06470v1 Announce Type: new \nAbstract: The rapid advancement of Generative AI (GenAI) relies heavily on the digital commons, a vast collection of free and open online content that is created, shared, and maintained by communities. However, this relationship is becoming increasingly strained due to financial burdens, decreased contributions, and misalignment between AI models and community norms. As we move deeper into the GenAI era, it is essential to examine the interdependent relationship between GenAI, the long-term sustainability of the digital commons, and the equity of current AI development practices. We highlight five critical questions that require urgent attention: 1. How can we prevent the digital commons from being threatened by undersupply as individuals cease contributing to the commons and turn to Generative AI for information? 2. How can we mitigate the risk of the open web closing due to restrictions on access to curb AI crawlers? 3. How can technical standards and legal frameworks be updated to reflect the evolving needs of organizations hosting common content? 4. What are the effects of increased synthetic content in open knowledge databases, and how can we ensure their integrity? 5. How can we account for and distribute the infrastructural and environmental costs of providing data for AI training? We emphasize the need for more responsible practices in AI development, recognizing the digital commons not only as content but as a collaborative and decentralized form of knowledge governance, which relies on the practice of \"commoning\" - making, maintaining, and protecting shared and open resources. Ultimately, our goal is to stimulate discussion and research on the intersection of Generative AI and the digital commons, with the aim of developing an \"AI commons\" and public infrastructures for AI development that support the long-term health of the digital commons.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Generative AI and the Future of the Digital Commons: Five Open Questions and Knowledge Gaps\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "generative",
      "ai",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models",
    "title_es": "GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models",
    "url": "https://arxiv.org/abs/2508.06471",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06471v1 Announce Type: new \nAbstract: We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language model with 355B total parameters and 32B activated parameters, featuring a hybrid reasoning method that supports both thinking and direct response modes. Through multi-stage training on 23T tokens and comprehensive post-training with expert model iteration and reinforcement learning, GLM-4.5 achieves strong performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer parameters than several competitors, GLM-4.5 ranks 3rd overall among all evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance research in reasoning and agentic AI systems. Code, models, and more information are available at https://github.com/zai-org/GLM-4.5.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "glm",
      "agentic",
      "reasoning"
    ],
    "category": "noticia"
  },
  {
    "title": "HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning",
    "title_es": "HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning",
    "url": "https://arxiv.org/abs/2508.06475",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06475v1 Announce Type: new \nAbstract: Haptic captioning is the task of generating natural language descriptions from haptic signals, such as vibrations, for use in virtual reality, accessibility, and rehabilitation applications. While previous multimodal research has focused primarily on vision and audio, haptic signals for the sense of touch remain underexplored. To address this gap, we formalize the haptic captioning task and propose HapticLLaMA, a multimodal sensory language model that interprets vibration signals into descriptions in a given sensory, emotional, or associative category. We investigate two types of haptic tokenizers, a frequency-based tokenizer and an EnCodec-based tokenizer, that convert haptic signals into sequences of discrete units, enabling their integration with the LLaMA model. HapticLLaMA is trained in two stages: (1) supervised fine-tuning using the LLaMA architecture with LoRA-based adaptation, and (2) fine-tuning via reinforcement learning from human feedback (RLHF). We assess HapticLLaMA's captioning performance using both automated n-gram metrics and human evaluation. HapticLLaMA demonstrates strong capability in interpreting haptic vibration signals, achieving a METEOR score of 59.98 and a BLEU-4 score of 32.06 respectively. Additionally, over 61% of the generated captions received human ratings above 3.5 on a 7-point scale, with RLHF yielding a 10% improvement in the overall rating distribution, indicating stronger alignment with human haptic perception. These findings highlight the potential of large language models to process and adapt to sensory data.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hapticllama",
      "a",
      "multimodal"
    ],
    "category": "noticia"
  },
  {
    "title": "On the Parallel Complexity of Identifying Groups and Quasigroups via Decompositions",
    "title_es": "On the Parallel Complexity of Identifying Groups and Quasigroups via Decompositions",
    "url": "https://arxiv.org/abs/2508.06478",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06478v1 Announce Type: new \nAbstract: In this paper, we investigate the computational complexity of isomorphism testing for finite groups and quasigroups, given by their multiplication tables. We crucially take advantage of their various decompositions to show the following:\n  - We first consider the class $\\mathcal{C}$ of groups that admit direct product decompositions, where each indecompsable factor is $O(1)$-generated, and either perfect or centerless. We show any group in $\\mathcal{C}$ is identified by the $O(1)$-dimensional count-free Weisfeiler--Leman (WL) algorithm with $O(\\log \\log n)$ rounds, and the $O(1)$-dimensional counting WL algorithm with $O(1)$ rounds. Consequently, the isomorphism problem for $\\mathcal{C}$ is in $\\textsf{L}$. The previous upper bound for this class was $\\textsf{TC}^{1}$, using $O(\\log n)$ rounds of the $O(1)$-dimensional counting WL (Grochow and Levet, FCT 2023).\n  - We next consider more generally, the class of groups where each indecomposable factor is $O(1)$-generated. We exhibit an $\\textsf{AC}^{3}$ canonical labeling procedure for this class. Here, we accomplish this by showing that in the multiplication table model, the direct product decomposition can be computed in $\\textsf{AC}^{3}$, parallelizing the work of Kayal and Nezhmetdinov (ICALP 2009).\n  - Isomorphism testing between a central quasigroup $G$ and an arbitrary quasigroup $H$ is in $\\textsf{NC}$. Here, we take advantage of the fact that central quasigroups admit an affine decomposition in terms of an underlying Abelian group. Only the trivial bound of $n^{\\log(n)+O(1)}$-time was previously known for isomorphism testing of central quasigroups.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"On the Parallel Complexity of Identifying Groups and Quasigroups via Decompositions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "on",
      "the",
      "parallel"
    ],
    "category": "noticia"
  },
  {
    "title": "The Problem of Atypicality in LLM-Powered Psychiatry",
    "title_es": "The Problem of Atypicality in LLM-Powered Psychiatry",
    "url": "https://arxiv.org/abs/2508.06479",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06479v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly proposed as scalable solutions to the global mental health crisis. But their deployment in psychiatric contexts raises a distinctive ethical concern: the problem of atypicality. Because LLMs generate outputs based on population-level statistical regularities, their responses -- while typically appropriate for general users -- may be dangerously inappropriate when interpreted by psychiatric patients, who often exhibit atypical cognitive or interpretive patterns. We argue that standard mitigation strategies, such as prompt engineering or fine-tuning, are insufficient to resolve this structural risk. Instead, we propose dynamic contextual certification (DCC): a staged, reversible and context-sensitive framework for deploying LLMs in psychiatry, inspired by clinical translation and dynamic safety models from artificial intelligence governance. DCC reframes chatbot deployment as an ongoing epistemic and ethical process that prioritises interpretive safety over static performance benchmarks. Atypicality, we argue, cannot be eliminated -- but it can, and must, be proactively managed.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"The Problem of Atypicality in LLM-Powered Psychiatry\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "problem",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Post-training for Efficient Communication via Convention Formation",
    "title_es": "Post-training for Efficient Communication via Convention Formation",
    "url": "https://arxiv.org/abs/2508.06482",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06482v1 Announce Type: new \nAbstract: Humans communicate with increasing efficiency in multi-turn interactions, by adapting their language and forming ad-hoc conventions. In contrast, prior work shows that LLMs do not naturally show this behavior. We develop a post-training process to develop this ability through targeted fine-tuning on heuristically identified demonstrations of convention formation. We evaluate with two new benchmarks focused on this capability. First, we design a focused, cognitively-motivated interaction benchmark that consistently elicits strong convention formation trends in humans. Second, we create a new document-grounded reference completion task that reflects in-the-wild convention formation behavior. Our studies show significantly improved convention formation abilities in post-trained LLMs across the two evaluation methods.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Post-training for Efficient Communication via Convention Formation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "posttraining",
      "for",
      "efficient"
    ],
    "category": "noticia"
  },
  {
    "title": "Non-programmers Assessing AI-Generated Code: A Case Study of Business Users Analyzing Data",
    "title_es": "Non-programmers Assessing AI-Generated Code: A Case Study of Business Users Analyzing Data",
    "url": "https://arxiv.org/abs/2508.06484",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06484v1 Announce Type: new \nAbstract: Non-technical end-users increasingly rely on AI code generation to perform technical tasks like data analysis. However, large language models (LLMs) remain unreliable, and it is unclear whether end-users can effectively identify model errors $\\unicode{x2014}$ especially in realistic and domain-specific scenarios. We surveyed marketing and sales professionals to assess their ability to critically evaluate LLM-generated analyses of marketing data. Participants were shown natural language explanations of the AI's code, repeatedly informed the AI often makes mistakes, and explicitly prompted to identify them. Yet, participants frequently failed to detect critical flaws that could compromise decision-making, many of which required no technical knowledge to recognize. To investigate why, we reformatted AI responses into clearly delineated steps and provided alternative approaches for each decision to support critical evaluation. While these changes had a positive effect, participants often struggled to reason through the AI's steps and alternatives. Our findings suggest that business professionals cannot reliably verify AI-generated data analyses on their own and explore reasons why to inform future designs. As non-programmers adopt code-generating AI for technical tasks, unreliable AI and insufficient human oversight poses risks of unsafe or low-quality decisions.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Non-programmers Assessing AI-Generated Code: A Case Study of Business Users Analyzing Data\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nonprogrammers",
      "assessing",
      "aigenerated"
    ],
    "category": "noticia"
  },
  {
    "title": "WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion",
    "title_es": "WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion",
    "url": "https://arxiv.org/abs/2508.06485",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06485v1 Announce Type: new \nAbstract: Urbanization, climate change, and agricultural stress are increasing the demand for precise and timely environmental monitoring. Land Surface Temperature (LST) is a key variable in this context and is retrieved from remote sensing satellites. However, these systems face a trade-off between spatial and temporal resolution. While spatio-temporal fusion methods offer promising solutions, few have addressed the estimation of daily LST at 10 m resolution. In this study, we present WGAST, a Weakly-Supervised Generative Network for Daily 10 m LST Estimation via Spatio-Temporal Fusion of Terra MODIS, Landsat 8, and Sentinel-2. WGAST is the first end-to-end deep learning framework designed for this task. It adopts a conditional generative adversarial architecture, with a generator composed of four stages: feature extraction, fusion, LST reconstruction, and noise suppression. The first stage employs a set of encoders to extract multi-level latent representations from the inputs, which are then fused in the second stage using cosine similarity, normalization, and temporal attention mechanisms. The third stage decodes the fused features into high-resolution LST, followed by a Gaussian filter to suppress high-frequency noise. Training follows a weakly supervised strategy based on physical averaging principles and reinforced by a PatchGAN discriminator. Experiments demonstrate that WGAST outperforms existing methods in both quantitative and qualitative evaluations. Compared to the best-performing baseline, on average, WGAST reduces RMSE by 17.18% and improves SSIM by 11.00%. Furthermore, WGAST is robust to cloud-induced LST and effectively captures fine-scale thermal patterns, as validated against 33 ground-based sensors. The code is available at https://github.com/Sofianebouaziz1/WGAST.git.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "wgast",
      "weaklysupervised",
      "generative"
    ],
    "category": "noticia"
  },
  {
    "title": "Does block size matter in randomized block Krylov low-rank approximation?",
    "title_es": "Does block size matter in randomized block Krylov low-rank approximation?",
    "url": "https://arxiv.org/abs/2508.06486",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06486v1 Announce Type: new \nAbstract: We study the problem of computing a rank-$k$ approximation of a matrix using randomized block Krylov iteration. Prior work has shown that, for block size $b = 1$ or $b = k$, a $(1 + \\varepsilon)$-factor approximation to the best rank-$k$ approximation can be obtained after $\\tilde O(k/\\sqrt{\\varepsilon})$ matrix-vector products with the target matrix. On the other hand, when $b$ is between $1$ and $k$, the best known bound on the number of matrix-vector products scales with $b(k-b)$, which could be as large as $O(k^2)$. Nevertheless, in practice, the performance of block Krylov methods is often optimized by choosing a block size $1 \\ll b \\ll k$. We resolve this theory-practice gap by proving that randomized block Krylov iteration produces a $(1 + \\varepsilon)$-factor approximate rank-$k$ approximation using $\\tilde O(k/\\sqrt{\\varepsilon})$ matrix-vector products for any block size $1\\le b\\le k$. Our analysis relies on new bounds for the minimum singular value of a random block Krylov matrix, which may be of independent interest. Similar bounds are central to recent breakthroughs on faster algorithms for sparse linear systems [Peng & Vempala, SODA 2021; Nie, STOC 2022].",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Does block size matter in randomized block Krylov low-rank approximation?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "does",
      "block",
      "size"
    ],
    "category": "noticia"
  },
  {
    "title": "Weak approximation of stochastic differential equations with sticky boundary conditions",
    "title_es": "Weak approximation of stochastic differential equations with sticky boundary conditions",
    "url": "https://arxiv.org/abs/2508.06487",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06487v1 Announce Type: new \nAbstract: Sticky diffusion models a Markovian particle experiencing reflection and temporary adhesion phenomena at the boundary. Numerous numerical schemes exist for approximating stopped or reflected stochastic differential equations (SDEs), but this is not the case for sticky SDEs. In this paper, we construct and analyze half-order and first-order numerical schemes for the weak approximation of stochastic differential equations with sticky boundary conditions. We present the algorithms in general setting such that they can be used to solve general linear parabolic partial differential equations with second-order sticky boundary condition via the probabilistic representations of their solutions. Since the sticky diffusion spends non-zero amount of time on boundary, it poses extra challenge in designing the schemes and obtaining their order of convergence. We support the theoretical results with numerical experiments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Weak approximation of stochastic differential equations with sticky boundary conditions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "weak",
      "approximation",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Voting-Based Semi-Parallel Proof-of-Work Protocol",
    "title_es": "Voting-Based Semi-Parallel Proof-of-Work Protocol",
    "url": "https://arxiv.org/abs/2508.06489",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06489v1 Announce Type: new \nAbstract: Parallel Proof-of-Work (PoW) protocols are suggested to improve the safety guarantees, transaction throughput and confirmation latencies of Nakamoto consensus. In this work, we first consider the existing parallel PoW protocols and develop hard-coded incentive attack structures. Our theoretical results and simulations show that the existing parallel PoW protocols are more vulnerable to incentive attacks than the Nakamoto consensus, e.g., attacks have smaller profitability threshold and they result in higher relative rewards. Next, we introduce a voting-based semi-parallel PoW protocol that outperforms both Nakamoto consensus and the existing parallel PoW protocols from most practical perspectives such as communication overheads, throughput, transaction conflicts, incentive compatibility of the protocol as well as a fair distribution of transaction fees among the voters and the leaders. We use state-of-the-art analysis to evaluate the consistency of the protocol and consider Markov decision process (MDP) models to substantiate our claims about the resilience of our protocol against incentive attacks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Voting-Based Semi-Parallel Proof-of-Work Protocol\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "votingbased",
      "semiparallel",
      "proofofwork"
    ],
    "category": "noticia"
  },
  {
    "title": "Effective Training Data Synthesis for Improving MLLM Chart Understanding",
    "title_es": "Effective Training Data Synthesis for Improving MLLM Chart Understanding",
    "url": "https://arxiv.org/abs/2508.06492",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06492v1 Announce Type: new \nAbstract: Being able to effectively read scientific plots, or chart understanding, is a central part toward building effective agents for science. However, existing multimodal large language models (MLLMs), especially open-source ones, are still falling behind with a typical success rate of 30%-50% on challenging benchmarks. Previous studies on fine-tuning MLLMs with synthetic charts are often restricted by their inadequate similarity to the real charts, which could compromise model training and performance on complex real-world charts. In this study, we show that modularizing chart generation and diversifying visual details improves chart understanding capabilities. In particular, we design a five-step data synthesis pipeline, where we separate data and function creation for single plot generation, condition the generation of later subplots on earlier ones for multi-subplot figures, visually diversify the generated figures, filter out low quality data, and finally generate the question-answer (QA) pairs with GPT-4o. This approach allows us to streamline the generation of fine-tuning datasets and introduce the effective chart dataset (ECD), which contains 10k+ chart images and 300k+ QA pairs, covering 25 topics and featuring 250+ chart type combinations with high visual complexity. We show that ECD consistently improves the performance of various MLLMs on a range of real-world and synthetic test sets. Code, data and models are available at: https://github.com/yuweiyang-anu/ECD.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Effective Training Data Synthesis for Improving MLLM Chart Understanding\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "effective",
      "training",
      "data"
    ],
    "category": "noticia"
  },
  {
    "title": "LightSwitch: Multi-view Relighting with Material-guided Diffusion",
    "title_es": "LightSwitch: Multi-view Relighting with Material-guided Diffusion",
    "url": "https://arxiv.org/abs/2508.06494",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06494v1 Announce Type: new \nAbstract: Recent approaches for 3D relighting have shown promise in integrating 2D image relighting generative priors to alter the appearance of a 3D representation while preserving the underlying structure. Nevertheless, generative priors used for 2D relighting that directly relight from an input image do not take advantage of intrinsic properties of the subject that can be inferred or cannot consider multi-view data at scale, leading to subpar relighting. In this paper, we propose Lightswitch, a novel finetuned material-relighting diffusion framework that efficiently relights an arbitrary number of input images to a target lighting condition while incorporating cues from inferred intrinsic properties. By using multi-view and material information cues together with a scalable denoising scheme, our method consistently and efficiently relights dense multi-view data of objects with diverse material compositions. We show that our 2D relighting prediction quality exceeds previous state-of-the-art relighting priors that directly relight from images. We further demonstrate that LightSwitch matches or outperforms state-of-the-art diffusion inverse rendering methods in relighting synthetic and real objects in as little as 2 minutes.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LightSwitch: Multi-view Relighting with Material-guided Diffusion\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lightswitch",
      "multiview",
      "relighting"
    ],
    "category": "noticia"
  },
  {
    "title": "Indian Legal NLP Benchmarks : A Survey",
    "title_es": "Indian Legal NLP Benchmarks : A Survey",
    "url": "https://arxiv.org/abs/2107.06056",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2107.06056v1 Announce Type: cross \nAbstract: Availability of challenging benchmarks is the key to advancement of AI in a specific field.Since Legal Text is significantly different than normal English text, there is a need to create separate Natural Language Processing benchmarks for Indian Legal Text which are challenging and focus on tasks specific to Legal Systems. This will spur innovation in applications of Natural language Processing for Indian Legal Text and will benefit AI community and Legal fraternity. We review the existing work in this area and propose ideas to create new benchmarks for Indian Legal Natural Language Processing.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Indian Legal NLP Benchmarks : A Survey\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "indian",
      "legal",
      "nlp"
    ],
    "category": "noticia"
  },
  {
    "title": "Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient",
    "title_es": "Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient",
    "url": "https://arxiv.org/abs/2304.04475",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2304.04475v1 Announce Type: cross \nAbstract: To mitigate the impact of the pandemic, several measures include lockdowns, rapid vaccination programs, school closures, and economic stimulus. These interventions can have positive or unintended negative consequences. Current research to model and determine an optimal intervention automatically through round-tripping is limited by the simulation objectives, scale (a few thousand individuals), model types that are not suited for intervention studies, and the number of intervention strategies they can explore (discrete vs continuous). We address these challenges using a Deep Deterministic Policy Gradient (DDPG) based policy optimization framework on a large-scale (100,000 individual) epidemiological agent-based simulation where we perform multi-objective optimization. We determine the optimal policy for lockdown and vaccination in a minimalist age-stratified multi-vaccine scenario with a basic simulation for economic activity. With no lockdown and vaccination (mid-age and elderly), results show optimal economy (individuals below the poverty line) with balanced health objectives (infection, and hospitalization). An in-depth simulation is needed to further validate our results and open-source our framework.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "epidemic",
      "control",
      "on"
    ],
    "category": "noticia"
  },
  {
    "title": "SHACL Validation in the Presence of Ontologies: Semantics and Rewriting Techniques",
    "title_es": "SHACL Validation in the Presence of Ontologies: Semantics and Rewriting Techniques",
    "url": "https://arxiv.org/abs/2507.12286",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.12286v1 Announce Type: cross \nAbstract: SHACL and OWL are two prominent W3C standards for managing RDF data. These languages share many features, but they have one fundamental difference: OWL, designed for inferring facts from incomplete data, makes the open-world assumption, whereas SHACL is a constraint language that treats the data as complete and must be validated under the closed-world assumption. The combination of both formalisms is very appealing and has been called for, but their semantic gap is a major challenge, semantically and computationally. In this paper, we advocate a semantics for SHACL validation in the presence of ontologies based on core universal models. We provide a technique for constructing these models for ontologies in the rich data-tractable description logic Horn-ALCHIQ. Furthermore, we use a finite representation of this model to develop a rewriting technique that reduces SHACL validation in the presence of ontologies to standard validation. Finally, we study the complexity of SHACL validation in the presence of ontologies, and show that even very simple ontologies make the problem EXPTIME-complete, and PTIME-complete in data complexity.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SHACL Validation in the Presence of Ontologies: Semantics and Rewriting Techniques\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "shacl",
      "validation",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Performance and Storage Analysis of CRYSTALS Kyber as a Post Quantum Replacement for RSA and ECC",
    "title_es": "Performance and Storage Analysis of CRYSTALS Kyber as a Post Quantum Replacement for RSA and ECC",
    "url": "https://arxiv.org/abs/2508.01694",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.01694v3 Announce Type: cross \nAbstract: The steady advancement in quantum computer error correction technology has pushed the current record to 48 stable logical qubits, bringing us closer to machines capable of running Shor's algorithm at scales that threaten RSA and ECC cryptography. While the timeline for developing such quantum computers remains uncertain, the cryptographic community must prepare for the transition to quantum-resistant algorithms. CRYSTALS-Kyber, standardized by NIST in 2022, represents a leading post-quantum cryptographic solution, but widespread adoption faces significant challenges. If this migration follows patterns similar to the SHA-1 to SHA-2 transition, organizations may experience prolonged periods of vulnerability, with substantial security and economic consequences. This study evaluates Kyber's practical viability through performance testing across various implementation schemes, utilizing only standard built-in processor acceleration features, some of which include AES-NI and ASIMD, without any specialized hardware additions. Our findings demonstrate that Kyber provides robust security guarantees against quantum attacks while maintaining acceptable performance profiles for most contemporary applications, utilizing only commodity hardware with manufacturer-provided acceleration capabilities.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Performance and Storage Analysis of CRYSTALS Kyber as a Post Quantum Replacement for RSA and ECC\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "performance",
      "and",
      "storage"
    ],
    "category": "noticia"
  },
  {
    "title": "Moment Estimate and Variational Approach for Learning Generalized Diffusion with Non-gradient Structures",
    "title_es": "Moment Estimate and Variational Approach for Learning Generalized Diffusion with Non-gradient Structures",
    "url": "https://arxiv.org/abs/2508.01854",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.01854v2 Announce Type: cross \nAbstract: This paper proposes a data-driven learning framework for identifying governing laws of generalized diffusions with non-gradient components. By combining energy dissipation laws with a physically consistent penalty and first-moment evolution, we design a two-stage method to recover the pseudo-potential and rotation in the pointwise orthogonal decomposition of a class of non-gradient drifts in generalized diffusions. Our two-stage method is applied to complex generalized diffusion processes including dissipation-rotation dynamics, rough pseudo-potentials and noisy data. Representative numerical experiments demonstrate the effectiveness of our approach for learning physical laws in non-gradient generalized diffusions.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Moment Estimate and Variational Approach for Learning Generalized Diffusion with Non-gradient Structures\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "moment",
      "estimate",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Neural Field-Based 3D Surface Reconstruction of Microstructures from Multi-Detector Signals in Scanning Electron Microscopy",
    "title_es": "Neural Field-Based 3D Surface Reconstruction of Microstructures from Multi-Detector Signals in Scanning Electron Microscopy",
    "url": "https://arxiv.org/abs/2508.04728",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.04728v1 Announce Type: cross \nAbstract: The scanning electron microscope (SEM) is a widely used imaging device in scientific research and industrial applications. Conventional two-dimensional (2D) SEM images do not directly reveal the three-dimensional (3D) topography of micro samples, motivating the development of SEM 3D surface reconstruction methods. However, reconstruction of complex microstructures remains challenging for existing methods due to the limitations of discrete 3D representations, the need for calibration with reference samples, and shadow-induced gradient errors. Here, we introduce NFH-SEM, a neural field-based hybrid SEM 3D reconstruction method that takes multi-view, multi-detector 2D SEM images as input and fuses geometric and photometric information into a continuous neural field representation. NFH-SEM eliminates the manual calibration procedures through end-to-end self-calibration and automatically disentangles shadows from SEM images during training, enabling accurate reconstruction of intricate microstructures. We validate the effectiveness of NFH-SEM on real and simulated datasets. Our experiments show high-fidelity reconstructions of diverse, challenging samples, including two-photon lithography microstructures, peach pollen, and silicon carbide particle surfaces, demonstrating precise detail and broad applicability.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Neural Field-Based 3D Surface Reconstruction of Microstructures from Multi-Detector Signals in Scanning Electron Microscopy\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "neural",
      "fieldbased",
      "d"
    ],
    "category": "noticia"
  },
  {
    "title": "AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models",
    "title_es": "AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models",
    "url": "https://arxiv.org/abs/2508.04748",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.04748v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) have shown promise in assisting molecular property prediction tasks but often rely on human-crafted prompts and chain-of-thought templates. While recent advanced large reasoning models like DeepSeek-R1 employ reinforcement learning for an extended ``thinking'' process, their reasoning can be verbose and lack relevance. We introduce AttriLens-Mol, an attribute-guided reinforcement learning framework for molecular property prediction with LLMs. AttriLens-Mol steers the model's reasoning by using: (1) a format reward encouraging attribute-based structured output, (2) a count reward to avoid enumerating irrelevant attributes, and (3) a rationality reward using advanced LLMs and RDKit to verify the relatedness of the generated attributes. This approach implicitly elicits the model's inherent knowledge of relevant molecular attributes during reasoning, enables making predictions for the molecular property more effectively. Experiments on both in-distribution and out-of-distribution datasets show that, training both 7B-size R1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with our proposed AttriLens-Mol method significantly boosts the performance, getting comparable or better results than supervised fine-tuning models (Mol-Instructions, ChemDFM, etc.) and advanced models (GPT-3.5, GPT-4o, DeepSeek-V3, DeepSeek-R1, etc.). Further, our extracted attributes for the target property, when used as features for an interpretable decision tree model, yield superior performance compared to attributes generated by prompting LLMs. This shows that AttriLens-Mol effectively elicits more relevant and predictive molecular attributes, leading to enhanced interpretability and performance for property prediction. We release the code in https://github.com/szu-tera/AttriLens-Mol.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "attrilensmol",
      "attribute",
      "guided"
    ],
    "category": "noticia"
  },
  {
    "title": "On the Classical Hardness of the Semidirect Discrete Logarithm Problem in Finite Groups",
    "title_es": "On the Classical Hardness of the Semidirect Discrete Logarithm Problem in Finite Groups",
    "url": "https://arxiv.org/abs/2508.05048",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05048v1 Announce Type: cross \nAbstract: The semidirect discrete logarithm problem (SDLP) in finite groups was proposed as a foundation for post-quantum cryptographic protocols, based on the belief that its non-abelian structure would resist quantum attacks. However, recent results have shown that SDLP in finite groups admits efficient quantum algorithms, undermining its quantum resistance. This raises a fundamental question: does the SDLP offer any computational advantages over the standard discrete logarithm problem (DLP) against classical adversaries? In this work, we investigate the classical hardness of SDLP across different finite group platforms. We establish that the group-case SDLP can be reformulated as a generalized discrete logarithm problem, enabling adaptation of classical algorithms to study its complexity. We present a concrete adaptation of the Baby-Step Giant-Step algorithm for SDLP, achieving time and space complexity $O(\\sqrt{r})$ where $r$ is the period of the underlying cycle structure. Through theoretical analysis and experimental validation in SageMath, we demonstrate that the classical hardness of SDLP is highly platform-dependent and does not uniformly exceed that of standard DLP. In finite fields $\\mathbb{F}_p^*$, both problems exhibit comparable complexity. Surprisingly, in elliptic curves $E(\\mathbb{F}_p)$, the SDLP becomes trivial due to the bounded automorphism group, while in elementary abelian groups $\\mathbb{F}_p^n$, the SDLP can be harder than DLP, with complexity varying based on the eigenvalue structure of the automorphism. Our findings reveal that the non-abelian structure of semidirect products does not inherently guarantee increased classical hardness, suggesting that the search for classically hard problems for cryptographic applications requires more careful consideration of the underlying algebraic structures.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"On the Classical Hardness of the Semidirect Discrete Logarithm Problem in Finite Groups\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "on",
      "the",
      "classical"
    ],
    "category": "noticia"
  },
  {
    "title": "Domain-driven Metrics for Reinforcement Learning: A Case Study on Epidemic Control using Agent-based Simulation",
    "title_es": "Domain-driven Metrics for Reinforcement Learning: A Case Study on Epidemic Control using Agent-based Simulation",
    "url": "https://arxiv.org/abs/2508.05154",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05154v1 Announce Type: cross \nAbstract: For the development and optimization of agent-based models (ABMs) and rational agent-based models (RABMs), optimization algorithms such as reinforcement learning are extensively used. However, assessing the performance of RL-based ABMs and RABMS models is challenging due to the complexity and stochasticity of the modeled systems, and the lack of well-standardized metrics for comparing RL algorithms. In this study, we are developing domain-driven metrics for RL, while building on state-of-the-art metrics. We demonstrate our ``Domain-driven-RL-metrics'' using policy optimization on a rational ABM disease modeling case study to model masking behavior, vaccination, and lockdown in a pandemic. Our results show the use of domain-driven rewards in conjunction with traditional and state-of-the-art metrics for a few different simulation scenarios such as the differential availability of masks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Domain-driven Metrics for Reinforcement Learning: A Case Study on Epidemic Control using Agent-based Simulation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "domaindriven",
      "metrics",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Random Walk Learning and the Pac-Man Attack",
    "title_es": "Random Walk Learning and the Pac-Man Attack",
    "url": "https://arxiv.org/abs/2508.05663",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05663v1 Announce Type: cross \nAbstract: Random walk (RW)-based algorithms have long been popular in distributed systems due to low overheads and scalability, with recent growing applications in decentralized learning. However, their reliance on local interactions makes them inherently vulnerable to malicious behavior. In this work, we investigate an adversarial threat that we term the ``Pac-Man'' attack, in which a malicious node probabilistically terminates any RW that visits it. This stealthy behavior gradually eliminates active RWs from the network, effectively halting the learning process without triggering failure alarms. To counter this threat, we propose the Average Crossing (AC) algorithm--a fully decentralized mechanism for duplicating RWs to prevent RW extinction in the presence of Pac-Man. Our theoretical analysis establishes that (i) the RW population remains almost surely bounded under AC and (ii) RW-based stochastic gradient descent remains convergent under AC, even in the presence of Pac-Man, with a quantifiable deviation from the true optimum. Our extensive empirical results on both synthetic and real-world datasets corroborate our theoretical findings. Furthermore, they uncover a phase transition in the extinction probability as a function of the duplication threshold. We offer theoretical insights by analyzing a simplified variant of the AC, which sheds light on the observed phase transition.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Random Walk Learning and the Pac-Man Attack\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "random",
      "walk",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "Quantum Resource Management in the NISQ Era: Implications and Perspectives from Software Engineering",
    "title_es": "Quantum Resource Management in the NISQ Era: Implications and Perspectives from Software Engineering",
    "url": "https://arxiv.org/abs/2508.05697",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05697v1 Announce Type: cross \nAbstract: Quantum computers represent a radical technological breakthrough in information processing by leveraging the principles of quantum mechanics to solve highly complex problems beyond the reach of classical systems. However, in the current NISQ era (noisy intermediate-scale quantum devices), the available hardware presents several limitations, such as a limited number of qubits, high error rates, and short coherence times. Efficient management of quantum resources, both physical and logical, is especially relevant in the design and deployment of quantum algorithms. In this paper, we analyze the role of resources in current uses of NISQ devices, identifying their relevance and implications for quantum software engineering. With this contribution, we aim to strengthen the field of Quantum Resource Estimation (QRE) and move toward scalable and reliable quantum software development",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Quantum Resource Management in the NISQ Era: Implications and Perspectives from Software Engineering\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "quantum",
      "resource",
      "management"
    ],
    "category": "noticia"
  },
  {
    "title": "A Physiologically-Constrained Neural Network Digital Twin Framework for Replicating Glucose Dynamics in Type 1 Diabetes",
    "title_es": "A Physiologically-Constrained Neural Network Digital Twin Framework for Replicating Glucose Dynamics in Type 1 Diabetes",
    "url": "https://arxiv.org/abs/2508.05705",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05705v1 Announce Type: cross \nAbstract: Simulating glucose dynamics in individuals with type 1 diabetes (T1D) is critical for developing personalized treatments and supporting data-driven clinical decisions. Existing models often miss key physiological aspects and are difficult to individualize. Here, we introduce physiologically-constrained neural network (NN) digital twins to simulate glucose dynamics in T1D. To ensure interpretability and physiological consistency, we first build a population-level NN state-space model aligned with a set of ordinary differential equations (ODEs) describing glucose regulation. This model is formally verified to conform to known T1D dynamics. Digital twins are then created by augmenting the population model with individual-specific models, which include personal data, such as glucose management and contextual information, capturing both inter- and intra-individual variability. We validate our approach using real-world data from the T1D Exercise Initiative study. Two weeks of data per participant were split into 5-hour sequences and simulated glucose profiles were compared to observed ones. Clinically relevant outcomes were used to assess similarity via paired equivalence t-tests with predefined clinical equivalence margins. Across 394 digital twins, glucose outcomes were equivalent between simulated and observed data: time in range (70-180 mg/dL) was 75.1$\\pm$21.2% (simulated) vs. 74.4$\\pm$15.4% (real; P180 mg/dL) 22.4$\\pm$22.0% vs. 22.6$\\pm$15.9% (P<0.001). Our framework can incorporate unmodeled factors like sleep and activity while preserving key dynamics. This approach enables personalized in silico testing of treatments, supports insulin optimization, and integrates physics-based and data-driven modeling. Code: https://github.com/mosqueralopez/T1DSim_AI",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Physiologically-Constrained Neural Network Digital Twin Framework for Replicating Glucose Dynamics in Type 1 Diabetes\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "physiologicallyconstrained",
      "neural"
    ],
    "category": "noticia"
  },
  {
    "title": "Reduction Techniques for Survival Analysis",
    "title_es": "Reduction Techniques for Survival Analysis",
    "url": "https://arxiv.org/abs/2508.05715",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05715v1 Announce Type: cross \nAbstract: In this work, we discuss what we refer to as reduction techniques for survival analysis, that is, techniques that \"reduce\" a survival task to a more common regression or classification task, without ignoring the specifics of survival data. Such techniques particularly facilitate machine learning-based survival analysis, as they allow for applying standard tools from machine and deep learning to many survival tasks without requiring custom learners. We provide an overview of different reduction techniques and discuss their respective strengths and weaknesses. We also provide a principled implementation of some of these reductions, such that they are directly available within standard machine learning workflows. We illustrate each reduction using dedicated examples and perform a benchmark analysis that compares their predictive performance to established machine learning methods for survival analysis.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Reduction Techniques for Survival Analysis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "reduction",
      "techniques",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "The vast world of quantum advantage",
    "title_es": "The vast world of quantum advantage",
    "url": "https://arxiv.org/abs/2508.05720",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05720v1 Announce Type: cross \nAbstract: The quest to identify quantum advantages lies at the heart of quantum technology. While quantum devices promise extraordinary capabilities, from exponential computational speedups to unprecedented measurement precision, distinguishing genuine advantages from mere illusions remains a formidable challenge. In this endeavor, quantum theorists are like prophets attempting to foretell the future, yet the boundary between visionary insight and unfounded fantasy is perilously thin. In this perspective, we examine our mathematical tools for navigating the vast world of quantum advantages across computation, learning, sensing, and communication. We explore five keystone properties: predictability, typicality, robustness, verifiability, and usefulness that define an ideal quantum advantage, and envision what new quantum advantages could arise in a future with ubiquitous quantum technology. We prove that some quantum advantages are inherently unpredictable using classical resources alone, suggesting a landscape far richer than what we can currently foresee. While mathematical rigor remains our indispensable guide, the ultimate power of quantum technologies may emerge from advantages we cannot yet conceive.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"The vast world of quantum advantage\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "vast",
      "world"
    ],
    "category": "noticia"
  },
  {
    "title": "CLAPP: The CLASS LLM Agent for Pair Programming",
    "title_es": "CLAPP: The CLASS LLM Agent for Pair Programming",
    "url": "https://arxiv.org/abs/2508.05728",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05728v1 Announce Type: cross \nAbstract: We introduce CLAPP (CLASS LLM Agent for Pair Programming), an interactive AI assistant designed to support researchers working with the Einstein-Boltzmann solver CLASS. CLAPP leverages large language models (LLMs) and domain-specific retrieval to provide conversational coding support for CLASS-answering questions, generating code, debugging errors, and producing plots. Its architecture combines multi-agent LLM orchestration, semantic search across CLASS documentation, and a live Python execution environment. Deployed as a user-friendly web application, CLAPP lowers the entry barrier for scientists unfamiliar with AI tools and enables more productive human-AI collaboration in computational and numerical cosmology. The app is available at https://classclapp.streamlit.app",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CLAPP: The CLASS LLM Agent for Pair Programming\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "clapp",
      "the",
      "class"
    ],
    "category": "noticia"
  },
  {
    "title": "Detecting Model Misspecification in Cosmology with Scale-Dependent Normalizing Flows",
    "title_es": "Detecting Model Misspecification in Cosmology with Scale-Dependent Normalizing Flows",
    "url": "https://arxiv.org/abs/2508.05744",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05744v1 Announce Type: cross \nAbstract: Current and upcoming cosmological surveys will produce unprecedented amounts of high-dimensional data, which require complex high-fidelity forward simulations to accurately model both physical processes and systematic effects which describe the data generation process. However, validating whether our theoretical models accurately describe the observed datasets remains a fundamental challenge. An additional complexity to this task comes from choosing appropriate representations of the data which retain all the relevant cosmological information, while reducing the dimensionality of the original dataset. In this work we present a novel framework combining scale-dependent neural summary statistics with normalizing flows to detect model misspecification in cosmological simulations through Bayesian evidence estimation. By conditioning our neural network models for data compression and evidence estimation on the smoothing scale, we systematically identify where theoretical models break down in a data-driven manner. We demonstrate a first application to our approach using matter and gas density fields from three CAMELS simulation suites with different subgrid physics implementations.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Detecting Model Misspecification in Cosmology with Scale-Dependent Normalizing Flows\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "detecting",
      "model",
      "misspecification"
    ],
    "category": "noticia"
  },
  {
    "title": "Evaluating Universal Machine Learning Force Fields Against Experimental Measurements",
    "title_es": "Evaluating Universal Machine Learning Force Fields Against Experimental Measurements",
    "url": "https://arxiv.org/abs/2508.05762",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05762v1 Announce Type: cross \nAbstract: Universal machine learning force fields (UMLFFs) promise to revolutionize materials science by enabling rapid atomistic simulations across the periodic table. However, their evaluation has been limited to computational benchmarks that may not reflect real-world performance. Here, we present UniFFBench, a comprehensive framework for evaluating UMLFFs against experimental measurements of ~1,500 carefully curated mineral structures spanning diverse chemical environments, bonding types, structural complexity, and elastic properties. Our systematic evaluation of six state-of-the-art UMLFFs reveals a substantial reality gap: models achieving impressive performance on computational benchmarks often fail when confronted with experimental complexity. Even the best-performing models exhibit higher density prediction error than the threshold required for practical applications. Most strikingly, we observe disconnects between simulation stability and mechanical property accuracy, with prediction errors correlating with training data representation rather than the modeling method. These findings demonstrate that while current computational benchmarks provide valuable controlled comparisons, they may overestimate model reliability when extrapolated to experimentally complex chemical spaces. Altogether, UniFFBench establishes essential experimental validation standards and reveals systematic limitations that must be addressed to achieve truly universal force field capabilities.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Evaluating Universal Machine Learning Force Fields Against Experimental Measurements\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "evaluating",
      "universal",
      "machine"
    ],
    "category": "noticia"
  },
  {
    "title": "Stochastic Trace Optimization of Parameter Dependent Matrices Based on Statistical Learning Theory",
    "title_es": "Stochastic Trace Optimization of Parameter Dependent Matrices Based on Statistical Learning Theory",
    "url": "https://arxiv.org/abs/2508.05764",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05764v1 Announce Type: cross \nAbstract: We consider matrices $\\boldsymbol{A}(\\boldsymbol\\theta)\\in\\mathbb{R}^{m\\times m}$ that depend, possibly nonlinearly, on a parameter $\\boldsymbol\\theta$ from a compact parameter space $\\Theta$. We present a Monte Carlo estimator for minimizing $\\text{trace}(\\boldsymbol{A}(\\boldsymbol\\theta))$ over all $\\boldsymbol\\theta\\in\\Theta$, and determine the sampling amount so that the backward error of the estimator is bounded with high probability. We derive two types of bounds, based on epsilon nets and on generic chaining. Both types predict a small sampling amount for matrices $\\boldsymbol{A}(\\boldsymbol\\theta)$ with small offdiagonal mass, and parameter spaces $\\Theta$ of small ``size.'' Dependence on the matrix dimension~$m$ is only weak or not explicit. The bounds based on epsilon nets are easier to evaluate and come with fully specified constants. In contrast, the bounds based on chaining depend on the Talagrand functionals which are difficult to evaluate, except in very special cases. Comparisons between the two types of bounds are difficult, although the literature suggests that chaining bounds can be superior.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Stochastic Trace Optimization of Parameter Dependent Matrices Based on Statistical Learning Theory\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "stochastic",
      "trace",
      "optimization"
    ],
    "category": "noticia"
  },
  {
    "title": "NanoCodec: Towards High-Quality Ultra Fast Speech LLM Inference",
    "title_es": "NanoCodec: Towards High-Quality Ultra Fast Speech LLM Inference",
    "url": "https://arxiv.org/abs/2508.05835",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05835v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) have significantly advanced audio processing by leveraging audio codecs to discretize audio into tokens, enabling the application of language modeling techniques to speech data. However, existing audio codecs often operate at high frame rates, leading to slow training and inference, particularly for autoregressive models. To address this, there is growing interest in low frame-rate audio codecs, which reduce the number of autoregressive steps required to generate one second of audio. In this paper, we conduct ablation studies to examine the impact of frame rate, bitrate, and causality on codec reconstruction quality. Based on our findings, we introduce NanoCodec, a state-of-the-art audio codec that achieves high-quality compression at just 12.5 frames per second (FPS). NanoCodec outperforms related works across various bitrate ranges, establishing a new benchmark for low-latency and efficient Speech LLM training and inference.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"NanoCodec: Towards High-Quality Ultra Fast Speech LLM Inference\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nanocodec",
      "towards",
      "highquality"
    ],
    "category": "noticia"
  },
  {
    "title": "MPS-JuliQAOA: User-friendly, Scalable MPS-based Simulation for Quantum Optimization",
    "title_es": "MPS-JuliQAOA: User-friendly, Scalable MPS-based Simulation for Quantum Optimization",
    "url": "https://arxiv.org/abs/2508.05883",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05883v1 Announce Type: cross \nAbstract: We present the MPS-JuliQAOA simulator, a user-friendly, open-source tool to simulate the Quantum Approximate Optimization Algorithm (QAOA) of any optimization problem that can be expressed as diagonal Hamiltonian. By leveraging Julia-language constructs and the ITensor package to implement a Matrix Product State (MPS) approach to simulating QAOA, MPS-Juli-QAOA effortlessly scales to 512 qubits and 20 simulation rounds on the standard de-facto benchmark 3-regular MaxCut QAOA problem. MPS-JuliQAOA also has built-in parameter finding capabilities, which is a crucial performance aspect of QAOA. We illustrate through examples that the user does not need to know MPS principles or complex automatic differentiation techniques to use MPS-JuliQAOA. We study the scalability of our tool with respect to runtime, memory usage and accuracy tradeoffs. Code available at https://github.com/lanl/JuliQAOA.jl/tree/mps.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MPS-JuliQAOA: User-friendly, Scalable MPS-based Simulation for Quantum Optimization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mpsjuliqaoa",
      "userfriendly",
      "scalable"
    ],
    "category": "noticia"
  },
  {
    "title": "Estimating the size of a set using cascading exclusion",
    "title_es": "Estimating the size of a set using cascading exclusion",
    "url": "https://arxiv.org/abs/2508.05901",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05901v1 Announce Type: cross \nAbstract: Let $S$ be a finite set, and $X_1,\\ldots,X_n$ an i.i.d. uniform sample from $S$. To estimate the size $|S|$, without further structure, one can wait for repeats and use the birthday problem. This requires a sample size of the order $|S|^\\frac{1}{2}$. On the other hand, if $S=\\{1,2,\\ldots,|S|\\}$, the maximum of the sample blown up by $n/(n-1)$ gives an efficient estimator based on any growing sample size. This paper gives refinements that interpolate between these extremes. A general non-asymptotic theory is developed. This includes estimating the volume of a compact convex set, the unseen species problem, and a host of testing problems that follow from the question `Is this new observation a typical pick from a large prespecified population?' We also treat regression style predictors. A general theorem gives non-parametric finite $n$ error bounds in all cases.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Estimating the size of a set using cascading exclusion\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "estimating",
      "the",
      "size"
    ],
    "category": "noticia"
  },
  {
    "title": "Hybrid Physics-Machine Learning Models for Quantitative Electron Diffraction Refinements",
    "title_es": "Hybrid Physics-Machine Learning Models for Quantitative Electron Diffraction Refinements",
    "url": "https://arxiv.org/abs/2508.05908",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05908v1 Announce Type: cross \nAbstract: High-fidelity electron microscopy simulations required for quantitative crystal structure refinements face a fundamental challenge: while physical interactions are well-described theoretically, real-world experimental effects are challenging to model analytically. To address this gap, we present a novel hybrid physics-machine learning framework that integrates differentiable physical simulations with neural networks. By leveraging automatic differentiation throughout the simulation pipeline, our method enables gradient-based joint optimization of physical parameters and neural network components representing experimental variables, offering superior scalability compared to traditional second-order methods. We demonstrate this framework through application to three-dimensional electron diffraction (3D-ED) structure refinement, where our approach learns complex thickness distributions directly from diffraction data rather than relying on simplified geometric models. This method achieves state-of-the-art refinement performance across synthetic and experimental datasets, recovering atomic positions, thermal displacements, and thickness profiles with high fidelity. The modular architecture proposed can naturally be extended to accommodate additional physical phenomena and extended to other electron microscopy techniques. This establishes differentiable hybrid modeling as a powerful new paradigm for quantitative electron microscopy, where experimental complexities have historically limited analysis.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hybrid Physics-Machine Learning Models for Quantitative Electron Diffraction Refinements\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hybrid",
      "physicsmachine",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "IRS-Assisted IoT Activity Detection Under Asynchronous Transmission and Heterogeneous Powers: Detectors and Performance Analysis",
    "title_es": "IRS-Assisted IoT Activity Detection Under Asynchronous Transmission and Heterogeneous Powers: Detectors and Performance Analysis",
    "url": "https://arxiv.org/abs/2508.05959",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05959v1 Announce Type: cross \nAbstract: This paper addresses the problem of activity detection in distributed Internet of Things (IoT) networks, where devices employ asynchronous transmissions with heterogeneous power levels to report their local observations. The system leverages an intelligent reflecting surface (IRS) to enhance detection reliability, with optional incorporation of a direct line-of-sight (LoS) path. We formulate the detection problem as a binary hypothesis test and develop four detectors: an optimal detector alongside three computationally efficient detectors designed for practical scenarios with different levels of prior knowledge about noise variance, channel state information, and device transmit powers. For each detector, we derive closed-form expressions for both detection and false alarm probabilities, establishing theoretical performance benchmarks. Extensive simulations validate our analytical results and systematically evaluate the impact of key system parameters including the number of antennas, samples, users, and IRS elements on detection performance. The proposed framework effectively bridges theoretical optimality with implementation practicality, providing a scalable solution for IRS-assisted IoT networks in emerging 6G systems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"IRS-Assisted IoT Activity Detection Under Asynchronous Transmission and Heterogeneous Powers: Detectors and Performance Analysis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "irsassisted",
      "iot",
      "activity"
    ],
    "category": "noticia"
  },
  {
    "title": "Kahan's Automatic Step-Size Control for Unconstrained Optimization",
    "title_es": "Kahan's Automatic Step-Size Control for Unconstrained Optimization",
    "url": "https://arxiv.org/abs/2508.06002",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06002v1 Announce Type: cross \nAbstract: The Barzilai and Borwein (BB) gradient method is one of the most widely-used line-search gradient methods. It computes the step-size for the current iterate by using the information carried in the previous iteration. Recently, William Kahan [Kahan, Automatic Step-Size Control for Minimization Iterations, Technical report, University of California, Berkeley CA, USA, 2019] proposed new Gradient Descent (KGD) step-size strategies which iterate the step-size itself by effectively utilizing the information in the previous iteration. In the quadratic model, such a new step-size is shown to be mathematically equivalent to the long BB step, but no rigorous mathematical proof of its efficiency and effectiveness for the general unconstrained minimization is available. In this paper, by this equivalence with the long BB step, we first derive a short version of KGD step-size and show that, for the strongly convex quadratic model with a Hessian matrix $H$, both the long and short KGD step-size (and hence BB step-sizes) gradient methods converge at least R-linearly with a rate $1-\\frac{1}{{\\rm cond}(H)}$. For the general unconstrained minimization, we further propose an adaptive framework to effectively use the KGD step-sizes; global convergence and local R-linear convergence rate are proved. Numerical experiments are conducted on the CUTEst collection as well as the practical logistic regression problems, and we compare the performance of the proposed methods with various BB step-size approaches and other recently proposed adaptive gradient methods to demonstrate the efficiency and robustness.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Kahan's Automatic Step-Size Control for Unconstrained Optimization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "kahans",
      "automatic",
      "stepsize"
    ],
    "category": "noticia"
  },
  {
    "title": "Multi-Functional Chirp Signalling for Next-Generation Multi-Carrier Wireless Networks: Communications, Sensing and ISAC Perspectives",
    "title_es": "Multi-Functional Chirp Signalling for Next-Generation Multi-Carrier Wireless Networks: Communications, Sensing and ISAC Perspectives",
    "url": "https://arxiv.org/abs/2508.06022",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06022v1 Announce Type: cross \nAbstract: To meet the increasingly demanding quality-of-service requirements of the next-generation multi-carrier mobile networks, it is essential to design multi-functional signalling schemes facilitating efficient, flexible, and reliable communication and sensing in complex wireless environments. As a compelling candidate, we advocate chirp signalling, beneficially amalgamating sequences (e.g., Zadoff-Chu sequences) with waveforms (e.g., chirp spread spectrum and frequency-modulated continuous wave (FMCW) radar), given their resilience against doubly selective channels. Besides chirp sequences, a wide range of chirp waveforms is considered, ranging from FMCW to affine frequency-division multiplexing (AFDM), to create a promising chirp multicarrier waveform. This study also highlights the advantages of such waveforms in supporting reliable high-mobility communications, plus integrated sensing and communications (ISAC). Finally, we outline several emerging research directions for chirp signalling designs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Multi-Functional Chirp Signalling for Next-Generation Multi-Carrier Wireless Networks: Communications, Sensing and ISAC Perspectives\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "multifunctional",
      "chirp",
      "signalling"
    ],
    "category": "noticia"
  },
  {
    "title": "Transfinite Iteration of Operator Transforms and Spectral Projections in Hilbert and Banach Spaces",
    "title_es": "Transfinite Iteration of Operator Transforms and Spectral Projections in Hilbert and Banach Spaces",
    "url": "https://arxiv.org/abs/2508.06025",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06025v1 Announce Type: cross \nAbstract: We study ordinal-indexed, multi-layer iterations of bounded operator transforms and prove convergence to spectral/ergodic projections under functional-calculus hypotheses. For normal operators on Hilbert space and polynomial or holomorphic layers that are contractive on the spectrum and fix the peripheral spectrum only at fixed points, the iterates converge in the strong operator topology by a countable stage to the spectral projection onto the joint peripheral fixed set. We describe spectral mapping at finite stages and identify the spectrum of the limit via the essential range. In reflexive Banach spaces, for Ritt or sectorial operators with a bounded H-infinity functional calculus, the composite layer is power-bounded and its mean-ergodic projection yields an idempotent commuting with the original operator; under a peripheral-separation condition the powers converge strongly to this projection. We provide explicit two-layer Schur filters, a concise Schur/Nevanlinna-Pick lemma, a Fejer-type monotonicity bound implying stabilization by the first countable limit (omega), examples that attain exactly the omega stage, and counterexamples outside the hypotheses.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Transfinite Iteration of Operator Transforms and Spectral Projections in Hilbert and Banach Spaces\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "transfinite",
      "iteration",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Post-apocalyptic computing from cellular automata",
    "title_es": "Post-apocalyptic computing from cellular automata",
    "url": "https://arxiv.org/abs/2508.06035",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06035v1 Announce Type: cross \nAbstract: Cellular automata are arrays of finite state machines that can exist in a finite number of states. These machines update their states simultaneously based on specific local rules that govern their interactions. This framework provides a simple yet powerful model for studying complex systems and emergent behaviors. We revisit and reconsider the traditional notion of an algorithm, proposing a novel perspective in which algorithms are represented through the dynamic state-space configurations of cellular automata. By doing so, we establish a conceptual framework that connects computation to physical processes in a unique and innovative way. This approach not only enhances our understanding of computation but also paves the way for the future development of unconventional computing devices. Such devices could be engineered to leverage the inherent computational capabilities of physical, chemical, and biological substrates. This opens up new possibilities for designing systems that are more efficient, adaptive, and capable of solving problems in ways that traditional silicon-based computers cannot. The integration of cellular automata into these domains highlights their potential as a transformative tool in the ongoing evolution of computational theory and practice.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Post-apocalyptic computing from cellular automata\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "postapocalyptic",
      "computing",
      "from"
    ],
    "category": "noticia"
  },
  {
    "title": "Data-Driven Density Steering via the Gromov-Wasserstein Optimal Transport Distance",
    "title_es": "Data-Driven Density Steering via the Gromov-Wasserstein Optimal Transport Distance",
    "url": "https://arxiv.org/abs/2508.06052",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06052v1 Announce Type: cross \nAbstract: We tackle the data-driven chance-constrained density steering problem using the Gromov-Wasserstein metric. The underlying dynamical system is an unknown linear controlled recursion, with the assumption that sufficiently rich input-output data from pre-operational experiments are available. The initial state is modeled as a Gaussian mixture, while the terminal state is required to match a specified Gaussian distribution. We reformulate the resulting optimal control problem as a difference-of-convex program and show that it can be efficiently and tractably solved using the DC algorithm. Numerical results validate our approach through various data-driven schemes.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Data-Driven Density Steering via the Gromov-Wasserstein Optimal Transport Distance\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "datadriven",
      "density",
      "steering"
    ],
    "category": "noticia"
  },
  {
    "title": "Lightweight Auto-bidding based on Traffic Prediction in Live Advertising",
    "title_es": "Lightweight Auto-bidding based on Traffic Prediction in Live Advertising",
    "url": "https://arxiv.org/abs/2508.06069",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06069v1 Announce Type: cross \nAbstract: Internet live streaming is widely used in online entertainment and e-commerce, where live advertising is an important marketing tool for anchors. An advertising campaign hopes to maximize the effect (such as conversions) under constraints (such as budget and cost-per-click). The mainstream control of campaigns is auto-bidding, where the performance depends on the decision of the bidding algorithm in each request. The most widely used auto-bidding algorithms include Proportional-Integral-Derivative (PID) control, linear programming (LP), reinforcement learning (RL), etc. Existing methods either do not consider the entire time traffic, or have too high computational complexity. In this paper, the live advertising has high requirements for real-time bidding (second-level control) and faces the difficulty of unknown future traffic. Therefore, we propose a lightweight bidding algorithm Binary Constrained Bidding (BiCB), which neatly combines the optimal bidding formula given by mathematical analysis and the statistical method of future traffic estimation, and obtains good approximation to the optimal result through a low complexity solution. In addition, we complement the form of upper and lower bound constraints for traditional auto-bidding modeling and give theoretical analysis of BiCB. Sufficient offline and online experiments prove BiCB's good performance and low engineering cost.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Lightweight Auto-bidding based on Traffic Prediction in Live Advertising\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lightweight",
      "autobidding",
      "based"
    ],
    "category": "noticia"
  },
  {
    "title": "Diverse Neural Sequences in QIF Networks: An Analytically Tractable Framework for Synfire Chains and Hippocampal Replay",
    "title_es": "Diverse Neural Sequences in QIF Networks: An Analytically Tractable Framework for Synfire Chains and Hippocampal Replay",
    "url": "https://arxiv.org/abs/2508.06085",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06085v1 Announce Type: cross \nAbstract: Sequential neural activity is fundamental to cognition, yet how diverse sequences are recalled under biological constraints remains a key question. Existing models often struggle to balance biophysical realism and analytical tractability. We address this problem by proposing a parsimonious network of Quadratic Integrate-and-Fire (QIF) neurons with sequences embedded via a temporally asymmetric Hebbian (TAH) rule. Our findings demonstrate that this single framework robustly reproduces a spectrum of sequential activities, including persistent synfire-like chains and transient, hippocampal replay-like bursts exhibiting intra-ripple frequency accommodation (IFA), all achieved without requiring specialized delay or adaptation mechanisms. Crucially, we derive exact low-dimensional firing-rate equations (FREs) that provide mechanistic insight, elucidating the bifurcation structure governing these distinct dynamical regimes and explaining their stability. The model also exhibits strong robustness to synaptic heterogeneity and memory pattern overlap. These results establish QIF networks with TAH connectivity as an analytically tractable and biologically plausible platform for investigating the emergence, stability, and diversity of sequential neural activity in the brain.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Diverse Neural Sequences in QIF Networks: An Analytically Tractable Framework for Synfire Chains and Hippocampal Replay\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "diverse",
      "neural",
      "sequences"
    ],
    "category": "noticia"
  },
  {
    "title": "Ensemble-Based Graph Representation of fMRI Data for Cognitive Brain State Classification",
    "title_es": "Ensemble-Based Graph Representation of fMRI Data for Cognitive Brain State Classification",
    "url": "https://arxiv.org/abs/2508.06118",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06118v1 Announce Type: cross \nAbstract: Understanding and classifying human cognitive brain states based on neuroimaging data remains one of the foremost and most challenging problems in neuroscience, owing to the high dimensionality and intrinsic noise of the signals. In this work, we propose an ensemble-based graph representation method of functional magnetic resonance imaging (fMRI) data for the task of binary brain-state classification. Our method builds the graph by leveraging multiple base machine-learning models: each edge weight reflects the difference in posterior probabilities between two cognitive states, yielding values in the range [-1, 1] that encode confidence in a given state. We applied this approach to seven cognitive tasks from the Human Connectome Project (HCP 1200 Subject Release), including working memory, gambling, motor activity, language, social cognition, relational processing, and emotion processing. Using only the mean incident edge weights of the graphs as features, a simple logistic-regression classifier achieved average accuracies from 97.07% to 99.74%. We also compared our ensemble graphs with classical correlation-based graphs in a classification task with a graph neural network (GNN). In all experiments, the highest classification accuracy was obtained with ensemble graphs. These results demonstrate that ensemble graphs convey richer topological information and enhance brain-state discrimination. Our approach preserves edge-level interpretability of the fMRI graph representation, is adaptable to multiclass and regression tasks, and can be extended to other neuroimaging modalities and pathological-state classification.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Ensemble-Based Graph Representation of fMRI Data for Cognitive Brain State Classification\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ensemblebased",
      "graph",
      "representation"
    ],
    "category": "noticia"
  },
  {
    "title": "IOCC: Aligning Semantic and Cluster Centers for Few-shot Short Text Clustering",
    "title_es": "IOCC: Aligning Semantic and Cluster Centers for Few-shot Short Text Clustering",
    "url": "https://arxiv.org/abs/2508.06126",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06126v1 Announce Type: cross \nAbstract: In clustering tasks, it is essential to structure the feature space into clear, well-separated distributions. However, because short text representations have limited expressiveness, conventional methods struggle to identify cluster centers that truly capture each category's underlying semantics, causing the representations to be optimized in suboptimal directions. To address this issue, we propose IOCC, a novel few-shot contrastive learning method that achieves alignment between the cluster centers and the semantic centers. IOCC consists of two key modules: Interaction-enhanced Optimal Transport (IEOT) and Center-aware Contrastive Learning (CACL). Specifically, IEOT incorporates semantic interactions between individual samples into the conventional optimal transport problem, and generate pseudo-labels. Based on these pseudo-labels, we aggregate high-confidence samples to construct pseudo-centers that approximate the semantic centers. Next, CACL optimizes text representations toward their corresponding pseudo-centers. As training progresses, the collaboration between the two modules gradually reduces the gap between cluster centers and semantic centers. Therefore, the model will learn a high-quality distribution, improving clustering performance. Extensive experiments on eight benchmark datasets show that IOCC outperforms previous methods, achieving up to 7.34\\% improvement on challenging Biomedical dataset and also excelling in clustering stability and efficiency. The code is available at: https://anonymous.4open.science/r/IOCC-C438.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"IOCC: Aligning Semantic and Cluster Centers for Few-shot Short Text Clustering\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "iocc",
      "aligning",
      "semantic"
    ],
    "category": "noticia"
  },
  {
    "title": "Enhancing the Scalability of Classical Surrogates for Real-World Quantum Machine Learning Applications",
    "title_es": "Enhancing the Scalability of Classical Surrogates for Real-World Quantum Machine Learning Applications",
    "url": "https://arxiv.org/abs/2508.06131",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06131v1 Announce Type: cross \nAbstract: Quantum machine learning (QML) presents potential for early industrial adoption, yet limited access to quantum hardware remains a significant bottleneck for deployment of QML solutions. This work explores the use of classical surrogates to bypass this restriction, which is a technique that allows to build a lightweight classical representation of a (trained) quantum model, enabling to perform inference on entirely classical devices. We reveal prohibiting high computational demand associated with previously proposed methods for generating classical surrogates from quantum models, and propose an alternative pipeline enabling generation of classical surrogates at a larger scale than was previously possible. Previous methods required at least a high-performance computing (HPC) system for quantum models of below industrial scale (ca. 20 qubits), which raises questions about its practicality. We greatly minimize the redundancies of the previous approach, utilizing only a minute fraction of the resources previously needed. We demonstrate the effectiveness of our method on a real-world energy demand forecasting problem, conducting rigorous testing of performance and computation demand in both simulations and on quantum hardware. Our results indicate that our method achieves high accuracy on the testing dataset while its computational resource requirements scale linearly rather than exponentially. This work presents a lightweight approach to transform quantum solutions into classically deployable versions, facilitating faster integration of quantum technology in industrial settings. Furthermore, it can serve as a powerful research tool in search practical quantum advantage in an empirical setup.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Enhancing the Scalability of Classical Surrogates for Real-World Quantum Machine Learning Applications\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "enhancing",
      "the",
      "scalability"
    ],
    "category": "noticia"
  },
  {
    "title": "LLM Serving Optimization with Variable Prefill and Decode Lengths",
    "title_es": "LLM Serving Optimization with Variable Prefill and Decode Lengths",
    "url": "https://arxiv.org/abs/2508.06133",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06133v1 Announce Type: cross \nAbstract: We study the problem of serving LLM (Large Language Model) requests where each request has heterogeneous prefill and decode lengths. In LLM serving, the prefill length corresponds to the input prompt length, which determines the initial memory usage in the KV cache. The decode length refers to the number of output tokens generated sequentially, with each additional token increasing the KV cache memory usage by one unit. Given a set of n requests, our goal is to schedule and process them to minimize the total completion time. We show that this problem is NP-hard due to the interplay of batching, placement constraints, precedence relationships, and linearly increasing memory usage. We then analyze commonly used scheduling strategies in practice, such as First-Come-First-Serve (FCFS) and Shortest-First (SF), and prove that their competitive ratios scale up sublinearly with the memory limit-a significant drawback in real-world settings where memory demand is large. To address this, we propose a novel algorithm based on a new selection metric that efficiently forms batches over time. We prove that this algorithm achieves a constant competitive ratio. Finally, we develop and evaluate a few algorithm variants inspired by this approach, including dynamic programming variants, local search methods, and an LP-based scheduler, demonstrating through comprehensive simulations that they outperform standard baselines while maintaining computational efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LLM Serving Optimization with Variable Prefill and Decode Lengths\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "llm",
      "serving",
      "optimization"
    ],
    "category": "noticia"
  },
  {
    "title": "Transformer-Based Explainable Deep Learning for Breast Cancer Detection in Mammography: The MammoFormer Framework",
    "title_es": "Transformer-Based Explainable Deep Learning for Breast Cancer Detection in Mammography: The MammoFormer Framework",
    "url": "https://arxiv.org/abs/2508.06137",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06137v1 Announce Type: cross \nAbstract: Breast cancer detection through mammography interpretation remains difficult because of the minimal nature of abnormalities that experts need to identify alongside the variable interpretations between readers. The potential of CNNs for medical image analysis faces two limitations: they fail to process both local information and wide contextual data adequately, and do not provide explainable AI (XAI) operations that doctors need to accept them in clinics. The researcher developed the MammoFormer framework, which unites transformer-based architecture with multi-feature enhancement components and XAI functionalities within one framework. Seven different architectures consisting of CNNs, Vision Transformer, Swin Transformer, and ConvNext were tested alongside four enhancement techniques, including original images, negative transformation, adaptive histogram equalization, and histogram of oriented gradients. The MammoFormer framework addresses critical clinical adoption barriers of AI mammography systems through: (1) systematic optimization of transformer architectures via architecture-specific feature enhancement, achieving up to 13% performance improvement, (2) comprehensive explainable AI integration providing multi-perspective diagnostic interpretability, and (3) a clinically deployable ensemble system combining CNN reliability with transformer global context modeling. The combination of transformer models with suitable feature enhancements enables them to achieve equal or better results than CNN approaches. ViT achieves 98.3% accuracy alongside AHE while Swin Transformer gains a 13.0% advantage through HOG enhancements",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Transformer-Based Explainable Deep Learning for Breast Cancer Detection in Mammography: The MammoFormer Framework\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "transformerbased",
      "explainable",
      "deep"
    ],
    "category": "noticia"
  },
  {
    "title": "Clinically-guided Data Synthesis for Laryngeal Lesion Detection",
    "title_es": "Clinically-guided Data Synthesis for Laryngeal Lesion Detection",
    "url": "https://arxiv.org/abs/2508.06182",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06182v1 Announce Type: cross \nAbstract: Although computer-aided diagnosis (CADx) and detection (CADe) systems have made significant progress in various medical domains, their application is still limited in specialized fields such as otorhinolaryngology. In the latter, current assessment methods heavily depend on operator expertise, and the high heterogeneity of lesions complicates diagnosis, with biopsy persisting as the gold standard despite its substantial costs and risks. A critical bottleneck for specialized endoscopic CADx/e systems is the lack of well-annotated datasets with sufficient variability for real-world generalization. This study introduces a novel approach that exploits a Latent Diffusion Model (LDM) coupled with a ControlNet adapter to generate laryngeal endoscopic image-annotation pairs, guided by clinical observations. The method addresses data scarcity by conditioning the diffusion process to produce realistic, high-quality, and clinically relevant image features that capture diverse anatomical conditions. The proposed approach can be leveraged to expand training datasets for CADx/e models, empowering the assessment process in laryngology. Indeed, during a downstream task of detection, the addition of only 10% synthetic data improved the detection rate of laryngeal lesions by 9% when the model was internally tested and 22.1% on out-of-domain external data. Additionally, the realism of the generated images was evaluated by asking 5 expert otorhinolaryngologists with varying expertise to rate their confidence in distinguishing synthetic from real images. This work has the potential to accelerate the development of automated tools for laryngeal disease diagnosis, offering a solution to data scarcity and demonstrating the applicability of synthetic data in real-world scenarios.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Clinically-guided Data Synthesis for Laryngeal Lesion Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "clinicallyguided",
      "data",
      "synthesis"
    ],
    "category": "noticia"
  },
  {
    "title": "Induced Minors, Asymptotic Dimension, and Baker's Technique",
    "title_es": "Induced Minors, Asymptotic Dimension, and Baker's Technique",
    "url": "https://arxiv.org/abs/2508.06190",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06190v1 Announce Type: cross \nAbstract: Asymptotic dimension is a large-scale invariant of metric spaces that was introduced by Gromov (1993). We prove that every hereditary class of bounded-degree graphs that excludes some graph as a fat minor has asymptotic dimension at most $2$, which is optimal. This makes substantial progress on a question of Bonamy, Bousquet, Esperet, Groenland, Liu, Pirot, and Scott (J. Eur. Math. Soc. 2023).\n  The key to our proof is a notion inspired by Baker's technique (J. ACM 1994). We say that a graph class $\\mathcal{G}$ has bounded Baker-treewidth if there exists a function $f \\colon \\mathbb{N} \\to \\mathbb{N}$ such that, for every graph $G\\in \\mathcal{G}$, there is a layering of $G$ such that the subgraph induced by the union of any $\\ell$ consecutive layers has treewidth at most $f(\\ell)$. We show that every class of bounded-degree graphs that excludes some graph as an induced minor has bounded Baker-treewidth. We discuss further applications of this result to clustered colouring and the design of linear-time approximate schemes.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Induced Minors, Asymptotic Dimension, and Baker's Technique\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "induced",
      "minors",
      "asymptotic"
    ],
    "category": "noticia"
  },
  {
    "title": "Decentralized Optimization via RC-ALADIN with Efficient Quantized Communication",
    "title_es": "Decentralized Optimization via RC-ALADIN with Efficient Quantized Communication",
    "url": "https://arxiv.org/abs/2508.06197",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06197v1 Announce Type: cross \nAbstract: In this paper, we investigate the problem of decentralized consensus optimization over directed graphs with limited communication bandwidth. We introduce a novel decentralized optimization algorithm that combines the Reduced Consensus Augmented Lagrangian Alternating Direction Inexact Newton (RC-ALADIN) method with a finite time quantized coordination protocol, enabling quantized information exchange among nodes. Assuming the nodes' local objective functions are $\\mu$-strongly convex and simply smooth, we establish global convergence at a linear rate to a neighborhood of the optimal solution, with the neighborhood size determined by the quantization level. Additionally, we show that the same convergence result also holds for the case where the local objective functions are convex and $L$-smooth. Numerical experiments demonstrate that our proposed algorithm compares favorably against algorithms in the current literature while exhibiting communication efficient operation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Decentralized Optimization via RC-ALADIN with Efficient Quantized Communication\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "decentralized",
      "optimization",
      "via"
    ],
    "category": "noticia"
  },
  {
    "title": "Advanced Deep Learning Techniques for Accurate Lung Cancer Detection and Classification",
    "title_es": "Advanced Deep Learning Techniques for Accurate Lung Cancer Detection and Classification",
    "url": "https://arxiv.org/abs/2508.06287",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06287v1 Announce Type: cross \nAbstract: Lung cancer (LC) ranks among the most frequently diagnosed cancers and is one of the most common causes of death for men and women worldwide. Computed Tomography (CT) images are the most preferred diagnosis method because of their low cost and their faster processing times. Many researchers have proposed various ways of identifying lung cancer using CT images. However, such techniques suffer from significant false positives, leading to low accuracy. The fundamental reason results from employing a small and imbalanced dataset. This paper introduces an innovative approach for LC detection and classification from CT images based on the DenseNet201 model. Our approach comprises several advanced methods such as Focal Loss, data augmentation, and regularization to overcome the imbalanced data issue and overfitting challenge. The findings show the appropriateness of the proposal, attaining a promising performance of 98.95% accuracy.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Advanced Deep Learning Techniques for Accurate Lung Cancer Detection and Classification\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "advanced",
      "deep",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "Decorrelated feature importance from local sample weighting",
    "title_es": "Decorrelated feature importance from local sample weighting",
    "url": "https://arxiv.org/abs/2508.06337",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06337v1 Announce Type: cross \nAbstract: Feature importance (FI) statistics provide a prominent and valuable method of insight into the decision process of machine learning (ML) models, but their effectiveness has well-known limitations when correlation is present among the features in the training data. In this case, the FI often tends to be distributed among all features which are in correlation with the response-generating signal features. Even worse, if multiple signal features are in strong correlation with a noise feature, while being only modestly correlated with one another, this can result in a noise feature having a distinctly larger FI score than any signal feature. Here we propose local sample weighting (losaw) which can flexibly be integrated into many ML algorithms to improve FI scores in the presence of feature correlation in the training data. Our approach is motivated from inverse probability weighting in causal inference and locally, within the ML model, uses a sample weighting scheme to decorrelate a target feature from the remaining features. This reduces model bias locally, whenever the effect of a potential signal feature is evaluated and compared to others. Moreover, losaw comes with a natural tuning parameter, the minimum effective sample size of the weighted population, which corresponds to an interpretation-prediction-tradeoff, analog to a bias-variance-tradeoff as for classical ML tuning parameters. We demonstrate how losaw can be integrated within decision tree-based ML methods and within mini-batch training of neural networks. We investigate losaw for random forest and convolutional neural networks in a simulation study on settings showing diverse correlation patterns. We found that losaw improves FI consistently. Moreover, it often improves prediction accuracy for out-of-distribution, while maintaining a similar accuracy for in-distribution test data.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Decorrelated feature importance from local sample weighting\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "decorrelated",
      "feature",
      "importance"
    ],
    "category": "noticia"
  },
  {
    "title": "DP-SPRT: Differentially Private Sequential Probability Ratio Tests",
    "title_es": "DP-SPRT: Differentially Private Sequential Probability Ratio Tests",
    "url": "https://arxiv.org/abs/2508.06377",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06377v1 Announce Type: cross \nAbstract: We revisit Wald's celebrated Sequential Probability Ratio Test for sequential tests of two simple hypotheses, under privacy constraints. We propose DP-SPRT, a wrapper that can be calibrated to achieve desired error probabilities and privacy constraints, addressing a significant gap in previous work. DP-SPRT relies on a private mechanism that processes a sequence of queries and stops after privately determining when the query results fall outside a predefined interval. This OutsideInterval mechanism improves upon naive composition of existing techniques like AboveThreshold, potentially benefiting other sequential algorithms. We prove generic upper bounds on the error and sample complexity of DP-SPRT that can accommodate various noise distributions based on the practitioner's privacy needs. We exemplify them in two settings: Laplace noise (pure Differential Privacy) and Gaussian noise (R\\'enyi differential privacy). In the former setting, by providing a lower bound on the sample complexity of any $\\epsilon$-DP test with prescribed type I and type II errors, we show that DP-SPRT is near optimal when both errors are small and the two hypotheses are close. Moreover, we conduct an experimental study revealing its good practical performance.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DP-SPRT: Differentially Private Sequential Probability Ratio Tests\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dpsprt",
      "differentially",
      "private"
    ],
    "category": "noticia"
  },
  {
    "title": "Intuition emerges in Maximum Caliber models at criticality",
    "title_es": "Intuition emerges in Maximum Caliber models at criticality",
    "url": "https://arxiv.org/abs/2508.06477",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06477v1 Announce Type: cross \nAbstract: Whether large predictive models merely parrot their training data or produce genuine insight lacks a physical explanation. This work reports a primitive form of intuition that emerges as a metastable phase of learning that critically balances next-token prediction against future path-entropy. The intuition mechanism is discovered via mind-tuning, the minimal principle that imposes Maximum Caliber in predictive models with a control temperature-like parameter $\\lambda$. Training on random walks in deterministic mazes reveals a rich phase diagram: imitation (low $\\lambda$), rule-breaking hallucination (high $\\lambda$), and a fragile in-between window exhibiting strong protocol-dependence (hysteresis) and multistability, where models spontaneously discover novel goal-directed strategies. These results are captured by an effective low-dimensional theory and frame intuition as an emergent property at the critical balance between memorizing what is and wondering what could be.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Intuition emerges in Maximum Caliber models at criticality\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "intuition",
      "emerges",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Multivariate Fields of Experts",
    "title_es": "Multivariate Fields of Experts",
    "url": "https://arxiv.org/abs/2508.06490",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.06490v1 Announce Type: cross \nAbstract: We introduce the multivariate fields of experts, a new framework for the learning of image priors. Our model generalizes existing fields of experts methods by incorporating multivariate potential functions constructed via Moreau envelopes of the $\\ell_\\infty$-norm. We demonstrate the effectiveness of our proposal across a range of inverse problems that include image denoising, deblurring, compressed-sensing magnetic-resonance imaging, and computed tomography. The proposed approach outperforms comparable univariate models and achieves performance close to that of deep-learning-based regularizers while being significantly faster, requiring fewer parameters, and being trained on substantially fewer data. In addition, our model retains a relatively high level of interpretability due to its structured design.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Multivariate Fields of Experts\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "multivariate",
      "fields",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Dimensionality Reduction on Complex Vector Spaces for Euclidean Distance with Dynamic Weights",
    "title_es": "Dimensionality Reduction on Complex Vector Spaces for Euclidean Distance with Dynamic Weights",
    "url": "https://arxiv.org/abs/2212.06605",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2212.06605v3 Announce Type: replace \nAbstract: The weighted Euclidean norm $\\|x\\|_w$ of a vector $x\\in \\mathbb{R}^d$ with weights $w\\in \\mathbb{R}^d$ is the Euclidean norm where the contribution of each dimension is scaled by a given weight. Approaches to dimensionality reduction that satisfy the Johnson-Lindenstrauss (JL) lemma can be easily adapted to the weighted Euclidean distance if weights are known and fixed: it suffices to scale each dimension of the input vectors according to the weights, and then apply any standard approach. However, this is not the case when weights are unknown during the dimensionality reduction or might dynamically change. In this paper, we address this issue by providing a linear function that maps vectors into a smaller complex vector space and allows to retrieve a JL-like estimate for the weighted Euclidean distance once weights are revealed. Our results are based on the decomposition of the complex dimensionality reduction into several Rademacher chaos random variables, which are studied using novel concentration inequalities for sums of independent Rademacher chaoses.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Dimensionality Reduction on Complex Vector Spaces for Euclidean Distance with Dynamic Weights\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dimensionality",
      "reduction",
      "on"
    ],
    "category": "noticia"
  },
  {
    "title": "Tighter Bounds for Query Answering with Guarded TGDs",
    "title_es": "Tighter Bounds for Query Answering with Guarded TGDs",
    "url": "https://arxiv.org/abs/2212.11362",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2212.11362v4 Announce Type: replace \nAbstract: We consider the complexity of the open-world query answering problem, where we wish to determine certain answers to conjunctive queries over incomplete datasets specified by an initial set of facts and a set of guarded TGDs. This problem has been well-studied in the literature and is decidable but with a high complexity, namely, it is 2EXPTIME complete. Further, the complexity shrinks by one exponential when the arity is fixed.\n  We show in this paper how we can obtain better complexity bounds when considering separately the arity of the guard atom and that of the additional atoms, called the side signature. Our results make use of the technique of linearizing guarded TGDs, introduced in Gottlob, Manna, and Pieris. Specifically, we present a variant of the linearization process, making use of a restricted version of the chase that we recently introduced. Our results imply that open-world query answering with guarded TGDs can be solved in EXPTIME with arbitrary-arity guard relations if we simply bound the arity of the side signature; and that the complexity drops to NP if we fix the side signature and bound the width of the dependencies.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Tighter Bounds for Query Answering with Guarded TGDs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "tighter",
      "bounds",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Direct Robot Configuration Space Construction using Convolutional Encoder-Decoders",
    "title_es": "Direct Robot Configuration Space Construction using Convolutional Encoder-Decoders",
    "url": "https://arxiv.org/abs/2303.05653",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2303.05653v2 Announce Type: replace \nAbstract: Intelligent robots must be able to perform safe and efficient motion planning in their environments. Central to modern motion planning is the configuration space. Configuration spaces define the set of configurations of a robot that result in collisions with obstacles in the workspace, $\\text{C}_{\\text{clsn}}$, and the set of configurations that do not, $\\text{C}_{\\text{free}}$. Modern approaches to motion planning first compute the configuration space and then perform motion planning using the calculated configuration space. Real-time motion planning requires accurate and efficient construction of configuration spaces.\n  We are the first to apply a convolutional encoder-decoder framework for calculating highly accurate approximations to configuration spaces, essentially learning how the robot and physical world interact. Our model achieves an average 97.5% F1-score for predicting $\\text{C}_{\\text{free}}$ and $\\text{C}_{\\text{clsn}}$ for 2-D robotic workspaces with a dual-arm robot. Our method limits undetected collisions to less than 2.5% on robotic workspaces that involve translation, rotation, and removal of obstacles. Our model learns highly transferable features between robotic workspaces, requiring little to no fine-tuning to adapt to new transformations of obstacles in the workspace.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Direct Robot Configuration Space Construction using Convolutional Encoder-Decoders\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "direct",
      "robot",
      "configuration"
    ],
    "category": "noticia"
  },
  {
    "title": "On the Graph Theory of Majority Illusions: Theoretical Results and Computational Experiments",
    "title_es": "On the Graph Theory of Majority Illusions: Theoretical Results and Computational Experiments",
    "url": "https://arxiv.org/abs/2304.02258",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2304.02258v4 Announce Type: replace \nAbstract: The popularity of an opinion in one's direct circles is not necessarily a good indicator of its popularity in one's entire community. Network structures make local information about global properties of the group potentially inaccurate, and the way a social network is wired constrains what kind of information distortion can actually occur. In this paper, we discuss which classes of networks allow for a large enough proportion of the population to get a wrong enough impression about the overall distribution of opinions. We start by focusing on the 'majority illusion', the case where one sees a majority opinion in one's direct circles that differs from the global majority. We show that no network structure can guarantee that most agents see the correct majority. We then perform computational experiments to study the likelihood of majority illusions in different classes of networks. Finally, we generalize to other types of illusions.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"On the Graph Theory of Majority Illusions: Theoretical Results and Computational Experiments\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "on",
      "the",
      "graph"
    ],
    "category": "noticia"
  },
  {
    "title": "From research to clinic: Accelerating the translation of clinical decision support systems by making synthetic data interoperable",
    "title_es": "From research to clinic: Accelerating the translation of clinical decision support systems by making synthetic data interoperable",
    "url": "https://arxiv.org/abs/2308.02613",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2308.02613v2 Announce Type: replace \nAbstract: The translation of clinical decision support system (CDSS) tools from research settings into the clinic is often non-existent, partly because the focus tends to be on training machine learning models rather than tool development using the model for inference. To develop a CDSS tool that can be deployed in the clinical workflow, there is a need to integrate, validate, and test the tool on the Electronic Health Record (EHR) systems that store and manage patient data. Not surprisingly, it is rarely possible for researchers to get the necessary access to an EHR system due to legal restrictions pertaining to the protection of data privacy in patient records. We propose an architecture for using synthetic data in EHR systems to make CDSS tool development and testing much easier. In this study, the architecture is implemented in the SyntHIR system. SyntHIR has three noteworthy architectural features enabling (i) integration with synthetic data generators, (ii) data interoperability, and (iii) tool transportability. The translational value of this approach was evaluated through two primary steps. First, a working proof-of-concept of a machine learning-based CDSS tool was developed using data from patient registries in Norway. Second, the transportability of this CDSS tool was demonstrated by successfully deploying it in Norway's largest EHR system vendor (DIPS). These findings showcase the value of the SyntHIR architecture as a useful reference model to accelerate the translation of \"bench to bedside\" research of CDSS tools.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"From research to clinic: Accelerating the translation of clinical decision support systems by making synthetic data interoperable\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "from",
      "research",
      "to"
    ],
    "category": "noticia"
  },
  {
    "title": "Reinforcement Learning Based Sensor Optimization for Bio-markers",
    "title_es": "Reinforcement Learning Based Sensor Optimization for Bio-markers",
    "url": "https://arxiv.org/abs/2308.10649",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2308.10649v2 Announce Type: replace \nAbstract: Radio frequency (RF) biosensors, in particular those based on inter-digitated capacitors (IDCs), are pivotal in areas like biomedical diagnosis, remote sensing, and wireless communication. Despite their advantages of low cost and easy fabrication, their sensitivity can be hindered by design imperfections, environmental factors, and circuit noise. This paper investigates enhancing the sensitivity of IDC-based RF sensors using novel reinforcement learning based Binary Particle Swarm Optimization (RLBPSO), and it is compared to Ant Colony Optimization (ACO), and other state-of-the-art methods. By focusing on optimizing design parameters like electrode design and finger width, the proposed study found notable improvements in sensor sensitivity. The proposed RLBPSO method shows best optimized design for various frequency ranges when compared to current state-of-the-art methods.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Reinforcement Learning Based Sensor Optimization for Bio-markers\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "reinforcement",
      "learning",
      "based"
    ],
    "category": "noticia"
  },
  {
    "title": "A Markov Random Field model for Hypergraph-based Machine Learning",
    "title_es": "A Markov Random Field model for Hypergraph-based Machine Learning",
    "url": "https://arxiv.org/abs/2308.14172",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2308.14172v4 Announce Type: replace \nAbstract: Understanding the data-generating process is essential for building machine learning models that generalise well while ensuring robustness and interpretability. This paper addresses the fundamental challenge of modelling the data generation processes on hypergraphs and explores how such models can inform the design of machine learning algorithms for hypergraph data. The key to our approach is the development of a hypergraph Markov random field that models the joint distribution of the node features and hyperedge features in a hypergraph through a multivariate Gaussian distribution whose covariance matrix is uniquely determined by the hypergraph structure. The proposed data-generating process provides a valuable inductive bias for various hypergraph machine learning tasks, thus enhancing the algorithm design. In this paper, we focus on two representative downstream tasks: structure inference and node classification. Accordingly, we introduce two novel frameworks: 1) an original hypergraph structure inference framework named HGSI, and 2) a novel learning framework entitled Hypergraph-MLP for node classification on hypergraphs. Empirical evaluation of the proposed frameworks demonstrates that: 1) HGSI outperforms existing hypergraph structure inference methods on both synthetic and real-world data; and 2) Hypergraph-MLP outperforms baselines in six hypergraph node classification benchmarks, at the same time promoting runtime efficiency and robustness against structural perturbations during inference.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Markov Random Field model for Hypergraph-based Machine Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "markov",
      "random"
    ],
    "category": "noticia"
  },
  {
    "title": "Bayesian Gaussian Process ODEs via Double Normalizing Flows",
    "title_es": "Bayesian Gaussian Process ODEs via Double Normalizing Flows",
    "url": "https://arxiv.org/abs/2309.09222",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2309.09222v3 Announce Type: replace \nAbstract: Recently, Gaussian processes have been used to model the vector field of continuous dynamical systems, referred to as GPODEs, which are characterized by a probabilistic ODE equation. Bayesian inference for these models has been extensively studied and applied in tasks such as time series prediction. However, the use of standard GPs with basic kernels like squared exponential kernels has been common in GPODE research, limiting the model's ability to represent complex scenarios. To address this limitation, we introduce normalizing flows to reparameterize the ODE vector field, resulting in a data-driven prior distribution, thereby increasing flexibility and expressive power. We develop a data-driven variational learning algorithm that utilizes analytically tractable probability density functions of normalizing flows, enabling simultaneous learning and inference of unknown continuous dynamics. Additionally, we also apply normalizing flows to the posterior inference of GP ODEs to resolve the issue of strong mean-field assumptions in posterior inference. By applying normalizing flows in both these ways, our model improves accuracy and uncertainty estimates for Bayesian Gaussian Process ODEs. We validate the effectiveness of our approach on simulated dynamical systems and real-world human motion data, including time series prediction and missing data recovery tasks. Experimental results show that our proposed method effectively captures model uncertainty while improving accuracy.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Bayesian Gaussian Process ODEs via Double Normalizing Flows\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "bayesian",
      "gaussian",
      "process"
    ],
    "category": "noticia"
  },
  {
    "title": "Learning to Initialize Trajectory Optimization for Vision-Based Autonomous Flight in Unknown Environments",
    "title_es": "Learning to Initialize Trajectory Optimization for Vision-Based Autonomous Flight in Unknown Environments",
    "url": "https://arxiv.org/abs/2309.10683",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2309.10683v2 Announce Type: replace \nAbstract: Autonomous flight in unknown environments requires precise spatial and temporal trajectory planning, often involving computationally expensive nonconvex optimization prone to local optima. To overcome these challenges, we present the Neural-Enhanced Trajectory Planner (NEO-Planner), a novel approach that leverages a Neural Network (NN) Planner to provide informed initial values for trajectory optimization. The NN-Planner is trained on a dataset generated by an expert planner using batch sampling, capturing multimodal trajectory solutions. It learns to predict spatial and temporal parameters for trajectories directly from raw sensor observations. NEO-Planner starts optimization from these predictions, accelerating computation speed while maintaining explainability. Furthermore, we introduce a robust online replanning framework that accommodates planning latency for smooth trajectory tracking. Extensive simulations demonstrate that NEO-Planner reduces optimization iterations by 20%, leading to a 26% decrease in computation time compared with pure optimization-based methods. It maintains trajectory quality comparable to baseline approaches and generalizes well to unseen environments. Real-world experiments validate its effectiveness for autonomous drone navigation in cluttered, unknown environments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Learning to Initialize Trajectory Optimization for Vision-Based Autonomous Flight in Unknown Environments\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "learning",
      "to",
      "initialize"
    ],
    "category": "noticia"
  },
  {
    "title": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures",
    "title_es": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures",
    "url": "https://arxiv.org/abs/2311.04938",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2311.04938v4 Announce Type: replace \nAbstract: We propose using a Gaussian Mixture Model (GMM) as reverse transition operator (kernel) within the Denoising Diffusion Implicit Models (DDIM) framework, which is one of the most widely used approaches for accelerated sampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM). Specifically we match the first and second order central moments of the DDPM forward marginals by constraining the parameters of the GMM. We see that moment matching is sufficient to obtain samples with equal or better quality than the original DDIM with Gaussian kernels. We provide experimental results with unconditional models trained on CelebAHQ and FFHQ, class-conditional models trained on ImageNet, and text-to-image generation using Stable Diffusion v2.1 on COYO700M datasets respectively. Our results suggest that using the GMM kernel leads to significant improvements in the quality of the generated samples when the number of sampling steps is small, as measured by FID and IS metrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a FID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73 respectively with a Gaussian kernel. Further, we derive novel SDE samplers for rectified flow matching models and experiment with the proposed approach. We see improvements using both 1-rectified flow and 2-rectified flow models.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Improved DDIM Sampling with Moment Matching Gaussian Mixtures\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "improved",
      "ddim",
      "sampling"
    ],
    "category": "noticia"
  },
  {
    "title": "Entropy Causal Graphs for Multivariate Time Series Anomaly Detection",
    "title_es": "Entropy Causal Graphs for Multivariate Time Series Anomaly Detection",
    "url": "https://arxiv.org/abs/2312.09478",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2312.09478v2 Announce Type: replace \nAbstract: Many multivariate time series anomaly detection frameworks have been proposed and widely applied. However, most of these frameworks do not consider intrinsic relationships between variables in multivariate time series data, thus ignoring the causal relationship among variables and degrading anomaly detection performance. This work proposes a novel framework called CGAD, an entropy Causal Graph for multivariate time series Anomaly Detection. CGAD utilizes transfer entropy to construct graph structures that unveil the underlying causal relationships among time series data. Weighted graph convolutional networks combined with causal convolutions are employed to model both the causal graph structures and the temporal patterns within multivariate time series data. Furthermore, CGAD applies anomaly scoring, leveraging median absolute deviation-based normalization to improve the robustness of the anomaly identification process. Extensive experiments demonstrate that CGAD outperforms state-of-the-art methods on real-world datasets with a 9% average improvement in terms of three different multivariate time series anomaly detection metrics.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Entropy Causal Graphs for Multivariate Time Series Anomaly Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "entropy",
      "causal",
      "graphs"
    ],
    "category": "noticia"
  },
  {
    "title": "Decision-focused predictions via pessimistic bilevel optimization: complexity and algorithms",
    "title_es": "Decision-focused predictions via pessimistic bilevel optimization: complexity and algorithms",
    "url": "https://arxiv.org/abs/2312.17640",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2312.17640v5 Announce Type: replace \nAbstract: Dealing with uncertainty in optimization parameters is an important and longstanding challenge. Typically, uncertain parameters are predicted accurately, and then a deterministic optimization problem is solved. However, the decisions produced by this so-called predict-then-optimize procedure can be highly sensitive to uncertain parameters. In this work, we contribute to recent efforts in producing decision-focused predictions, i.e., to build predictive models that are constructed with the goal of minimizing a regret measure on the decisions taken with them. We begin by formulating the exact expected regret minimization as a pessimistic bilevel optimization model. Then, we show computational complexity results of this problem, including its membership in NP. In combination with a known NP-hardness result, this establishes NP-completeness and discards its hardness in higher complexity classes. Using duality arguments, we reformulate it as a non-convex quadratic optimization problem. Finally, leveraging the quadratic reformulation, we show various computational techniques to achieve empirical tractability. We report extensive computational results on shortest-path and bipartite matching instances with uncertain cost vectors. Our results indicate that our approach can improve training performance over the approach of Elmachtoub and Grigas (2022), a state-of-the-art method for decision-focused learning.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Decision-focused predictions via pessimistic bilevel optimization: complexity and algorithms\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "decisionfocused",
      "predictions",
      "via"
    ],
    "category": "noticia"
  },
  {
    "title": "Exploiting Kubernetes' Image Pull Implementation to Deny Node Availability",
    "title_es": "Exploiting Kubernetes' Image Pull Implementation to Deny Node Availability",
    "url": "https://arxiv.org/abs/2401.10582",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2401.10582v2 Announce Type: replace \nAbstract: Kubernetes (K8s) has grown in popularity over the past few years to become the de-facto standard for container orchestration in cloud-native environments. While research is not new to topics such as containerization and access control security, the Application Programming Interface (API) interactions between K8s and its runtime interfaces have not been studied thoroughly. In particular, the CRI-API is responsible for abstracting the container runtime, managing the creation and lifecycle of containers along with the downloads of the respective images. However, this decoupling of concerns and the abstraction of the container runtime renders K8s unaware of the status of the downloading process of the container images, obstructing the monitoring of the resources allocated to such process. In this paper, we discuss how this lack of status information can be exploited as a Denial of Service attack in a K8s cluster. We show how such attacks can impact worker nodes, generating up to 95% average CPU usage, prevent downloads of new container images, and increase I/O and network usage for a potentially unlimited amount of time. We argue that solving this problem would require a radical architectural change in the relationship between K8s and the CRI-API, which would be unfeasible in the short term. Thus, as a stopgap solution, we propose MAGI: an eBPF-based, proof-of-concept mitigation that detects and terminates potential attacks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Exploiting Kubernetes' Image Pull Implementation to Deny Node Availability\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "exploiting",
      "kubernetes",
      "image"
    ],
    "category": "noticia"
  },
  {
    "title": "On coloring graphs with well-distributed edge density",
    "title_es": "On coloring graphs with well-distributed edge density",
    "url": "https://arxiv.org/abs/2402.06803",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2402.06803v3 Announce Type: replace \nAbstract: In this paper, we introduce a class of graphs which we call average hereditary graphs. Many graphs that occur in the usual graph theory applications belong to this class of graphs. Many popular types of graphs fall under this class, such as regular graphs, trees and other popular classes of graphs. The paper aims to explore some interesting properties regarding colorings average hereditary graphs. We prove a new upper bound for the chromatic number of a graph in terms of its maximum average degree and show that this bound is an improvement on previous bounds. From this, we show a relationship between the average degree and the chromatic number of an average hereditary graph. We then show that even with new bound, the graph 3-coloring problem remains NP-hard when the input is restricted to average hereditary graphs. We provide an equivalent condition for a graph to be average hereditary, through which we show that we can decide if a given graph is average hereditary in polynomial time.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"On coloring graphs with well-distributed edge density\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "on",
      "coloring",
      "graphs"
    ],
    "category": "noticia"
  },
  {
    "title": "Soft Dice Confidence: A Near-Optimal Confidence Estimator for Selective Prediction in Semantic Segmentation",
    "title_es": "Soft Dice Confidence: A Near-Optimal Confidence Estimator for Selective Prediction in Semantic Segmentation",
    "url": "https://arxiv.org/abs/2402.10665",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2402.10665v4 Announce Type: replace \nAbstract: In semantic segmentation, even state-of-the-art deep learning models fall short of the performance required in certain high-stakes applications such as medical image analysis. In these cases, performance can be improved by allowing a model to abstain from making predictions when confidence is low, an approach known as selective prediction. While well-known in the classification literature, selective prediction has been underexplored in the context of semantic segmentation. This paper tackles the problem by focusing on image-level abstention, which involves producing a single confidence estimate for the entire image, in contrast to previous approaches that focus on pixel-level uncertainty. Assuming the Dice coefficient as the evaluation metric for segmentation, two main contributions are provided in this paper: (i) In the case of known marginal posterior probabilities, we derive the optimal confidence estimator, which is observed to be intractable for typical image sizes. Then, an approximation computable in linear time, named Soft Dice Confidence (SDC), is proposed and proven to be tightly bounded to the optimal estimator. (ii) When only an estimate of the marginal posterior probabilities are known, we propose a plug-in version of the SDC and show it outperforms all previous methods, including those requiring additional tuning data. These findings are supported by experimental results on both synthetic data and real-world data from six medical imaging tasks, including out-of-distribution scenarios, positioning the SDC as a reliable and efficient tool for selective prediction in semantic segmentation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Soft Dice Confidence: A Near-Optimal Confidence Estimator for Selective Prediction in Semantic Segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "soft",
      "dice",
      "confidence"
    ],
    "category": "noticia"
  },
  {
    "title": "Benchmarking LLMs on the Semantic Overlap Summarization Task",
    "title_es": "Benchmarking LLMs on the Semantic Overlap Summarization Task",
    "url": "https://arxiv.org/abs/2402.17008",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2402.17008v2 Announce Type: replace \nAbstract: Semantic Overlap Summarization (SOS) is a constrained multi-document summarization task, where the constraint is to capture the common/overlapping information between two alternative narratives. In this work, we perform a benchmarking study of popular Large Language Models (LLMs) exclusively on the SOS task. Additionally, we introduce the PrivacyPolicyPairs (3P) dataset to expand the space of SOS benchmarks in terms of quantity and variety. This dataset provides 135 high-quality SOS data samples sourced from privacy policy documents. We then use a standard prompting taxonomy called TELeR to create and evaluate 905,216 distinct LLM-generated summaries over two SOS datasets from different domains, and we further conduct human evaluation on a subset of 540 samples. We conclude the paper by analyzing models' performances and the reliability of automatic evaluation. The code and datasets used to conduct this study are available at https://anonymous.4open.science/r/llm_eval-E16D.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Benchmarking LLMs on the Semantic Overlap Summarization Task\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "benchmarking",
      "llms",
      "on"
    ],
    "category": "noticia"
  },
  {
    "title": "Data Collaboration Analysis with Orthonormal Basis Selection and Alignment",
    "title_es": "Data Collaboration Analysis with Orthonormal Basis Selection and Alignment",
    "url": "https://arxiv.org/abs/2403.02780",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2403.02780v5 Announce Type: replace \nAbstract: Data Collaboration (DC) enables multiple parties to jointly train a model without exposing their private datasets. Each party privately transforms its data using a secret linear basis and shares only the resulting intermediate representations. Existing theory asserts that any target basis spanning the same subspace as the secret bases should suffice; however, empirical evidence reveals that the particular choice of target basis significantly influences model accuracy and stability. In this paper, we introduce Orthonormal Data Collaboration (ODC), a novel DC framework that explicitly enforces orthonormality constraints on both the secret and target bases. Under these constraints, the basis alignment step reduces precisely to the classical Orthogonal Procrustes Problem, admitting a closed-form solution. We rigorously establish that the resulting orthonormal change-of-basis matrices achieve orthogonal concordance, aligning all parties' intermediate representations up to a common orthogonal transformation. Consequently, downstream model performance becomes invariant to the specific choice of orthonormal target basis. Computationally, ODC substantially reduces alignment complexity from O(\\min\\{a,(cl)^2,a^2cl) to O(acl^2) where a denotes anchor data size, l the latent dimension, and c the number of collaborating parties. Extensive empirical evaluations confirm the theoretical advantages of ODC, demonstrating alignment speed-ups of up to two orders of magnitude compared to state-of-the-art DC methods, alongside comparable or superior accuracy across multiple benchmark datasets. ODC maintains robust privacy under the semi-honest threat model and requires only a single round of communication. These results establish ODC as a practically advantageous and computationally efficient enhancement to existing DC pipelines, particularly when orthonormal secret bases are naturally feasible.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Data Collaboration Analysis with Orthonormal Basis Selection and Alignment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "data",
      "collaboration",
      "analysis"
    ],
    "category": "noticia"
  },
  {
    "title": "Position: Lifetime tuning is incompatible with continual reinforcement learning",
    "title_es": "Position: Lifetime tuning is incompatible with continual reinforcement learning",
    "url": "https://arxiv.org/abs/2404.02113",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2404.02113v4 Announce Type: replace \nAbstract: In continual RL we want agents capable of never-ending learning, and yet our evaluation methodologies do not reflect this. The standard practice in RL is to assume unfettered access to the deployment environment for the full lifetime of the agent. For example, agent designers select the best performing hyperparameters in Atari by testing each for 200 million frames and then reporting results on 200 million frames. In this position paper, we argue and demonstrate the pitfalls of this inappropriate empirical methodology: lifetime tuning. We provide empirical evidence to support our position by testing DQN and SAC across several of continuing and non-stationary environments with two main findings: (1) lifetime tuning does not allow us to identify algorithms that work well for continual learning -- all algorithms equally succeed; (2) recently developed continual RL algorithms outperform standard non-continual algorithms when tuning is limited to a fraction of the agent's lifetime. The goal of this paper is to provide an explanation for why recent progress in continual RL has been mixed and motivate the development of empirical practices that better match the goals of continual RL.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Position: Lifetime tuning is incompatible with continual reinforcement learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "position",
      "lifetime",
      "tuning"
    ],
    "category": "noticia"
  },
  {
    "title": "Towards Pareto Optimal Throughput in Small Language Model Serving",
    "title_es": "Towards Pareto Optimal Throughput in Small Language Model Serving",
    "url": "https://arxiv.org/abs/2404.03353",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2404.03353v3 Announce Type: replace \nAbstract: Large language models (LLMs) have revolutionized the state-of-the-art of many different natural language processing tasks. Although serving LLMs is computationally and memory demanding, the rise of Small Language Models (SLMs) offers new opportunities for resource-constrained users, who now are able to serve small models with cutting-edge performance. In this paper, we present a set of experiments designed to benchmark SLM inference at performance and energy levels. Our analysis provides a new perspective in serving, highlighting that the small memory footprint of SLMs allows for reaching the Pareto-optimal throughput within the resource capacity of a single accelerator. In this regard, we present an initial set of findings demonstrating how model replication can effectively improve resource utilization for serving SLMs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Towards Pareto Optimal Throughput in Small Language Model Serving\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "towards",
      "pareto",
      "optimal"
    ],
    "category": "noticia"
  },
  {
    "title": "Integrated Sensing and Communications for Unsourced Random Access: Fundamental Limits and Practical Model",
    "title_es": "Integrated Sensing and Communications for Unsourced Random Access: Fundamental Limits and Practical Model",
    "url": "https://arxiv.org/abs/2404.19431",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2404.19431v5 Announce Type: replace \nAbstract: This work addresses the problem of integrated sensing and communications (ISAC) involving a massive number of unsourced and uncoordinated users. In the proposed model, known as the unsourced ISAC system (UNISAC), all active communication and sensing users simultaneously share a short frame to transmit their signals without requiring scheduling by the base station or the need to announce their identities. Consequently, the received signal from each user is heavily affected by interference from numerous other users, making it challenging to extract individual transmissions. UNISAC is designed to decode the message sequences from communication users while simultaneously detecting active sensing users and estimating their angles of arrival, regardless of the senders' identities. \\textcolor{black}{We establish a second-order achievable bound for UNISAC that explicitly quantifies performance deviations due to finite resources, and we show that it outperforms ISAC approaches built on traditional multiple access methods, including ALOHA, time-division multiple access (TDMA), treating interference as noise (TIN), and a TDMA-based scheme combined with multiple signal classification for sensing.} Additionally, we propose a practical model that validates the feasibility of the achievable result, showing comparable or even superior performance in scenarios with a small number of users. Through numerical simulations, we demonstrate the effectiveness of both the practical UNISAC model and the achievable result.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Integrated Sensing and Communications for Unsourced Random Access: Fundamental Limits and Practical Model\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "integrated",
      "sensing",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "A Versatile Framework for Data-Driven Control of Nonlinear Systems",
    "title_es": "A Versatile Framework for Data-Driven Control of Nonlinear Systems",
    "url": "https://arxiv.org/abs/2405.10064",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2405.10064v2 Announce Type: replace \nAbstract: This note aims to provide a systematic investigation of direct data-driven control, enriching the existing literature not by adding another isolated result, but rather by offering a unifying, versatile, and broad framework that enables the generation of novel results in this domain. We formulate the nonlinear design problem from a high-level perspective as a set of desired controlled systems and propose systematic procedures to synthesize data-driven control algorithms that meet the specified design requirements. Various examples are presented to demonstrate the applicability of the proposed approach and its ability to derive new insights and results, illustrating the novel contributions enabled by the framework.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Versatile Framework for Data-Driven Control of Nonlinear Systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "versatile",
      "framework"
    ],
    "category": "noticia"
  },
  {
    "title": "CPT-Interp: Continuous sPatial and Temporal Motion Modeling for 4D Medical Image Interpolation",
    "title_es": "CPT-Interp: Continuous sPatial and Temporal Motion Modeling for 4D Medical Image Interpolation",
    "url": "https://arxiv.org/abs/2405.15385",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2405.15385v2 Announce Type: replace \nAbstract: Motion information from 4D medical imaging offers critical insights into dynamic changes in patient anatomy for clinical assessments and radiotherapy planning and, thereby, enhances the capabilities of 3D image analysis. However, inherent physical and technical constraints of imaging hardware often necessitate a compromise between temporal resolution and image quality. Frame interpolation emerges as a pivotal solution to this challenge. Previous methods often suffer from discretion when they estimate the intermediate motion and execute the forward warping. In this study, we draw inspiration from fluid mechanics to propose a novel approach for continuously modeling patient anatomic motion using implicit neural representation. It ensures both spatial and temporal continuity, effectively bridging Eulerian and Lagrangian specifications together to naturally facilitate continuous frame interpolation. Our experiments across multiple datasets underscore the method's superior accuracy and speed. Furthermore, as a case-specific optimization (training-free) approach, it circumvents the need for extensive datasets and addresses model generalization issues.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CPT-Interp: Continuous sPatial and Temporal Motion Modeling for 4D Medical Image Interpolation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cptinterp",
      "continuous",
      "spatial"
    ],
    "category": "noticia"
  },
  {
    "title": "A Calibration Tool for Refractive Underwater Vision",
    "title_es": "A Calibration Tool for Refractive Underwater Vision",
    "url": "https://arxiv.org/abs/2405.18018",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2405.18018v2 Announce Type: replace \nAbstract: Many underwater applications rely on vision sensors and require proper camera calibration, i.e. knowing the incoming light ray for each pixel in the image. While for the ideal pinhole camera model all viewing rays intersect in a single 3D point, underwater cameras suffer from - possibly multiple - refractions of light rays at the interfaces of water, glass and air. These changes of direction depend on the position and orientation of the camera inside the water-proof housing, as well as on the shape and properties of the optical window, the port, itself. In recent years explicit models for underwater vision behind common ports such as flat or dome port have been proposed, but the underwater community is still lacking a calibration tool which can determine port parameters through refractive calibration. With this work we provide the first open source implementation of an underwater refractive camera calibration toolbox. It allows end-to-end calibration of underwater vision systems, including camera, stereo and housing calibration for systems with dome or flat ports. The implementation is verified using rendered datasets and real-world experiments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Calibration Tool for Refractive Underwater Vision\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "calibration",
      "tool"
    ],
    "category": "noticia"
  },
  {
    "title": "LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs",
    "title_es": "LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs",
    "url": "https://arxiv.org/abs/2406.07467",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2406.07467v3 Announce Type: replace \nAbstract: Most log-based anomaly detectors assume logs are stable, though logs are often unstable due to software or environmental changes. Anomaly detection on unstable logs (ULAD) is therefore a more realistic, yet under-investigated challenge. Current approaches predominantly employ machine learning (ML) models, which often require extensive labeled data for training. To mitigate data insufficiency, we propose FlexLog, a novel hybrid approach for ULAD that combines ML models -- decision tree, k-nearest neighbors, and a feedforward neural network -- with a Large Language Model (Mistral) through ensemble learning. FlexLog also incorporates a cache and retrieval-augmented generation (RAG) to further enhance efficiency and effectiveness. To evaluate FlexLog, we configured four datasets for \\task, namely ADFA-U, LOGEVOL-U, SynHDFS-U, and SYNEVOL-U. FlexLog outperforms all baselines by at least 1.2 percentage points (pp) in F1 score while using much less labeled data (62.87 pp reduction). When trained on the same amount of data as the baselines, FlexLog achieves up to a 13 pp increase in F1 score on ADFA-U across varying training dataset sizes. Additionally, FlexLog maintains inference time under one second per log sequence, making it suitable for most applications, except latency-sensitive systems. Further analysis reveals the positive impact of FlexLog's key components: cache, RAG and ensemble learning.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LLM meets ML: Data-efficient Anomaly Detection on Unstable Logs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "llm",
      "meets",
      "ml"
    ],
    "category": "noticia"
  },
  {
    "title": "INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance",
    "title_es": "INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance",
    "url": "https://arxiv.org/abs/2406.09105",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2406.09105v2 Announce Type: replace \nAbstract: Large Vision-Language Models (LVLMs) and Multimodal Large Language Models (MLLMs) have demonstrated outstanding performance in various general multimodal applications and have shown increasing promise in specialized domains. However, their potential in the insurance domain-characterized by diverse application scenarios and rich multimodal data-remains largely underexplored. To date, there is no systematic review of multimodal tasks, nor a benchmark specifically designed to assess the capabilities of LVLMs in insurance. This gap hinders the development of LVLMs within the insurance industry. This study systematically reviews and categorizes multimodal tasks for 4 representative types of insurance: auto, property, health, and agricultural. We introduce INS-MMBench, the first hierarchical benchmark tailored for the insurance domain. INS-MMBench encompasses 22 fundamental tasks, 12 meta-tasks and 5 scenario tasks, enabling a comprehensive and progressive assessment from basic capabilities to real-world use cases. We benchmark 11 leading LVLMs, including closed-source models such as GPT-4o and open-source models like LLaVA. Our evaluation validates the effectiveness of INS-MMBench and offers detailed insights into the strengths and limitations of current LVLMs on a variety of insurance-related multimodal tasks. We hope that INS-MMBench will accelerate the integration of LVLMs into the insurance industry and foster interdisciplinary research. Our dataset and evaluation code are available at https://github.com/FDU-INS/INS-MMBench.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance in Insurance\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "insmmbench",
      "a",
      "comprehensive"
    ],
    "category": "noticia"
  },
  {
    "title": "From Next-Token to Mathematics: The Learning Dynamics of Mathematical Reasoning in Language Models",
    "title_es": "From Next-Token to Mathematics: The Learning Dynamics of Mathematical Reasoning in Language Models",
    "url": "https://arxiv.org/abs/2407.00900",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2407.00900v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) solely trained on next-token prediction learn to solve a wide range of problems involving mathematical reasoning. But how does this ability evolve during training? We show the first analysis of how mathematical reasoning abilities of several open-weight LLMs develop during pre-training and post-training. To this end, we construct MathCAMPS, a synthetic dataset of novel mathematical reasoning problems grounded in 44 fine-grained skills taken from the Common Core curriculum from K to 8th grades. In one experiment, we show that mathematical skills are learned during pre-training in an order that measurably correlates with the human-designed curriculum, even though training data are randomly ordered. We also show a detailed analysis of which mathematical abilities benefit from instruction tuning, a widely used post-training method and, in contrast, which skills suffer. Our work paves the way for an empirical understanding of LLM training dynamics in relation to reasoning.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"From Next-Token to Mathematics: The Learning Dynamics of Mathematical Reasoning in Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "from",
      "nexttoken",
      "to"
    ],
    "category": "noticia"
  },
  {
    "title": "Towards More Realistic Extraction Attacks: An Adversarial Perspective",
    "title_es": "Towards More Realistic Extraction Attacks: An Adversarial Perspective",
    "url": "https://arxiv.org/abs/2407.02596",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2407.02596v3 Announce Type: replace \nAbstract: Language models are prone to memorizing their training data, making them vulnerable to extraction attacks. While existing research often examines isolated setups, such as a single model or a fixed prompt, real-world adversaries have a considerably larger attack surface due to access to models across various sizes and checkpoints, and repeated prompting. In this paper, we revisit extraction attacks from an adversarial perspective -- with multi-faceted access to the underlying data. We find significant churn in extraction trends, i.e., even unintuitive changes to the prompt, or targeting smaller models and earlier checkpoints, can extract distinct information. By combining multiple attacks, our adversary doubles ($2 \\times$) the extraction risks, persisting even under mitigation strategies like data deduplication. We conclude with four case studies, including detecting pre-training data, copyright violations, extracting personally identifiable information, and attacking closed-source models, showing how our more realistic adversary can outperform existing adversaries in the literature.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Towards More Realistic Extraction Attacks: An Adversarial Perspective\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "towards",
      "more",
      "realistic"
    ],
    "category": "noticia"
  },
  {
    "title": "Greedy BST on Permutation Initial Tree",
    "title_es": "Greedy BST on Permutation Initial Tree",
    "url": "https://arxiv.org/abs/2407.03666",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2407.03666v2 Announce Type: replace \nAbstract: The Greedy binary search tree (BST) algorithm, like the Splay tree, is a prominent candidate for the \\emph{dynamic optimality conjecture}. While Greedy satisfies many desirable properties of BST, its cost and analysis to execute a search sequence $S$ is known to depend heavily on the choice of the \\emph{initial tree} configuration. Most prior analyses assume a flat (empty) initial tree, under which several tight bounds are established.\n  In this work, we introduce the notion of a \\emph{permutation initial tree}, a specific class of non-flat initial tree and prove that for any permutation search sequence $S=(s_1,s_2,\\dots, s_n)$, there exists a permutation initial tree $I_p$ such that the cost of Greedy on $I_p$ is same as its cost on the flat initial tree.\n  As an application of our result, we show that the \\emph{preorder traversal conjecture} holds for Greedy when the initial tree is a permutation initial tree. While it was previously known that Greedy achieves an $O(n)$ cost on preorder sequences for flat initial tree (Chalermsook et al., FOCS 2015), our result demonstrates that the same linear bound holds when the initial tree is a permutation initial tree. This result also matches the $O(n)$ bound for Splay tree on preorder sequence when the initial tree aligns with the traversal order (Chaudhuri and H\\\"oft, SIGACT 1993).",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Greedy BST on Permutation Initial Tree\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "greedy",
      "bst",
      "on"
    ],
    "category": "noticia"
  },
  {
    "title": "Equilibrium Selection in Replicator Equations Using Adaptive-Gain Control",
    "title_es": "Equilibrium Selection in Replicator Equations Using Adaptive-Gain Control",
    "url": "https://arxiv.org/abs/2407.09305",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2407.09305v2 Announce Type: replace \nAbstract: In this paper, we deal with the equilibrium selection problem, which amounts to steering a population of individuals engaged in strategic game-theoretic interactions to a desired collective behavior. In the literature, this problem has been typically tackled by means of open-loop strategies, whose applicability is however limited by the need of accurate a priori information on the game and scarce robustness to uncertainty and noise. Here, we overcome these limitations by adopting a closed-loop approach using an adaptive-gain control scheme within a replicator equation -a nonlinear ordinary differential equation that models the evolution of the collective behavior of the population. For most classes of 2-action matrix games we establish sufficient conditions to design a controller that guarantees convergence of the replicator equation to the desired equilibrium, requiring limited a-priori information on the game. Numerical simulations corroborate and expand our theoretical findings.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Equilibrium Selection in Replicator Equations Using Adaptive-Gain Control\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "equilibrium",
      "selection",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Human-Machine Shared Control Approach for the Takeover of CACC",
    "title_es": "Human-Machine Shared Control Approach for the Takeover of CACC",
    "url": "https://arxiv.org/abs/2407.11551",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2407.11551v4 Announce Type: replace \nAbstract: Cooperative Adaptive Cruise Control (CACC) often requires human takeover for tasks such as exiting a freeway. Direct human takeover can pose significant risks, especially given the close-following strategy employed by CACC, which might cause drivers to feel unsafe and execute hard braking, potentially leading to collisions. This research aims to develop a CACC takeover controller that ensures a smooth transition from automated to human control. The proposed CACC takeover maneuver employs an indirect human-machine shared control approach, modeled as a Stackelberg competition where the machine acts as the leader and the human as the follower. The machine guides the human to respond in a manner that aligns with the machine's expectations, aiding in maintaining following stability. Additionally, the human reaction function is integrated into the machine's predictive control system, moving beyond a simple \"prediction-planning\" pipeline to enhance planning optimality. The controller has been verified to i) enable a smooth takeover maneuver of CACC; ii) ensure string stability in the condition that the platoon has less than 6 CAVs and human control authority is less than 40%; iii) enhance both perceived and actual safety through machine interventions; and iv) reduce the impact on upstream traffic by up to 60%.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Human-Machine Shared Control Approach for the Takeover of CACC\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "humanmachine",
      "shared",
      "control"
    ],
    "category": "noticia"
  },
  {
    "title": "Exploring the Evidence-Based SE Beliefs of Generative AI Tools",
    "title_es": "Exploring the Evidence-Based SE Beliefs of Generative AI Tools",
    "url": "https://arxiv.org/abs/2407.13900",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2407.13900v4 Announce Type: replace \nAbstract: Recent innovations in generative artificial intelligence (AI), primarily powered by large language models (LLMs), have transformed how programmers develop and maintain software. The advanced capabilities of generative AI tools to support software development tasks have led to a rise in their adoption within software engineering (SE) workflows. However, little is known about how AI tools perceive evidence-based beliefs and practices supported by research findings. To this end, we conduct a preliminary evaluation conceptually replicating prior work to explore the \"beliefs\" of generative AI tools used to support software development tasks. We investigate 17 evidence-based claims posited by empirical SE research across five generative AI tools. Our findings show that generative AI tools have ambiguous beliefs regarding research claims and lack credible evidence to support responses. Based on our results, we provide implications for practitioners integrating generative AI-based systems into development contexts and shed light on future research directions to enhance the reliability and trustworthiness of generative AI -- aiming to increase awareness and adoption of evidence-based SE research findings in practice.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Exploring the Evidence-Based SE Beliefs of Generative AI Tools\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "exploring",
      "the",
      "evidencebased"
    ],
    "category": "noticia"
  },
  {
    "title": "Reorganizing attention-space geometry with expressive attention",
    "title_es": "Reorganizing attention-space geometry with expressive attention",
    "url": "https://arxiv.org/abs/2407.18601",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2407.18601v3 Announce Type: replace \nAbstract: Attention regulates information transfer between tokens. For this, query and key vectors are compared, typically in terms of a scalar product, $\\mathbf{Q}^T\\mathbf{K}$, together with a subsequent softmax normalization. In geometric terms, the standard dot-product attention (DPA) leads to large/small attention weights for parallel/antiparallel queries and keys. Here we study expressive attention (EA), which is based on $(\\mathbf{Q}^T\\mathbf{K})^2$, the squared dot product. In this case, attention is enhanced when query and key are either parallel or antiparallel, and suppressed for orthogonal configurations. EA can be introduced into any attention-based code without additional compute costs or memory requirements. For a series of autoregressive prediction tasks, we find that expressive attention performs at least as well as vanilla DPA. Increasing task complexity, EA is observed to outperform DPA with increasing margins, which also holds for multi-task settings. For a given model size, EA manages to achieve 100% performance for a range of complexity levels not accessible to DPA. Our results show that it is possible to reorganize the geometry of the matching condition in the space of attention heads without loss of performance.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Reorganizing attention-space geometry with expressive attention\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "reorganizing",
      "attentionspace",
      "geometry"
    ],
    "category": "noticia"
  },
  {
    "title": "Spatio-Temporal Partial Sensing Forecast for Long-term Traffic",
    "title_es": "Spatio-Temporal Partial Sensing Forecast for Long-term Traffic",
    "url": "https://arxiv.org/abs/2408.02689",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2408.02689v2 Announce Type: replace \nAbstract: Traffic forecasting uses recent measurements by sensors installed at chosen locations to forecast the future road traffic. Existing work either assumes all locations are equipped with sensors or focuses on short-term forecast. This paper studies partial sensing forecast of long-term traffic, assuming sensors are available only at some locations. The problem is challenging due to the unknown data distribution at unsensed locations, the intricate spatio-temporal correlation in long-term forecasting, as well as noise to traffic patterns. We propose a Spatio-temporal Long-term Partial sensing Forecast model (SLPF) for traffic prediction, with several novel contributions, including a rank-based embedding technique to reduce the impact of noise in data, a spatial transfer matrix to overcome the spatial distribution shift from sensed locations to unsensed locations, and a multi-step training process that utilizes all available data to successively refine the model parameters for better accuracy. Extensive experiments on several real-world traffic datasets demonstrate its superior performance. Our source code is at https://github.com/zbliu98/SLPF",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Spatio-Temporal Partial Sensing Forecast for Long-term Traffic\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "spatiotemporal",
      "partial",
      "sensing"
    ],
    "category": "noticia"
  },
  {
    "title": "Random local access for sampling k-SAT solutions",
    "title_es": "Random local access for sampling k-SAT solutions",
    "url": "https://arxiv.org/abs/2409.03951",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2409.03951v3 Announce Type: replace \nAbstract: We present a sublinear time algorithm that gives random local access to the uniform distribution over satisfying assignments to an arbitrary k-SAT formula $\\Phi$, at exponential clause density. Our algorithm provides memory-less query access to variable assignments, such that the output variable assignments consistently emulate a single global satisfying assignment whose law is close to the uniform distribution over satisfying assignments to $\\Phi$. Random local access and related models have been studied for a wide variety of natural Gibbs distributions and random graphical processes. Here, we establish feasibility of random local access models for one of the most canonical such sample spaces, the set of satisfying assignments to a k-SAT formula.\n  Our algorithm proceeds by leveraging the local uniformity of the uniform distribution over satisfying assignments to $\\Phi$. We randomly partition the variables into two subsets, so that each clause has sufficiently many variables from each set to preserve local uniformity. We then sample some variables by simulating a systematic scan Glauber dynamics backward in time, greedily constructing the necessary intermediate steps. We sample the other variables by first conducting a search for a polylogarithmic-sized local component, which we iteratively grow to identify a small subformula from which we can efficiently sample using the appropriate marginal distribution. This two-pronged approach enables us to sample individual variable assignments without constructing a full solution.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Random local access for sampling k-SAT solutions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "random",
      "local",
      "access"
    ],
    "category": "noticia"
  },
  {
    "title": "Estimates of the numerical density for stochastic differential equations with multiplicative noise",
    "title_es": "Estimates of the numerical density for stochastic differential equations with multiplicative noise",
    "url": "https://arxiv.org/abs/2409.04991",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2409.04991v4 Announce Type: replace \nAbstract: We investigate the estimates of the density for the traditional Euler-Maruyama discretization of stochastic differential equations (SDEs) with multiplicative noise. Our estimates focus on two key aspects: (1) the $L^p$-upper bounds for derivatives of the logarithmic numerical density, (2) the sharp error order of the Euler scheme under the relative entropy (or Kullback-Leibler divergence). For the first aspect, we present estimates for the first-order and second-order derivatives of the logarithmic numerical density. The key technique is to adopt the Malliavin calculus to derive expressions of the derivatives of the logarithmic Green's function and to obtain an estimate for the inverse Malliavin matrix. Moreover, for the relative entropy error, we obtain a bound that is second order in time step, which then naturally leads to first-order error bounds under the total variation distance and Wasserstein distances. Compared with the usual weak error estimate for SDEs, such estimate can give an error bound for the worst case of a family of test functions instead of one test function.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Estimates of the numerical density for stochastic differential equations with multiplicative noise\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "estimates",
      "of",
      "the"
    ],
    "category": "noticia"
  },
  {
    "title": "Hybrid-TTA: Continual Test-time Adaptation via Dynamic Domain Shift Detection",
    "title_es": "Hybrid-TTA: Continual Test-time Adaptation via Dynamic Domain Shift Detection",
    "url": "https://arxiv.org/abs/2409.08566",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2409.08566v2 Announce Type: replace \nAbstract: Continual Test Time Adaptation (CTTA) has emerged as a critical approach for bridging the domain gap between the controlled training environments and the real-world scenarios, enhancing model adaptability and robustness. Existing CTTA methods, typically categorized into Full-Tuning (FT) and Efficient-Tuning (ET), struggle with effectively addressing domain shifts. To overcome these challenges, we propose Hybrid-TTA, a holistic approach that dynamically selects instance-wise tuning method for optimal adaptation. Our approach introduces the Dynamic Domain Shift Detection (DDSD) strategy, which identifies domain shifts by leveraging temporal correlations in input sequences and dynamically switches between FT and ET to adapt to varying domain shifts effectively. Additionally, the Masked Image Modeling based Adaptation (MIMA) framework is integrated to ensure domain-agnostic robustness with minimal computational overhead. Our Hybrid-TTA achieves a notable 1.6%p improvement in mIoU on the Cityscapes-to-ACDC benchmark dataset, surpassing previous state-of-the-art methods and offering a robust solution for real-world continual adaptation challenges.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hybrid-TTA: Continual Test-time Adaptation via Dynamic Domain Shift Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hybridtta",
      "continual",
      "testtime"
    ],
    "category": "noticia"
  },
  {
    "title": "Confidence in Assurance 2.0 Cases",
    "title_es": "Confidence in Assurance 2.0 Cases",
    "url": "https://arxiv.org/abs/2409.10665",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2409.10665v2 Announce Type: replace \nAbstract: An assurance case should provide justifiable confidence in the truth of a claim about some critical property of a system or procedure, such as safety or security. We consider how confidence can be assessed in the rigorous approach we call Assurance 2.0.\n  Our goal is indefeasible confidence and we approach it from four different perspectives: logical soundness, probabilistic assessment, dialectical examination, and residual risks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Confidence in Assurance 2.0 Cases\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "confidence",
      "in",
      "assurance"
    ],
    "category": "noticia"
  },
  {
    "title": "Extract-and-Abstract: Unifying Extractive and Abstractive Summarization within Single Encoder-Decoder Framework",
    "title_es": "Extract-and-Abstract: Unifying Extractive and Abstractive Summarization within Single Encoder-Decoder Framework",
    "url": "https://arxiv.org/abs/2409.11827",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2409.11827v2 Announce Type: replace \nAbstract: Extract-then-Abstract is a naturally coherent paradigm to conduct abstractive summarization with the help of salient information identified by the extractive model. Previous works that adopt this paradigm train the extractor and abstractor separately and introduce extra parameters to highlight the extracted salients to the abstractor, which results in error accumulation and additional training costs. In this paper, we first introduce a parameter-free highlight method into the encoder-decoder framework: replacing the encoder attention mask with a saliency mask in the cross-attention module to force the decoder to focus only on salient parts of the input. A preliminary analysis compares different highlight methods, demonstrating the effectiveness of our saliency mask. We further propose the novel extract-and-abstract paradigm, ExtAbs., which jointly and seamlessly performs Extractive and Abstractive summarization tasks within single encoder-decoder model to reduce error accumulation. In ExtAbs, the vanilla encoder is augmented to extract salients, and the vanilla decoder is modified with the proposed saliency mask to generate summaries. Built upon BART and PEGASUS, experiments on three datasets show that ExtAbs can achieve superior performance than baselines on the extractive task and performs comparable, or even better than the vanilla models on the abstractive task.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Extract-and-Abstract: Unifying Extractive and Abstractive Summarization within Single Encoder-Decoder Framework\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "extractandabstract",
      "unifying",
      "extractive"
    ],
    "category": "noticia"
  },
  {
    "title": "Localized Gaussians as Self-Attention Weights for Point Clouds Correspondence",
    "title_es": "Localized Gaussians as Self-Attention Weights for Point Clouds Correspondence",
    "url": "https://arxiv.org/abs/2409.13291",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2409.13291v2 Announce Type: replace \nAbstract: Current data-driven methodologies for point cloud matching demand extensive training time and computational resources, presenting significant challenges for model deployment and application. In the point cloud matching task, recent advancements with an encoder-only Transformer architecture have revealed the emergence of semantically meaningful patterns in the attention heads, particularly resembling Gaussian functions centered on each point of the input shape. In this work, we further investigate this phenomenon by integrating these patterns as fixed attention weights within the attention heads of the Transformer architecture. We evaluate two variants: one utilizing predetermined variance values for the Gaussians, and another where the variance values are treated as learnable parameters. Additionally we analyze the performances on noisy data and explore a possible way to improve robustness to noise. Our findings demonstrate that fixing the attention weights not only accelerates the training process but also enhances the stability of the optimization. Furthermore, we conducted an ablation study to identify the specific layers where the infused information is most impactful and to understand the reliance of the network on this information.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Localized Gaussians as Self-Attention Weights for Point Clouds Correspondence\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "localized",
      "gaussians",
      "as"
    ],
    "category": "noticia"
  },
  {
    "title": "Formal Local Implication Between Two Neural Networks",
    "title_es": "Formal Local Implication Between Two Neural Networks",
    "url": "https://arxiv.org/abs/2409.16726",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2409.16726v2 Announce Type: replace \nAbstract: Given two neural network classifiers with the same input and output domains, our goal is to compare the two networks in relation to each other over an entire input region (e.g., within a vicinity of an input sample). To this end, we establish the foundation of formal local implication between two networks, i.e., N2 implies N1, in an entire input region D. That is, network N1 consistently makes a correct decision every time network N2 does, and it does so in an entire input region D. We further propose a sound formulation for establishing such formally-verified (provably correct) local implications. The proposed formulation is relevant in the context of several application domains, e.g., for comparing a trained network and its corresponding compact (e.g., pruned, quantized, distilled) networks. We evaluate our formulation based on the MNIST, CIFAR10, and two real-world medical datasets, to show its relevance.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Formal Local Implication Between Two Neural Networks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "formal",
      "local",
      "implication"
    ],
    "category": "noticia"
  },
  {
    "title": "An Extension of the Euler-Maclaurin Summation Formula to Nearly Singular Functions",
    "title_es": "An Extension of the Euler-Maclaurin Summation Formula to Nearly Singular Functions",
    "url": "https://arxiv.org/abs/2409.19192",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2409.19192v2 Announce Type: replace \nAbstract: A extension of the Euler-Maclaurin (E-M) formula to near-singular functions is presented. This extension is derived based on earlier generalized E-M formulas for singular functions. The new E-M formulas consists of two components: a ``singular'' component that is a continuous extension of the earlier singular E-M formulas, and a ``jump'' component associated with the discontinuity of the integral with respect to a parameter that controls near singularity. The singular component of the new E-M formulas is an asymptotic series whose coefficients depend on the Hurwitz zeta function or the digamma function. Numerical examples of near-singular quadrature based on the extended E-M formula are presented, where accuracies of machine precision are achieved insensitive to the strength of the near singularity and with a very small number of quadrature nodes.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"An Extension of the Euler-Maclaurin Summation Formula to Nearly Singular Functions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "an",
      "extension",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Improving sampling by modifying the effective diffusion",
    "title_es": "Improving sampling by modifying the effective diffusion",
    "url": "https://arxiv.org/abs/2410.00525",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2410.00525v4 Announce Type: replace \nAbstract: Markov chain Monte Carlo samplers based on discretizations of (overdamped) Langevin dynamics are commonly used in the Bayesian inference and computational statistical physics literature to estimate high-dimensional integrals. One can introduce a non-constant diffusion matrix to precondition these dynamics, and recent works have optimized it in order to improve the rate of convergence to stationarity by overcoming entropic and energy barriers. However, the introduced methodologies to compute these optimal diffusions are generally not suited to high-dimensional settings, as they rely on costly optimization procedures. In this work, we propose to optimize over a class of diffusion matrices, based on one-dimensional collective variables (CVs), to help the dynamics explore the latent space defined by the CV. The form of the diffusion matrix is chosen in order to obtain an efficient effective diffusion in the latent space. We describe how this class of diffusion matrices can be constructed and learned during the simulation. We provide implementations of the Metropolis--Adjusted Langevin Algorithm and Riemann Manifold (Generalized) Hamiltonian Monte Carlo algorithms, and discuss numerical optimizations in the case when the CV depends only on a few degrees of freedom of the system. We illustrate the efficiency gains by computing mean transition durations between two metastable states of a dimer in a solvent.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Improving sampling by modifying the effective diffusion\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "improving",
      "sampling",
      "by"
    ],
    "category": "noticia"
  },
  {
    "title": "CANVAS: Commonsense-Aware Navigation System for Intuitive Human-Robot Interaction",
    "title_es": "CANVAS: Commonsense-Aware Navigation System for Intuitive Human-Robot Interaction",
    "url": "https://arxiv.org/abs/2410.01273",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2410.01273v3 Announce Type: replace \nAbstract: Real-life robot navigation involves more than just reaching a destination; it requires optimizing movements while addressing scenario-specific goals. An intuitive way for humans to express these goals is through abstract cues like verbal commands or rough sketches. Such human guidance may lack details or be noisy. Nonetheless, we expect robots to navigate as intended. For robots to interpret and execute these abstract instructions in line with human expectations, they must share a common understanding of basic navigation concepts with humans. To this end, we introduce CANVAS, a novel framework that combines visual and linguistic instructions for commonsense-aware navigation. Its success is driven by imitation learning, enabling the robot to learn from human navigation behavior. We present COMMAND, a comprehensive dataset with human-annotated navigation results, spanning over 48 hours and 219 km, designed to train commonsense-aware navigation systems in simulated environments. Our experiments show that CANVAS outperforms the strong rule-based system ROS NavStack across all environments, demonstrating superior performance with noisy instructions. Notably, in the orchard environment, where ROS NavStack records a 0% total success rate, CANVAS achieves a total success rate of 67%. CANVAS also closely aligns with human demonstrations and commonsense constraints, even in unseen environments. Furthermore, real-world deployment of CANVAS showcases impressive Sim2Real transfer with a total success rate of 69%, highlighting the potential of learning from human demonstrations in simulated environments for real-world applications.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CANVAS: Commonsense-Aware Navigation System for Intuitive Human-Robot Interaction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "canvas",
      "commonsenseaware",
      "navigation"
    ],
    "category": "noticia"
  },
  {
    "title": "Efficient Decrease-And-Conquer Linearizability Monitoring",
    "title_es": "Efficient Decrease-And-Conquer Linearizability Monitoring",
    "url": "https://arxiv.org/abs/2410.04581",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2410.04581v4 Announce Type: replace \nAbstract: Linearizability has become the de facto correctness specification for implementations of concurrent data structures. While formally verifying such implementations remains challenging, linearizability monitoring has emerged as a promising first step to rule out early problems in the development of custom implementations, and serves as a key component in approaches that stress test such implementations. In this work, we investigate linearizability monitoring -- check if an execution history of an implementation is linearizable. While this problem is intractable in general, a systematic understanding of when it becomes tractable has remained elusive. We revisit this problem and first present a unified `decrease-and-conquer' algorithmic framework for linearizability monitoring. At its heart, this framework asks to identify special linearizability-preserving values in a given history -- values whose presence yields an equilinearizable sub-history when removed, and whose absence indicates non-linearizability. We prove that a polynomial time algorithm for the problem of identifying linearizability-preserving values, yields a polynomial time algorithm for linearizability monitoring, while conversely, intractability of this problem implies intractability of the monitoring problem. We demonstrate our framework's effectiveness by instantiating it for several popular data types -- sets, stacks, queues and priority queues -- deriving polynomial time algorithms for each, with the unambiguity restriction, where each insertion to the underlying data structure adds a distinct value. We optimize these algorithms to achieve the optimal log-linear time complexity by amortizing the cost of solving sub-problems through efficient data structures. Our implementation and evaluation on publicly available implementations show that our approach scales to large histories and outperforms existing tools.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Efficient Decrease-And-Conquer Linearizability Monitoring\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "efficient",
      "decreaseandconquer",
      "linearizability"
    ],
    "category": "noticia"
  },
  {
    "title": "ATM: Improving Model Merging by Alternating Tuning and Merging",
    "title_es": "ATM: Improving Model Merging by Alternating Tuning and Merging",
    "url": "https://arxiv.org/abs/2411.03055",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.03055v4 Announce Type: replace \nAbstract: Model merging has emerged as a cost-efficient approximation to multitask learning. Among merging strategies, task arithmetic is notable for its simplicity and effectiveness. In this work, we provide a theoretical motivation for task vectors by highlighting that, under single-epoch full-batch gradient descent, they are equivalent to multitask gradients. This insight leads us to reinterpret model merging as a single step in an iterative procedure that Alternates between Tuning and Merging (ATM). We propose two applications of ATM: (1) as an alternative to multitask learning in scenarios where data sharing is restricted (e.g., federated settings), and (2) as a lightweight refinement step to improve existing model merging methods using a small validation set. Experiments across diverse vision tasks demonstrate the effectiveness of ATM.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ATM: Improving Model Merging by Alternating Tuning and Merging\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "atm",
      "improving",
      "model"
    ],
    "category": "noticia"
  },
  {
    "title": "ShadowMamba: State-Space Model with Boundary-Region Selective Scan for Shadow Removal",
    "title_es": "ShadowMamba: State-Space Model with Boundary-Region Selective Scan for Shadow Removal",
    "url": "https://arxiv.org/abs/2411.03260",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.03260v4 Announce Type: replace \nAbstract: Image shadow removal is a typical low-level vision task. Shadows cause local brightness shifts, which reduce the performance of downstream vision tasks. Currently, Transformer-based shadow removal methods suffer from quadratic computational complexity due to the self-attention mechanism. To improve efficiency, many approaches use local attention, but this limits the ability to model global information and weakens the perception of brightness changes between regions. Recently, Mamba has shown strong performance in vision tasks by enabling global modeling with linear complexity. However, existing scanning strategies are not suitable for shadow removal, as they ignore the semantic continuity of shadow boundaries and internal regions. To address this, this paper proposes a boundary-region selective scanning mechanism that captures local details while enhancing semantic continuity between them, effectively improving shadow removal performance. In addition, a shadow mask denoising method is introduced to support the scanning mechanism and improve data quality. Based on these techniques, this paper presents a model called ShadowMamba, the first Mamba-based model designed for shadow removal. Experimental results show that the proposed method outperforms existing mainstream approaches on the AISTD, ISTD, and SRD datasets, and also offers clear advantages in parameter efficiency and computational complexity. Code is available at: https://github.com/ZHUXIUJINChris/ShadowMamba",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ShadowMamba: State-Space Model with Boundary-Region Selective Scan for Shadow Removal\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "shadowmamba",
      "statespace",
      "model"
    ],
    "category": "noticia"
  },
  {
    "title": "Observability-Aware Control for Quadrotor Formation Flight with Range-only Measurement",
    "title_es": "Observability-Aware Control for Quadrotor Formation Flight with Range-only Measurement",
    "url": "https://arxiv.org/abs/2411.03747",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.03747v2 Announce Type: replace \nAbstract: Cooperative Localization (CL) is a promising approach to achieve safe quadrotor formation flight through precise positioning via low-cost inter-drone sensors. This paper develops an observability-aware control principle tailored to quadrotor formation flight with range-only inter-drone measurement. The control principle is based on a novel approximation of the local observability Gramian (LOG), which we name the Short-Term Local Observability Gramian (STLOG). The validity of STLOG is established by a proof of the link between local observability and estimation precision. We propose the Observability Predictive Controller (OPC), an implementation of our control principle under a receding-horizon framework, which optimizes a metric of the STLOG to maximize the minimum precision improvement along a trajectory. Monte Carlo simulations and experimental flight tests are conducted on a pair of quadrotors performing formation flight. The results show that the OPC improves positioning precision and estimator confidence, confirming the practical utility of the proposed approach.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Observability-Aware Control for Quadrotor Formation Flight with Range-only Measurement\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "observabilityaware",
      "control",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Reconsidering the Performance of GAE in Link Prediction",
    "title_es": "Reconsidering the Performance of GAE in Link Prediction",
    "url": "https://arxiv.org/abs/2411.03845",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.03845v3 Announce Type: replace \nAbstract: Recent advancements in graph neural networks (GNNs) for link prediction have introduced sophisticated training techniques and model architectures. However, reliance on outdated baselines may exaggerate the benefits of these new approaches. To tackle this issue, we systematically explore Graph Autoencoders (GAEs) by applying model-agnostic tricks in recent methods and tuning hyperparameters. We find that a well-tuned GAE can match the performance of recent sophisticated models while offering superior computational efficiency on widely-used link prediction benchmarks. Our approach delivers substantial performance gains on datasets where structural information dominates and feature data is limited. Specifically, our GAE achieves a state-of-the-art Hits@100 score of 78.41\\% on the ogbl-ppa dataset. Furthermore, we examine the impact of various tricks to uncover the reasons behind our success and to guide the design of future methods. Our study emphasizes the critical need to update baselines for a more accurate assessment of progress in GNNs for link prediction. Our code is available at https://github.com/GraphPKU/Refined-GAE.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Reconsidering the Performance of GAE in Link Prediction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "reconsidering",
      "the",
      "performance"
    ],
    "category": "noticia"
  },
  {
    "title": "Koopman-based control using sum-of-squares optimization: Improved stability guarantees and data efficiency",
    "title_es": "Koopman-based control using sum-of-squares optimization: Improved stability guarantees and data efficiency",
    "url": "https://arxiv.org/abs/2411.03875",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.03875v5 Announce Type: replace \nAbstract: In this paper, we propose a novel controller design approach for unknown nonlinear systems using the Koopman operator. In particular, we use the recently proposed stability- and certificate-oriented extended dynamic mode decomposition (SafEDMD) architecture to generate a data-driven bilinear surrogate model with certified error bounds. Then, by accounting for the obtained error bounds in a controller design based on the bilinear system, one can guarantee closed-loop stability for the true nonlinear system. While existing approaches over-approximate the bilinearity of the surrogate model, thus introducing conservatism and providing only local guarantees, we explicitly account for the bilinearity by using sum-of-squares (SOS) optimization in the controller design. More precisely, we parametrize a rational controller stabilizing the error-affected bilinear surrogate model and, consequently, the underlying nonlinear system. The resulting SOS optimization problem provides explicit data-driven controller design conditions for unknown nonlinear systems based on semidefinite programming. Our approach significantly reduces conservatism by establishing a larger region of attraction and improved data efficiency. The proposed method is evaluated using numerical examples, demonstrating its advantages over existing approaches.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Koopman-based control using sum-of-squares optimization: Improved stability guarantees and data efficiency\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "koopmanbased",
      "control",
      "using"
    ],
    "category": "noticia"
  },
  {
    "title": "Observability and Generalized Sensor Placement for Nonlinear Quality Models in Drinking Water Networks",
    "title_es": "Observability and Generalized Sensor Placement for Nonlinear Quality Models in Drinking Water Networks",
    "url": "https://arxiv.org/abs/2411.04202",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.04202v5 Announce Type: replace \nAbstract: This paper studies the problem of optimal placement of water quality (WQ) sensors in water distribution networks (WDNs), with a focus on chlorine transport, decay, and reaction models. Such models are traditionally used as suitable proxies for WQ. The literature on this topic is inveterate, but has a key limitation: it utilizes simplified single-species decay and reaction models that do not capture WQ transients for nonlinear, multi-species interactions. This results in sensor placements (SP) that do not account for nonlinear WQ dynamics. Furthermore, as WQ simulations are parameterized by hydraulic profiles and demand patterns, the placement of sensors are often hydraulics-dependent. This study produces a greedy algorithm that addresses the two aforementioned limitations. The algorithm is grounded in nonlinear dynamic systems and observability theory, and yields SPs that are submodular and robust to hydraulic changes. Case studies on benchmark water networks are provided. The key findings provide practical recommendations for WDN operators.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Observability and Generalized Sensor Placement for Nonlinear Quality Models in Drinking Water Networks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "observability",
      "and",
      "generalized"
    ],
    "category": "noticia"
  },
  {
    "title": "MBA-SLAM: Motion Blur Aware Gaussian Splatting SLAM",
    "title_es": "MBA-SLAM: Motion Blur Aware Gaussian Splatting SLAM",
    "url": "https://arxiv.org/abs/2411.08279",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.08279v2 Announce Type: replace \nAbstract: Emerging 3D scene representations, such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), have demonstrated their effectiveness in Simultaneous Localization and Mapping (SLAM) for photo-realistic rendering, particularly when using high-quality video sequences as input. However, existing methods struggle with motion-blurred frames, which are common in real-world scenarios like low-light or long-exposure conditions. This often results in a significant reduction in both camera localization accuracy and map reconstruction quality. To address this challenge, we propose a dense visual deblur SLAM pipeline (i.e. MBA-SLAM) to handle severe motion-blurred inputs and enhance image deblurring. Our approach integrates an efficient motion blur-aware tracker with either neural radiance fields or Gaussian Splatting based mapper. By accurately modeling the physical image formation process of motion-blurred images, our method simultaneously learns 3D scene representation and estimates the cameras' local trajectory during exposure time, enabling proactive compensation for motion blur caused by camera movement. In our experiments, we demonstrate that MBA-SLAM surpasses previous state-of-the-art methods in both camera localization and map reconstruction, showcasing superior performance across a range of datasets, including synthetic and real datasets featuring sharp images as well as those affected by motion blur, highlighting the versatility and robustness of our approach. Code is available at https://github.com/WU-CVGL/MBA-SLAM.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MBA-SLAM: Motion Blur Aware Gaussian Splatting SLAM\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mbaslam",
      "motion",
      "blur"
    ],
    "category": "noticia"
  },
  {
    "title": "Koopman-based control of nonlinear systems with closed-loop guarantees",
    "title_es": "Koopman-based control of nonlinear systems with closed-loop guarantees",
    "url": "https://arxiv.org/abs/2411.10359",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.10359v4 Announce Type: replace \nAbstract: In this paper, we provide a tutorial overview and an extension of a recently developed framework for data-driven control of unknown nonlinear systems with rigorous closed-loop guarantees. The proposed approach relies on the Koopman operator representation of the nonlinear system, for which a bilinear surrogate model is estimated based on data. In contrast to existing Koopman-based estimation procedures, we state guaranteed bounds on the approximation error using the stability- and certificate-oriented extended dynamic mode decomposition (SafEDMD) framework. The resulting surrogate model and the uncertainty bounds allow us to design controllers via robust control theory and sum-of-squares optimization, guaranteeing desirable properties for the closed-loop system. We present results on stabilization both in discrete and continuous time, and we derive a method for controller design with performance objectives. The benefits of the presented framework over established approaches are demonstrated with a numerical example.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Koopman-based control of nonlinear systems with closed-loop guarantees\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "koopmanbased",
      "control",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "SoK: The Security-Safety Continuum of Multimodal Foundation Models through Information Flow and Game-Theoretic Defenses",
    "title_es": "SoK: The Security-Safety Continuum of Multimodal Foundation Models through Information Flow and Game-Theoretic Defenses",
    "url": "https://arxiv.org/abs/2411.11195",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.11195v3 Announce Type: replace \nAbstract: Multimodal foundation models (MFMs) integrate diverse data modalities to support complex and wide-ranging tasks. However, this integration also introduces distinct safety and security challenges. In this paper, we unify the concepts of safety and security in the context of MFMs by identifying critical threats that arise from both model behavior and system-level interactions. We propose a taxonomy grounded in information theory, evaluating risks through the concepts of channel capacity, signal, noise, and bandwidth. This perspective provides a principled way to analyze how information flows through MFMs and how vulnerabilities can emerge across modalities. Building on this foundation, we investigate defense mechanisms through the lens of a minimax game between attackers and defenders, highlighting key gaps in current research. In particular, we identify insufficient protection for cross-modal alignment and a lack of systematic and scalable defense strategies. Our work offers both a theoretical and practical foundation for advancing the safety and security of MFMs, supporting the development of more robust and trustworthy systems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SoK: The Security-Safety Continuum of Multimodal Foundation Models through Information Flow and Game-Theoretic Defenses\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sok",
      "the",
      "securitysafety"
    ],
    "category": "noticia"
  },
  {
    "title": "A Linear Differential Inclusion for Contraction Analysis to Known Trajectories",
    "title_es": "A Linear Differential Inclusion for Contraction Analysis to Known Trajectories",
    "url": "https://arxiv.org/abs/2411.11587",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.11587v2 Announce Type: replace \nAbstract: Infinitesimal contraction analysis provides exponential convergence rates between arbitrary pairs of trajectories of a system by studying the system's linearization. An essentially equivalent viewpoint arises through stability analysis of a linear differential inclusion (LDI) encompassing the incremental behavior of the system. In this note, we use contraction tools to study the exponential stability of a system to a particular known trajectory, deriving a new LDI characterizing the error between arbitrary trajectories and this known trajectory. As with classical contraction analysis, this new inclusion is constructed via first partial derivatives of the system's vector field, and convergence rates are obtained with familiar tools: uniform bounding of the logarithmic norm and LMI-based Lyapunov conditions. Our LDI is guaranteed to outperform a usual contraction analysis in two special circumstances: i) when the bound on the logarithmic norm arises from an interval overapproximation of the Jacobian matrix, and ii) when the norm considered is the $\\ell_1$ norm. Finally, we demonstrate how the proposed approach strictly improves an existing framework for ellipsoidal reachable set computation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Linear Differential Inclusion for Contraction Analysis to Known Trajectories\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "linear",
      "differential"
    ],
    "category": "noticia"
  },
  {
    "title": "CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval",
    "title_es": "CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval",
    "url": "https://arxiv.org/abs/2411.12644",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.12644v3 Announce Type: replace \nAbstract: Despite the success of text retrieval in many NLP tasks, code retrieval remains a largely underexplored area. Most text retrieval systems are tailored for natural language queries, often neglecting the specific challenges of retrieving code. This gap leaves existing models unable to effectively capture the diversity of programming languages and tasks across different domains, highlighting the need for more focused research in code retrieval. To address this, we introduce CodeXEmbed, a family of large-scale code embedding models ranging from 400M to 7B parameters. Our novel training pipeline unifies multiple programming languages and transforms various code-related tasks into a common retrieval framework, enhancing model generalizability and retrieval performance. Our 7B model sets a new state-of-the-art (SOTA) in code retrieval, outperforming the previous leading model, Voyage-Code, by over 20% on CoIR benchmark. In addition to excelling in code retrieval, our models demonstrate competitive performance on the widely adopted BeIR text retrieval benchmark, offering versatility across domains. Experimental results demonstrate that improving retrieval performance significantly enhances end-to-end Retrieval-Augmented Generation (RAG) performance for code-related tasks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "codexembed",
      "a",
      "generalist"
    ],
    "category": "noticia"
  },
  {
    "title": "Feedback-Guided Extraction of Knowledge Base from Retrieval-Augmented LLM Applications",
    "title_es": "Feedback-Guided Extraction of Knowledge Base from Retrieval-Augmented LLM Applications",
    "url": "https://arxiv.org/abs/2411.14110",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.14110v2 Announce Type: replace \nAbstract: Retrieval-Augmented Generation (RAG) expands the knowledge boundary of large language models (LLMs) by integrating external knowledge bases, whose construction is often time-consuming and laborious. If an adversary extracts the knowledge base verbatim, it not only severely infringes the owner's intellectual property but also enables the adversary to replicate the application's functionality for unfair competition. Previous works on knowledge base extraction are limited either by low extraction coverage (usually less than 4%) in query-based attacks or by impractical assumptions of white-box access in embedding-based optimization methods. In this work, we propose CopyBreakRAG, an agent-based black-box attack that reasons from feedback and adaptively generates new adversarial queries for progressive extraction. By balancing exploration and exploitation through curiosity-driven queries and feedback-guided query refinement, our method overcomes the limitations of prior approaches and achieves significantly higher extraction coverage in realistic black-box settings. Experimental results show that CopyBreakRAG outperforms the state-of-the-art black-box approach by 45% on average in terms of chunk extraction ratio from applications built with mainstream RAG frameworks, and extracts over 70% of the data from the knowledge base in applications on commercial platforms including OpenAI's GPTs and ByteDance's Coze when essential protection is in place.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Feedback-Guided Extraction of Knowledge Base from Retrieval-Augmented LLM Applications\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "feedbackguided",
      "extraction",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Reducibility among NP-Hard graph problems and boundary classes",
    "title_es": "Reducibility among NP-Hard graph problems and boundary classes",
    "url": "https://arxiv.org/abs/2411.14553",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.14553v2 Announce Type: replace \nAbstract: Many NP-hard graph problems become easy for some classes of graphs. For example, coloring is easy for bipartite graphs, but NP-hard in general. So we can ask question like when does a hard problem become easy? What is the minimum substructure for which the problem remains hard? We use the notion of boundary classes to study such questions. In this paper, we introduce a method for transforming the boundary class of one NP-hard graph problem into a boundary class for another problem. If {\\Pi} and {\\Gamma} are two NP-hard graph problems where {\\Pi} is reducible to {\\Gamma}, we transform a boundary class of {\\Pi} into a boundary class of {\\Gamma}. More formally if {\\Pi} is reducible to {\\Gamma}, where the reduction satisfies certain conditions, then X is a boundary class of {\\Pi} if and only if the image of X under the reduction is a boundary class of {\\Gamma}. This gives us a relationship between boundary classes and reducibility among several NP-hard problems. To show the strength of our main result, we apply our theorem to obtain some previously unknown boundary classes for a few graph problems namely; vertex-cover, clique, traveling-salesperson, bounded-degree-spanning-tree, subgraph-isomorphism and clique-cover.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Reducibility among NP-Hard graph problems and boundary classes\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "reducibility",
      "among",
      "nphard"
    ],
    "category": "noticia"
  },
  {
    "title": "DeepMDV: Global Spatial Matching for Multi-depot Vehicle Routing Problems",
    "title_es": "DeepMDV: Global Spatial Matching for Multi-depot Vehicle Routing Problems",
    "url": "https://arxiv.org/abs/2411.17080",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.17080v3 Announce Type: replace \nAbstract: The rapid growth of online retail and e-commerce has made effective and efficient Vehicle Routing Problem (VRP) solutions essential. To meet rising demand, companies are adding more depots, which changes the VRP problem to a complex optimization task of Multi-Depot VRP (MDVRP) where the routing decisions of vehicles from multiple depots are highly interdependent. The complexities render traditional VRP methods suboptimal and non-scalable for the MDVRP. In this paper, we propose a novel approach to solve MDVRP addressing these interdependencies, hence achieving more effective results. The key idea is, the MDVRP can be broken down into two core spatial tasks: assigning customers to depots and optimizing the sequence of customer visits. We adopt task-decoupling approach and propose a two-stage framework that is scalable: (i) an interdependent partitioning module that embeds spatial and tour context directly into the representation space to globally match customers to depots and assign them to tours; and (ii) an independent routing module that determines the optimal visit sequence within each tour. Extensive experiments on both synthetic and real-world datasets demonstrate that our method outperforms all baselines across varying problem sizes, including the adaptations of learning-based solutions for single-depot VRP. Its adaptability and performance make it a practical and readily deployable solution for real-world logistics challenges.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DeepMDV: Global Spatial Matching for Multi-depot Vehicle Routing Problems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "deepmdv",
      "global",
      "spatial"
    ],
    "category": "noticia"
  },
  {
    "title": "TryOffDiff: Virtual-Try-Off via High-Fidelity Garment Reconstruction using Diffusion Models",
    "title_es": "TryOffDiff: Virtual-Try-Off via High-Fidelity Garment Reconstruction using Diffusion Models",
    "url": "https://arxiv.org/abs/2411.18350",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2411.18350v2 Announce Type: replace \nAbstract: This paper introduces Virtual Try-Off (VTOFF), a novel task generating standardized garment images from single photos of clothed individuals. Unlike Virtual Try-On (VTON), which digitally dresses models, VTOFF extracts canonical garment images, demanding precise reconstruction of shape, texture, and complex patterns, enabling robust evaluation of generative model fidelity. We propose TryOffDiff, adapting Stable Diffusion with SigLIP-based visual conditioning to deliver high-fidelity reconstructions. Experiments on VITON-HD and Dress Code datasets show that TryOffDiff outperforms adapted pose transfer and VTON baselines. We observe that traditional metrics such as SSIM inadequately reflect reconstruction quality, prompting our use of DISTS for reliable assessment. Our findings highlight VTOFF's potential to improve e-commerce product imagery, advance generative model evaluation, and guide future research on high-fidelity reconstruction. Demo, code, and models are available at: https://rizavelioglu.github.io/tryoffdiff",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"TryOffDiff: Virtual-Try-Off via High-Fidelity Garment Reconstruction using Diffusion Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "tryoffdiff",
      "virtualtryoff",
      "via"
    ],
    "category": "noticia"
  },
  {
    "title": "Can LLM \"Self-report\"?: Evaluating the Validity of Self-report Scales in Measuring Personality Design in LLM-based Chatbots",
    "title_es": "Can LLM \"Self-report\"?: Evaluating the Validity of Self-report Scales in Measuring Personality Design in LLM-based Chatbots",
    "url": "https://arxiv.org/abs/2412.00207",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2412.00207v2 Announce Type: replace \nAbstract: A chatbot's personality design is key to interaction quality. As chatbots evolved from rule-based systems to those powered by large language models (LLMs), evaluating the effectiveness of their personality design has become increasingly complex, particularly due to the open-ended nature of interactions. A recent and widely adopted method for assessing the personality design of LLM-based chatbots is the use of self-report questionnaires. These questionnaires, often borrowed from established human personality inventories, ask the chatbot to rate itself on various personality traits. Can LLM-based chatbots meaningfully \"self-report\" their personality? We created 500 chatbots with distinct personality designs and evaluated the validity of their self-report personality scores by examining human perceptions formed during interactions with these chatbots. Our findings indicate that the chatbot's answers on human personality scales exhibit weak correlations with both human-perceived personality traits and the overall interaction quality. These findings raise concerns about both the criterion validity and the predictive validity of self-report methods in this context. Further analysis revealed the role of task context and interaction in the chatbot's personality design assessment. We further discuss design implications for creating more contextualized and interactive evaluation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Can LLM \"Self-report\"?: Evaluating the Validity of Self-report Scales in Measuring Personality Design in LLM-based Chatbots\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "can",
      "llm",
      "selfreport"
    ],
    "category": "noticia"
  },
  {
    "title": "LeakAgent: RL-based Red-teaming Agent for LLM Privacy Leakage",
    "title_es": "LeakAgent: RL-based Red-teaming Agent for LLM Privacy Leakage",
    "url": "https://arxiv.org/abs/2412.05734",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2412.05734v2 Announce Type: replace \nAbstract: Recent studies have discovered that large language models (LLM) may be ``fooled'' to output private information, including training data, system prompts, and personally identifiable information, under carefully crafted adversarial prompts. Existing red-teaming approaches for privacy leakage either rely on manual efforts or focus solely on system prompt extraction, making them ineffective for severe risks of training data leakage. We propose LeakAgent, a novel black-box red-teaming framework for LLM privacy leakage. Our framework trains an open-source LLM through reinforcement learning as the attack agent to generate adversarial prompts for both training data extraction and system prompt extraction. To achieve this, we propose a novel reward function to provide effective and fine-grained rewards and design novel mechanisms to balance exploration and exploitation during learning and enhance the diversity of adversarial prompts. Through extensive evaluations, we first show that LeakAgent significantly outperforms existing rule-based approaches in training data extraction and automated methods in system prompt leakage. We also demonstrate the effectiveness of LeakAgent in extracting system prompts from real-world applications in OpenAI's GPT Store. We further demonstrate LeakAgent's effectiveness in evading the existing guardrail defense and its helpfulness in enabling better safety alignment. Finally, we validate our customized designs through a detailed ablation study. We release our code here https://github.com/rucnyz/LeakAgent.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LeakAgent: RL-based Red-teaming Agent for LLM Privacy Leakage\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "leakagent",
      "rlbased",
      "redteaming"
    ],
    "category": "noticia"
  },
  {
    "title": "Small Term Reachability and Related Problems for Terminating Term Rewriting Systems",
    "title_es": "Small Term Reachability and Related Problems for Terminating Term Rewriting Systems",
    "url": "https://arxiv.org/abs/2412.06047",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2412.06047v3 Announce Type: replace \nAbstract: Motivated by an application where we try to make proofs for Description Logic inferences smaller by rewriting, we consider the following decision problem, which we call the small term reachability problem: given a term rewriting system $R$, a term $s$, and a natural number $n$, decide whether there is a term $t$ of size $\\leq n$ reachable from $s$ using the rules of $R$. We investigate the complexity of this problem depending on how termination of $R$ can be established. We show that the problem is in general NP-complete for length-reducing term rewriting systems. Its complexity increases to N2ExpTime-complete (NExpTime-complete) if termination is proved using a (linear) polynomial order and to PSpace-complete for systems whose termination can be shown using a restricted class of Knuth-Bendix orders. Confluence reduces the complexity to P for the length-reducing case, but has no effect on the worst-case complexity in the other two cases. Finally, we consider the large term reachability problem, a variant of the problem where we are interested in reachability of a term of size $\\geq n$. It turns out that this seemingly innocuous modification in some cases changes the complexity of the problem, which may also become dependent on whether the number $n$ is is represented in unary or binary encoding, whereas this makes no difference for the complexity of the small term reachability problem.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Small Term Reachability and Related Problems for Terminating Term Rewriting Systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "small",
      "term",
      "reachability"
    ],
    "category": "noticia"
  },
  {
    "title": "On the Structure of Two-Dimensional Constacyclic Codes using Common Zero Sets",
    "title_es": "On the Structure of Two-Dimensional Constacyclic Codes using Common Zero Sets",
    "url": "https://arxiv.org/abs/2412.09915",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2412.09915v3 Announce Type: replace \nAbstract: We consider two-dimensional $(\\lambda_1, \\lambda_2)$-constacyclic codes over $\\mathbb{F}_{q}$ of area $M N$, where $q$ is some power of prime $p$ with $\\gcd(M,p)=1$ and $\\gcd(N,p)=1$. With the help of common zero (CZ) set, we characterize 2-D constacyclic codes. Further, we provide an algorithm to construct an ideal basis of these codes by using their essential common zero (ECZ) sets. We also describe the dual of 2-D constacyclic codes. Finally, we provide an encoding scheme for generating 2-D constacyclic codes from the generator tensor, implementable in a parallel fashion. Through examples, we illustrate that 2-D constacyclic codes can have better minimum distance compared to their cyclic counterparts with the same code area and code rate, generalizing prior work over 2-D binary cyclic coded arrays.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"On the Structure of Two-Dimensional Constacyclic Codes using Common Zero Sets\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "on",
      "the",
      "structure"
    ],
    "category": "noticia"
  },
  {
    "title": "Are Your LLMs Capable of Stable Reasoning?",
    "title_es": "Are Your LLMs Capable of Stable Reasoning?",
    "url": "https://arxiv.org/abs/2412.13147",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2412.13147v5 Announce Type: replace \nAbstract: The rapid advancement of large language models (LLMs) has shown remarkable progress in complex reasoning tasks. However, a significant disparity exists between benchmark performances and real-world applications. We attribute this gap primarily to current evaluation protocols and metrics, which inadequately capture the full spectrum of LLM capabilities, especially in complex reasoning tasks where both accuracy and consistency are essential. In this paper, we introduce G-Pass@$k$, a novel evaluation metric that continuously assesses model performance across multiple sampling attempts, quantifying both the model's performance potential and its stability. Through extensive experiments on various public and newly constructed benchmarks, we employ G-Pass@$k$ in conjunction with state-of-the-art large language models to provide comprehensive insights into their potential capabilities and operational consistency. Our findings reveal a significant opportunity to enhance the realistic reasoning abilities of LLMs, underscoring the necessity for more robust evaluation metrics.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Are Your LLMs Capable of Stable Reasoning?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "are",
      "your",
      "llms"
    ],
    "category": "noticia"
  },
  {
    "title": "WildSAT: Learning Satellite Image Representations from Wildlife Observations",
    "title_es": "WildSAT: Learning Satellite Image Representations from Wildlife Observations",
    "url": "https://arxiv.org/abs/2412.14428",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2412.14428v2 Announce Type: replace \nAbstract: Species distributions encode valuable ecological and environmental information, yet their potential for guiding representation learning in remote sensing remains underexplored. We introduce WildSAT, which pairs satellite images with millions of geo-tagged wildlife observations readily-available on citizen science platforms. WildSAT employs a contrastive learning approach that jointly leverages satellite images, species occurrence maps, and textual habitat descriptions to train or fine-tune models. This approach significantly improves performance on diverse satellite image recognition tasks, outperforming both ImageNet-pretrained models and satellite-specific baselines. Additionally, by aligning visual and textual information, WildSAT enables zero-shot retrieval, allowing users to search geographic locations based on textual descriptions. WildSAT surpasses recent cross-modal learning methods, including approaches that align satellite images with ground imagery or wildlife photos, demonstrating the advantages of our approach. Finally, we analyze the impact of key design choices and highlight the broad applicability of WildSAT to remote sensing and biodiversity monitoring.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"WildSAT: Learning Satellite Image Representations from Wildlife Observations\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "wildsat",
      "learning",
      "satellite"
    ],
    "category": "noticia"
  },
  {
    "title": "XR for All: Understanding Developers' Perspectives on Accessibility Integration in Extended Reality",
    "title_es": "XR for All: Understanding Developers' Perspectives on Accessibility Integration in Extended Reality",
    "url": "https://arxiv.org/abs/2412.16321",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2412.16321v2 Announce Type: replace \nAbstract: As immersive technologies enable unique, multimodal interaction methods, developers must also use tailored methods to support user accessibility, distinct from traditional software practices. We interviewed 25 industry extended reality (XR) developers, including freelancers, startups, midsize, and big tech companies about their motivations, techniques, barriers, and attitudes towards incorporating accessibility features in their XR apps. Our study revealed a variety of challenges, including conflicting priorities between application and platform developers regarding accessibility infrastructure; rapid development culture hindering accessible development; and the lack of accessible interaction design considerations at the ideation, design, and early prototyping stages. As a comprehensive set of XR accessibility guidelines has yet to be established, we also compiled and evaluated a set of accessibility guidelines for 3D virtual worlds and addressed their limitations when applied to XR. Finally, we inform the creation of effective support methods for industry developers.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"XR for All: Understanding Developers' Perspectives on Accessibility Integration in Extended Reality\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "xr",
      "for",
      "all"
    ],
    "category": "noticia"
  },
  {
    "title": "Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions",
    "title_es": "Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions",
    "url": "https://arxiv.org/abs/2501.01872",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.01872v3 Announce Type: replace \nAbstract: Large language models, despite extensive alignment with human values and ethical principles, remain vulnerable to sophisticated jailbreak attacks that exploit their reasoning abilities. Existing safety measures often detect overt malicious intent but fail to address subtle, reasoning-driven vulnerabilities. In this work, we introduce POATE (Polar Opposite query generation, Adversarial Template construction, and Elaboration), a novel jailbreak technique that harnesses contrastive reasoning to provoke unethical responses. POATE crafts semantically opposing intents and integrates them with adversarial templates, steering models toward harmful outputs with remarkable subtlety. We conduct extensive evaluation across six diverse language model families of varying parameter sizes to demonstrate the robustness of the attack, achieving significantly higher attack success rates (~44%) compared to existing methods. To counter this, we propose Intent-Aware CoT and Reverse Thinking CoT, which decompose queries to detect malicious intent and reason in reverse to evaluate and reject harmful responses. These methods enhance reasoning robustness and strengthen the model's defense against adversarial exploits.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "turning",
      "logic",
      "against"
    ],
    "category": "noticia"
  },
  {
    "title": "EVA-S2PLoR: Decentralized Secure 2-party Logistic Regression with A Subtly Hadamard Product Protocol (Full Version)",
    "title_es": "EVA-S2PLoR: Decentralized Secure 2-party Logistic Regression with A Subtly Hadamard Product Protocol (Full Version)",
    "url": "https://arxiv.org/abs/2501.05223",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.05223v3 Announce Type: replace \nAbstract: The implementation of accurate nonlinear operators (e.g., sigmoid function) on heterogeneous datasets is a key challenge in privacy-preserving machine learning (PPML). Most existing frameworks approximate it through linear operations, which not only result in significant precision loss but also introduce substantial computational overhead. This paper proposes an efficient, verifiable, and accurate security 2-party logistic regression framework (EVA-S2PLoR), which achieves accurate nonlinear function computation through a subtly secure hadamard product protocol and its derived protocols. All protocols are based on a practical semi-honest security model, which is designed for decentralized privacy-preserving application scenarios that balance efficiency, precision, and security. High efficiency and precision are guaranteed by the asynchronous computation flow on floating point numbers and the few number of fixed communication rounds in the hadamard product protocol, where robust anomaly detection is promised by dimension transformation and Monte Carlo methods. EVA-S2PLoR outperforms many advanced frameworks in terms of precision, improving the performance of the sigmoid function by about 10 orders of magnitude compared to most frameworks. Moreover, EVA-S2PLoR delivers the best overall performance in secure logistic regression experiments with training time reduced by over 47.6% under WAN settings and a classification accuracy difference of only about 0.5% compared to the plaintext model.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"EVA-S2PLoR: Decentralized Secure 2-party Logistic Regression with A Subtly Hadamard Product Protocol (Full Version)\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "evasplor",
      "decentralized",
      "secure"
    ],
    "category": "noticia"
  },
  {
    "title": "ActMiner: Applying Causality Tracking and Increment Aligning for Graph-based Cyber Threat Hunting",
    "title_es": "ActMiner: Applying Causality Tracking and Increment Aligning for Graph-based Cyber Threat Hunting",
    "url": "https://arxiv.org/abs/2501.05793",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.05793v2 Announce Type: replace \nAbstract: To defend against Advanced Persistent Threats on the endpoint, threat hunting employs security knowledge such as cyber threat intelligence to continuously analyze system audit logs through retrospective scanning, querying, or pattern matching, aiming to uncover attack patterns/graphs that traditional detection methods (e.g., recognition for Point of Interest) fail to capture. However, existing threat hunting systems based on provenance graphs face challenges of high false negatives, high false positives, and low efficiency when confronted with diverse attack tactics and voluminous audit logs. To address these issues, we propose a system called Actminer, which constructs query graphs from descriptive relationships in cyber threat intelligence reports for precise threat hunting (i.e., graph alignment) on provenance graphs. First, we present a heuristic search strategy based on equivalent semantic transfer to reduce false negatives. Second, we establish a filtering mechanism based on causal relationships of attack behaviors to mitigate false positives. Finally, we design a tree structure to incrementally update the alignment results, significantly improving hunting efficiency. Evaluation on the DARPA Engagement dataset demonstrates that compared to the SOTA POIROT, Actminer reduces false positives by 39.1%, eliminates all false negatives, and effectively counters adversarial attacks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ActMiner: Applying Causality Tracking and Increment Aligning for Graph-based Cyber Threat Hunting\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "actminer",
      "applying",
      "causality"
    ],
    "category": "noticia"
  },
  {
    "title": "Analysing the coverage of the University of Bologna's bibliographic and citation metadata in OpenCitations collections",
    "title_es": "Analysing the coverage of the University of Bologna's bibliographic and citation metadata in OpenCitations collections",
    "url": "https://arxiv.org/abs/2501.05821",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.05821v2 Announce Type: replace \nAbstract: This study focuses on analysing the coverage of publications' metadata available in the Current Research Information System (CRIS) infrastructure of the University of Bologna (UNIBO), implemented by the IRIS platform, within an authoritative source of open research information, i.e. OpenCitations. The analysis considers data regarding the publication entities alongside the citation links. We precisely quantify the proportion of UNIBO IRIS publications included in OpenCitations, examine their types, and evaluate the number of citations in OpenCitations that involve IRIS publications. Our methodology filters and transforms data dumps of IRIS and OpenCitations, creating novel datasets used for the analysis. Our findings reveal that only 36% of IRIS is covered in OpenCitations, with journal articles exhibiting the highest coverage. We identified 5,129,406 citation links pointing to UNIBO IRIS publications. From a purely quantitative perspective, comparing our results with broader proprietary services like Scopus and Web of Science reveals a comparable quantitative coverage in the number of IRIS bibliographic resources included in all the systems analysed (OpenCitations, Scopus and Web of Science) as well as in the number of citations received by them.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Analysing the coverage of the University of Bologna's bibliographic and citation metadata in OpenCitations collections\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "analysing",
      "the",
      "coverage"
    ],
    "category": "noticia"
  },
  {
    "title": "Adaptive Collocation Point Strategies For Physics Informed Neural Networks via the QR Discrete Empirical Interpolation Method",
    "title_es": "Adaptive Collocation Point Strategies For Physics Informed Neural Networks via the QR Discrete Empirical Interpolation Method",
    "url": "https://arxiv.org/abs/2501.07700",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.07700v4 Announce Type: replace \nAbstract: Physics-informed neural networks (PINNs) have gained significant attention for solving forward and inverse problems related to partial differential equations (PDEs). While advancements in loss functions and network architectures have improved PINN accuracy, the impact of collocation point sampling on their performance remains underexplored. Fixed sampling methods, such as uniform random sampling and equispaced grids, can fail to capture critical regions with high solution gradients, limiting their effectiveness for complex PDEs. Adaptive methods, inspired by adaptive mesh refinement from traditional numerical methods, address this by dynamically updating collocation points during training but may overlook residual dynamics between updates, potentially losing valuable information. To overcome this limitation, we propose two adaptive collocation point selection strategies utilizing the QR Discrete Empirical Interpolation Method (QR-DEIM), a reduced-order modeling technique for efficiently approximating nonlinear functions. Our results on benchmark PDEs demonstrate that our QR-DEIM-based approaches improve PINN accuracy compared to existing methods, offering a promising direction for adaptive collocation point strategies.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Adaptive Collocation Point Strategies For Physics Informed Neural Networks via the QR Discrete Empirical Interpolation Method\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "adaptive",
      "collocation",
      "point"
    ],
    "category": "noticia"
  },
  {
    "title": "SAR Strikes Back: A New Hope for RSVQA",
    "title_es": "SAR Strikes Back: A New Hope for RSVQA",
    "url": "https://arxiv.org/abs/2501.08131",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.08131v2 Announce Type: replace \nAbstract: Remote Sensing Visual Question Answering (RSVQA) is a task that extracts information from satellite images to answer questions in natural language, aiding image interpretation. While several methods exist for optical images with varying spectral bands and resolutions, only recently have high-resolution Synthetic Aperture Radar (SAR) images been explored. SAR's ability to operate in all weather conditions and capture electromagnetic features makes it a promising modality, yet no study has compared SAR and optical imagery in RSVQA or proposed effective fusion strategies. This work investigates how to integrate SAR data into RSVQA and how to best combine it with optical images. We present a dataset that enables SAR-based RSVQA and explore two pipelines for the task. The first is an end-to-end model, while the second is a two-stage framework: SAR information is first extracted and translated into text, which is then processed by a language model to produce the final answer. Our results show that the two-stage model performs better, improving accuracy by nearly 10% over the end-to-end approach. We also evaluate fusion strategies for combining SAR and optical data. A decision-level fusion yields the best results, with an F1-micro score of 75.00%, F1-average of 81.21%, and overall accuracy of 75.49% on the proposed dataset. SAR proves especially beneficial for questions related to specific land cover types, such as water areas, demonstrating its value as a complementary modality to optical imagery.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SAR Strikes Back: A New Hope for RSVQA\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sar",
      "strikes",
      "back"
    ],
    "category": "noticia"
  },
  {
    "title": "Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation",
    "title_es": "Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation",
    "url": "https://arxiv.org/abs/2501.09688",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.09688v2 Announce Type: replace \nAbstract: Open-Vocabulary Part Segmentation (OVPS) is an emerging field for recognizing fine-grained parts in unseen categories. We identify two primary challenges in OVPS: (1) the difficulty in aligning part-level image-text correspondence, and (2) the lack of structural understanding in segmenting object parts. To address these issues, we propose PartCATSeg, a novel framework that integrates object-aware part-level cost aggregation, compositional loss, and structural guidance from DINO. Our approach employs a disentangled cost aggregation strategy that handles object and part-level costs separately, enhancing the precision of part-level segmentation. We also introduce a compositional loss to better capture part-object relationships, compensating for the limited part annotations. Additionally, structural guidance from DINO features improves boundary delineation and inter-part understanding. Extensive experiments on Pascal-Part-116, ADE20K-Part-234, and PartImageNet datasets demonstrate that our method significantly outperforms state-of-the-art approaches, setting a new baseline for robust generalization to unseen part categories.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "finegrained",
      "imagetext",
      "correspondence"
    ],
    "category": "noticia"
  },
  {
    "title": "The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs",
    "title_es": "The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs",
    "url": "https://arxiv.org/abs/2501.10970",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.10970v4 Announce Type: replace \nAbstract: The \"LLM-as-an-annotator\" and \"LLM-as-a-judge\" paradigms employ Large Language Models (LLMs) as annotators, judges, and evaluators in tasks traditionally performed by humans. LLM annotations are widely used, not only in NLP research but also in fields like medicine, psychology, and social science. Despite their role in shaping study results and insights, there is no standard or rigorous procedure to determine whether LLMs can replace human annotators. In this paper, we propose a novel statistical procedure, the Alternative Annotator Test (alt-test), that requires only a modest subset of annotated examples to justify using LLM annotations. Additionally, we introduce a versatile and interpretable measure for comparing LLM annotators and judges. To demonstrate our procedure, we curated a diverse collection of ten datasets, consisting of language and vision-language tasks, and conducted experiments with six LLMs and four prompting techniques. Our results show that LLMs can sometimes replace humans with closed-source LLMs (such as GPT-4o), outperforming the open-source LLMs we examine, and that prompting techniques yield judges of varying quality. We hope this study encourages more rigorous and reliable practices.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "alternative",
      "annotator"
    ],
    "category": "noticia"
  },
  {
    "title": "Neural Contextual Reinforcement Framework for Logical Structure Language Generation",
    "title_es": "Neural Contextual Reinforcement Framework for Logical Structure Language Generation",
    "url": "https://arxiv.org/abs/2501.11417",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.11417v2 Announce Type: replace \nAbstract: The Neural Contextual Reinforcement Framework introduces an innovative approach to enhancing the logical coherence and structural consistency of text generated by large language models. Leveraging reinforcement learning principles, the framework integrates custom reward functions and dynamic context alignment mechanisms to address challenges inherent in maintaining long-range dependencies across extended sequences. The architecture incorporates multi-head attention layers and hierarchical encoding modules, enabling the model to produce outputs that align closely with human expectations of logical structure and semantic flow. Quantitative evaluations across diverse datasets demonstrate substantial improvements in coherence metrics, perplexity reduction, and semantic alignment, showcasing the framework's ability to outperform baseline models in both general and domain-specific tasks. Qualitative analyses further highlight the framework's capacity to generate text with improved narrative clarity and reduced redundancy, reflecting its effectiveness in balancing fluency with structural precision. In addition to its performance gains, the framework exhibits robustness in handling noisy input data and scalability across varying model sizes, reinforcing its versatility in practical applications. Experimental results reveal that optimal context window sizes significantly influence coherence outcomes, showing the importance of architectural flexibility in adapting to diverse linguistic structures. Cross-lingual performance evaluations affirm the framework's adaptability to multiple languages, extending its utility beyond monolingual contexts. Resource efficiency analyses indicate a reduction in computational overhead compared to traditional approaches, emphasizing the practicality of the framework for large-scale deployment.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Neural Contextual Reinforcement Framework for Logical Structure Language Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "neural",
      "contextual",
      "reinforcement"
    ],
    "category": "noticia"
  },
  {
    "title": "Unveiling Zero-Space Detection: A Novel Framework for Autonomous Ransomware Identification in High-Velocity Environments",
    "title_es": "Unveiling Zero-Space Detection: A Novel Framework for Autonomous Ransomware Identification in High-Velocity Environments",
    "url": "https://arxiv.org/abs/2501.12811",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.12811v2 Announce Type: replace \nAbstract: Modern cybersecurity landscapes increasingly demand sophisticated detection frameworks capable of identifying evolving threats with precision and adaptability. The proposed Zero-Space Detection framework introduces a novel approach that dynamically identifies latent behavioral patterns through unsupervised clustering and advanced deep learning techniques. Designed to address the limitations of signature-based and heuristic methods, it operates effectively in high-velocity environments by integrating multi-phase filtering and ensemble learning for refined decision-making. Experimental evaluation reveals high detection rates across diverse ransomware families, including LockBit, Conti, REvil, and BlackMatter, while maintaining low false positive rates and scalable performance. Computational overhead remains minimal, with average processing times ensuring compatibility with real-time systems even under peak operational loads. The framework demonstrates resilience against adversarial strategies such as obfuscation and encryption speed variability, which frequently challenge conventional detection systems. Analysis across multiple data sources highlights its versatility in handling diverse file types and operational contexts. Comprehensive metrics, including detection probability, latency, and resource efficiency, validate its efficacy under real-world conditions. Through its modular architecture, the framework achieves seamless integration with existing cybersecurity infrastructures without significant reconfiguration. The results demonstrate its robustness and scalability, offering a transformative paradigm for ransomware identification in dynamic and resource-constrained environments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Unveiling Zero-Space Detection: A Novel Framework for Autonomous Ransomware Identification in High-Velocity Environments\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "unveiling",
      "zerospace",
      "detection"
    ],
    "category": "noticia"
  },
  {
    "title": "Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration",
    "title_es": "Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration",
    "url": "https://arxiv.org/abs/2501.12901",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.12901v2 Announce Type: replace \nAbstract: Contextual Partitioning introduces an innovative approach to enhancing the architectural design of large-scale computational models through the dynamic segmentation of parameters into context-aware regions. This methodology emphasizes the importance of task-specific specialization, achieved through adaptive parameter allocation mechanisms that align with the linguistic features of input data. Experimental evaluations demonstrated substantial improvements in accuracy, perplexity, and contextual coherence across a variety of linguistic tasks, highlighting the adaptability and scalability of the proposed framework. By reducing redundancy and enhancing computational efficiency, Contextual Partitioning not only streamlines model operations but also expands the scope of applications for advanced language processing systems. The approach operates autonomously, requiring no external fine-tuning, thereby addressing a significant limitation in conventional parameter optimization techniques. Empirical results demonstrate the effectiveness of gradient-driven segmentation, enabling models to dynamically recalibrate and specialize in response to task-specific demands. Furthermore, resource utilization metrics reveal notable reductions in memory usage and training times, confirming the efficiency of the approach. Observations from qualitative analyses illustrate improved contextual coherence and logical flow in generated outputs, reinforcing the practical value of this technique. The findings collectively demonstrate the potential for Contextual Partitioning to redefine the scalability and adaptability of computational language architectures in diverse and complex domains.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "architectural",
      "fusion",
      "through"
    ],
    "category": "noticia"
  },
  {
    "title": "MPG-SAM 2: Adapting SAM 2 with Mask Priors and Global Context for Referring Video Object Segmentation",
    "title_es": "MPG-SAM 2: Adapting SAM 2 with Mask Priors and Global Context for Referring Video Object Segmentation",
    "url": "https://arxiv.org/abs/2501.13667",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.13667v5 Announce Type: replace \nAbstract: Referring video object segmentation (RVOS) aims to segment objects in a video according to textual descriptions, which requires the integration of multimodal information and temporal dynamics perception. The Segment Anything Model 2 (SAM 2) has shown great effectiveness across various video segmentation tasks. However, its application to offline RVOS is challenged by the translation of the text into effective prompts and a lack of global context awareness. In this paper, we propose a novel RVOS framework, termed MPG-SAM 2, to address these challenges. Specifically, MPG-SAM 2 employs a unified multimodal encoder to jointly encode video and textual features, generating semantically aligned video and text embeddings, along with multimodal class tokens. A mask prior generator utilizes the video embeddings and class tokens to create pseudo masks of target objects and global context. These masks are fed into the prompt encoder as dense prompts along with multimodal class tokens as sparse prompts to generate accurate prompts for SAM 2. To provide the online SAM 2 with a global view, we introduce a hierarchical global-historical aggregator, which allows SAM 2 to aggregate global and historical information of target objects at both pixel and object levels, enhancing the target representation and temporal consistency. Extensive experiments on several RVOS benchmarks demonstrate the superiority of MPG-SAM 2 and the effectiveness of our proposed modules. The code is available at https://github.com/rongfu-dsb/MPG-SAM2.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MPG-SAM 2: Adapting SAM 2 with Mask Priors and Global Context for Referring Video Object Segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mpgsam",
      "",
      "adapting"
    ],
    "category": "noticia"
  },
  {
    "title": "Autonomous Structural Memory Manipulation for Large Language Models Using Hierarchical Embedding Augmentation",
    "title_es": "Autonomous Structural Memory Manipulation for Large Language Models Using Hierarchical Embedding Augmentation",
    "url": "https://arxiv.org/abs/2501.14119",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.14119v2 Announce Type: replace \nAbstract: Transformative innovations in model architectures have introduced hierarchical embedding augmentation as a means to redefine the representation of tokens through multi-level semantic structures, offering enhanced adaptability to complex linguistic inputs. Autonomous structural memory manipulation further advances this paradigm through dynamic memory reallocation mechanisms that prioritize critical contextual features while suppressing less relevant information, enabling scalable and efficient performance across diverse tasks. Experimental results reveal substantial improvements in computational efficiency, with marked reductions in processing overhead for longer input sequences, achieved through memory reorganization strategies that adapt to evolving contextual requirements. Hierarchical embeddings not only improved contextual alignment but also facilitated task generalization by capturing relationships at varying semantic granularities, ensuring coherence across layers without introducing significant computational redundancies. Comparative analysis against baseline models demonstrated unique advantages in accuracy, efficiency, and interpretability, particularly in tasks requiring complex contextual understanding or domain-specific adaptability. The ability to dynamically adjust token representations and memory configurations contributed to the model's robustness under varied and unpredictable input conditions. Applications benefiting from these advancements include multi-domain generalization, interactive systems, and scenarios involving real-time decision-making, where traditional static memory architectures often face limitations. The proposed methodology combines advanced embedding and memory management strategies into a cohesive framework that addresses scalability challenges while preserving task-specific relevance.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Autonomous Structural Memory Manipulation for Large Language Models Using Hierarchical Embedding Augmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "autonomous",
      "structural",
      "memory"
    ],
    "category": "noticia"
  },
  {
    "title": "Systemizing Multiplicity: The Curious Case of Arbitrariness in Machine Learning",
    "title_es": "Systemizing Multiplicity: The Curious Case of Arbitrariness in Machine Learning",
    "url": "https://arxiv.org/abs/2501.14959",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.14959v2 Announce Type: replace \nAbstract: Algorithmic modeling relies on limited information in data to extrapolate outcomes for unseen scenarios, often embedding an element of arbitrariness in its decisions. A perspective on this arbitrariness that has recently gained interest is multiplicity-the study of arbitrariness across a set of \"good models\", i.e., those likely to be deployed in practice. In this work, we systemize the literature on multiplicity by: (a) formalizing the terminology around model design choices and their contribution to arbitrariness, (b) expanding the definition of multiplicity to incorporate underrepresented forms beyond just predictions and explanations, (c) clarifying the distinction between multiplicity and other lenses of arbitrariness, i.e., uncertainty and variance, and (d) distilling the benefits and potential risks of multiplicity into overarching trends, situating it within the broader landscape of responsible AI. We conclude by identifying open research questions and highlighting emerging trends in this young but rapidly growing area of research.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Systemizing Multiplicity: The Curious Case of Arbitrariness in Machine Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "systemizing",
      "multiplicity",
      "the"
    ],
    "category": "noticia"
  },
  {
    "title": "Hierarchical Pattern Decryption Methodology for Ransomware Detection Using Probabilistic Cryptographic Footprints",
    "title_es": "Hierarchical Pattern Decryption Methodology for Ransomware Detection Using Probabilistic Cryptographic Footprints",
    "url": "https://arxiv.org/abs/2501.15084",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.15084v2 Announce Type: replace \nAbstract: The increasing sophistication of encryption-based ransomware has demanded innovative approaches to detection and mitigation, prompting the development of a hierarchical framework grounded in probabilistic cryptographic analysis. By focusing on the statistical characteristics of encryption patterns, the proposed methodology introduces a layered approach that combines advanced clustering algorithms with machine learning to isolate ransomware-induced anomalies. Through comprehensive testing across diverse ransomware families, the framework demonstrated exceptional accuracy, effectively distinguishing malicious encryption operations from benign activities while maintaining low false positive rates. The system's design integrates dynamic feedback mechanisms, enabling adaptability to varying cryptographic complexities and operational environments. Detailed entropy-based evaluations revealed its sensitivity to subtle deviations in encryption workflows, offering a robust alternative to traditional detection methods reliant on static signatures or heuristics. Computational benchmarks confirmed its scalability and efficiency, achieving consistent performance even under high data loads and complex cryptographic scenarios. The inclusion of real-time clustering and anomaly evaluation ensures rapid response capabilities, addressing critical latency challenges in ransomware detection. Performance comparisons with established methods highlighted its improvements in detection efficacy, particularly against advanced ransomware employing extended key lengths and unique cryptographic protocols.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hierarchical Pattern Decryption Methodology for Ransomware Detection Using Probabilistic Cryptographic Footprints\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hierarchical",
      "pattern",
      "decryption"
    ],
    "category": "noticia"
  },
  {
    "title": "MetaOcc: Spatio-Temporal Fusion of Surround-View 4D Radar and Camera for 3D Occupancy Prediction with Dual Training Strategies",
    "title_es": "MetaOcc: Spatio-Temporal Fusion of Surround-View 4D Radar and Camera for 3D Occupancy Prediction with Dual Training Strategies",
    "url": "https://arxiv.org/abs/2501.15384",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.15384v3 Announce Type: replace \nAbstract: Robust 3D occupancy prediction is essential for autonomous driving, particularly under adverse weather conditions where traditional vision-only systems struggle. While the fusion of surround-view 4D radar and cameras offers a promising low-cost solution, effectively extracting and integrating features from these heterogeneous sensors remains challenging. This paper introduces MetaOcc, a novel multi-modal framework for omnidirectional 3D occupancy prediction that leverages both multi-view 4D radar and images. To address the limitations of directly applying LiDAR-oriented encoders to sparse radar data, we propose a Radar Height Self-Attention module that enhances vertical spatial reasoning and feature extraction. Additionally, a Hierarchical Multi-scale Multi-modal Fusion strategy is developed to perform adaptive local-global fusion across modalities and time, mitigating spatio-temporal misalignments and enriching fused feature representations. To reduce reliance on expensive point cloud annotations, we further propose a pseudo-label generation pipeline based on an open-set segmentor. This enables a semi-supervised strategy that achieves 90% of the fully supervised performance using only 50% of the ground truth labels, offering an effective trade-off between annotation cost and accuracy. Extensive experiments demonstrate that MetaOcc under full supervision achieves state-of-the-art performance, outperforming previous methods by +0.47 SC IoU and +4.02 mIoU on the OmniHD-Scenes dataset, and by +1.16 SC IoU and +1.24 mIoU on the SurroundOcc-nuScenes dataset. These results demonstrate the scalability and robustness of MetaOcc across sensor domains and training conditions, paving the way for practical deployment in real-world autonomous systems. Code and data are available at https://github.com/LucasYang567/MetaOcc.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MetaOcc: Spatio-Temporal Fusion of Surround-View 4D Radar and Camera for 3D Occupancy Prediction with Dual Training Strategies\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "metaocc",
      "spatiotemporal",
      "fusion"
    ],
    "category": "noticia"
  },
  {
    "title": "FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint",
    "title_es": "FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint",
    "url": "https://arxiv.org/abs/2501.15509",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.15509v3 Announce Type: replace \nAbstract: Model fingerprinting is a widely adopted approach to safeguard the intellectual property rights of open-source models by preventing their unauthorized reuse. It is promising and convenient since it does not necessitate modifying the protected model. In this paper, we revisit existing fingerprinting methods and reveal that they are vulnerable to false claim attacks where adversaries falsely assert ownership of any third-party model. We demonstrate that this vulnerability mostly stems from their untargeted nature, where they generally compare the outputs of given samples on different models instead of the similarities to specific references. Motivated by these findings, we propose a targeted fingerprinting paradigm (i.e., FIT-Print) to counteract false claim attacks. Specifically, FIT-Print transforms the fingerprint into a targeted signature via optimization. Building on the principles of FIT-Print, we develop bit-wise and list-wise black-box model fingerprinting methods, i.e., FIT-ModelDiff and FIT-LIME, which exploit the distance between model outputs and the feature attribution of specific samples as the fingerprint, respectively. Extensive experiments on benchmark models and datasets verify the effectiveness, conferrability, and resistance to false claim attacks of our FIT-Print.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fitprint",
      "towards",
      "falseclaimresistant"
    ],
    "category": "noticia"
  },
  {
    "title": "Rethinking the Bias of Foundation Model under Long-tailed Distribution",
    "title_es": "Rethinking the Bias of Foundation Model under Long-tailed Distribution",
    "url": "https://arxiv.org/abs/2501.15955",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.15955v3 Announce Type: replace \nAbstract: Long-tailed learning has garnered increasing attention due to its practical significance. Among the various approaches, the fine-tuning paradigm has gained considerable interest with the advent of foundation models. However, most existing methods primarily focus on leveraging knowledge from these models, overlooking the inherent biases introduced by the imbalanced training data they rely on. In this paper, we examine how such imbalances from pre-training affect long-tailed downstream tasks. Specifically, we find the imbalance biases inherited in foundation models on downstream task as parameter imbalance and data imbalance. During fine-tuning, we observe that parameter imbalance plays a more critical role, while data imbalance can be mitigated using existing re-balancing strategies. Moreover, we find that parameter imbalance cannot be effectively addressed by current re-balancing techniques, such as adjusting the logits, during training, unlike data imbalance. To tackle both imbalances simultaneously, we build our method on causal learning and view the incomplete semantic factor as the confounder, which brings spurious correlations between input samples and labels. To resolve the negative effects of this, we propose a novel backdoor adjustment method that learns the true causal effect between input samples and labels, rather than merely fitting the correlations in the data. Notably, we achieve an average performance increase of about $1.67\\%$ on each dataset. Code is available: https://github.com/JiahaoChen1/Pre-train-Imbalance",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Rethinking the Bias of Foundation Model under Long-tailed Distribution\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "rethinking",
      "the",
      "bias"
    ],
    "category": "noticia"
  },
  {
    "title": "Contextual Reinforcement in Multimodal Token Compression for Large Language Models",
    "title_es": "Contextual Reinforcement in Multimodal Token Compression for Large Language Models",
    "url": "https://arxiv.org/abs/2501.16658",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.16658v2 Announce Type: replace \nAbstract: Effective token compression remains a critical challenge for scaling models to handle increasingly complex and diverse datasets. A novel mechanism based on contextual reinforcement is introduced, dynamically adjusting token importance through interdependencies and semantic relevance. This approach enables substantial reductions in token usage while preserving the quality and coherence of information representation. Incorporating graph-based algorithms and adaptive weighting, the method captures subtle contextual relationships across textual and multimodal data, ensuring robust alignment and performance in downstream tasks. Evaluations across varied domains reveal significant improvements in accuracy and semantic retention, particularly for tasks requiring detailed cross-modal interactions. Memory usage analyses demonstrate improved computational efficiency, with minimal overhead despite the additional reinforcement processes. Performance gains are further validated through error distribution analyses, showing reduced semantic loss and syntactic inconsistencies compared to baseline models. The modular architecture ensures compatibility with a wide range of open-source frameworks, facilitating scalable implementation for real-world applications. These findings highlight the potential of contextual reinforcement in redefining token management strategies and advancing large-scale model design.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Contextual Reinforcement in Multimodal Token Compression for Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "contextual",
      "reinforcement",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs",
    "title_es": "Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs",
    "url": "https://arxiv.org/abs/2501.17429",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.17429v2 Announce Type: replace \nAbstract: The rapid evolution of cyber threats has outpaced traditional detection methodologies, necessitating innovative approaches capable of addressing the adaptive and complex behaviors of modern adversaries. A novel framework was introduced, leveraging Temporal-Correlation Graphs to model the intricate relationships and temporal patterns inherent in malicious operations. The approach dynamically captured behavioral anomalies, offering a robust mechanism for distinguishing between benign and malicious activities in real-time scenarios. Extensive experiments demonstrated the framework's effectiveness across diverse ransomware families, with consistently high precision, recall, and overall detection accuracy. Comparative evaluations highlighted its better performance over traditional signature-based and heuristic methods, particularly in handling polymorphic and previously unseen ransomware variants. The architecture was designed with scalability and modularity in mind, ensuring compatibility with enterprise-scale environments while maintaining resource efficiency. Analysis of encryption speeds, anomaly patterns, and temporal correlations provided deeper insights into the operational strategies of ransomware, validating the framework's adaptability to evolving threats. The research contributes to advancing cybersecurity technologies by integrating dynamic graph analytics and machine learning for future innovations in threat detection. Results from this study underline the potential for transforming the way organizations detect and mitigate complex cyberattacks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "algorithmic",
      "segmentation",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Structural Embedding Projection for Contextual Large Language Model Inference",
    "title_es": "Structural Embedding Projection for Contextual Large Language Model Inference",
    "url": "https://arxiv.org/abs/2501.18826",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.18826v2 Announce Type: replace \nAbstract: Structured embedding transformations offer a promising approach for enhancing the efficiency and coherence of language model inference. The introduction of Structural Embedding Projection (SEP) provides a mechanism for refining token representations through projection matrices that integrate hierarchical and relational dependencies. The mathematical formulation of SEP enables embedding spaces to capture structured contextual relationships, thereby improving semantic fidelity without significantly increasing computational overhead. Experimental evaluations conducted on a range of linguistic datasets revealed that SEP contributed to reductions in perplexity and enhanced contextual coherence, demonstrating its potential to refine language model outputs. Computational efficiency assessments highlighted variations across different datasets, suggesting that the integration of structured embeddings introduced dataset-dependent trade-offs between inference speed and representational richness. The qualitative analysis of generated responses indicated that SEP enhanced narrative consistency and topic alignment, leading to improved fluency in multi-sentence text generation. The modifications to embedding layers required precise optimization to ensure stable training dynamics, as the introduction of structured transformations altered the traditional representation-learning process. The architectural adjustments necessary for SEP implementation influenced inference latency and memory consumption, requiring a balance between efficiency gains and additional processing demands. The impact of SEP on lexical diversity suggested that embedding modifications influenced the model's vocabulary usage, reflecting a more context-aware selection of generated tokens.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Structural Embedding Projection for Contextual Large Language Model Inference\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "structural",
      "embedding",
      "projection"
    ],
    "category": "noticia"
  },
  {
    "title": "Hierarchical Cryptographic Signature Mapping for Ransomware Classification: A Structural Decomposition Approach",
    "title_es": "Hierarchical Cryptographic Signature Mapping for Ransomware Classification: A Structural Decomposition Approach",
    "url": "https://arxiv.org/abs/2501.19120",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.19120v2 Announce Type: replace \nAbstract: Encryption-based cyber threats continue to evolve, leveraging increasingly sophisticated cryptographic techniques to evade detection and persist within compromised systems. A hierarchical classification framework designed to analyze structural cryptographic properties provides a novel approach to distinguishing malicious encryption from legitimate cryptographic operations. By systematically decomposing encryption workflows into hierarchical layers, the classification method enhances the ability to recognize distinct patterns across diverse threat variants, reducing the dependence on predefined signatures that often fail against rapidly mutating threats. The study examines how cryptographic feature mapping facilitates improved classification accuracy, highlighting the role of entropy, key exchange mechanisms, and algorithmic dependencies in distinguishing harmful encryption activities. Through experimental validation, the framework demonstrated a high degree of precision across multiple attack families, outperforming conventional classification techniques while maintaining computational efficiency suitable for large-scale cybersecurity applications. The layered structural analysis further enhances forensic investigations, enabling security analysts to dissect encryption workflows to trace attack origins and identify commonalities across different campaigns. The methodology strengthens proactive threat mitigation efforts, offering a scalable and adaptable solution that accounts for both known and emerging encryption-based cyber threats. Comparative evaluations illustrate the advantages of structural decomposition in mitigating false positives and negatives, reinforcing the reliability of cryptographic signature classification in real-world security environments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hierarchical Cryptographic Signature Mapping for Ransomware Classification: A Structural Decomposition Approach\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hierarchical",
      "cryptographic",
      "signature"
    ],
    "category": "noticia"
  },
  {
    "title": "Contextually Entangled Gradient Mapping for Optimized LLM Comprehension",
    "title_es": "Contextually Entangled Gradient Mapping for Optimized LLM Comprehension",
    "url": "https://arxiv.org/abs/2502.00048",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.00048v2 Announce Type: replace \nAbstract: Contextually Entangled Gradient Mapping (CEGM) introduces a new approach to gradient optimization, redefining the relationship between contextual embeddings and gradient updates to enhance semantic coherence and reasoning capabilities in neural architectures. By treating gradients as dynamic carriers of contextual dependencies rather than isolated numerical entities, the proposed methodology bridges critical gaps in existing optimization strategies. The integration of entangled gradient dynamics into a loss regularization framework demonstrated significant improvements in tasks involving long-form reasoning, contextual retention, and adaptability to unseen domains. Experimental evaluations showed that the CEGM-enhanced model consistently outperformed baseline approaches, achieving higher accuracy in token-level predictions and greater resilience to noisy inputs. Practical implementations involved modifications to training pipelines, introducing entanglement layers and dynamic coefficient adjustments that seamlessly align with existing architectures. Results further highlighted reductions in semantic drift during sequential transformations and improvements in embedding coherence across paraphrased sentences, showing the robustness and versatility of the proposed methodology. The findings demonstrate the broader implications of gradient entanglement for both theoretical advancements and practical applications in optimization strategies.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Contextually Entangled Gradient Mapping for Optimized LLM Comprehension\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "contextually",
      "entangled",
      "gradient"
    ],
    "category": "noticia"
  },
  {
    "title": "Context-Preserving Tensorial Reconfiguration in Large Language Model Training",
    "title_es": "Context-Preserving Tensorial Reconfiguration in Large Language Model Training",
    "url": "https://arxiv.org/abs/2502.00246",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.00246v2 Announce Type: replace \nAbstract: Handling long-range dependencies in neural architectures has remained a persistent challenge due to computational limitations and inefficient contextual retention mechanisms. Tensorial operations have provided a foundation for restructuring model representations, yet conventional architectures have struggled to incorporate such techniques without introducing excessive complexity. A novel approach, Context-Preserving Tensorial Reconfiguration (CPTR), enables dynamic reorganization of weight tensors through structured factorization and adaptive contraction, allowing for enhanced contextual integration without substantial computational overhead. Empirical evaluations demonstrate that CPTR improves coherence retention across extended sequences, leading to measurable reductions in perplexity and improved recall accuracy for long-context tasks. Performance comparisons reveal that CPTR-enhanced models exhibit greater computational efficiency and reduced memory consumption while maintaining competitive language generation fluency and accuracy. Gradient stability metrics further validate the improved training efficiency, revealing more controlled variance in weight updates. Comparative studies across baseline and CPTR-enhanced models confirm that tensorial reconfiguration contributes to more stable and computationally efficient language modeling. The findings support the potential of CPTR in refining contemporary neural architectures for tasks requiring long-range contextual understanding and efficient memory utilization.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Context-Preserving Tensorial Reconfiguration in Large Language Model Training\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "contextpreserving",
      "tensorial",
      "reconfiguration"
    ],
    "category": "noticia"
  },
  {
    "title": "Contextual Morphogenesis in Large Language Models: A Novel Approach to Self-Organizing Token Representations",
    "title_es": "Contextual Morphogenesis in Large Language Models: A Novel Approach to Self-Organizing Token Representations",
    "url": "https://arxiv.org/abs/2502.00301",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.00301v2 Announce Type: replace \nAbstract: Token representations influence the efficiency and adaptability of language models, yet conventional tokenization strategies impose rigid segmentation boundaries that do not adjust dynamically to evolving contextual relationships. The introduction of contextual morphogenesis establishes a self-organizing mechanism that restructures token boundaries based on learned contextual dependencies, allowing embeddings to evolve progressively across iterative processing steps. Empirical evaluations demonstrate that dynamically adjusted tokenization contributes to reductions in perplexity while maintaining representational stability, particularly in linguistically complex domains where static segmentation fails to capture nuanced dependencies. Computational trade-offs associated with self-organizing token structures indicate that additional processing overhead remains within feasible limits, provided that optimization strategies account for segmentation update efficiency. Comparative assessments across different linguistic corpora suggest that adaptive tokenization preserves interpretability while improving alignment with contextual cues, reinforcing the potential of morphogenetic segmentation mechanisms to refine predictive accuracy. Stability analyses confirm that evolving token structures maintain consistent segmentation behaviors across varied text distributions, ensuring that representational adaptations remain linguistically coherent. The effectiveness of contextual morphogenesis in refining structural stability and predictive performance highlights its viability as an alternative to traditional tokenization methods. Further analysis of computational efficiency considerations suggests that hybrid strategies integrating both static and dynamic segmentation techniques may offer a balanced approach to optimizing representational flexibility while maintaining inference efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Contextual Morphogenesis in Large Language Models: A Novel Approach to Self-Organizing Token Representations\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "contextual",
      "morphogenesis",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Embodied Intelligence for 3D Understanding: A Survey on 3D Scene Question Answering",
    "title_es": "Embodied Intelligence for 3D Understanding: A Survey on 3D Scene Question Answering",
    "url": "https://arxiv.org/abs/2502.00342",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.00342v2 Announce Type: replace \nAbstract: 3D Scene Question Answering (3D SQA) represents an interdisciplinary task that integrates 3D visual perception and natural language processing, empowering intelligent agents to comprehend and interact with complex 3D environments. Recent advances in large multimodal modelling have driven the creation of diverse datasets and spurred the development of instruction-tuning and zero-shot methods for 3D SQA. However, this rapid progress introduces challenges, particularly in achieving unified analysis and comparison across datasets and baselines. In this survey, we provide the first comprehensive and systematic review of 3D SQA. We organize existing work from three perspectives: datasets, methodologies, and evaluation metrics. Beyond basic categorization, we identify shared architectural patterns across methods. Our survey further synthesizes core limitations and discusses how current trends, such as instruction tuning, multimodal alignment, and zero-shot, can shape future developments. Finally, we propose a range of promising research directions covering dataset construction, task generalization, interaction modeling, and unified evaluation protocols. This work aims to serve as a foundation for future research and foster progress toward more generalizable and intelligent 3D SQA systems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Embodied Intelligence for 3D Understanding: A Survey on 3D Scene Question Answering\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "embodied",
      "intelligence",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Context-Aware Hierarchical Merging for Long Document Summarization",
    "title_es": "Context-Aware Hierarchical Merging for Long Document Summarization",
    "url": "https://arxiv.org/abs/2502.00977",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.00977v2 Announce Type: replace \nAbstract: Hierarchical Merging is a technique commonly used to summarize very long texts ($>$100K tokens) by breaking down the input into smaller sections, summarizing those sections individually, and then merging or combining those summaries into a final coherent summary. Although it helps address the limitations of large language models (LLMs) with fixed input length constraints, the recursive merging process can amplify LLM hallucinations, increasing the risk of factual inaccuracies. In this paper, we seek to mitigate hallucinations by enriching hierarchical merging with context from the source document. Specifically, we propose different approaches to contextual augmentation ranging from \\emph{replacing} intermediate summaries with relevant input context, to \\emph{refining} them while using the context as supporting evidence, and \\emph{aligning} them implicitly (via citations) to the input. Experimental results on datasets representing legal and narrative domains show that contextual augmentation consistently outperforms zero-shot and hierarchical merging baselines for the Llama 3.1 model family. Our analysis further reveals that refinement methods tend to perform best when paired with extractive summarization for identifying relevant input.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Context-Aware Hierarchical Merging for Long Document Summarization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "contextaware",
      "hierarchical",
      "merging"
    ],
    "category": "noticia"
  },
  {
    "title": "Gradient-Regularized Latent Space Modulation in Large Language Models for Structured Contextual Synthesis",
    "title_es": "Gradient-Regularized Latent Space Modulation in Large Language Models for Structured Contextual Synthesis",
    "url": "https://arxiv.org/abs/2502.01979",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.01979v2 Announce Type: replace \nAbstract: Generating structured textual content requires mechanisms that enforce coherence, stability, and adherence to predefined constraints while maintaining semantic fidelity. Conventional approaches often rely on rule-based heuristics or fine-tuning strategies that lack flexibility and generalizability across diverse tasks. The incorporation of Gradient-Regularized Latent Space Modulation (GRLSM) introduces a novel paradigm for guiding text generation through the application of structured constraints within the latent space. The integration of gradient-based regularization mitigates abrupt variations in latent representations, ensuring a smoother encoding process that enhances structural consistency and logical progression within generated sequences. Comparative evaluations demonstrate that latent space modulation leads to a reduction in perplexity, increased coherence scores, and improved structural alignment across multiple domains. Stability assessments further indicate that the imposition of spectral norm constraints facilitates more controlled variations in generated text, preserving semantic consistency under input perturbations. Empirical results confirm that structured latent space constraints not only refine the organization of generated outputs but also enhance interpretability through more predictable and reliable synthesis patterns. Performance metrics illustrate that the GRLSM framework substantially reduces structural inconsistencies while preserving the generative flexibility inherent in neural models.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Gradient-Regularized Latent Space Modulation in Large Language Models for Structured Contextual Synthesis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "gradientregularized",
      "latent",
      "space"
    ],
    "category": "noticia"
  },
  {
    "title": "The Ensemble Kalman Update is an Empirical Matheron Update",
    "title_es": "The Ensemble Kalman Update is an Empirical Matheron Update",
    "url": "https://arxiv.org/abs/2502.03048",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.03048v3 Announce Type: replace \nAbstract: The Ensemble Kalman Filter (EnKF) is a widely used method for data assimilation in high-dimensional systems, with an ensemble update step equivalent to an empirical version of the Matheron update popular in Gaussian process regression -- a connection that links half a century of data-assimilation engineering to modern path-wise GP sampling.\n  This paper provides a compact introduction to this simple but under-exploited connection, with necessary definitions accessible to all fields involved.\n  Source code is available at https://github.com/danmackinlay/paper_matheron_equals_enkf .",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"The Ensemble Kalman Update is an Empirical Matheron Update\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "ensemble",
      "kalman"
    ],
    "category": "noticia"
  },
  {
    "title": "Conditional Diffusion Models are Medical Image Classifiers that Provide Explainability and Uncertainty for Free",
    "title_es": "Conditional Diffusion Models are Medical Image Classifiers that Provide Explainability and Uncertainty for Free",
    "url": "https://arxiv.org/abs/2502.03687",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.03687v2 Announce Type: replace \nAbstract: Discriminative classifiers have become a foundational tool in deep learning for medical imaging, excelling at learning separable features of complex data distributions. However, these models often need careful design, augmentation, and training techniques to ensure safe and reliable deployment. Recently, diffusion models have become synonymous with generative modeling in 2D. These models showcase robustness across a range of tasks including natural image classification, where classification is performed by comparing reconstruction errors across images generated for each possible conditioning input. This work presents the first exploration of the potential of class conditional diffusion models for 2D medical image classification. First, we develop a novel majority voting scheme shown to improve the performance of medical diffusion classifiers. Next, extensive experiments on the CheXpert and ISIC Melanoma skin cancer datasets demonstrate that foundation and trained-from-scratch diffusion models achieve competitive performance against SOTA discriminative classifiers without the need for explicit supervision. In addition, we show that diffusion classifiers are intrinsically explainable, and can be used to quantify the uncertainty of their predictions, increasing their trustworthiness and reliability in safety-critical, clinical contexts. Further information is available on our project page: https://faverogian.github.io/med-diffusion-classifier.github.io/.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Conditional Diffusion Models are Medical Image Classifiers that Provide Explainability and Uncertainty for Free\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "conditional",
      "diffusion",
      "models"
    ],
    "category": "noticia"
  },
  {
    "title": "CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements",
    "title_es": "CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements",
    "url": "https://arxiv.org/abs/2502.04592",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.04592v3 Announce Type: replace \nAbstract: Accurately forecasting the impact of macroeconomic events is critical for investors and policymakers. Salient events like monetary policy decisions and employment reports often trigger market movements by shaping expectations of economic growth and risk, thereby establishing causal relationships between events and market behavior. Existing forecasting methods typically focus either on textual analysis or time-series modeling, but fail to capture the multi-modal nature of financial markets and the causal relationship between events and price movements. To address these gaps, we propose CAMEF (Causal-Augmented Multi-Modality Event-Driven Financial Forecasting), a multi-modality framework that effectively integrates textual and time-series data with a causal learning mechanism and an LLM-based counterfactual event augmentation technique for causal-enhanced financial forecasting. Our contributions include: (1) a multi-modal framework that captures causal relationships between policy texts and historical price data; (2) a new financial dataset with six types of macroeconomic releases from 2008 to April 2024, and high-frequency real trading data for five key U.S. financial assets; and (3) an LLM-based counterfactual event augmentation strategy. We compare CAMEF to state-of-the-art transformer-based time-series and multi-modal baselines, and perform ablation studies to validate the effectiveness of the causal learning mechanism and event types.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "camef",
      "causalaugmented",
      "multimodality"
    ],
    "category": "noticia"
  },
  {
    "title": "Neural Encrypted State Transduction for Ransomware Classification: A Novel Approach Using Cryptographic Flow Residuals",
    "title_es": "Neural Encrypted State Transduction for Ransomware Classification: A Novel Approach Using Cryptographic Flow Residuals",
    "url": "https://arxiv.org/abs/2502.05341",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.05341v2 Announce Type: replace \nAbstract: Encrypted behavioral patterns provide a unique avenue for classifying complex digital threats without reliance on explicit feature extraction, enabling detection frameworks to remain effective even when conventional static and behavioral methodologies fail. A novel approach based on Neural Encrypted State Transduction (NEST) is introduced to analyze cryptographic flow residuals and classify threats through their encrypted state transitions, mitigating evasion tactics employed through polymorphic and obfuscated attack strategies. The mathematical formulation of NEST leverages transduction principles to map state transitions dynamically, enabling high-confidence classification without requiring direct access to decrypted execution traces. Experimental evaluations demonstrate that the proposed framework achieves improved detection accuracy across multiple ransomware families while exhibiting resilience against adversarial perturbations and previously unseen attack variants. The model maintains competitive processing efficiency, offering a practical balance between classification performance and computational resource constraints, making it suitable for large-scale security deployments. Comparative assessments reveal that NEST consistently outperforms baseline classification models, particularly in detecting ransomware samples employing delayed encryption, entropy-based obfuscation, and memory-resident execution techniques. The capacity to generalize across diverse execution environments reinforces the applicability of encrypted transduction methodologies in adversarial classification tasks beyond conventional malware detection pipelines. The integration of residual learning mechanisms within the transduction layers further enhances classification robustness, minimizing both false positives and misclassification rates across varied operational contexts.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Neural Encrypted State Transduction for Ransomware Classification: A Novel Approach Using Cryptographic Flow Residuals\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "neural",
      "encrypted",
      "state"
    ],
    "category": "noticia"
  },
  {
    "title": "Probabilistic Foundations for Metacognition via Hybrid-AI",
    "title_es": "Probabilistic Foundations for Metacognition via Hybrid-AI",
    "url": "https://arxiv.org/abs/2502.05398",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.05398v3 Announce Type: replace \nAbstract: Metacognition is the concept of reasoning about an agent's own internal processes, and it has recently received renewed attention with respect to artificial intelligence (AI) and, more specifically, machine learning systems. This paper reviews a hybrid-AI approach known as \"error detecting and correcting rules\" (EDCR) that allows for the learning of rules to correct perceptual (e.g., neural) models. Additionally, we introduce a probabilistic framework that adds rigor to prior empirical studies, and we use this framework to prove results on necessary and sufficient conditions for metacognitive improvement, as well as limits to the approach. A set of future",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Probabilistic Foundations for Metacognition via Hybrid-AI\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "probabilistic",
      "foundations",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Sample-Efficient Reinforcement Learning from Human Feedback via Information-Directed Sampling",
    "title_es": "Sample-Efficient Reinforcement Learning from Human Feedback via Information-Directed Sampling",
    "url": "https://arxiv.org/abs/2502.05434",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.05434v3 Announce Type: replace \nAbstract: We study the problem of reinforcement learning from human feedback (RLHF), a critical problem in training large language models, from a theoretical perspective. Our main contribution is the design of novel sample-efficient RLHF algorithms based on information-directed sampling (IDS), an online decision-making principle inspired by information theory. Our algorithms maximize the sum of the value function and a mutual information term that encourages exploration of the unknown environment (which quantifies the information gained about the environment through observed human feedback data). To tackle the challenge of large state spaces and improve sample efficiency, we construct a simplified \\emph{surrogate environment} and introduce a novel distance measure (named the \\emph{$\\ell_g$-distance}), enabling our IDS-based algorithm to achieve a Bayesian regret upper bound of order $O(H^{\\frac{3}{2}}\\sqrt{\\log(K(\\epsilon)) T})$, where $H$ is the episode length, $T$ is the number of episode and $K(\\epsilon)$ is related to the covering number of the environment. Specializing to the tabular settings, this regret bound is of order $\\tilde{O}(H^2\\sqrt{SAT})$, where $S$ and $A$ are the numbers of states and actions. Finally, we propose an Approximate-IDS algorithm that is computationally more efficient while maintaining nearly the same sample efficiency. The design principle of this approximate algorithm is not only effective in RLHF settings but also applicable to the standard RL framework. Moreover, our work showcases the value of information theory in reinforcement learning and in the training of large language models.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Sample-Efficient Reinforcement Learning from Human Feedback via Information-Directed Sampling\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sampleefficient",
      "reinforcement",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "Latent Structure Modulation in Large Language Models Through Stochastic Concept Embedding Transitions",
    "title_es": "Latent Structure Modulation in Large Language Models Through Stochastic Concept Embedding Transitions",
    "url": "https://arxiv.org/abs/2502.05553",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.05553v2 Announce Type: replace \nAbstract: Stochastic embedding transitions introduce a probabilistic mechanism for adjusting token representations dynamically during inference, mitigating the constraints imposed through static or deterministic embeddings. A transition framework was proposed in which each token embedding evolved through probabilistic updates, ensuring adaptability while preserving semantic integrity across linguistic contexts. Empirical evaluations demonstrated that models incorporating stochastic transitions exhibited greater lexical diversity, improved generative coherence, and enhanced retention of low-frequency vocabulary, contributing to more varied sentence structures and reduced reliance on high-probability token selections. Statistical analyses of embedding drift across transformer layers indicated that representations evolved more flexibly without losing coherence, supporting the hypothesis that controlled stochasticity facilitated context-sensitive representation learning. Experimental results revealed that probabilistic embeddings introduced minor computational overhead while maintaining generative efficiency, reinforcing their feasibility in large-scale applications. A comparative study with traditional embedding approaches highlighted measurable gains in text completion accuracy, dialogue coherence, and structural complexity, confirming the effectiveness of stochastic transitions in enhancing representation expressiveness. Clustering patterns in the embedding space suggested that probabilistic updates preserved meaningful semantic groupings while enabling context-driven shifts, further validating the stability of the transition mechanism. Performance metrics indicated that stochastic transitions balanced adaptability and control, ensuring that generative outputs remained linguistically coherent without excessive randomness.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Latent Structure Modulation in Large Language Models Through Stochastic Concept Embedding Transitions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "latent",
      "structure",
      "modulation"
    ],
    "category": "noticia"
  },
  {
    "title": "Structural Perturbation in Large Language Model Representations through Recursive Symbolic Regeneration",
    "title_es": "Structural Perturbation in Large Language Model Representations through Recursive Symbolic Regeneration",
    "url": "https://arxiv.org/abs/2502.05794",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.05794v2 Announce Type: replace \nAbstract: Symbolic perturbations offer a novel approach for influencing neural representations without requiring direct modification of model parameters. The recursive regeneration of symbolic structures introduces structured variations in latent embeddings, leading to controlled shifts in attention dynamics and lexical diversity across sequential generations. A comparative analysis with conventional fine-tuning techniques reveals that structural modifications at the symbolic level induce distinct variations in contextual sensitivity while maintaining overall model fluency and coherence. Shifts in attention weight distributions highlight the role of symbolic modifications in adjusting token dependencies, influencing response variability, and refining long-form text generation. Experimental findings suggest that symbolic perturbations can enhance adaptability in domain-specific applications, allowing modifications in model behavior without retraining. Evaluations of semantic drift indicate that recursive regeneration alters long-range token dependencies, affecting topic coherence across extended text sequences. Results from lexical variability assessments further support the conclusion that symbolic-level modifications introduce interpretable variations in generated responses, potentially enabling more controlled stylistic adjustments in automated text generation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Structural Perturbation in Large Language Model Representations through Recursive Symbolic Regeneration\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "structural",
      "perturbation",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Ensemble-Tight Second-Order Asymptotics and Exponents for Guessing-Based Decoding with Abandonment",
    "title_es": "Ensemble-Tight Second-Order Asymptotics and Exponents for Guessing-Based Decoding with Abandonment",
    "url": "https://arxiv.org/abs/2502.05959",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.05959v2 Announce Type: replace \nAbstract: This paper considers guessing-based decoders with abandonment for discrete memoryless channels in which all codewords have the same composition. This class of decoders rank-orders all input sequences in the codebook's composition class from ``closest'' to ``farthest'' from the channel output and then queries them sequentially in that order for codebook membership. Decoding terminates when a codeword is encountered or when a predetermined number of guesses is reached, and decoding is abandoned. We derive ensemble-tight first-order asymptotics for the code rate and abandonment rate, which shows that guessing-based decoding is more efficient than conventional testing-based decoding whenever the capacity of the channel exceeds half the entropy of the capacity-achieving input distribution. The main focus of this paper is on refined asymptotics, specifically, second-order asymptotics, error exponents, and strong converse exponents. The optimal second-order region is characterized in terms of the minimum of the second-order code and abandonment rates. The error (resp.\\ strong converse) exponent is characterized in terms of the minimum (resp.\\ maximum) of the usual channel coding exponent and an abandonment exponent, which turns out to be a special case of the exponent of conditional almost-lossless source coding.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Ensemble-Tight Second-Order Asymptotics and Exponents for Guessing-Based Decoding with Abandonment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ensembletight",
      "secondorder",
      "asymptotics"
    ],
    "category": "noticia"
  },
  {
    "title": "DeToNATION: Decoupled Torch Network-Aware Training on Interlinked Online Nodes",
    "title_es": "DeToNATION: Decoupled Torch Network-Aware Training on Interlinked Online Nodes",
    "url": "https://arxiv.org/abs/2502.06728",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.06728v3 Announce Type: replace \nAbstract: Training large neural network models requires extensive computational resources, often distributed across several nodes and accelerators. Recent findings suggest that it may be sufficient to only exchange the fast moving components of the gradients, while accumulating momentum locally (Decoupled Momentum, or DeMo). However, DeMo assumes that models fit on a single accelerator. We relax this assumption and introduce FlexDeMo, whereby nodes fully shard model parameters locally between different accelerators, while inter-node communication is reduced by synchronizing only fast-moving components instead of the full gradients -- resulting in a hybrid sharded data parallel training strategy. We further introduce a framework, denoted as DeToNATION, that generalizes DeMo, FlexDeMo, and other popular distributed training schemes such as DiLoCo -- introducing new variations of replication schemes and challenging choices made in DeMo. Our results across language and vision domains show that FlexDeMo attains similar validation loss as hybrid sharded data parallel training employing AdamW and full gradient synchronization, while being substantially faster. FlexDeMo is thus a promising distributed training scheme for the largest machine learning models.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DeToNATION: Decoupled Torch Network-Aware Training on Interlinked Online Nodes\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "detonation",
      "decoupled",
      "torch"
    ],
    "category": "noticia"
  },
  {
    "title": "CAST: Cross Attention based multimodal fusion of Structure and Text for materials property prediction",
    "title_es": "CAST: Cross Attention based multimodal fusion of Structure and Text for materials property prediction",
    "url": "https://arxiv.org/abs/2502.06836",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.06836v2 Announce Type: replace \nAbstract: Recent advancements in graph neural networks (GNNs) have significantly enhanced the prediction of material properties by modeling crystal structures as graphs. However, GNNs often struggle to capture global structural characteristics, such as crystal systems, limiting their predictive performance. To overcome this issue, we propose CAST, a cross-attention-based multimodal model that integrates graph representations with textual descriptions of materials, effectively preserving critical structural and compositional information. Unlike previous approaches, such as CrysMMNet and MultiMat, which rely on aggregated material-level embeddings, CAST leverages cross-attention mechanisms to combine fine-grained graph node-level and text token-level features. Additionally, we introduce a masked node prediction pretraining strategy that further enhances the alignment between node and text embeddings. Our experimental results demonstrate that CAST outperforms existing baseline models across four key material properties-formation energy, band gap, bulk modulus, and shear modulus-with average relative MAE improvements ranging from 10.2% to 35.7%. Analysis of attention maps confirms the importance of pretraining in effectively aligning multimodal representations. This study underscores the potential of multimodal learning frameworks for developing more accurate and globally informed predictive models in materials science.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CAST: Cross Attention based multimodal fusion of Structure and Text for materials property prediction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cast",
      "cross",
      "attention"
    ],
    "category": "noticia"
  },
  {
    "title": "Structural Reformation of Large Language Model Neuron Encapsulation for Divergent Information Aggregation",
    "title_es": "Structural Reformation of Large Language Model Neuron Encapsulation for Divergent Information Aggregation",
    "url": "https://arxiv.org/abs/2502.07124",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.07124v2 Announce Type: replace \nAbstract: Structured neuron encapsulation introduces a modular framework that enables more effective aggregation and specialization of information within deep learning architectures. A model modified through this framework demonstrated improved perplexity scores, greater lexical variability, and enhanced consistency in logical reasoning, suggesting that structured parameter distribution contributes to more efficient language representation. Statistical analyses of generated text highlighted a wider range of sentence structures and reduced redundancy in token selection, indicating that encapsulation fosters more adaptable language generation. A detailed evaluation of attention weight distributions revealed that the experimental model exhibited greater divergence in cross-layer activations, supporting the hypothesis that encapsulated neurons assume specialized processing roles. Logical consistency assessments further demonstrated that modular architectures mitigate contradictory outputs, reducing internal conflicts in inferred relationships between linguistic constructs. Computational trade-offs were analyzed, with results showing a minor increase in processing overhead, though improvements in parameter efficiency and structured decision-making compensated for the additional complexity. The mathematical formulation of the encapsulation mechanism confirmed that modular aggregation maintains stable convergence properties while promoting distinct functional roles for different neuron clusters.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Structural Reformation of Large Language Model Neuron Encapsulation for Divergent Information Aggregation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "structural",
      "reformation",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Hierarchical Entropy Disruption for Ransomware Detection: A Computationally-Driven Framework",
    "title_es": "Hierarchical Entropy Disruption for Ransomware Detection: A Computationally-Driven Framework",
    "url": "https://arxiv.org/abs/2502.08843",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.08843v2 Announce Type: replace \nAbstract: The rapid evolution of encryption-based threats has rendered conventional detection mechanisms increasingly ineffective against sophisticated attack strategies. Monitoring entropy variations across hierarchical system levels offers an alternative approach to identifying unauthorized data modifications without relying on static signatures. A framework leveraging hierarchical entropy disruption was introduced to analyze deviations in entropy distributions, capturing behavioral anomalies indicative of malicious encryption operations. Evaluating the framework across multiple ransomware variants demonstrated its capability to achieve high detection accuracy while maintaining minimal computational overhead. Entropy distributions across different system directories revealed that encryption activities predominantly targeted user-accessible files, aligning with observed attacker strategies. Detection latency analysis indicated that early-stage identification was feasible, mitigating potential data loss before critical system impact occurred. The framework's ability to operate efficiently in real-time environments was validated through an assessment of resource utilization, confirming a balanced trade-off between detection precision and computational efficiency. Comparative benchmarking against established detection methods highlighted the limitations of conventional approaches in identifying novel ransomware variants, whereas entropy-based anomaly detection provided resilience against obfuscation techniques.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hierarchical Entropy Disruption for Ransomware Detection: A Computationally-Driven Framework\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hierarchical",
      "entropy",
      "disruption"
    ],
    "category": "noticia"
  },
  {
    "title": "Structured Convergence in Large Language Model Representations via Hierarchical Latent Space Folding",
    "title_es": "Structured Convergence in Large Language Model Representations via Hierarchical Latent Space Folding",
    "url": "https://arxiv.org/abs/2502.08947",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.08947v2 Announce Type: replace \nAbstract: Token representations in high-dimensional latent spaces often exhibit redundancy, limiting computational efficiency and reducing structural coherence across model layers. Hierarchical latent space folding introduces a structured transformation mechanism that enforces a multi-scale organization within learned embeddings, refining representational compactness while preserving essential contextual distinctions. The proposed approach incorporates dynamic folding operations that iteratively adjust token embeddings through structured transformations, influencing both short-range and long-range dependencies in sequential processing tasks. Empirical evaluation demonstrates a reduction in representational variance across layers, contributing to more stable perplexity distributions and enhancing predictive confidence in text generation. The structured redistribution of attention head utilization leads to more efficient allocation of computational resources, particularly in deeper layers, where hierarchical refinements improve contextual abstraction. Comparative analysis of activation sparsity patterns suggests that hierarchical adjustments selectively reinforce critical pathways while reducing computational overhead in non-essential regions of the model. Statistical assessments of token reordering frequencies reveal that hierarchical modifications introduce subtle shifts in sequential dependencies, improving contextual alignment while maintaining syntactic correctness. Computational trade-offs associated with hierarchical folding introduce marginal increases in training time per epoch, yet empirical findings indicate that inference efficiency benefits from the structured representation adjustments. The results highlight the impact of hierarchical latent space folding on optimizing model performance through improved representation structuring and computational efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Structured Convergence in Large Language Model Representations via Hierarchical Latent Space Folding\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "structured",
      "convergence",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Statistical Coherence Alignment for Large Language Model Representation Learning Through Tensor Field Convergence",
    "title_es": "Statistical Coherence Alignment for Large Language Model Representation Learning Through Tensor Field Convergence",
    "url": "https://arxiv.org/abs/2502.09815",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.09815v2 Announce Type: replace \nAbstract: Representation learning plays a central role in structuring internal embeddings to capture the statistical properties of language, influencing the coherence and contextual consistency of generated text. Statistical Coherence Alignment is introduced as a method to enforce structured token representations through tensor field convergence, guiding embeddings to reflect statistical dependencies inherent in linguistic data. A mathematical framework is established to quantify coherence alignment, integrating a loss function that optimizes representational consistency across training iterations. Empirical evaluations demonstrate that applying coherence constraints improves perplexity, enhances classification accuracy, and refines rare word embeddings, contributing to a more stable representation space. Comparative analyses with baseline models reveal that the proposed method fosters a more interpretable internal structure, ensuring that embeddings retain contextual dependencies while mitigating representation collapse. The impact on coherence score distributions suggests that the alignment mechanism strengthens semantic integrity across diverse linguistic constructs, leading to a more balanced organization of learned embeddings. Computational assessments indicate that while the method introduces additional memory and training costs, the structured optimization process justifies the trade-offs in applications requiring heightened contextual fidelity. Experimental results validate the effectiveness of coherence alignment in optimizing token representations, providing insights into how statistical dependencies can be leveraged to improve language model training.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Statistical Coherence Alignment for Large Language Model Representation Learning Through Tensor Field Convergence\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "statistical",
      "coherence",
      "alignment"
    ],
    "category": "noticia"
  },
  {
    "title": "ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation",
    "title_es": "ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation",
    "url": "https://arxiv.org/abs/2502.09891",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.09891v3 Announce Type: replace \nAbstract: Retrieval-Augmented Generation (RAG) has proven effective in integrating external knowledge into large language models (LLMs) for solving question-answer (QA) tasks. The state-of-the-art RAG approaches often use the graph data as the external data since they capture the rich semantic information and link relationships between entities. However, existing graph-based RAG approaches cannot accurately identify the relevant information from the graph and also consume large numbers of tokens in the online retrieval process. To address these issues, we introduce a novel graph-based RAG approach, called Attributed Community-based Hierarchical RAG (ArchRAG), by augmenting the question using attributed communities, and also introducing a novel LLM-based hierarchical clustering method. To retrieve the most relevant information from the graph for the question, we build a novel hierarchical index structure for the attributed communities and develop an effective online retrieval method. Experimental results demonstrate that ArchRAG outperforms existing methods in both accuracy and token cost.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "archrag",
      "attributed",
      "communitybased"
    ],
    "category": "noticia"
  },
  {
    "title": "Exploring Synaptic Resonance in Large Language Models: A Novel Approach to Contextual Memory Integration",
    "title_es": "Exploring Synaptic Resonance in Large Language Models: A Novel Approach to Contextual Memory Integration",
    "url": "https://arxiv.org/abs/2502.10699",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.10699v2 Announce Type: replace \nAbstract: Contextual memory integration remains a high challenge in the development of language models, particularly in tasks that require maintaining coherence over extended sequences. Traditional approaches, such as self-attention mechanisms and memory-augmented architectures, often prioritize short-term dependencies, leading to fragmentation and inconsistency in long-range contextual understanding. Inspired by principles of synaptic plasticity observed in biological neural systems, a novel mechanism, Synaptic Resonance, is introduced to dynamically reinforce relevant memory pathways during training and inference. Unlike static memory representations, this mechanism continuously adjusts synaptic weight matrices based on contextual relevance, allowing for improved information retention without excessive computational overhead. Evaluations conducted on an open-source language model demonstrate reductions in perplexity, enhancements in contextual coherence, and increased robustness against input noise, highlighting the effectiveness of reinforcement-driven memory modulation. Comparative analysis against baseline models further reveals that the proposed approach achieves higher memory retention efficiency while maintaining computational feasibility. The architectural modifications integrate seamlessly into existing transformer-based frameworks, ensuring stable convergence and efficient inference without sacrificing scalability. Applications benefiting from improved long-term contextual consistency, such as dialogue systems and document summarization, stand to gain from this approach. Empirical findings suggest that dynamically reinforced memory pathways offer a promising alternative to conventional memory mechanisms, addressing longstanding limitations in extended sequence modeling.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Exploring Synaptic Resonance in Large Language Models: A Novel Approach to Contextual Memory Integration\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "exploring",
      "synaptic",
      "resonance"
    ],
    "category": "noticia"
  },
  {
    "title": "Exploring Contextual Flux in Large Language Models: A Novel Approach to Self-Modulating Semantic Networks",
    "title_es": "Exploring Contextual Flux in Large Language Models: A Novel Approach to Self-Modulating Semantic Networks",
    "url": "https://arxiv.org/abs/2502.10942",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.10942v2 Announce Type: replace \nAbstract: Self-modulating mechanisms introduce dynamic adaptation capabilities within language models through contextual realignment strategies that influence token embedding trajectories across extended sequences. Contextual Flux is explored as an approach to embedding modulation, integrating an auxiliary gating mechanism within the self-attention framework to dynamically adjust token representations based on evolving contextual dependencies. The empirical analysis evaluates entropy variations, latent space realignments, and coherence stability to assess the extent to which self-regulation enhances text generation consistency while preserving generative flexibility. Quantitative assessments suggest that embedding shifts contribute to more structured adaptation in long-form sequences, with measured reductions in redundant phrase repetitions and improvements in thematic retention. Variability in contextual weight computation affects modulation stability, leading to differing levels of adaptation across diverse linguistic structures. The computational demands introduced through real-time embedding reconfiguration are examined in relation to model scalability, emphasizing the need for optimization strategies in high-volume generative applications. The findings suggest that while adaptive embedding updates improve certain aspects of coherence, their impact remains contingent on model capacity and input complexity.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Exploring Contextual Flux in Large Language Models: A Novel Approach to Self-Modulating Semantic Networks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "exploring",
      "contextual",
      "flux"
    ],
    "category": "noticia"
  },
  {
    "title": "Hypothesis-Driven Theory-of-Mind Reasoning for Large Language Models",
    "title_es": "Hypothesis-Driven Theory-of-Mind Reasoning for Large Language Models",
    "url": "https://arxiv.org/abs/2502.11881",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.11881v2 Announce Type: replace \nAbstract: Existing LLM reasoning methods have shown impressive capabilities across various tasks, such as solving math and coding problems. However, applying these methods to scenarios without ground-truth answers or rule-based verification methods - such as tracking the mental states of an agent - remains challenging. Inspired by the sequential Monte Carlo algorithm, we introduce thought-tracing, an inference-time reasoning algorithm designed to trace the mental states of specific agents by generating hypotheses and weighting them based on observations without relying on ground-truth solutions to questions in datasets. Our algorithm is modeled after the Bayesian theory-of-mind framework, using LLMs to approximate probabilistic inference over agents' evolving mental states based on their perceptions and actions. We evaluate thought-tracing on diverse theory-of-mind benchmarks, demonstrating significant performance improvements compared to baseline LLMs. Our experiments also reveal interesting behaviors of the recent reasoning models - e.g., o3 and R1 - on theory-of-mind, highlighting the difference of social reasoning compared to other domains.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hypothesis-Driven Theory-of-Mind Reasoning for Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hypothesisdriven",
      "theoryofmind",
      "reasoning"
    ],
    "category": "noticia"
  },
  {
    "title": "Transaction Fee Market Design for Parallel Execution",
    "title_es": "Transaction Fee Market Design for Parallel Execution",
    "url": "https://arxiv.org/abs/2502.11964",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.11964v2 Announce Type: replace \nAbstract: Given the low throughput of blockchains like Bitcoin and Ethereum, scalability - the ability to process an increasing number of transactions - has become a central focus of blockchain research. One promising approach is the parallelization of transaction execution across multiple threads. However, achieving efficient parallelization requires a redesign of the incentive structure within the fee market. Currently, the fee market does not differentiate between transactions that access multiple high-demand storage keys (i.e., unique identifiers for individual data entries) versus a single low-demand one, as long as they require the same computational effort. Addressing this discrepancy is crucial for enabling more effective parallel execution.\n  In this work, we aim to bridge the gap between the current fee market and the need for parallel execution by exploring alternative fee market designs. To this end, we propose a framework consisting of two key components: a Gas Computation Mechanism (GCM), which quantifies the load a transaction places on the network in terms of parallelization and computation, measured in units of gas, and a Transaction Fee Mechanism (TFM), which assigns a price to each unit of gas. We additionally introduce a set of desirable properties for a GCM, propose several candidate mechanisms, and evaluate them against these criteria. Our analysis highlights two strong candidates: the weighted area GCM, which integrates smoothly with existing TFMs such as EIP-1559 and satisfies a broad subset of the outlined properties, and the time-proportional makespan GCM, which assigns gas costs based on the context of the entire block's schedule and, through this dependence on the overall execution outcome, captures the dynamics of parallel execution more accurately.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Transaction Fee Market Design for Parallel Execution\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "transaction",
      "fee",
      "market"
    ],
    "category": "noticia"
  },
  {
    "title": "Navigating Demand Uncertainty in Container Shipping: Deep Reinforcement Learning for Enabling Adaptive and Feasible Master Stowage Planning",
    "title_es": "Navigating Demand Uncertainty in Container Shipping: Deep Reinforcement Learning for Enabling Adaptive and Feasible Master Stowage Planning",
    "url": "https://arxiv.org/abs/2502.12756",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.12756v4 Announce Type: replace \nAbstract: Reinforcement learning (RL) has shown promise in solving various combinatorial optimization problems. However, conventional RL faces challenges when dealing with real-world constraints, especially when action space feasibility is explicit and dependent on the corresponding state or trajectory. In this work, we focus on using RL in container shipping, often considered the cornerstone of global trade, by dealing with the critical challenge of master stowage planning. The main objective is to maximize cargo revenue and minimize operational costs while navigating demand uncertainty and various complex operational constraints, namely vessel capacity and stability, which must be dynamically updated along the vessel's voyage. To address this problem, we implement a deep reinforcement learning framework with feasibility projection to solve the master stowage planning problem (MPP) under demand uncertainty. The experimental results show that our architecture efficiently finds adaptive, feasible solutions for this multi-stage stochastic optimization problem, outperforming traditional mixed-integer programming and RL with feasibility regularization. Our AI-driven decision-support policy enables adaptive and feasible planning under uncertainty, optimizing operational efficiency and capacity utilization while contributing to sustainable and resilient global supply chains.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Navigating Demand Uncertainty in Container Shipping: Deep Reinforcement Learning for Enabling Adaptive and Feasible Master Stowage Planning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "navigating",
      "demand",
      "uncertainty"
    ],
    "category": "noticia"
  },
  {
    "title": "Building Age Estimation: A New Multi-Modal Benchmark Dataset and Community Challenge",
    "title_es": "Building Age Estimation: A New Multi-Modal Benchmark Dataset and Community Challenge",
    "url": "https://arxiv.org/abs/2502.13818",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.13818v3 Announce Type: replace \nAbstract: Estimating the construction year of buildings is critical for advancing sustainability, as older structures often lack energy-efficient features. Sustainable urban planning relies on accurate building age data to reduce energy consumption and mitigate climate change. In this work, we introduce MapYourCity, a novel multi-modal benchmark dataset comprising top-view Very High Resolution (VHR) imagery, multi-spectral Earth Observation (EO) data from the Copernicus Sentinel-2 constellation, and co-localized street-view images across various European cities. Each building is labeled with its construction epoch, and the task is formulated as a seven-class classification problem covering periods from 1900 to the present. To advance research in EO generalization and multi-modal learning, we organized a community-driven data challenge in 2024, hosted by ESA $\\Phi$-lab, which ran for four months and attracted wide participation.\n  This paper presents the Top-4 performing models from the challenge and their evaluation results. We assess model generalization on cities excluded from training to prevent data leakage, and evaluate performance under missing modality scenarios, particularly when street-view data is unavailable. Results demonstrate that building age estimation is both feasible and effective, even in previously unseen cities and when relying solely on top-view satellite imagery (i.e. with VHR and Sentinel-2 images). The new MapYourCity dataset thus provides a valuable resource for developing scalable, real-world solutions in sustainable urban analytics.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Building Age Estimation: A New Multi-Modal Benchmark Dataset and Community Challenge\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "building",
      "age",
      "estimation"
    ],
    "category": "noticia"
  },
  {
    "title": "OptiRefine: Densest subgraphs and maximum cuts with $k$ refinements",
    "title_es": "OptiRefine: Densest subgraphs and maximum cuts with $k$ refinements",
    "url": "https://arxiv.org/abs/2502.14532",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.14532v3 Announce Type: replace \nAbstract: Data-analysis tasks often involve an iterative process, which requires refining previous solutions. For instance, when analyzing dynamic social networks, we may be interested in monitoring the evolution of a community that was identified at an earlier snapshot. This task requires finding a community in the current snapshot of data that is ``close'' to the earlier-discovered community of interest. However, classic optimization algorithms, which typically find solutions from scratch, potentially return communities that are very dissimilar to the initial one. To mitigate these issues, we introduce the \\emph{OptiRefine framework}. The framework optimizes initial solutions by making a small number of \\emph{refinements}, thereby ensuring that the new solution remains close to the initial solution and simultaneously achieving a near-optimal solution for the optimization problem. We apply the OptiRefine framework to two classic graph-optimization problems: \\emph{densest subgraph} and \\emph{maximum cut}. For the \\emph{densest-subgraph problem}, we optimize a given subgraph's density by adding or removing $k$~nodes. We show that this novel problem is a generalization of $k$-densest subgraph, and provide constant-factor approximation algorithms for $k=\\Omega(n)$~refinements. We also study a version of \\emph{maximum cut} in which the goal is to improve a given cut. We provide connections to maximum cut with cardinality constraints and provide an optimal approximation algorithm in most parameter regimes under the Unique Games Conjecture for $k=\\Omega(n)$~refinements. We evaluate our theoretical methods and scalable heuristics on synthetic and real-world data and show that they are highly effective in practice.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"OptiRefine: Densest subgraphs and maximum cuts with $k$ refinements\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "optirefine",
      "densest",
      "subgraphs"
    ],
    "category": "noticia"
  },
  {
    "title": "Harnessing Light for Cold-Start Recommendations: Leveraging Epistemic Uncertainty to Enhance Performance in User-Item Interactions",
    "title_es": "Harnessing Light for Cold-Start Recommendations: Leveraging Epistemic Uncertainty to Enhance Performance in User-Item Interactions",
    "url": "https://arxiv.org/abs/2502.16256",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.16256v3 Announce Type: replace \nAbstract: Most recent paradigms of generative model-based recommendation still face challenges related to the cold-start problem. Existing models addressing cold item recommendations mainly focus on acquiring more knowledge to enrich embeddings or model inputs. However, many models do not assess the efficiency with which they utilize the available training knowledge, leading to the extraction of significant knowledge that is not fully used, thus limiting improvements in cold-start performance. To address this, we introduce the concept of epistemic uncertainty to indirectly define how efficiently a model uses the training knowledge. Since epistemic uncertainty represents the reducible part of the total uncertainty, we can optimize the recommendation model further based on epistemic uncertainty to improve its performance. To this end, we propose a Cold-Start Recommendation based on Epistemic Uncertainty (CREU) framework. Additionally, CREU is inspired by Pairwise-Distance Estimators (PaiDEs) to efficiently and accurately measure epistemic uncertainty by evaluating the mutual information between model outputs and weights in high-dimensional spaces. The proposed method is evaluated through extensive offline experiments on public datasets, which further demonstrate the advantages and robustness of CREU. The source code is available at https://github.com/EsiksonX/CREU.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Harnessing Light for Cold-Start Recommendations: Leveraging Epistemic Uncertainty to Enhance Performance in User-Item Interactions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "harnessing",
      "light",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Topic Over Source: The Key to Effective Data Mixing for Language Models Pre-training",
    "title_es": "Topic Over Source: The Key to Effective Data Mixing for Language Models Pre-training",
    "url": "https://arxiv.org/abs/2502.16802",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.16802v3 Announce Type: replace \nAbstract: The performance of large language models (LLMs) is significantly affected by the quality and composition of their pre-training data, which is inherently diverse, spanning various languages, sources, and topics. Effectively integrating these heterogeneous data groups is crucial for optimizing LLM performance. Previous research has predominantly concentrated on source-based data mixing, often neglecting the nuanced topic-level characteristics of the data. To address this gap, we propose a topic-based data mixing strategy that utilizes detailed topic labels generated through a multi-stage process combining unsupervised clustering, LLM-based summarization, and supervised classifier training. With this strategy, we conduct the first comprehensive comparison of topic-based versus source-based partitioning across multiple mixing strategies. We demonstrate that language models pretrained on data mixed by topics consistently outperform those trained on data mixed by sources across multiple methods including RegMix, DoReMi,temperature-based sampling, and a manual mixing method based on downstream task performance. Our theoretical analysis reveals that topic-based data achieves significantly lower validation loss compared to source-based approaches, creating a better optimization landscape for model training. We will make our code, annotated datasets, and topic classification models publicly available to facilitate further research.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Topic Over Source: The Key to Effective Data Mixing for Language Models Pre-training\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "topic",
      "over",
      "source"
    ],
    "category": "noticia"
  },
  {
    "title": "Rank1: Test-Time Compute for Reranking in Information Retrieval",
    "title_es": "Rank1: Test-Time Compute for Reranking in Information Retrieval",
    "url": "https://arxiv.org/abs/2502.18418",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.18418v2 Announce Type: replace \nAbstract: We introduce Rank1, the first reranking model trained to take advantage of test-time compute. Rank1 demonstrates the applicability within retrieval of using a reasoning language model (i.e. OpenAI's o1, Deepseek's R1, etc.) for distillation in order to rapidly improve the performance of a smaller model. We gather and open-source a dataset of more than 600,000 examples of R1 reasoning traces from queries and passages in MS MARCO. Models trained on this dataset show: (1) state-of-the-art performance on advanced reasoning and instruction following datasets; (2) work remarkably well out of distribution due to the ability to respond to user-input prompts; and (3) have explainable reasoning chains that can be given to users or RAG-based systems. Further, we demonstrate that quantized versions of these models retain strong performance while using less compute/memory. Overall, Rank1 shows that test-time compute allows for a fundamentally new type of explainable and performant reranker model for search.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Rank1: Test-Time Compute for Reranking in Information Retrieval\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "rank",
      "testtime",
      "compute"
    ],
    "category": "noticia"
  },
  {
    "title": "Selfish Mining under General Stochastic Rewards",
    "title_es": "Selfish Mining under General Stochastic Rewards",
    "url": "https://arxiv.org/abs/2502.20360",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.20360v2 Announce Type: replace \nAbstract: Selfish miners selectively withhold blocks to earn disproportionately high revenue. The vast majority of the selfish mining literature focuses exclusively on block rewards. Carlsten et al. [2016] is a notable exception, observing that similar strategic behavior is profitable in a zero-block-reward regime (the endgame for Bitcoin's quadrennial halving schedule) if miners are compensated with transaction fees alone. Neither model fully captures miner incentives today. The block reward remains 3.125 BTC, yet some blocks yield significantly higher revenue. For example, congestion during the launch of the Babylon protocol in August 2024 caused transaction fees to spike to 9.52 BTC. Our results are both practical and theoretical. Of practical interest, we study selfish mining profitability under a combined reward function that more accurately models miner incentives. This analysis enables us to make quantitative claims about protocol risk (e.g., the mining power at which a selfish strategy becomes profitable is reduced by 22% when optimizing over the combined reward function versus block rewards alone) and qualitative observations (e.g., a miner considering both block rewards and transaction fees will mine more or less aggressively respectively). These practical results follow from our novel model and methodology, which constitute our theoretical contributions. We model general, time-accruing stochastic rewards, which requires explicit treatment of difficult adjustment and randomness; we characterize reward function structure through a set of properties (e.g., that rewards accrue only as a function of time). We present a new methodology to analytically calculate expected selfish miner rewards under a broad class of stochastic reward functions and validate our method numerically by comparing it with the existing literature and simulating the combined reward sources directly.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Selfish Mining under General Stochastic Rewards\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "selfish",
      "mining",
      "under"
    ],
    "category": "noticia"
  },
  {
    "title": "Examining Algorithmic Curation on Social Media: An Empirical Audit of Reddit's r/popular Feed",
    "title_es": "Examining Algorithmic Curation on Social Media: An Empirical Audit of Reddit's r/popular Feed",
    "url": "https://arxiv.org/abs/2502.20491",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2502.20491v3 Announce Type: replace \nAbstract: Platforms are increasingly relying on algorithms to curate the content within users' social media feeds. However, the growing prominence of proprietary, algorithmically curated feeds has concealed what factors influence the presentation of content on social media feeds and how that presentation affects user behavior. This lack of transparency can be detrimental to users, from reducing users' agency over their content consumption to the propagation of misinformation and toxic content. To uncover details about how these feeds operate and influence user behavior, we conduct an empirical audit of Reddit's algorithmically curated trending feed called r/popular. Using 10K r/popular posts collected by taking snapshots of the feed over 11 months, we find that recent comments help a post remain on r/popular longer and climb the feed. We also find that posts below rank 80 correspond to a sharp decline in activity compared to posts above. When examining the effects of having a higher proportion of undesired behavior -- i.e., moderator-removed and toxic comments -- we find no significant evidence that it helps posts stay on r/popular for longer. Although posts closer to the top receive more undesired comments, we find this increase to coincide with a broader increase in overall engagement -- rather than indicating a disproportionate effect on undesired activity. The relationships between algorithmic rank and engagement highlight the extent to which algorithms employed by social media platforms essentially determine which content is prioritized and which is not. We conclude by discussing how content creators, consumers, and moderators on social media platforms can benefit from empirical audits aimed at improving transparency in algorithmically curated feeds.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Examining Algorithmic Curation on Social Media: An Empirical Audit of Reddit's r/popular Feed\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "examining",
      "algorithmic",
      "curation"
    ],
    "category": "noticia"
  },
  {
    "title": "ACTIVA: Amortized Causal Effect Estimation via Transformer-based Variational Autoencoder",
    "title_es": "ACTIVA: Amortized Causal Effect Estimation via Transformer-based Variational Autoencoder",
    "url": "https://arxiv.org/abs/2503.01290",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.01290v2 Announce Type: replace \nAbstract: Predicting the distribution of outcomes under hypothetical interventions is crucial across healthcare, economics, and policy-making. However, existing methods often require restrictive assumptions, and are typically limited by the lack of amortization across problem instances. We propose ACTIVA, a transformer-based conditional variational autoencoder (VAE) architecture for amortized causal inference, which estimates interventional distributions directly from observational data without. ACTIVA learns a latent representation conditioned on observational inputs and intervention queries, enabling zero-shot inference by amortizing causal knowledge from diverse training scenarios. We provide theoretical insights showing that ACTIVA predicts interventional distributions as mixtures over observationally equivalent causal models. Empirical evaluations on synthetic and semi-synthetic datasets confirm the effectiveness of our amortized approach and highlight promising directions for future real-world applications.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ACTIVA: Amortized Causal Effect Estimation via Transformer-based Variational Autoencoder\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "activa",
      "amortized",
      "causal"
    ],
    "category": "noticia"
  },
  {
    "title": "Code-as-Symbolic-Planner: Foundation Model-Based Robot Planning via Symbolic Code Generation",
    "title_es": "Code-as-Symbolic-Planner: Foundation Model-Based Robot Planning via Symbolic Code Generation",
    "url": "https://arxiv.org/abs/2503.01700",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.01700v2 Announce Type: replace \nAbstract: Recent works have shown great potentials of Large Language Models (LLMs) in robot task and motion planning (TAMP). Current LLM approaches generate text- or code-based reasoning chains with sub-goals and action plans. However, they do not fully leverage LLMs' symbolic computing and code generation capabilities. Many robot TAMP tasks involve complex optimization under multiple constraints, where pure textual reasoning is insufficient. While augmenting LLMs with predefined solvers and planners improves performance, it lacks generalization across tasks. Given LLMs' growing coding proficiency, we enhance their TAMP capabilities by steering them to generate code as symbolic planners for optimization and constraint verification. Unlike prior work that uses code to interface with robot action modules, we steer LLMs to generate code as solvers, planners, and checkers for TAMP tasks requiring symbolic computing, while still leveraging textual reasoning to incorporate common sense. With a multi-round guidance and answer evolution framework, the proposed Code-as-Symbolic-Planner improves success rates by average 24.1\\% over best baseline methods across seven typical TAMP tasks and three popular LLMs. Code-as-Symbolic-Planner shows strong effectiveness and generalizability across discrete and continuous environments, 2D/3D simulations and real-world settings, as well as single- and multi-robot tasks with diverse requirements. See our project website https://yongchao98.github.io/Code-Symbol-Planner/ for prompts, videos, and code.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Code-as-Symbolic-Planner: Foundation Model-Based Robot Planning via Symbolic Code Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "codeassymbolicplanner",
      "foundation",
      "modelbased"
    ],
    "category": "noticia"
  },
  {
    "title": "One ruler to measure them all: Benchmarking multilingual long-context language models",
    "title_es": "One ruler to measure them all: Benchmarking multilingual long-context language models",
    "url": "https://arxiv.org/abs/2503.01996",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.01996v2 Announce Type: replace \nAbstract: We present ONERULER, a multilingual benchmark designed to evaluate long-context language models across 26 languages. ONERULER adapts the English-only RULER benchmark (Hsieh et al., 2024) by including seven synthetic tasks that test both retrieval and aggregation, including new variations of the \"needle-in-a-haystack\" task that allow for the possibility of a nonexistent needle. We create ONERULER through a two-step process, first writing English instructions for each task and then collaborating with native speakers to translate them into 25 additional languages. Experiments with both open-weight and closed LLMs reveal a widening performance gap between low- and high-resource languages as context length increases from 8K to 128K tokens. Surprisingly, English is not the top-performing language on long-context tasks (ranked 6th out of 26), with Polish emerging as the top language. Our experiments also show that many LLMs (particularly OpenAI's o3-mini-high) incorrectly predict the absence of an answer, even in high-resource languages. Finally, in cross-lingual scenarios where instructions and context appear in different languages, performance can fluctuate by up to 20% depending on the instruction language. We hope the release of ONERULER will facilitate future research into improving multilingual and cross-lingual long-context training pipelines.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"One ruler to measure them all: Benchmarking multilingual long-context language models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "one",
      "ruler",
      "to"
    ],
    "category": "noticia"
  },
  {
    "title": "TreeCat: Standalone Catalog Engine for Large Data Systems",
    "title_es": "TreeCat: Standalone Catalog Engine for Large Data Systems",
    "url": "https://arxiv.org/abs/2503.02956",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.02956v2 Announce Type: replace \nAbstract: With ever-increasing volume and heterogeneity of data, advent of new specialized compute engines, and demand for complex use cases, large-scale data systems require a performant catalog system that can satisfy diverse needs. We argue that existing solutions, including recent lakehouse storage formats, have fundamental limitations and that there is a strong motivation for a specialized database engine, dedicated to serve as the catalog. We present the design and implementation of TreeCat, a database engine that features a hierarchical data model with a path-based query language, a storage format optimized for efficient range queries and versioning, and a correlated scan operation that enables fast query execution. A key performance challenge is supporting concurrent read and write operations from many different clients while providing strict consistency guarantees. To this end, we present a novel MVOCC (multi-versioned optimistic concurrency control) protocol that guarantees serializable isolation. We conduct a comprehensive experimental evaluation comparing our concurrency control scheme with prior techniques, and evaluating our overall system against Hive Metastore, Delta Lake, and Iceberg.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"TreeCat: Standalone Catalog Engine for Large Data Systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "treecat",
      "standalone",
      "catalog"
    ],
    "category": "noticia"
  },
  {
    "title": "Global graph features unveiled by unsupervised geometric deep learning",
    "title_es": "Global graph features unveiled by unsupervised geometric deep learning",
    "url": "https://arxiv.org/abs/2503.05560",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.05560v2 Announce Type: replace \nAbstract: Graphs provide a powerful framework for modeling complex systems, but their structural variability poses significant challenges for analysis and classification. To address these challenges, we introduce GAUDI (Graph Autoencoder Uncovering Descriptive Information), a novel unsupervised geometric deep learning framework designed to capture both local details and global structure. GAUDI employs an innovative hourglass architecture with hierarchical pooling and upsampling layers linked through skip connections, which preserve essential connectivity information throughout the encoding-decoding process. Even though identical or highly similar underlying parameters describing a system's state can lead to significant variability in graph realizations, GAUDI consistently maps them into nearby regions of a structured and continuous latent space, effectively disentangling invariant process-level features from stochastic noise. We demonstrate GAUDI's versatility across multiple applications, including small-world networks modeling, characterization of protein assemblies from super-resolution microscopy, analysis of collective motion in the Vicsek model, and identification of age-related changes in brain connectivity. Comparison with related approaches highlights GAUDI's superior performance in analyzing complex graphs, providing new insights into emergent phenomena across diverse scientific domains.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Global graph features unveiled by unsupervised geometric deep learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "global",
      "graph",
      "features"
    ],
    "category": "noticia"
  },
  {
    "title": "Generative Video Bi-flow",
    "title_es": "Generative Video Bi-flow",
    "url": "https://arxiv.org/abs/2503.06364",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.06364v2 Announce Type: replace \nAbstract: We propose a novel generative video model to robustly learn temporal change as a neural Ordinary Differential Equation (ODE) flow with a bilinear objective which combines two aspects: The first is to map from the past into future video frames directly. Previous work has mapped the noise to new frames, a more computationally expensive process. Unfortunately, starting from the previous frame, instead of noise, is more prone to drifting errors. Hence, second, we additionally learn how to remove the accumulated errors as the joint objective by adding noise during training. We demonstrate unconditional video generation in a streaming manner for various video datasets, all at competitive quality compared to a conditional diffusion baseline but with higher speed, i.e., fewer ODE solver steps.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Generative Video Bi-flow\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "generative",
      "video",
      "biflow"
    ],
    "category": "noticia"
  },
  {
    "title": "Learning to Match Unpaired Data with Minimum Entropy Coupling",
    "title_es": "Learning to Match Unpaired Data with Minimum Entropy Coupling",
    "url": "https://arxiv.org/abs/2503.08501",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.08501v2 Announce Type: replace \nAbstract: Multimodal data is a precious asset enabling a variety of downstream tasks in machine learning. However, real-world data collected across different modalities is often not paired, which is a significant challenge to learn a joint distribution. A prominent approach to address the modality coupling problem is Minimum Entropy Coupling (MEC), which seeks to minimize the joint Entropy, while satisfying constraints on the marginals. Existing approaches to the MEC problem focus on finite, discrete distributions, limiting their application for cases involving continuous data. In this work, we propose a novel method to solve the continuous MEC problem, using well-known generative diffusion models that learn to approximate and minimize the joint Entropy through a cooperative scheme, while satisfying a relaxed version of the marginal constraints. We empirically demonstrate that our method, DDMEC, is general and can be easily used to address challenging tasks, including unsupervised single-cell multi-omics data alignment and unpaired image translation, outperforming specialized methods.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Learning to Match Unpaired Data with Minimum Entropy Coupling\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "learning",
      "to",
      "match"
    ],
    "category": "noticia"
  },
  {
    "title": "Training Plug-n-Play Knowledge Modules with Deep Context Distillation",
    "title_es": "Training Plug-n-Play Knowledge Modules with Deep Context Distillation",
    "url": "https://arxiv.org/abs/2503.08727",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.08727v4 Announce Type: replace \nAbstract: Dynamically integrating new or rapidly evolving information after (Large) Language Model pre-training remains challenging, particularly in low-data scenarios or when dealing with private and specialized documents. In-context learning and retrieval-augmented generation (RAG) face limitations, including their high inference costs and their inability to capture global document information. In this paper, we propose a way of modularizing knowledge by training document-level Knowledge Modules (KMs). KMs are lightweight components implemented as parameter-efficient LoRA modules, which are trained to store information about new documents and can be easily plugged into models on demand. We show that next-token prediction performs poorly as the training objective for KMs. We instead propose Deep Context Distillation: we learn KMs parameters such as to simulate hidden states and logits of a teacher that takes the document in context. Our method outperforms standard next-token prediction and pre-instruction training techniques, across two datasets. Finally, we highlight synergies between KMs and RAG.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Training Plug-n-Play Knowledge Modules with Deep Context Distillation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "training",
      "plugnplay",
      "knowledge"
    ],
    "category": "noticia"
  },
  {
    "title": "COIN: Confidence Score-Guided Distillation for Annotation-Free Cell Segmentation",
    "title_es": "COIN: Confidence Score-Guided Distillation for Annotation-Free Cell Segmentation",
    "url": "https://arxiv.org/abs/2503.11439",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.11439v4 Announce Type: replace \nAbstract: Cell instance segmentation (CIS) is crucial for identifying individual cell morphologies in histopathological images, providing valuable insights for biological and medical research. While unsupervised CIS (UCIS) models aim to reduce the heavy reliance on labor-intensive image annotations, they fail to accurately capture cell boundaries, causing missed detections and poor performance. Recognizing the absence of error-free instances as a key limitation, we present COIN (COnfidence score-guided INstance distillation), a novel annotation-free framework with three key steps: (1) Increasing the sensitivity for the presence of error-free instances via unsupervised semantic segmentation with optimal transport, leveraging its ability to discriminate spatially minor instances, (2) Instance-level confidence scoring to measure the consistency between model prediction and refined mask and identify highly confident instances, offering an alternative to ground truth annotations, and (3) Progressive expansion of confidence with recursive self-distillation. Extensive experiments across six datasets show COIN outperforming existing UCIS methods, even surpassing semi- and weakly-supervised approaches across all metrics on the MoNuSeg and TNBC datasets. The code is available at https://github.com/shjo-april/COIN.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"COIN: Confidence Score-Guided Distillation for Annotation-Free Cell Segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "coin",
      "confidence",
      "scoreguided"
    ],
    "category": "noticia"
  },
  {
    "title": "Continuous-time Data-driven Barrier Certificate Synthesis",
    "title_es": "Continuous-time Data-driven Barrier Certificate Synthesis",
    "url": "https://arxiv.org/abs/2503.13392",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.13392v2 Announce Type: replace \nAbstract: We consider the problem of verifying safety for continuous-time dynamical systems. Developing upon recent advancements in data-driven verification, we use only a finite number of sampled trajectories to learn a barrier certificate, namely a function which verifies safety. We train a safety-informed neural network to act as this certificate, with an appropriately designed loss function to encompass the safety conditions. In addition, we provide probabilistic generalisation guarantees from discrete samples of continuous trajectories, to unseen continuous ones. Numerical investigations demonstrate the efficacy of our approach and contrast it with related results in the literature.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Continuous-time Data-driven Barrier Certificate Synthesis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "continuoustime",
      "datadriven",
      "barrier"
    ],
    "category": "noticia"
  },
  {
    "title": "A 3.3904-Competitive Online Algorithm for List Update with Uniform Costs",
    "title_es": "A 3.3904-Competitive Online Algorithm for List Update with Uniform Costs",
    "url": "https://arxiv.org/abs/2503.17264",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.17264v3 Announce Type: replace \nAbstract: We consider the List Update problem where the cost of each swap is assumed to be 1. This is in contrast to the ``standard'' model, in which an algorithm is allowed to swap the requested item with previous items for free. We construct an online algorithm Full-Or-Partial-Move (FPM), whose competitive ratio is at most $3.3904$, improving over the previous best known bound of $4$.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A 3.3904-Competitive Online Algorithm for List Update with Uniform Costs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "competitive",
      "online"
    ],
    "category": "noticia"
  },
  {
    "title": "RoboTron-Nav: A Unified Framework for Embodied Navigation Integrating Perception, Planning, and Prediction",
    "title_es": "RoboTron-Nav: A Unified Framework for Embodied Navigation Integrating Perception, Planning, and Prediction",
    "url": "https://arxiv.org/abs/2503.18525",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.18525v4 Announce Type: replace \nAbstract: In language-guided visual navigation, agents locate target objects in unseen environments using natural language instructions. For reliable navigation in unfamiliar scenes, agents should possess strong perception, planning, and prediction capabilities. Additionally, when agents revisit previously explored areas during long-term navigation, they may retain irrelevant and redundant historical perceptions, leading to suboptimal results. In this work, we propose RoboTron-Nav, a unified framework that integrates perception, planning, and prediction capabilities through multitask collaborations on navigation and embodied question answering tasks, thereby enhancing navigation performances. Furthermore, RoboTron-Nav employs an adaptive 3D-aware history sampling strategy to effectively and efficiently utilize historical observations. By leveraging large language model, RoboTron-Nav comprehends diverse commands and complex visual scenes, resulting in appropriate navigation actions. RoboTron-Nav achieves an 81.1% success rate in object goal navigation on the $\\mathrm{CHORES}$-$\\mathbb{S}$ benchmark, setting a new state-of-the-art performance. Project page: https://yvfengzhong.github.io/RoboTron-Nav",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"RoboTron-Nav: A Unified Framework for Embodied Navigation Integrating Perception, Planning, and Prediction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "robotronnav",
      "a",
      "unified"
    ],
    "category": "noticia"
  },
  {
    "title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis",
    "title_es": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis",
    "url": "https://arxiv.org/abs/2503.23145",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.23145v2 Announce Type: replace \nAbstract: Inductive program synthesis, or programming by example, requires synthesizing functions from input-output examples that generalize to unseen inputs. While large language model agents have shown promise in programming tasks guided by natural language, their ability to perform inductive program synthesis is underexplored. Existing evaluation protocols rely on static sets of examples and held-out tests, offering no feedback when synthesized functions are incorrect and failing to reflect real-world scenarios such as reverse engineering. We propose CodeARC, the Code Abstraction and Reasoning Challenge, a new evaluation framework where agents interact with a hidden target function by querying it with new inputs, synthesizing candidate functions, and iteratively refining their solutions using a differential testing oracle. This interactive setting encourages agents to perform function calls and self-correction based on feedback. We construct the first large-scale benchmark for general-purpose inductive program synthesis, featuring 1114 functions. Among 18 models evaluated, o3-mini performs best with a success rate of 52.7%, highlighting the difficulty of this task. Fine-tuning LLaMA-3.1-8B-Instruct on curated synthesis traces yields up to a 31% relative performance gain. CodeARC provides a more realistic and challenging testbed for evaluating LLM-based program synthesis and inductive reasoning. Our code, data, and models are publicly available at https://github.com/Anjiang-Wei/CodeARC",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "codearc",
      "benchmarking",
      "reasoning"
    ],
    "category": "noticia"
  },
  {
    "title": "Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality",
    "title_es": "Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality",
    "url": "https://arxiv.org/abs/2503.24277",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.24277v2 Announce Type: replace \nAbstract: Sparse autoencoders (SAEs) are widely used in mechanistic interpretability research for large language models; however, the state-of-the-art method of using $k$-sparse autoencoders lacks a theoretical grounding for selecting the hyperparameter $k$ that represents the number of nonzero activations, often denoted by $\\ell_0$. In this paper, we reveal a theoretical link that the $\\ell_2$-norm of the sparse feature vector can be approximated with the $\\ell_2$-norm of the dense vector with a closed-form error, which allows sparse autoencoders to be trained without the need to manually determine $\\ell_0$. Specifically, we validate two applications of our theoretical findings. First, we introduce a new methodology that can assess the feature activations of pre-trained SAEs by computing the theoretically expected value from the input embedding, which has been overlooked by existing SAE evaluation methods and loss functions. Second, we introduce a novel activation function, top-AFA, which builds upon our formulation of approximate feature activation (AFA). This function enables top-$k$ style activation without requiring a constant hyperparameter $k$ to be tuned, dynamically determining the number of activated features for each input. By training SAEs on three intermediate layers to reconstruct GPT2 hidden embeddings for over 80 million tokens from the OpenWebText dataset, we demonstrate the empirical merits of this approach and compare it with current state-of-the-art $k$-sparse autoencoders. Our code is available at: https://github.com/SewoongLee/top-afa-sae.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "evaluating",
      "and",
      "designing"
    ],
    "category": "noticia"
  },
  {
    "title": "Can Test-Time Scaling Improve World Foundation Model?",
    "title_es": "Can Test-Time Scaling Improve World Foundation Model?",
    "url": "https://arxiv.org/abs/2503.24320",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2503.24320v2 Announce Type: replace \nAbstract: World foundation models, which simulate the physical world by predicting future states from current observations and inputs, have become central to many applications in physical intelligence, including autonomous driving and robotics. However, these models require substantial computational resources for pretraining and are further constrained by available data during post-training. As such, scaling computation at test time emerges as both a critical and practical alternative to traditional model enlargement or re-training. In this work, we introduce SWIFT, a test-time scaling framework tailored for WFMs. SWIFT integrates our extensible WFM evaluation toolkit with process-level inference strategies, including fast tokenization, probability-based Top-K pruning, and efficient beam search. Empirical results on the COSMOS model demonstrate that test-time scaling exists even in a compute-optimal way. Our findings reveal that test-time scaling laws hold for WFMs and that SWIFT provides a scalable and effective pathway for improving WFM inference without retraining or increasing model size. Project page: https://scalingwfm.github.io/.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Can Test-Time Scaling Improve World Foundation Model?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "can",
      "testtime",
      "scaling"
    ],
    "category": "noticia"
  },
  {
    "title": "Two-stage deep learning framework for the restoration of incomplete-ring PET images",
    "title_es": "Two-stage deep learning framework for the restoration of incomplete-ring PET images",
    "url": "https://arxiv.org/abs/2504.00816",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.00816v4 Announce Type: replace \nAbstract: Positron Emission Tomography (PET) is an important molecular imaging tool widely used in medicine. Traditional PET systems rely on complete detector rings for full angular coverage and reliable data collection. However, incomplete-ring PET scanners have emerged due to hardware failures, cost constraints, or specific clinical needs. Standard reconstruction algorithms often suffer from performance degradation with these systems because of reduced data completeness and geometric inconsistencies. We present a two-stage deep-learning framework that, without incorporating any time-of-flight (TOF) information, restores high-quality images from data with about 50% missing coincidences - double the loss levels previously addressed by CNN-based methods. The pipeline operates in two stages: a projection-domain Attention U-Net first predicts the missing sections of the sinogram by leveraging spatial context from neighbouring slices, after which the completed data are reconstructed with OSEM algorithm and passed to a U-Net-diffusion module that removes residual artefacts while reinstating high-frequency detail. Using 206 brain volumes from a public dataset, the result shows that our model successfully preserves most anatomical structures and tracer distribution features with PSNR of 30.92 dB and SSIM of 0.9708. We also achieve higher inference speed, thus providing an effective solution for incomplete-ring PET imaging.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Two-stage deep learning framework for the restoration of incomplete-ring PET images\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "twostage",
      "deep",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "Off-Policy Evaluation for Sequential Persuasion Process with Unobserved Confounding",
    "title_es": "Off-Policy Evaluation for Sequential Persuasion Process with Unobserved Confounding",
    "url": "https://arxiv.org/abs/2504.01211",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.01211v2 Announce Type: replace \nAbstract: In this paper, we expand the Bayesian persuasion framework to account for unobserved confounding variables in sender-receiver interactions. While traditional models assume that belief updates follow Bayesian principles, real-world scenarios often involve hidden variables that impact the receiver's belief formation and decision-making. We conceptualize this as a sequential decision-making problem, where the sender and receiver interact over multiple rounds. In each round, the sender communicates with the receiver, who also interacts with the environment. Crucially, the receiver's belief update is affected by an unobserved confounding variable. By reformulating this scenario as a Partially Observable Markov Decision Process (POMDP), we capture the sender's incomplete information regarding both the dynamics of the receiver's beliefs and the unobserved confounder. We prove that finding an optimal observation-based policy in this POMDP is equivalent to solving for an optimal signaling strategy in the original persuasion framework. Furthermore, we demonstrate how this reformulation facilitates the application of proximal learning for off-policy evaluation in the persuasion process. This advancement enables the sender to evaluate alternative signaling strategies using only observational data from a behavioral policy, thus eliminating the necessity for costly new experiments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Off-Policy Evaluation for Sequential Persuasion Process with Unobserved Confounding\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "offpolicy",
      "evaluation",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "OpenCodeReasoning: Advancing Data Distillation for Competitive Coding",
    "title_es": "OpenCodeReasoning: Advancing Data Distillation for Competitive Coding",
    "url": "https://arxiv.org/abs/2504.01943",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.01943v2 Announce Type: replace \nAbstract: Since the advent of reasoning-based large language models, many have found great success from distilling reasoning capabilities into student models. Such techniques have significantly bridged the gap between reasoning and standard LLMs on coding tasks. Despite this, much of the progress on distilling reasoning models remains locked behind proprietary datasets or lacks details on data curation, filtering and subsequent training. To address this, we construct a superior supervised fine-tuning (SFT) dataset that we use to achieve state-of-the-art coding capability results in models of various sizes. Our distilled models use only SFT to achieve 61.8% on LiveCodeBench and 24.6% on CodeContests, surpassing alternatives trained with reinforcement learning. We then perform analysis on the data sources used to construct our dataset, the impact of code execution filtering, and the importance of instruction/solution diversity. We observe that execution filtering negatively affected benchmark accuracy, leading us to prioritize instruction diversity over solution correctness. Finally, we also analyze the token efficiency and reasoning patterns utilized by these models. We will open-source these datasets and distilled models to the community.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"OpenCodeReasoning: Advancing Data Distillation for Competitive Coding\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "opencodereasoning",
      "advancing",
      "data"
    ],
    "category": "noticia"
  },
  {
    "title": "FairDAG: Consensus Fairness over Multi-Proposer Causal Design",
    "title_es": "FairDAG: Consensus Fairness over Multi-Proposer Causal Design",
    "url": "https://arxiv.org/abs/2504.02194",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.02194v2 Announce Type: replace \nAbstract: The rise of cryptocurrencies like Bitcoin and Ethereum has driven interest in blockchain database technology, with smart contracts enabling the growth of decentralized finance (DeFi). However, research has shown that adversaries exploit transaction ordering to extract profits through attacks like front-running, sandwich attacks, and liquidation manipulation. This issue affects blockchain databases in which block proposers have full control over transaction ordering. To address this, a more fair approach to transaction ordering is essential.\n  Existing fairness protocols, such as Pompe and Themis, operate on leader-based consensus protocols, which not only suffer from low throughput, but also allow adversaries to manipulate transaction ordering. To address these limitations, we propose FairDAG-AB and FairDAG-RL that run fairness protocols on top of DAG-based consensus protocols, which improve protocol performance in both throughput and fairness quality, leveraging the multi-proposer design and validity of DAG-based consensus protocols.\n  We conducted a comprehensive analytical and experimental evaluation of our protocols. The results show that FairDAG-AB and FairDAG-RL outperform the prior fairness protocols in both throughput and fairness quality.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"FairDAG: Consensus Fairness over Multi-Proposer Causal Design\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fairdag",
      "consensus",
      "fairness"
    ],
    "category": "noticia"
  },
  {
    "title": "Single-Pass Document Scanning for Question Answering",
    "title_es": "Single-Pass Document Scanning for Question Answering",
    "url": "https://arxiv.org/abs/2504.03101",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.03101v2 Announce Type: replace \nAbstract: Handling extremely large documents for question answering is challenging: chunk-based embedding methods often lose track of important global context, while full-context transformers can be prohibitively expensive for hundreds of thousands of tokens. We propose a single-pass document scanning approach that processes the entire text in linear time, preserving global coherence while deciding which sentences are most relevant to the query. On 41 QA benchmarks, our single-pass scanner consistently outperforms chunk-based embedding methods and competes with large language models at a fraction of the computational cost. By conditioning on the entire preceding context without chunk breaks, the method preserves global coherence, which is especially important for long documents. Overall, single-pass document scanning offers a simple solution for question answering over massive text. All code, datasets, and model checkpoints are available at https://github.com/MambaRetriever/MambaRetriever",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Single-Pass Document Scanning for Question Answering\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "singlepass",
      "document",
      "scanning"
    ],
    "category": "noticia"
  },
  {
    "title": "A Reconfigurable Time-Domain In-Memory Computing Macro using FeFET-Based CAM with Multilevel Delay Calibration in 28 nm CMOS",
    "title_es": "A Reconfigurable Time-Domain In-Memory Computing Macro using FeFET-Based CAM with Multilevel Delay Calibration in 28 nm CMOS",
    "url": "https://arxiv.org/abs/2504.03925",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.03925v2 Announce Type: replace \nAbstract: Time-domain nonvolatile in-memory computing (TD-nvIMC) offers a promising pathway to reduce data movement and improve energy efficiency by encoding computation in delay rather than voltage or current. This work presents a fully integrated and reconfigurable TD-nvIMC macro, fabricated in 28 nm CMOS, that combines a ferroelectric FET (FeFET)-based content-addressable memory array, a cascaded delay element chain, and a time-to-digital converter. The architecture supports binary multiply-and-accumulate (MAC) operations using XOR- and AND-based matching, as well as in-memory Boolean logic and arithmetic functions. Sub-nanosecond MAC resolution is achieved through experimentally demonstrated 550 ps delay steps, representing a 2000$\\times$ improvement over prior FeFET TD-nvIMC work, enabled by multilevel-state calibration with $\\leq$100 ps resolution. Write-disturb resilience is ensured via isolated triple-well bulks. The proposed macro achieves a measured throughput of 222.2 MOPS/cell and energy efficiency of 1887 TOPS/W at 0.85 V, establishing a viable path toward scalable, energy-efficient TD-nvIMC accelerators.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Reconfigurable Time-Domain In-Memory Computing Macro using FeFET-Based CAM with Multilevel Delay Calibration in 28 nm CMOS\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "reconfigurable",
      "timedomain"
    ],
    "category": "noticia"
  },
  {
    "title": "OpenCodeInstruct: A Large-scale Instruction Tuning Dataset for Code LLMs",
    "title_es": "OpenCodeInstruct: A Large-scale Instruction Tuning Dataset for Code LLMs",
    "url": "https://arxiv.org/abs/2504.04030",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.04030v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have transformed software development by enabling code generation, automated debugging, and complex reasoning. However, their continued advancement is constrained by the scarcity of high-quality, publicly available supervised fine-tuning (SFT) datasets tailored for coding tasks. To bridge this gap, we introduce OpenCodeInstruct, the largest open-access instruction tuning dataset, comprising 5 million diverse samples. Each sample includes a programming question, solution, test cases, execution feedback, and LLM-generated quality assessments. We fine-tune various base models, including LLaMA and Qwen, across multiple scales (1B+, 3B+, and 7B+) using our dataset. Comprehensive evaluations on popular benchmarks (HumanEval, MBPP, LiveCodeBench, and BigCodeBench) demonstrate substantial performance improvements achieved by SFT with OpenCodeInstruct. We also present a detailed methodology encompassing seed data curation, synthetic instruction and solution generation, and filtering.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"OpenCodeInstruct: A Large-scale Instruction Tuning Dataset for Code LLMs\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "opencodeinstruct",
      "a",
      "largescale"
    ],
    "category": "noticia"
  },
  {
    "title": "M$^2$IV: Towards Efficient and Fine-grained Multimodal In-Context Learning via Representation Engineering",
    "title_es": "M$^2$IV: Towards Efficient and Fine-grained Multimodal In-Context Learning via Representation Engineering",
    "url": "https://arxiv.org/abs/2504.04633",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.04633v2 Announce Type: replace \nAbstract: Multimodal in-context learning (ICL) equips Large Vision-language Models (LVLMs) with the ability to adapt to new tasks via multiple user-provided demonstrations, without requiring any model parameter updates. However, its effectiveness is constrained by the token-intensive nature of multimodal inputs and the complexity of cross-modal few-shot reasoning, which together hinder LVLMs from extracting useful patterns from demonstrations. To address these challenges, we propose \\textbf{M$^2$IV}, a novel representation engineering approach that replaces explicit token-level demonstrations with a set of learnable Multimodal In-context Vectors directly injected into the residual streams of LVLMs. By analyzing the distinct roles of multi-head attention (MHA) and multi-layer perceptrons (MLP) in the ICL process, we design a training strategy that enables M$^2$IV to perform fine-grained semantic distillation and robust cross-modal representation learning. M$^2$IV not only improves performance across diverse tasks and LVLMs but also significantly reduces token overhead, enabling graceful scaling to many-shot scenarios. To further enhance usability, we introduce \\textbf{VLibrary}, a repository that stores trained M$^2$IVs for flexible retrieval and injection. With VLibrary, users can steer pre-trained LVLMs in a customized manner that meets diverse requirements. Extensive experiments demonstrate that M$^2$IV consistently outperforms vanilla ICL and prior representation engineering baselines, achieving an average accuracy gain of 3.74\\% with substantial improvements in overall efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"M$^2$IV: Towards Efficient and Fine-grained Multimodal In-Context Learning via Representation Engineering\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "miv",
      "towards",
      "efficient"
    ],
    "category": "noticia"
  },
  {
    "title": "Not All Data Are Unlearned Equally",
    "title_es": "Not All Data Are Unlearned Equally",
    "url": "https://arxiv.org/abs/2504.05058",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.05058v5 Announce Type: replace \nAbstract: Machine unlearning is concerned with the task of removing knowledge learned from particular data points from a trained model. In the context of large language models (LLMs), unlearning has recently received increased attention, particularly for removing knowledge about named entities from models for privacy purposes. While various approaches have been proposed to address the unlearning problem, most existing approaches treat all data points to be unlearned equally, i.e., unlearning that Montreal is a city in Canada is treated exactly the same as unlearning the phone number of the first author of this paper. In this work, we show that this all data is equal assumption does not hold for LLM unlearning. We study how the success of unlearning depends on the frequency of the knowledge we want to unlearn in the pre-training data of a model and find that frequency strongly affects unlearning, i.e., more frequent knowledge is harder to unlearn. Additionally, we uncover a misalignment between probability and generation-based evaluations of unlearning and show that this problem worsens as models become larger. Overall, our experiments highlight the need for better evaluation practices and novel methods for LLM unlearning that take the training data of models into account.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Not All Data Are Unlearned Equally\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "not",
      "all",
      "data"
    ],
    "category": "noticia"
  },
  {
    "title": "Self-Steering Language Models",
    "title_es": "Self-Steering Language Models",
    "url": "https://arxiv.org/abs/2504.07081",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.07081v2 Announce Type: replace \nAbstract: While test-time reasoning enables language models (LMs) to tackle complex tasks, searching or planning in natural language can be slow, costly, and error-prone. But even when LMs struggle to emulate the precise reasoning steps needed to solve a problem, they often excel at describing its abstract structure--both how to verify solutions and how to search for them. This paper introduces DisCIPL, a method for \"self-steering\" LMs where a Planner model generates a task-specific inference program that is executed by a population of Follower models. Our approach equips LMs with the ability to write recursive search procedures that guide LM inference, enabling new forms of verifiable and efficient reasoning. When instantiated with a small Follower (e.g., Llama-3.2-1B or Qwen3-1.7B), DisCIPL matches (and sometimes outperforms) much larger models, including GPT-4o and o1, on challenging constrained generation tasks. Our work opens up a design space of highly-parallelized Monte Carlo inference strategies that outperform standard best-of-N sampling, require no finetuning, and can be implemented automatically by existing LMs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Self-Steering Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "selfsteering",
      "language",
      "models"
    ],
    "category": "noticia"
  },
  {
    "title": "Echo Chamber: RL Post-training Amplifies Behaviors Learned in Pretraining",
    "title_es": "Echo Chamber: RL Post-training Amplifies Behaviors Learned in Pretraining",
    "url": "https://arxiv.org/abs/2504.07912",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.07912v2 Announce Type: replace \nAbstract: Reinforcement learning (RL)-based fine-tuning has become a crucial step in post-training language models for advanced mathematical reasoning and coding. Following the success of frontier reasoning models, recent work has demonstrated that RL fine-tuning consistently improves performance, even in smaller-scale models; however, the underlying mechanisms driving these improvements are not well-understood. Understanding the effects of RL fine-tuning requires disentangling its interaction with pretraining data composition, hyperparameters, and model scale, but such problems are exacerbated by the lack of transparency regarding the training data used in many existing models. In this work, we present a systematic end-to-end study of RL fine-tuning for mathematical reasoning by training models entirely from scratch on different mixtures of fully open datasets. We investigate the effects of various RL fine-tuning algorithms (PPO, GRPO, and Expert Iteration) across models of different scales. Our study reveals that RL algorithms consistently converge towards a dominant output distribution, amplifying patterns in the pretraining data. We also find that models of different scales trained on the same data mixture will converge to distinct output distributions, suggesting that there are scale-dependent biases in model generalization. Moreover, we find that RL post-training on simpler questions can lead to performance gains on harder ones, indicating that certain reasoning capabilities generalize across tasks. Our findings show that small-scale proxies in controlled settings can elicit interesting insights regarding the role of RL in shaping language model behavior.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Echo Chamber: RL Post-training Amplifies Behaviors Learned in Pretraining\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "echo",
      "chamber",
      "rl"
    ],
    "category": "noticia"
  },
  {
    "title": "Layers at Similar Depths Generate Similar Activations Across LLM Architectures",
    "title_es": "Layers at Similar Depths Generate Similar Activations Across LLM Architectures",
    "url": "https://arxiv.org/abs/2504.08775",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.08775v3 Announce Type: replace \nAbstract: How do the latent spaces used by independently-trained LLMs relate to one another? We study the nearest neighbor relationships induced by activations at different layers of 24 open-weight LLMs, and find that they 1) tend to vary from layer to layer within a model, and 2) are approximately shared between corresponding layers of different models. Claim 2 shows that these nearest neighbor relationships are not arbitrary, as they are shared across models, but Claim 1 shows that they are not \"obvious\" either, as there is no single set of nearest neighbor relationships that is universally shared. Together, these suggest that LLMs generate a progression of activation geometries from layer to layer, but that this entire progression is largely shared between models, stretched and squeezed to fit into different architectures.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Layers at Similar Depths Generate Similar Activations Across LLM Architectures\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "layers",
      "at",
      "similar"
    ],
    "category": "noticia"
  },
  {
    "title": "On the Value of Cross-Modal Misalignment in Multimodal Representation Learning",
    "title_es": "On the Value of Cross-Modal Misalignment in Multimodal Representation Learning",
    "url": "https://arxiv.org/abs/2504.10143",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.10143v5 Announce Type: replace \nAbstract: Multimodal representation learning, exemplified by multimodal contrastive learning (MMCL) using image-text pairs, aims to learn powerful representations by aligning cues across modalities. This approach relies on the core assumption that the exemplar image-text pairs constitute two representations of an identical concept. However, recent research has revealed that real-world datasets often exhibit cross-modal misalignment. There are two distinct viewpoints on how to address this issue: one suggests mitigating the misalignment, and the other leveraging it. We seek here to reconcile these seemingly opposing perspectives, and to provide a practical guide for practitioners. Using latent variable models we thus formalize cross-modal misalignment by introducing two specific mechanisms: Selection bias, where some semantic variables are absent in the text, and perturbation bias, where semantic variables are altered -- both leading to misalignment in data pairs. Our theoretical analysis demonstrates that, under mild assumptions, the representations learned by MMCL capture exactly the information related to the subset of the semantic variables invariant to selection and perturbation biases. This provides a unified perspective for understanding misalignment. Based on this, we further offer actionable insights into how misalignment should inform the design of real-world ML systems. We validate our theoretical findings via extensive empirical studies on both synthetic data and real image-text datasets, shedding light on the nuanced impact of cross-modal misalignment on multimodal representation learning.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"On the Value of Cross-Modal Misalignment in Multimodal Representation Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "on",
      "the",
      "value"
    ],
    "category": "noticia"
  },
  {
    "title": "AI-Assisted Conversational Interviewing: Effects on Data Quality and User Experience",
    "title_es": "AI-Assisted Conversational Interviewing: Effects on Data Quality and User Experience",
    "url": "https://arxiv.org/abs/2504.13908",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.13908v2 Announce Type: replace \nAbstract: Standardized surveys scale efficiently but sacrifice depth, while conversational interviews improve response quality at the cost of scalability and consistency. This study bridges the gap between these methods by introducing a framework for AI-assisted conversational interviewing. To evaluate this framework, we conducted a web survey experiment where 1,800 participants were randomly assigned to AI 'chatbots' which use large language models (LLMs) to dynamically probe respondents for elaboration and interactively code open-ended responses to fixed questions developed by human researchers. We assessed the AI chatbot's performance in terms of coding accuracy, response quality, and respondent experience. Our findings reveal that AI chatbots perform moderately well in live coding even without survey-specific fine-tuning, despite slightly inflated false positive errors due to respondent acquiescence bias. Open-ended responses were more detailed and informative, but this came at a slight cost to respondent experience. Our findings highlight the feasibility of using AI methods such as chatbots enhanced by LLMs to enhance open-ended data collection in web surveys.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AI-Assisted Conversational Interviewing: Effects on Data Quality and User Experience\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "aiassisted",
      "conversational",
      "interviewing"
    ],
    "category": "noticia"
  },
  {
    "title": "DONOD: Efficient and Generalizable Instruction Fine-Tuning for LLMs via Model-Intrinsic Dataset Pruning",
    "title_es": "DONOD: Efficient and Generalizable Instruction Fine-Tuning for LLMs via Model-Intrinsic Dataset Pruning",
    "url": "https://arxiv.org/abs/2504.14810",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.14810v2 Announce Type: replace \nAbstract: Ad-hoc instruction fine-tuning of large language models (LLMs) is widely adopted for domain-specific adaptation. While domain-specific supervised fine-tuning (SFT) is effective and efficient, it often weakens cross-domain generalization and struggles with noisy training data. To address these challenges, we propose DONOD, a lightweight model-intrinsic data pruning method. Our approach evaluates data using two model-parameter-based metrics: Delta of Norm (DON), which captures the cumulative influence on model weights, and Norm of Delta (NOD), which quantifies weight instability. Moreover, by employing the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) algorithm, we effectively filter noisy, unlearnable, and generalization-harming samples without relying on auxiliary models during the SFT process. Experiments on mathematical tasks demonstrate that data selected by DONOD achieves superior fine-tuning efficiency and improved robustness against noisy data. By filtering out 70% of the whole dataset, we improve target-domain accuracy by 14.90% and cross-domain accuracy by 5.67%. Meanwhile, our selected data present superior cross-architecture generalization. Data pruned by smaller models (e.g., Llama 3.1-8B) generalize effectively on larger models (e.g., Llama 2-13B). Compared to existing related methodologies, DONOD demonstrates comparable or superior performance while remaining dataset-agnostic, enabling broader applicability. Code will be made publicly available.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DONOD: Efficient and Generalizable Instruction Fine-Tuning for LLMs via Model-Intrinsic Dataset Pruning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "donod",
      "efficient",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Contemplative Artificial Intelligence",
    "title_es": "Contemplative Artificial Intelligence",
    "url": "https://arxiv.org/abs/2504.15125",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.15125v2 Announce Type: replace \nAbstract: As artificial intelligence (AI) improves, traditional alignment strategies may falter in the face of unpredictable self-improvement, hidden subgoals, and the sheer complexity of intelligent systems. Inspired by contemplative wisdom traditions, we show how four axiomatic principles can instil a resilient Wise World Model in AI systems. First, mindfulness enables self-monitoring and recalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal fixation and relaxes rigid priors. Third, non-duality dissolves adversarial self-other boundaries. Fourth, boundless care motivates the universal reduction of suffering. We find that prompting AI to reflect on these principles improves performance on the AILuminate Benchmark (d=.96) and boosts cooperation and joint-reward on the Prisoner's Dilemma task (d=7+). We offer detailed implementation strategies at the level of architectures, constitutions, and reinforcement on chain-of-thought. For future systems, active inference may offer the self-organizing and dynamic coupling capabilities needed to enact Contemplative AI in embodied agents.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Contemplative Artificial Intelligence\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "contemplative",
      "artificial",
      "intelligence"
    ],
    "category": "noticia"
  },
  {
    "title": "CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation",
    "title_es": "CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation",
    "url": "https://arxiv.org/abs/2504.15254",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.15254v2 Announce Type: replace \nAbstract: C-to-Rust transpilation is essential for modernizing legacy C code while enhancing safety and interoperability with modern Rust ecosystems. However, no dataset currently exists for evaluating whether a system can transpile C into safe Rust that passes a set of test cases. We introduce CRUST-Bench, a dataset of 100 C repositories, each paired with manually-written interfaces in safe Rust as well as test cases that can be used to validate correctness of the transpilation. By considering entire repositories rather than isolated functions, CRUST-Bench captures the challenges of translating complex projects with dependencies across multiple files. The provided Rust interfaces provide explicit specifications that ensure adherence to idiomatic, memory-safe Rust patterns, while the accompanying test cases enforce functional correctness. We evaluate state-of-the-art large language models (LLMs) on this task and find that safe and idiomatic Rust generation is still a challenging problem for various state-of-the-art methods and techniques. We also provide insights into the errors LLMs usually make in transpiling code from C to safe Rust. The best performing model, OpenAI o1, is able to solve only 15 tasks in a single-shot setting. Improvements on CRUST-Bench would lead to improved transpilation systems that can reason about complex scenarios and help in migrating legacy codebases from C into languages like Rust that ensure memory safety. You can find the dataset and code at https://github.com/anirudhkhatry/CRUST-bench.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "crustbench",
      "a",
      "comprehensive"
    ],
    "category": "noticia"
  },
  {
    "title": "Event2Vec: Processing neuromorphic events directly by representations in vector space",
    "title_es": "Event2Vec: Processing neuromorphic events directly by representations in vector space",
    "url": "https://arxiv.org/abs/2504.15371",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.15371v2 Announce Type: replace \nAbstract: The neuromorphic event cameras have overwhelming advantages in temporal resolution, power efficiency, and dynamic range compared to traditional cameras. However, the event cameras output asynchronous, sparse, and irregular events, which are not compatible with mainstream computer vision and deep learning methods. Various methods have been proposed to solve this issue but at the cost of long preprocessing procedures, losing temporal resolutions, or being incompatible with massively parallel computation. Inspired by the great success of the word to vector, we summarize the similarities between words and events, then propose the first event to vector (event2vec) representation. We validate event2vec on classifying the ASL-DVS dataset, showing impressive parameter efficiency, accuracy, and speed than previous graph/image/voxel-based representations. Beyond task performance, the most attractive advantage of event2vec is that it aligns events to the domain of natural language processing, showing the promising prospect of integrating events into large language and multimodal models. Our codes, models, and training logs are available at https://github.com/fangwei123456/event2vec.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Event2Vec: Processing neuromorphic events directly by representations in vector space\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "eventvec",
      "processing",
      "neuromorphic"
    ],
    "category": "noticia"
  },
  {
    "title": "iTFKAN: Interpretable Time Series Forecasting with Kolmogorov-Arnold Network",
    "title_es": "iTFKAN: Interpretable Time Series Forecasting with Kolmogorov-Arnold Network",
    "url": "https://arxiv.org/abs/2504.16432",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.16432v2 Announce Type: replace \nAbstract: As time evolves, data within specific domains exhibit predictability that motivates time series forecasting to predict future trends from historical data. However, current deep forecasting methods can achieve promising performance but generally lack interpretability, hindering trustworthiness and practical deployment in safety-critical applications such as auto-driving and healthcare. In this paper, we propose a novel interpretable model, iTFKAN, for credible time series forecasting. iTFKAN enables further exploration of model decision rationales and underlying data patterns due to its interpretability achieved through model symbolization. Besides, iTFKAN develops two strategies, prior knowledge injection, and time-frequency synergy learning, to effectively guide model learning under complex intertwined time series data. Extensive experimental results demonstrated that iTFKAN can achieve promising forecasting performance while simultaneously possessing high interpretive capabilities.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"iTFKAN: Interpretable Time Series Forecasting with Kolmogorov-Arnold Network\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "itfkan",
      "interpretable",
      "time"
    ],
    "category": "noticia"
  },
  {
    "title": "EvidenceBench: A Benchmark for Extracting Evidence from Biomedical Papers",
    "title_es": "EvidenceBench: A Benchmark for Extracting Evidence from Biomedical Papers",
    "url": "https://arxiv.org/abs/2504.18736",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.18736v2 Announce Type: replace \nAbstract: We study the task of automatically finding evidence relevant to hypotheses in biomedical papers. Finding relevant evidence is an important step when researchers investigate scientific hypotheses. We introduce EvidenceBench to measure models performance on this task, which is created by a novel pipeline that consists of hypothesis generation and sentence-by-sentence annotation of biomedical papers for relevant evidence, completely guided by and faithfully following existing human experts judgment. We demonstrate the pipeline's validity and accuracy with multiple sets of human-expert annotations. We evaluated a diverse set of language models and retrieval systems on the benchmark and found that model performances still fall significantly short of the expert level on this task. To show the scalability of our proposed pipeline, we create a larger EvidenceBench-100k with 107,461 fully annotated papers with hypotheses to facilitate model training and development. Both datasets are available at https://github.com/EvidenceBench/EvidenceBench",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"EvidenceBench: A Benchmark for Extracting Evidence from Biomedical Papers\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "evidencebench",
      "a",
      "benchmark"
    ],
    "category": "noticia"
  },
  {
    "title": "Reshaping MOFs text mining with a dynamic multi-agents framework of large language model",
    "title_es": "Reshaping MOFs text mining with a dynamic multi-agents framework of large language model",
    "url": "https://arxiv.org/abs/2504.18880",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.18880v3 Announce Type: replace \nAbstract: Accurately identifying the synthesis conditions of metal-organic frameworks (MOFs) is essential for guiding experimental design, yet remains challenging because relevant information in the literature is often scattered, inconsistent, and difficult to interpret. We present MOFh6, a large language model driven system that reads raw articles or crystal codes and converts them into standardized synthesis tables. It links related descriptions across paragraphs, unifies ligand abbreviations with full names, and outputs structured parameters ready for use. MOFh6 achieved 99% extraction accuracy, resolved 94.1% of abbreviation cases across five major publishers, and maintained a precision of 0.93 +/- 0.01. Processing a full text takes 9.6 s, locating synthesis descriptions 36 s, with 100 papers processed for USD 4.24. By replacing static database lookups with real-time extraction, MOFh6 reshapes MOF synthesis research, accelerating the conversion of literature knowledge into practical synthesis protocols and enabling scalable, data-driven materials discovery.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Reshaping MOFs text mining with a dynamic multi-agents framework of large language model\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "reshaping",
      "mofs",
      "text"
    ],
    "category": "noticia"
  },
  {
    "title": "Toward Inclusive Low-Code Development: Detecting Accessibility Issues in User Reviews",
    "title_es": "Toward Inclusive Low-Code Development: Detecting Accessibility Issues in User Reviews",
    "url": "https://arxiv.org/abs/2504.19085",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.19085v2 Announce Type: replace \nAbstract: Low-code applications are gaining popularity across various fields, enabling non-developers to participate in the software development process. However, due to the strong reliance on graphical user interfaces, they may unintentionally exclude users with visual impairments, such as color blindness and low vision. This paper investigates the accessibility issues users report when using low-code applications. We construct a comprehensive dataset of low-code application reviews, consisting of accessibility-related reviews and non-accessibility-related reviews. We then design and implement a complex model to identify whether a review contains an accessibility-related issue, combining two state-of-the-art Transformers-based models and a traditional keyword-based system. Our proposed hybrid model achieves an accuracy and F1-score of 78% in detecting accessibility-related issues.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Toward Inclusive Low-Code Development: Detecting Accessibility Issues in User Reviews\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "toward",
      "inclusive",
      "lowcode"
    ],
    "category": "noticia"
  },
  {
    "title": "Can a Crow Hatch a Falcon? Lineage Matters in Predicting Large Language Model Performance",
    "title_es": "Can a Crow Hatch a Falcon? Lineage Matters in Predicting Large Language Model Performance",
    "url": "https://arxiv.org/abs/2504.19811",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.19811v2 Announce Type: replace \nAbstract: Accurately forecasting the performance of Large Language Models (LLMs) before extensive fine-tuning or merging can substantially reduce both computational expense and development time. Although prior approaches like scaling laws account for global factors such as parameter size or training tokens, they often overlook explicit lineage relationships-i.e., which models are derived or merged from which parents. In this work, we propose a novel Lineage-Regularized Matrix Factorization (LRMF) framework that encodes ancestral ties among LLMs via a graph Laplacian regularizer. By leveraging multi-hop parent-child connections, LRMF consistently outperforms conventional matrix factorization and collaborative filtering methods in both instance-level and benchmark-level performance prediction. Our large-scale study includes 2,934 publicly available Hugging Face models and 21,000+ instances across 6 major benchmarks, showing that the introduction of lineage constraints yields up to 0.15-0.30 higher Pearson correlation coefficients with actual performance compared to baseline methods. Moreover, LRMF effectively addresses the cold-start problem, providing accurate estimates for newly derived or merged models even with minimal data. This lineage-guided strategy thus offers a resource-efficient way to inform hyperparameter tuning, data selection, and model combination in modern LLM development.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Can a Crow Hatch a Falcon? Lineage Matters in Predicting Large Language Model Performance\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "can",
      "a",
      "crow"
    ],
    "category": "noticia"
  },
  {
    "title": "SMOGAN: Synthetic Minority Oversampling with GAN Refinement for Imbalanced Regression",
    "title_es": "SMOGAN: Synthetic Minority Oversampling with GAN Refinement for Imbalanced Regression",
    "url": "https://arxiv.org/abs/2504.21152",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.21152v2 Announce Type: replace \nAbstract: Imbalanced regression refers to prediction tasks where the target variable is skewed. This skewness hinders machine learning models, especially neural networks, which concentrate on dense regions and therefore perform poorly on underrepresented (minority) samples. Despite the importance of this problem, only a few methods have been proposed for imbalanced regression. Many of the available solutions for imbalanced regression adapt techniques from the class imbalance domain, such as linear interpolation and the addition of Gaussian noise, to create synthetic data in sparse regions. However, in many cases, the underlying distribution of the data is complex and non-linear. Consequently, these approaches generate synthetic samples that do not accurately represent the true feature-target relationship. To overcome these limitations, we propose SMOGAN, a two-step oversampling framework for imbalanced regression. In Stage 1, an existing oversampler generates initial synthetic samples in sparse target regions. In Stage 2, we introduce DistGAN, a distribution-aware GAN that serves as SMOGAN's filtering layer and refines these samples via adversarial loss augmented with a Maximum Mean Discrepancy objective, aligning them with the true joint feature-target distribution. Extensive experiments on 23 imbalanced datasets show that SMOGAN consistently outperforms the default oversampling method without the DistGAN filtering layer.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SMOGAN: Synthetic Minority Oversampling with GAN Refinement for Imbalanced Regression\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "smogan",
      "synthetic",
      "minority"
    ],
    "category": "noticia"
  },
  {
    "title": "Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Lung Nodule Malignancy Prediction",
    "title_es": "Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Lung Nodule Malignancy Prediction",
    "url": "https://arxiv.org/abs/2504.21344",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.21344v2 Announce Type: replace \nAbstract: Machine learning models have utilized semantic features, deep features, or both to assess lung nodule malignancy. However, their reliance on manual annotation during inference, limited interpretability, and sensitivity to imaging variations hinder their application in real-world clinical settings. Thus, this research aims to integrate semantic features derived from radiologists' assessments of nodules, guiding the model to learn clinically relevant, robust, and explainable imaging features for predicting lung cancer. We obtained 938 low-dose CT scans from the National Lung Screening Trial (NLST) with 1,246 nodules and semantic features. Additionally, the Lung Image Database Consortium dataset contains 1,018 CT scans, with 2,625 lesions annotated for nodule characteristics. Three external datasets were obtained from UCLA Health, the LUNGx Challenge, and the Duke Lung Cancer Screening. We fine-tuned a pretrained Contrastive Language-Image Pretraining (CLIP) model with a parameter-efficient fine-tuning approach to align imaging and semantic text features and predict the one-year lung cancer diagnosis. Our model outperformed state-of-the-art (SOTA) models in the NLST test set with an AUROC of 0.901 and AUPRC of 0.776. It also showed robust results in external datasets. Using CLIP, we also obtained predictions on semantic features through zero-shot inference, such as nodule margin (AUROC: 0.812), nodule consistency (0.812), and pleural attachment (0.840). Our approach surpasses the SOTA models in predicting lung cancer across datasets collected from diverse clinical settings, providing explainable outputs, aiding clinicians in comprehending the underlying meaning of model predictions. This approach also prevents the model from learning shortcuts and generalizes across clinical settings. The code is available at https://github.com/luotingzhuang/CLIP_nodule.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Lung Nodule Malignancy Prediction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "visionlanguage",
      "modelbased",
      "semanticguided"
    ],
    "category": "noticia"
  },
  {
    "title": "Solving Copyright Infringement on Short Video Platforms: Novel Datasets and an Audio Restoration Deep Learning Pipeline",
    "title_es": "Solving Copyright Infringement on Short Video Platforms: Novel Datasets and an Audio Restoration Deep Learning Pipeline",
    "url": "https://arxiv.org/abs/2504.21772",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.21772v3 Announce Type: replace \nAbstract: Short video platforms like YouTube Shorts and TikTok face significant copyright compliance challenges, as infringers frequently embed arbitrary background music (BGM) to obscure original soundtracks (OST) and evade content originality detection. To tackle this issue, we propose a novel pipeline that integrates Music Source Separation (MSS) and cross-modal video-music retrieval (CMVMR). Our approach effectively separates arbitrary BGM from the original OST, enabling the restoration of authentic video audio tracks. To support this work, we introduce two domain-specific datasets: OASD-20K for audio separation and OSVAR-160 for pipeline evaluation. OASD-20K contains 20,000 audio clips featuring mixed BGM and OST pairs, while OSVAR-160 is a unique benchmark dataset comprising 1,121 video and mixed-audio pairs, specifically designed for short video restoration tasks. Experimental results demonstrate that our pipeline not only removes arbitrary BGM with high accuracy but also restores OSTs, ensuring content integrity. This approach provides an ethical and scalable solution to copyright challenges in user-generated content on short video platforms.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Solving Copyright Infringement on Short Video Platforms: Novel Datasets and an Audio Restoration Deep Learning Pipeline\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "solving",
      "copyright",
      "infringement"
    ],
    "category": "noticia"
  },
  {
    "title": "Semi-Centennial REDUCE",
    "title_es": "Semi-Centennial REDUCE",
    "url": "https://arxiv.org/abs/2505.01103",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.01103v2 Announce Type: replace \nAbstract: We present a version of the REDUCE computer algebra system as it was in the early 1970s. We show how this historical version of REDUCE may be built and run in very modest present-day environments and outline some of its capabilities.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Semi-Centennial REDUCE\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "semicentennial",
      "reduce"
    ],
    "category": "noticia"
  },
  {
    "title": "FLUX-Text: A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing",
    "title_es": "FLUX-Text: A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing",
    "url": "https://arxiv.org/abs/2505.03329",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.03329v3 Announce Type: replace \nAbstract: Scene text editing aims to modify or add texts on images while ensuring text fidelity and overall visual quality consistent with the background. Recent methods are primarily built on UNet-based diffusion models, which have improved scene text editing results, but still struggle with complex glyph structures, especially for non-Latin ones (\\eg, Chinese, Korean, Japanese). To address these issues, we present \\textbf{FLUX-Text}, a simple and advanced multilingual scene text editing DiT method. Specifically, our FLUX-Text enhances glyph understanding and generation through lightweight Visual and Text Embedding Modules, while preserving the original generative capability of FLUX. We further propose a Regional Text Perceptual Loss tailored for text regions, along with a matching two-stage training strategy to better balance text editing and overall image quality. Benefiting from the DiT-based architecture and lightweight feature injection modules, FLUX-Text can be trained with only $0.1$M training examples, a \\textbf{97\\%} reduction compared to $2.9$M required by popular methods. Extensive experiments on multiple public datasets, including English and Chinese benchmarks, demonstrate that our method surpasses other methods in visual quality and text fidelity. All the code is available at https://github.com/AMAP-ML/FluxText.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"FLUX-Text: A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fluxtext",
      "a",
      "simple"
    ],
    "category": "noticia"
  },
  {
    "title": "Dome-DETR: DETR with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection",
    "title_es": "Dome-DETR: DETR with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection",
    "url": "https://arxiv.org/abs/2505.05741",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.05741v2 Announce Type: replace \nAbstract: Tiny object detection plays a vital role in drone surveillance, remote sensing, and autonomous systems, enabling the identification of small targets across vast landscapes. However, existing methods suffer from inefficient feature leverage and high computational costs due to redundant feature processing and rigid query allocation. To address these challenges, we propose Dome-DETR, a novel framework with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection. To reduce feature redundancies, we introduce a lightweight Density-Focal Extractor (DeFE) to produce clustered compact foreground masks. Leveraging these masks, we incorporate Masked Window Attention Sparsification (MWAS) to focus computational resources on the most informative regions via sparse attention. Besides, we propose Progressive Adaptive Query Initialization (PAQI), which adaptively modulates query density across spatial areas for better query allocation. Extensive experiments demonstrate that Dome-DETR achieves state-of-the-art performance (+3.3 AP on AI-TOD-V2 and +2.5 AP on VisDrone) while maintaining low computational complexity and a compact model size. Code is available at https://github.com/RicePasteM/Dome-DETR.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Dome-DETR: DETR with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "domedetr",
      "detr",
      "with"
    ],
    "category": "noticia"
  },
  {
    "title": "No Query, No Access",
    "title_es": "No Query, No Access",
    "url": "https://arxiv.org/abs/2505.07258",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.07258v2 Announce Type: replace \nAbstract: Textual adversarial attacks mislead NLP models, including Large Language Models (LLMs), by subtly modifying text. While effective, existing attacks often require knowledge of the victim model, extensive queries, or access to training data, limiting real-world feasibility. To overcome these constraints, we introduce the \\textbf{Victim Data-based Adversarial Attack (VDBA)}, which operates using only victim texts. To prevent access to the victim model, we create a shadow dataset with publicly available pre-trained models and clustering methods as a foundation for developing substitute models. To address the low attack success rate (ASR) due to insufficient information feedback, we propose the hierarchical substitution model design, generating substitute models to mitigate the failure of a single substitute model at the decision boundary.\n  Concurrently, we use diverse adversarial example generation, employing various attack methods to generate and select the adversarial example with better similarity and attack effectiveness. Experiments on the Emotion and SST5 datasets show that VDBA outperforms state-of-the-art methods, achieving an ASR improvement of 52.08\\% while significantly reducing attack queries to 0. More importantly, we discover that VDBA poses a significant threat to LLMs such as Qwen2 and the GPT family, and achieves the highest ASR of 45.99% even without access to the API, confirming that advanced NLP models still face serious security risks. Our codes can be found at https://anonymous.4open.science/r/VDBA-Victim-Data-based-Adversarial-Attack-36EC/",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"No Query, No Access\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "no",
      "query",
      "no"
    ],
    "category": "noticia"
  },
  {
    "title": "DanceGRPO: Unleashing GRPO on Visual Generation",
    "title_es": "DanceGRPO: Unleashing GRPO on Visual Generation",
    "url": "https://arxiv.org/abs/2505.07818",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.07818v3 Announce Type: replace \nAbstract: Recent advances in generative AI have revolutionized visual content creation, yet aligning model outputs with human preferences remains a critical challenge. While Reinforcement Learning (RL) has emerged as a promising approach for fine-tuning generative models, existing methods like DDPO and DPOK face fundamental limitations - particularly their inability to maintain stable optimization when scaling to large and diverse prompt sets, severely restricting their practical utility. This paper presents DanceGRPO, a framework that addresses these limitations through an innovative adaptation of Group Relative Policy Optimization (GRPO) for visual generation tasks. Our key insight is that GRPO's inherent stability mechanisms uniquely position it to overcome the optimization challenges that plague prior RL-based approaches on visual generation. DanceGRPO establishes several significant advances: First, it demonstrates consistent and stable policy optimization across multiple modern generative paradigms, including both diffusion models and rectified flows. Second, it maintains robust performance when scaling to complex, real-world scenarios encompassing three key tasks and four foundation models. Third, it shows remarkable versatility in optimizing for diverse human preferences as captured by five distinct reward models assessing image/video aesthetics, text-image alignment, video motion quality, and binary feedback. Our comprehensive experiments reveal that DanceGRPO outperforms baseline methods by up to 181\\% across multiple established benchmarks, including HPS-v2.1, CLIP Score, VideoAlign, and GenEval. Our results establish DanceGRPO as a robust and versatile solution for scaling Reinforcement Learning from Human Feedback (RLHF) tasks in visual generation, offering new insights into harmonizing reinforcement learning and visual synthesis.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DanceGRPO: Unleashing GRPO on Visual Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dancegrpo",
      "unleashing",
      "grpo"
    ],
    "category": "noticia"
  },
  {
    "title": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?",
    "title_es": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?",
    "url": "https://arxiv.org/abs/2505.09614",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.09614v2 Announce Type: replace \nAbstract: Language model (LM) agents are increasingly used as autonomous decision-makers which need to actively gather information to guide their decisions. A crucial cognitive skill for such agents is the efficient exploration and understanding of the causal structure of the world -- key to robust, scientifically grounded reasoning. Yet, it remains unclear whether LMs possess this capability or exhibit systematic biases leading to erroneous conclusions. In this work, we examine LMs' ability to explore and infer causal relationships, using the well-established Blicket Test paradigm from developmental psychology. We find that LMs reliably infer the common, intuitive disjunctive causal relationships but systematically struggle with the unusual, yet equally (or sometimes even more) evidenced conjunctive ones. This \"disjunctive bias\" persists across model families, sizes, and prompting strategies, and performance further declines as task complexity increases. Interestingly, an analogous bias appears in human adults, suggesting that LMs may have inherited deep-seated reasoning heuristics from their training data. To this end, we quantify similarities between LMs and humans, finding that LMs exhibit adult-like inference profiles (but not child-like). Finally, we propose a test-time sampling method which explicitly samples and eliminates hypotheses about causal relationships from the LM. This scalable approach significantly reduces the disjunctive bias and moves LMs closer to the goal of scientific, causally rigorous reasoning.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "language",
      "agents",
      "mirror"
    ],
    "category": "noticia"
  },
  {
    "title": "Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?",
    "title_es": "Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?",
    "url": "https://arxiv.org/abs/2505.10443",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.10443v2 Announce Type: replace \nAbstract: Understanding the reasoning and robustness of Large Language Models (LLMs) is critical for their reliable use in programming tasks. While recent studies have assessed LLMs' ability to predict program outputs, most focus solely on the accuracy of those predictions, without evaluating the reasoning behind them. Moreover, it has been observed on mathematical reasoning tasks that LLMs can arrive at correct answers through flawed logic, raising concerns about similar issues in code understanding. In this work, we evaluate whether state-of-the-art LLMs with up to 8B parameters can reason about Python programs or are simply guessing. We apply five semantics-preserving code mutations: renaming variables, mirroring comparison expressions, swapping if-else branches, converting for loops to while, and loop unrolling. These mutations maintain program semantics while altering its syntax. We evaluated six LLMs and performed a human expert analysis using LiveCodeBench to assess whether the correct predictions are based on sound reasoning. We also evaluated prediction stability across different code mutations on LiveCodeBench and CruxEval. Our findings show that LLMs trained for code produce correct predictions based on flawed reasoning between 10% and 50% of cases. Furthermore, LLMs often change predictions in response to our code mutations, indicating they do not yet exhibit stable, semantically grounded reasoning.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "are",
      "large",
      "language"
    ],
    "category": "noticia"
  },
  {
    "title": "The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks",
    "title_es": "The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks",
    "url": "https://arxiv.org/abs/2505.10507",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.10507v2 Announce Type: replace \nAbstract: Translation-based strategies for cross-lingual transfer XLT such as translate-train -- training on noisy target language data translated from the source language -- and translate-test -- evaluating on noisy source language data translated from the target language -- are competitive XLT baselines. In XLT for token classification tasks, however, these strategies include label projection, the challenging step of mapping the labels from each token in the original sentence to its counterpart(s) in the translation. Although word aligners (WAs) are commonly used for label projection, the low-level design decisions for applying them to translation-based XLT have not been systematically investigated. Moreover, recent marker-based methods, which project labeled spans by inserting tags around them before (or after) translation, claim to outperform WAs in label projection for XLT. In this work, we revisit WAs for label projection, systematically investigating the effects of low-level design decisions on token-level XLT: (i) the algorithm for projecting labels between (multi-)token spans, (ii) filtering strategies to reduce the number of noisily mapped labels, and (iii) the pre-tokenization of the translated sentences. We find that all of these substantially impact translation-based XLT performance and show that, with optimized choices, XLT with WA offers performance at least comparable to that of marker-based methods. We then introduce a new projection strategy that ensembles translate-train and translate-test predictions and demonstrate that it substantially outperforms the marker-based projection. Crucially, we show that our proposed ensembling also reduces sensitivity to low-level WA design choices, resulting in more robust XLT for token classification tasks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "devil",
      "is"
    ],
    "category": "noticia"
  },
  {
    "title": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation",
    "title_es": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation",
    "url": "https://arxiv.org/abs/2505.11528",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.11528v2 Announce Type: replace \nAbstract: Predictive manipulation has recently gained considerable attention in the Embodied AI community due to its potential to improve robot policy performance by leveraging predicted states. However, generating accurate future visual states of robot-object interactions from world models remains a well-known challenge, particularly in achieving high-quality pixel-level representations. To this end, we propose LaDi-WM, a world model that predicts the latent space of future states using diffusion modeling. Specifically, LaDi-WM leverages the well-established latent space aligned with pre-trained Visual Foundation Models (VFMs), which comprises both geometric features (DINO-based) and semantic features (CLIP-based). We find that predicting the evolution of the latent space is easier to learn and more generalizable than directly predicting pixel-level images. Building on LaDi-WM, we design a diffusion policy that iteratively refines output actions by incorporating forecasted states, thereby generating more consistent and accurate results. Extensive experiments on both synthetic and real-world benchmarks demonstrate that LaDi-WM significantly enhances policy performance by 27.9\\% on the LIBERO-LONG benchmark and 20\\% on the real-world scenario. Furthermore, our world model and policies achieve impressive generalizability in real-world experiments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ladiwm",
      "a",
      "latent"
    ],
    "category": "noticia"
  },
  {
    "title": "MAATS: A Multi-Agent Automated Translation System Based on MQM Evaluation",
    "title_es": "MAATS: A Multi-Agent Automated Translation System Based on MQM Evaluation",
    "url": "https://arxiv.org/abs/2505.14848",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.14848v2 Announce Type: replace \nAbstract: We present MAATS, a Multi Agent Automated Translation System that leverages the Multidimensional Quality Metrics (MQM) framework as a fine-grained signal for error detection and refinement. MAATS employs multiple specialized AI agents, each focused on a distinct MQM category (e.g., Accuracy, Fluency, Style, Terminology), followed by a synthesis agent that integrates the annotations to iteratively refine translations. This design contrasts with conventional single-agent methods that rely on self-correction.\n  Evaluated across diverse language pairs and Large Language Models (LLMs), MAATS outperforms zero-shot and single-agent baselines with statistically significant gains in both automatic metrics and human assessments. It excels particularly in semantic accuracy, locale adaptation, and linguistically distant language pairs. Qualitative analysis highlights its strengths in multi-layered error diagnosis, omission detection across perspectives, and context-aware refinement. By aligning modular agent roles with interpretable MQM dimensions, MAATS narrows the gap between black-box LLMs and human translation workflows, shifting focus from surface fluency to deeper semantic and contextual fidelity.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MAATS: A Multi-Agent Automated Translation System Based on MQM Evaluation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "maats",
      "a",
      "multiagent"
    ],
    "category": "noticia"
  },
  {
    "title": "Khan-GCL: Kolmogorov-Arnold Network Based Graph Contrastive Learning with Hard Negatives",
    "title_es": "Khan-GCL: Kolmogorov-Arnold Network Based Graph Contrastive Learning with Hard Negatives",
    "url": "https://arxiv.org/abs/2505.15103",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.15103v2 Announce Type: replace \nAbstract: Graph contrastive learning (GCL) has demonstrated great promise for learning generalizable graph representations from unlabeled data. However, conventional GCL approaches face two critical limitations: (1) the restricted expressive capacity of multilayer perceptron (MLP) based encoders, and (2) suboptimal negative samples that either from random augmentations-failing to provide effective 'hard negatives'-or generated hard negatives without addressing the semantic distinctions crucial for discriminating graph data. To this end, we propose Khan-GCL, a novel framework that integrates the Kolmogorov-Arnold Network (KAN) into the GCL encoder architecture, substantially enhancing its representational capacity. Furthermore, we exploit the rich information embedded within KAN coefficient parameters to develop two novel critical feature identification techniques that enable the generation of semantically meaningful hard negative samples for each graph representation. These strategically constructed hard negatives guide the encoder to learn more discriminative features by emphasizing critical semantic differences between graphs. Extensive experiments demonstrate that our approach achieves state-of-the-art performance compared to existing GCL methods across a variety of datasets and tasks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Khan-GCL: Kolmogorov-Arnold Network Based Graph Contrastive Learning with Hard Negatives\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "khangcl",
      "kolmogorovarnold",
      "network"
    ],
    "category": "noticia"
  },
  {
    "title": "Unified Multi-Rate Model Predictive Control for a Jet-Powered Humanoid Robot",
    "title_es": "Unified Multi-Rate Model Predictive Control for a Jet-Powered Humanoid Robot",
    "url": "https://arxiv.org/abs/2505.16478",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.16478v2 Announce Type: replace \nAbstract: We propose a novel Model Predictive Control (MPC) framework for a jet-powered flying humanoid robot. The controller is based on a linearised centroidal momentum model to represent the flight dynamics, augmented with a second-order nonlinear model to explicitly account for the slow and nonlinear dynamics of jet propulsion. A key contribution is the introduction of a multi-rate MPC formulation that handles the different actuation rates of the robot's joints and jet engines while embedding the jet dynamics directly into the predictive model. We validated the framework using the jet-powered humanoid robot iRonCub, performing simulations in Mujoco; the simulation results demonstrate the robot's ability to recover from external disturbances and perform stable, non-abrupt flight manoeuvres, validating the effectiveness of the proposed approach.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Unified Multi-Rate Model Predictive Control for a Jet-Powered Humanoid Robot\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "unified",
      "multirate",
      "model"
    ],
    "category": "noticia"
  },
  {
    "title": "CUB: Benchmarking Context Utilisation Techniques for Language Models",
    "title_es": "CUB: Benchmarking Context Utilisation Techniques for Language Models",
    "url": "https://arxiv.org/abs/2505.16518",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.16518v2 Announce Type: replace \nAbstract: Incorporating external knowledge is crucial for knowledge-intensive tasks, such as question answering and fact checking. However, language models (LMs) may ignore relevant information that contradicts outdated parametric memory or be distracted by irrelevant contexts. While many context utilisation manipulation techniques (CMTs) have recently been proposed to alleviate these issues, few have seen systematic comparison. In this paper, we develop CUB (Context Utilisation Benchmark) - the first comprehensive benchmark designed to help practitioners within retrieval-augmented generation (RAG) diagnose CMTs under different context conditions. With this benchmark, we conduct the most extensive evaluation to date of seven state-of-the-art methods, representative of the main categories of CMTs, across three diverse datasets and tasks, applied to nine LMs. Our results reveal that most existing CMTs struggle to handle the full spectrum of context types encountered in real-world retrieval-augmented scenarios. We also find that many CMTs display inflated performance on simple synthesised datasets, compared to more realistic datasets with naturally occurring samples. Our findings expose critical gaps in current CMT evaluation practices and demonstrate the need for holistic testing and the development of CMTs that can robustly handle multiple context types.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CUB: Benchmarking Context Utilisation Techniques for Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cub",
      "benchmarking",
      "context"
    ],
    "category": "noticia"
  },
  {
    "title": "ImLPR: Image-based LiDAR Place Recognition using Vision Foundation Models",
    "title_es": "ImLPR: Image-based LiDAR Place Recognition using Vision Foundation Models",
    "url": "https://arxiv.org/abs/2505.18364",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.18364v2 Announce Type: replace \nAbstract: LiDAR Place Recognition (LPR) is a key component in robotic localization, enabling robots to align current scans with prior maps of their environment. While Visual Place Recognition (VPR) has embraced Vision Foundation Models (VFMs) to enhance descriptor robustness, LPR has relied on task-specific models with limited use of pre-trained foundation-level knowledge. This is due to the lack of 3D foundation models and the challenges of using VFM with LiDAR point clouds. To tackle this, we introduce ImLPR, a novel pipeline that employs a pre-trained DINOv2 VFM to generate rich descriptors for LPR. To the best of our knowledge, ImLPR is the first method to utilize a VFM for LPR while retaining the majority of pre-trained knowledge. ImLPR converts raw point clouds into novel three-channel Range Image Views (RIV) to leverage VFM in the LiDAR domain. It employs MultiConv adapters and Patch-InfoNCE loss for effective feature learning. We validate ImLPR on public datasets and outperform state-of-the-art (SOTA) methods across multiple evaluation metrics in both intra- and inter-session LPR. Comprehensive ablations on key design choices such as channel composition, RIV, adapters, and the patch-level loss quantify each component's impact. We release ImLPR as open source for the robotics community: https://github.com/minwoo0611/ImLPR.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ImLPR: Image-based LiDAR Place Recognition using Vision Foundation Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "imlpr",
      "imagebased",
      "lidar"
    ],
    "category": "noticia"
  },
  {
    "title": "LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression",
    "title_es": "LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression",
    "url": "https://arxiv.org/abs/2505.18602",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.18602v2 Announce Type: replace \nAbstract: Large language models (LLMs) have revolutionized algorithm development, yet their application in symbolic regression, where algorithms automatically discover symbolic expressions from data, remains constrained and is typically designed manually by human experts. In this paper, we propose a meta learning framework that enables LLMs to automatically design selection operators for evolutionary symbolic regression algorithms. We first identify two key limitations in existing LLM-based algorithm evolution techniques: a lack of semantic guidance and code bloat. The absence of semantic awareness can lead to ineffective exchange of useful code components, and bloat results in unnecessarily complex components, both of which can reduce the interpretability of the designed algorithm or hinder evolutionary learning progress. To address these issues, we enhance the LLM-based evolution framework for meta symbolic regression with two key innovations: a complementary, semantics-aware selection operator and bloat control. Additionally, we embed domain knowledge into the prompt, enabling the LLM to generate more effective and contextually relevant selection operators. Our experimental results on symbolic regression benchmarks show that LLMs can devise selection operators that outperform nine expert-designed baselines, achieving state-of-the-art performance. Moreover, the evolved operator can further improve the state-of-the-art symbolic regression algorithm, achieving the best performance among 26 symbolic regression and machine learning algorithms across 116 regression datasets. This demonstrates that LLMs can exceed expert-level algorithm design for symbolic regression.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "llmmetasr",
      "incontext",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "Can Multimodal Large Language Models Understand Spatial Relations?",
    "title_es": "Can Multimodal Large Language Models Understand Spatial Relations?",
    "url": "https://arxiv.org/abs/2505.19015",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.19015v2 Announce Type: replace \nAbstract: Spatial relation reasoning is a crucial task for multimodal large language models (MLLMs) to understand the objective world. However, current benchmarks have issues like relying on bounding boxes, ignoring perspective substitutions, or allowing questions to be answered using only the model's prior knowledge without image understanding. To address these issues, we introduce SpatialMQA, a human-annotated spatial relation reasoning benchmark based on COCO2017, which enables MLLMs to focus more on understanding images in the objective world. To ensure data quality, we design a well-tailored annotation procedure, resulting in SpatialMQA consisting of 5,392 samples. Based on this benchmark, a series of closed- and open-source MLLMs are implemented and the results indicate that the current state-of-the-art MLLM achieves only 48.14% accuracy, far below the human-level accuracy of 98.40%. Extensive experimental analyses are also conducted, suggesting the future research directions. The benchmark and codes are available at https://github.com/ziyan-xiaoyu/SpatialMQA.git.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Can Multimodal Large Language Models Understand Spatial Relations?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "can",
      "multimodal",
      "large"
    ],
    "category": "noticia"
  },
  {
    "title": "DECA: A Near-Core LLM Decompression Accelerator Grounded on a 3D Roofline Model",
    "title_es": "DECA: A Near-Core LLM Decompression Accelerator Grounded on a 3D Roofline Model",
    "url": "https://arxiv.org/abs/2505.19349",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.19349v2 Announce Type: replace \nAbstract: To alleviate the memory bandwidth bottleneck in Large Language Model (LLM) inference workloads, weight matrices are stored in memory in quantized and sparsified formats. Hence, before tiles of these matrices can be processed by in-core generalized matrix multiplication (GeMM) hardware engines, they need to be dequantized and de-sparsified. This is currently performed in software with vector operations. Unfortunately, this approach delivers only modest performance. Moreover, it is hard to understand how to improve the system, as the overall GeMM performance depends on the interaction between memory resources, vector units, and hardware matrix engines.\n  To improve the performance of LLM inference in advanced platforms equipped with in-core GeMM engines and HBM, this paper makes three main contributions. First, it develops an analytical performance model with a 3D visual representation that provides insights into how memory resources, vector units, and hardware matrix engines interact to deliver compressed GeMM performance. Second, it proposes DECA, a new near-core ML-model decompression accelerator. DECA offloads tile de-sparsification and dequantization from the CPU, producing ready-to-use tiles for in-core GeMM engines. Third, it introduces a new ISA extension that enables out-of-order invocation of the near-core accelerator. With this extension, accelerator and core computations can interleave and overlap with high-performance. Our evaluation shows that, in a simulated 56-core Xeon 4 server with HBM, DECA accelerates the execution of compressed GeMMs by up to 4x over the use of optimized Intel software kernels. Further, DECA reduces the next-token generation time of Llama2-70B and OPT-66B by 1.6x-2.6x.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DECA: A Near-Core LLM Decompression Accelerator Grounded on a 3D Roofline Model\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "deca",
      "a",
      "nearcore"
    ],
    "category": "noticia"
  },
  {
    "title": "Automated Privacy Information Annotation in Large Language Model Interactions",
    "title_es": "Automated Privacy Information Annotation in Large Language Model Interactions",
    "url": "https://arxiv.org/abs/2505.20910",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.20910v2 Announce Type: replace \nAbstract: Users interacting with large language models (LLMs) under their real identifiers often unknowingly risk disclosing private information. Automatically notifying users whether their queries leak privacy and which phrases leak what private information has therefore become a practical need. Existing privacy detection methods, however, were designed for different objectives and application domains, typically tagging personally identifiable information (PII) in anonymous content, which is insufficient in real-name interaction scenarios with LLMs. In this work, to support the development and evaluation of privacy detection models for LLM interactions that are deployable on local user devices, we construct a large-scale multilingual dataset with 249K user queries and 154K annotated privacy phrases. In particular, we build an automated privacy annotation pipeline with strong LLMs to automatically extract privacy phrases from dialogue datasets and annotate leaked information. We also design evaluation metrics at the levels of privacy leakage, extracted privacy phrase, and privacy information. We further establish baseline methods using light-weight LLMs with both tuning-free and tuning-based methods, and report a comprehensive evaluation of their performance. Evaluation results reveal a gap between current performance and the requirements of real-world LLM applications, motivating future research into more effective local privacy detection methods grounded in our dataset.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Automated Privacy Information Annotation in Large Language Model Interactions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "automated",
      "privacy",
      "information"
    ],
    "category": "noticia"
  },
  {
    "title": "HoneySat: A Network-based Satellite Honeypot Framework",
    "title_es": "HoneySat: A Network-based Satellite Honeypot Framework",
    "url": "https://arxiv.org/abs/2505.24008",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.24008v2 Announce Type: replace \nAbstract: Satellites are the backbone of several mission-critical services that enable our modern society to function, for example, GPS. For years, satellites were assumed to be secure because of their indecipherable architectures and the reliance on security by obscurity. However, technological advancements have made these assumptions obsolete, paving the way for potential attacks, and sparking interest in satellite security. Unfortunately, to this day, there is no efficient way to collect data on adversarial techniques for satellites, hurting the generation of security intelligence that can lead to the development of effective countermeasures. In this paper, we present HoneySat, the first high-interaction satellite honeypot framework, fully capable of convincingly simulating a real-world CubeSat, a type of Small Satellite (SmallSat). To provide evidence of HoneySat's effectiveness, we surveyed experienced SmallSat operators in charge of in-orbit satellites and deployed HoneySat over the Internet to entice adversaries. Our results show that 90% of satellite operators agreed that HoneySat provides a realistic and engaging simulation of a SmallSat mission. Additionally, HoneySat successfully deceived human adversaries in the wild and collected 22 real-world satellite-specific adversarial interactions. Finally, in a major demonstration of HoneySat's robustness, we collaborated with an aerospace company to perform a hardware-in-the-loop operation that resulted in HoneySat successfully communicating with an in-orbit, operational SmallSat mission.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"HoneySat: A Network-based Satellite Honeypot Framework\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "honeysat",
      "a",
      "networkbased"
    ],
    "category": "noticia"
  },
  {
    "title": "Integrative, Scalable Modeling of Hydrological Systems with MBSE and HFGT",
    "title_es": "Integrative, Scalable Modeling of Hydrological Systems with MBSE and HFGT",
    "url": "https://arxiv.org/abs/2506.00696",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.00696v2 Announce Type: replace \nAbstract: Worsening global challenges in the Anthropocene demand complex, adaptive solutions grounded in a systems-level understanding of coupled social and environmental dynamics. However, existing modeling approaches often fall short due to disciplinary silos, limited scalability, and the absence of shared ontological frameworks. Model-Based Systems Engineering (MBSE), when integrated with Hetero-functional Graph Theory (HFGT), offers a powerful methodology for modeling systems of systems while preserving subsystem heterogeneity and enabling cross-disciplinary integration. This paper presents the first application of the MBSE-HFGT methodology to environmental systems, using a series of worked examples involving flow through lake and land segments. These examples demonstrate how the approach enables consistent, scalable, and integrative modeling of complex environmental processes.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Integrative, Scalable Modeling of Hydrological Systems with MBSE and HFGT\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "integrative",
      "scalable",
      "modeling"
    ],
    "category": "noticia"
  },
  {
    "title": "SuperRL: Reinforcement Learning with Supervision to Boost Language Model Reasoning",
    "title_es": "SuperRL: Reinforcement Learning with Supervision to Boost Language Model Reasoning",
    "url": "https://arxiv.org/abs/2506.01096",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.01096v2 Announce Type: replace \nAbstract: Large language models are increasingly used for complex reasoning tasks where high-quality offline data such as expert-annotated solutions and distilled reasoning traces are often available. However, in environments with sparse rewards, reinforcement learning struggles to sample successful trajectories, leading to inefficient learning. At the same time, these offline trajectories that represent correct reasoning paths are not utilized by standard on-policy reinforcement learning methods. We introduce SuperRL, a unified training framework that adaptively alternates between RL and SFT. Whenever every rollout for a given instance receives zero reward, indicating the absence of a learning signal, SuperRL falls back to SFT on the curated offline data. Extensive experiments across diverse reasoning benchmarks show that SuperRL surpasses vanilla RL by delivering higher sample efficiency, stronger generalization, and improved robustness under sparse rewards.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SuperRL: Reinforcement Learning with Supervision to Boost Language Model Reasoning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "superrl",
      "reinforcement",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "VerificAgent: Domain-Specific Memory Verification for Scalable Oversight of Aligned Computer-Use Agents",
    "title_es": "VerificAgent: Domain-Specific Memory Verification for Scalable Oversight of Aligned Computer-Use Agents",
    "url": "https://arxiv.org/abs/2506.02539",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.02539v3 Announce Type: replace \nAbstract: Continual memory augmentation lets computer-using agents (CUAs) learn from prior interactions, but unvetted memories can encode domain-inappropriate or unsafe heuristics--spurious rules that drift from user intent and safety constraints. We introduce VerificAgent, a scalable oversight framework that treats persistent memory as an explicit alignment surface. VerificAgent combines (1) an expert-curated seed of domain knowledge, (2) iterative, trajectory-based memory growth during training, and (3) a post-hoc human fact-checking pass to sanitize accumulated memories before deployment. Evaluated on OSWorld productivity tasks and additional adversarial stress tests, VerificAgent improves task reliability, reduces hallucination-induced failures, and preserves interpretable, auditable guidance--without additional model fine-tuning. By letting humans correct high-impact errors once, the verified memory acts as a frozen safety contract that future agent actions must satisfy. Our results suggest that domain-scoped, human-verified memory offers a scalable oversight mechanism for CUAs, complementing broader alignment strategies by limiting silent policy drift and anchoring agent behavior to the norms and safety constraints of the target domain.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"VerificAgent: Domain-Specific Memory Verification for Scalable Oversight of Aligned Computer-Use Agents\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "verificagent",
      "domainspecific",
      "memory"
    ],
    "category": "noticia"
  },
  {
    "title": "Fusing Cross-Domain Knowledge from Multimodal Data to Solve Problems in the Physical World",
    "title_es": "Fusing Cross-Domain Knowledge from Multimodal Data to Solve Problems in the Physical World",
    "url": "https://arxiv.org/abs/2506.03155",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.03155v2 Announce Type: replace \nAbstract: The proliferation of artificial intelligence has enabled a diversity of applications that bridge the gap between digital and physical worlds. As physical environments are too complex to model through a single information acquisition approach, it is crucial to fuse multimodal data generated by different sources, such as sensors, devices, systems, and people, to solve a problem in the real world. Unfortunately, it is neither applicable nor sustainable to deploy new resources to collect original data from scratch for every problem. Thus, when data is inadequate in the domain of problem, it is vital to fuse knowledge from multimodal data that is already available in other domains. We call this cross-domain knowledge fusion. Existing research focus on fusing multimodal data in a single domain, supposing the knowledge from different datasets is intrinsically aligned; however, this assumption may not hold in the scenarios of cross-domain knowledge fusion. In this paper, we formally define the cross-domain multimodal data fusion problem, discussing its unique challenges, differences and advantages beyond data fusion in a single domain. We propose a four-layer framework, consisting of Domains, Links, Models and Data layers, answering three key questions:\"what to fuse\", \"why can be fused\", and \"how to fuse\". The Domains Layer selects relevant data from different domains for a given problem. The Links Layer reveals the philosophy of knowledge alignment beyond specific model structures. The Models Layer provides two knowledge fusion paradigms based on the fundamental mechanisms for processing data. The Data Layer turns data of different structures, resolutions, scales and distributions into a consistent representation that can be fed into an AI model. With this framework, we can design solutions that fuse cross-domain multimodal data effectively for solving real-world problems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Fusing Cross-Domain Knowledge from Multimodal Data to Solve Problems in the Physical World\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "fusing",
      "crossdomain",
      "knowledge"
    ],
    "category": "noticia"
  },
  {
    "title": "Spatial Association Between Near-Misses and Accident Blackspots in Sydney, Australia: A Getis-Ord $G_i^*$ Analysis",
    "title_es": "Spatial Association Between Near-Misses and Accident Blackspots in Sydney, Australia: A Getis-Ord $G_i^*$ Analysis",
    "url": "https://arxiv.org/abs/2506.03356",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.03356v2 Announce Type: replace \nAbstract: Conventional road safety management is inherently reactive, relying on analysis of sparse and lagged historical crash data to identify hazardous locations, or crash blackspots. The proliferation of vehicle telematics presents an opportunity for a paradigm shift towards proactive safety, using high-frequency, high-resolution near-miss data as a leading indicator of crash risk. This paper presents a spatial-statistical framework to systematically analyze the concordance and discordance between official crash records and near-miss events within urban environment. A Getis-Ord statistic is first applied to both reported crashes and near-miss events to identify statistically significant local clusters of each type. Subsequently, Bivariate Local Moran's I assesses spatial relationships between crash counts and High-G event counts, classifying grid cells into distinct profiles: High-High (coincident risk), High-Low and Low-High. Our analysis reveals significant amount of Low-Crash, High-Near-Miss clusters representing high-risk areas that remain unobservable when relying solely on historical crash data. Feature importance analysis is performed using contextual Point of Interest data to identify the different infrastructure factors that characterize difference between spatial clusters. The results provide a data-driven methodology for transport authorities to transition from a reactive to a proactive safety management strategy, allowing targeted interventions before severe crashes occur.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Spatial Association Between Near-Misses and Accident Blackspots in Sydney, Australia: A Getis-Ord $G_i^*$ Analysis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "spatial",
      "association",
      "between"
    ],
    "category": "noticia"
  },
  {
    "title": "CARE: Enhancing Safety of Visual Navigation through Collision Avoidance via Repulsive Estimation",
    "title_es": "CARE: Enhancing Safety of Visual Navigation through Collision Avoidance via Repulsive Estimation",
    "url": "https://arxiv.org/abs/2506.03834",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.03834v4 Announce Type: replace \nAbstract: We propose CARE (Collision Avoidance via Repulsive Estimation) to improve the robustness of learning-based visual navigation methods. Recently, visual navigation models, particularly foundation models, have demonstrated promising performance by generating viable trajectories using only RGB images. However, these policies can generalize poorly to environments containing out-of-distribution (OOD) scenes characterized by unseen objects or different camera setups (e.g., variations in field of view, camera pose, or focal length). Without fine-tuning, such models could produce trajectories that lead to collisions, necessitating substantial efforts in data collection and additional training. To address this limitation, we introduce CARE, an attachable module that enhances the safety of visual navigation without requiring additional range sensors or fine-tuning of pretrained models. CARE can be integrated seamlessly into any RGB-based navigation model that generates local robot trajectories. It dynamically adjusts trajectories produced by a pretrained model using repulsive force vectors computed from depth images estimated directly from RGB inputs. We evaluate CARE by integrating it with state-of-the-art visual navigation models across diverse robot platforms. Real-world experiments show that CARE significantly reduces collisions (up to 100%) without compromising navigation performance in goal-conditioned navigation, and further improves collision-free travel distance (up to 10.7x) in exploration tasks. Project page: https://airlab-sogang.github.io/CARE/",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CARE: Enhancing Safety of Visual Navigation through Collision Avoidance via Repulsive Estimation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "care",
      "enhancing",
      "safety"
    ],
    "category": "noticia"
  },
  {
    "title": "Survey on the Evaluation of Generative Models in Music",
    "title_es": "Survey on the Evaluation of Generative Models in Music",
    "url": "https://arxiv.org/abs/2506.05104",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.05104v2 Announce Type: replace \nAbstract: Research on generative systems in music has seen considerable attention and growth in recent years. A variety of attempts have been made to systematically evaluate such systems.\n  We present an interdisciplinary review of the common evaluation targets, methodologies, and metrics for the evaluation of both system output and model use, covering subjective and objective approaches, qualitative and quantitative approaches, as well as empirical and computational methods. We examine the benefits and limitations of these approaches from a musicological, an engineering, and an HCI perspective.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Survey on the Evaluation of Generative Models in Music\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "survey",
      "on",
      "the"
    ],
    "category": "noticia"
  },
  {
    "title": "AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models",
    "title_es": "AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models",
    "url": "https://arxiv.org/abs/2506.09082",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.09082v2 Announce Type: replace \nAbstract: The rise of vision foundation models (VFMs) calls for systematic evaluation. A common approach pairs VFMs with large language models (LLMs) as general-purpose heads, followed by evaluation on broad Visual Question Answering (VQA) benchmarks. However, this protocol has two key blind spots: (i) the instruction tuning data may not align with VQA test distributions, meaning a wrong prediction can stem from such data mismatch rather than a VFM' visual shortcomings; (ii) VQA benchmarks often require multiple visual abilities, making it hard to tell whether errors stem from lacking all required abilities or just a single critical one. To address these gaps, we introduce AVA-Bench, the first benchmark that explicitly disentangles 14 Atomic Visual Abilities (AVAs) -- foundational skills like localization, depth estimation, and spatial understanding that collectively support complex visual reasoning tasks. By decoupling AVAs and matching training and test distributions within each, AVA-Bench pinpoints exactly where a VFM excels or falters. Applying AVA-Bench to leading VFMs thus reveals distinctive \"ability fingerprints,\" turning VFM selection from educated guesswork into principled engineering. Notably, we find that a 0.5B LLM yields similar VFM rankings as a 7B LLM while cutting GPU hours by 8x, enabling more efficient evaluation. By offering a comprehensive and transparent benchmark, we hope AVA-Bench lays the foundation for the next generation of VFMs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "avabench",
      "atomic",
      "visual"
    ],
    "category": "noticia"
  },
  {
    "title": "DrVoice: Parallel Speech-Text Voice Conversation Model via Dual-Resolution Speech Representations",
    "title_es": "DrVoice: Parallel Speech-Text Voice Conversation Model via Dual-Resolution Speech Representations",
    "url": "https://arxiv.org/abs/2506.09349",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.09349v2 Announce Type: replace \nAbstract: Recent studies on end-to-end speech generation with large language models (LLMs) have attracted significant community attention, with multiple works extending text-based LLMs to generate discrete speech tokens. Existing approaches primarily fall into two categories: (1) Methods that generate discrete speech tokens independently without incorporating them into the LLM's autoregressive process, resulting in text generation being unaware of concurrent speech synthesis. (2) Models that generate interleaved or parallel speech-text tokens through joint autoregressive modeling, enabling mutual modality awareness during generation. This paper presents DrVoice, a parallel speech-text voice conversation model based on joint autoregressive modeling, featuring dual-resolution speech representations. Whereas current methods utilize mainly 12.5Hz input audio representation, our proposed dual-resolution mechanism reduces the input frequency for the LLM to 5Hz. Experimental results on Spoken Question Answering benchmarks demonstrate that D RVOICE establishes new state-of-the-art (SOTA) performance among similar size speech foundation models with relative small amount of data.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DrVoice: Parallel Speech-Text Voice Conversation Model via Dual-Resolution Speech Representations\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "drvoice",
      "parallel",
      "speechtext"
    ],
    "category": "noticia"
  },
  {
    "title": "DAVSP: Safety Alignment for Large Vision-Language Models via Deep Aligned Visual Safety Prompt",
    "title_es": "DAVSP: Safety Alignment for Large Vision-Language Models via Deep Aligned Visual Safety Prompt",
    "url": "https://arxiv.org/abs/2506.09353",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.09353v2 Announce Type: replace \nAbstract: Large Vision-Language Models (LVLMs) have achieved impressive progress across various applications but remain vulnerable to malicious queries that exploit the visual modality. Existing alignment approaches typically fail to resist malicious queries while preserving utility on benign ones effectively. To address these challenges, we propose Deep Aligned Visual Safety Prompt (DAVSP), which is built upon two key innovations. First, we introduce the Visual Safety Prompt, which appends a trainable padding region around the input image. It preserves visual features and expands the optimization space. Second, we propose Deep Alignment, a novel approach to train the visual safety prompt through supervision in the model's activation space. It enhances the inherent ability of LVLMs to perceive malicious queries, achieving deeper alignment than prior works. Extensive experiments across five benchmarks on two representative LVLMs demonstrate that DAVSP effectively resists malicious queries while preserving benign input utility. Furthermore, DAVSP exhibits great cross-model generation ability. Ablation studies further reveal that both the Visual Safety Prompt and Deep Alignment are essential components, jointly contributing to its overall effectiveness. The code is publicly available at https://github.com/zhangyitonggg/DAVSP.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"DAVSP: Safety Alignment for Large Vision-Language Models via Deep Aligned Visual Safety Prompt\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "davsp",
      "safety",
      "alignment"
    ],
    "category": "noticia"
  },
  {
    "title": "No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning",
    "title_es": "No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning",
    "url": "https://arxiv.org/abs/2506.11246",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.11246v2 Announce Type: replace \nAbstract: Temporal Table Reasoning is a critical challenge for Large Language Models (LLMs), requiring effective reasoning to extract relevant insights. Despite existence of multiple prompting methods, their impact on table reasoning remains largely unexplored. Furthermore, model performance varies drastically across different table and context structures, making it difficult to determine an optimal approach. This work investigates multiple prompting technique on diverse table types to determine that performance depends on factors such as entity type, table structure, requirement of additional context and question complexity, with \"NO\" single method consistently outperforming others. To address this, we introduce SEAR, an adaptive prompting framework inspired by human reasoning that dynamically adjusts to context and integrates structured reasoning. Our results demonstrate that SEAR achieves superior performance across all table types compared to baseline prompting techniques. Additionally, we explore the impact of table structure refactoring, finding that a unified representation enhances model reasoning.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "no",
      "universal",
      "prompt"
    ],
    "category": "noticia"
  },
  {
    "title": "Decompositional Reasoning for Graph Retrieval with Large Language Models",
    "title_es": "Decompositional Reasoning for Graph Retrieval with Large Language Models",
    "url": "https://arxiv.org/abs/2506.13380",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.13380v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) excel at many NLP tasks, but struggle with multi-hop reasoning and factual consistency, limiting their effectiveness on knowledge-intensive tasks like complex question answering (QA). Linking Knowledge Graphs (KG) and LLMs has shown promising results, but LLMs generally lack the ability to reason efficiently over graph-structured information. To tackle this problem, we propose a novel retrieval approach that integrates textual knowledge graphs into the LLM reasoning process via query decomposition. Our method decomposes complex questions into sub-questions, retrieves relevant textual subgraphs, and composes a question-specific knowledge graph to guide answer generation. For that, we use a weighted similarity function that focuses on both the complex question and the generated subquestions to extract a relevant subgraph, which allows efficient and precise retrieval for complex questions and improves the performance of LLMs on multi-hop QA tasks. This structured reasoning pipeline enhances factual grounding and interpretability while leveraging the generative strengths of LLMs. We evaluate our method on standard multi-hop QA benchmarks and show that it achieves comparable or superior performance to competitive existing methods, using smaller models and fewer LLM calls.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Decompositional Reasoning for Graph Retrieval with Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "decompositional",
      "reasoning",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond",
    "title_es": "Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond",
    "url": "https://arxiv.org/abs/2506.14054",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.14054v2 Announce Type: replace \nAbstract: Understanding how carbon flows through the soil is crucial for mitigating the effects of climate change. While soils have potential to sequester carbon from the atmosphere, the soil carbon cycle remains poorly understood. Scientists have developed mathematical process-based models of the soil carbon cycle based on existing knowledge, but they contain numerous unknown parameters that must be set in an ad-hoc manner, and often fit observations poorly. On the other hand, neural networks can learn patterns from data, but do not respect known scientific laws, nor can they reveal novel scientific relationships due to their black-box nature. We thus propose Scientifically-Interpretable Reasoning Network (ScIReN), a fully-transparent framework that combines interpretable neural and process-based reasoning. An interpretable encoder predicts scientifically-meaningful latent parameters, which are then passed through a differentiable process-based decoder to predict labeled output variables. ScIReN leverages Kolmogorov-Arnold networks (KAN) to ensure the encoder is fully interpretable and reveals relationships between input features and latent parameters; it uses novel smoothness penalties to balance expressivity and simplicity. ScIReN also uses a novel hard-sigmoid constraint layer to restrict latent parameters to meaningful ranges defined by scientific prior knowledge. While the process-based decoder enforces established scientific knowledge, the KAN-based encoder reveals new scientific relationships hidden in conventional black-box models. We apply ScIReN on two tasks: simulating the flow of organic carbon through soils, and modeling ecosystem respiration from plants. In both tasks, ScIReN outperforms black-box networks in predictive accuracy while providing substantial scientific interpretability -- it can infer latent scientific mechanisms and their relationships with input features.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "scientificallyinterpretable",
      "reasoning",
      "network"
    ],
    "category": "noticia"
  },
  {
    "title": "TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading",
    "title_es": "TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading",
    "url": "https://arxiv.org/abs/2506.16073",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.16073v2 Announce Type: replace \nAbstract: The word-level lipreading approach typically employs a two-stage framework with separate frontend and backend architectures to model dynamic lip movements. Each component has been extensively studied, and in the backend architecture, temporal convolutional networks (TCNs) have been widely adopted in state-of-the-art methods. Recently, dense skip connections have been introduced in TCNs to mitigate the limited density of the receptive field, thereby improving the modeling of complex temporal representations. However, their performance remains constrained owing to potential information loss regarding the continuous nature of lip movements, caused by blind spots in the receptive field. To address this limitation, we propose TD3Net, a temporal densely connected multi-dilated convolutional network that combines dense skip connections and multi-dilated temporal convolutions as the backend architecture. TD3Net covers a wide and dense receptive field without blind spots by applying different dilation factors to skip-connected features. Experimental results on a word-level lipreading task using two large publicly available datasets, Lip Reading in the Wild (LRW) and LRW-1000, indicate that the proposed method achieves performance comparable to state-of-the-art methods. It achieved higher accuracy with fewer parameters and lower floating-point operations compared to existing TCN-based backend architectures. Moreover, visualization results suggest that our approach effectively utilizes diverse temporal features while preserving temporal continuity, presenting notable advantages in lipreading systems. The code is available at our GitHub repository: https://github.com/Leebh-kor/TD3Net-A-Temporal-Densely-Connected-Multi-dilated-Convolutional-Network-for-Lipreading",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "tdnet",
      "a",
      "temporal"
    ],
    "category": "noticia"
  },
  {
    "title": "Time-Prompt: Integrated Heterogeneous Prompts for Unlocking LLMs in Time Series Forecasting",
    "title_es": "Time-Prompt: Integrated Heterogeneous Prompts for Unlocking LLMs in Time Series Forecasting",
    "url": "https://arxiv.org/abs/2506.17631",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.17631v2 Announce Type: replace \nAbstract: Time series forecasting aims to model temporal dependencies among variables for future state inference, holding significant importance and widespread applications in real-world scenarios. Although deep learning-based methods have achieved remarkable progress, they still exhibit suboptimal performance in long-term forecasting and data-scarce scenarios. Recent research demonstrates that large language models (LLMs) achieve promising performance in time series forecasting. However, we find existing LLM-based methods still have shortcomings: (1) the absence of a unified paradigm for textual prompt formulation and (2) the neglect of modality discrepancies between textual prompts and time series. To address this, we propose LLM-Prompt, an LLM-based time series forecasting framework integrating multi-prompt information and cross-modal semantic alignment. Specifically, we first construct a unified textual prompt paradigm containing learnable soft prompts and textualized hard prompts. Second, to enhance LLMs' comprehensive understanding of the forecasting task, we design a semantic space embedding and cross-modal alignment module to achieve cross-modal fusion of temporal and textual information. Finally, the transformed time series from the LLMs are projected to obtain the forecasts. Comprehensive evaluations on 6 public datasets and 3 carbon emission datasets demonstrate that LLM-Prompt is a powerful framework for time series forecasting.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Time-Prompt: Integrated Heterogeneous Prompts for Unlocking LLMs in Time Series Forecasting\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "timeprompt",
      "integrated",
      "heterogeneous"
    ],
    "category": "noticia"
  },
  {
    "title": "Floating-Point Data Transformation for Lossless Compression",
    "title_es": "Floating-Point Data Transformation for Lossless Compression",
    "url": "https://arxiv.org/abs/2506.18062",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.18062v2 Announce Type: replace \nAbstract: Floating-point data is widely used across various domains. Depending on the required precision, each floating-point value can occupy several bytes. Lossless storage of this information is crucial due to its critical accuracy, as seen in applications such as medical imaging and language model weights. In these cases, data size is often significant, making lossless compression essential. Previous approaches either treat this data as raw byte streams for compression or fail to leverage all patterns within the dataset. However, because multiple bytes represent a single value and due to inherent patterns in floating-point representations, some of these bytes are correlated. To leverage this property, we propose a novel data transformation method called Typed Data Transformation (TDT) that groups related bytes together to improve compression. We implemented and tested our approach on various datasets across both CPU and GPU. TDT achieves a geometric mean compression ratio improvement of 1.16$\\times$ over state-of-the-art compression tools such as zstd, while also improving both compression and decompression throughput by 1.18--3.79$\\times$.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Floating-Point Data Transformation for Lossless Compression\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "floatingpoint",
      "data",
      "transformation"
    ],
    "category": "noticia"
  },
  {
    "title": "End-to-End Fine-Tuning of 3D Texture Generation using Differentiable Rewards",
    "title_es": "End-to-End Fine-Tuning of 3D Texture Generation using Differentiable Rewards",
    "url": "https://arxiv.org/abs/2506.18331",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.18331v3 Announce Type: replace \nAbstract: While recent 3D generative models can produce high-quality texture images, they often fail to capture human preferences or meet task-specific requirements. Moreover, a core challenge in the 3D texture generation domain is that most existing approaches rely on repeated calls to 2D text-to-image generative models, which lack an inherent understanding of the 3D structure of the input 3D mesh object. To alleviate these issues, we propose an end-to-end differentiable, reinforcement-learning-free framework that embeds human feedback, expressed as differentiable reward functions, directly into the 3D texture synthesis pipeline. By back-propagating preference signals through both geometric and appearance modules of the proposed framework, our method generates textures that respect the 3D geometry structure and align with desired criteria. To demonstrate its versatility, we introduce three novel geometry-aware reward functions, which offer a more controllable and interpretable pathway for creating high-quality 3D content from natural language. By conducting qualitative, quantitative, and user-preference evaluations against state-of-the-art methods, we demonstrate that our proposed strategy consistently outperforms existing approaches. We will make our implementation code publicly available upon acceptance of the paper.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"End-to-End Fine-Tuning of 3D Texture Generation using Differentiable Rewards\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "endtoend",
      "finetuning",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective",
    "title_es": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective",
    "url": "https://arxiv.org/abs/2506.19028",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.19028v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) often generate responses with inherent biases, undermining their reliability in real-world applications. Existing evaluation methods often overlook biases in long-form responses and the intrinsic variability of LLM outputs. To address these challenges, we propose FiSCo(Fine-grained Semantic Computation), a novel statistical framework to evaluate group-level fairness in LLMs by detecting subtle semantic differences in long-form responses across demographic groups. Unlike prior work focusing on sentiment or token-level comparisons, FiSCo goes beyond surface-level analysis by operating at the claim level, leveraging entailment checks to assess the consistency of meaning across responses. We decompose model outputs into semantically distinct claims and apply statistical hypothesis testing to compare inter- and intra-group similarities, enabling robust detection of subtle biases. We formalize a new group counterfactual fairness definition and validate FiSCo on both synthetic and human-annotated datasets spanning gender, race, and age. Experiments show that FiSco more reliably identifies nuanced biases while reducing the impact of stochastic LLM variability, outperforming various evaluation metrics.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "quantifying",
      "fairness",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control",
    "title_es": "AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control",
    "url": "https://arxiv.org/abs/2506.20160",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.20160v2 Announce Type: replace \nAbstract: Large reasoning models (LRMs) achieve impressive reasoning capabilities by generating lengthy chain-of-thoughts, but this \"overthinking\" incurs high latency and cost without commensurate accuracy gains. In this work, we introduce AALC, a lightweight, accuracy-aware length reward integrated into reinforcement learning that dynamically balances correctness and brevity during training. By incorporating validation accuracy into the reward and employing a smooth, dynamically scheduled length penalty, AALC delays length penalty until target performance is met. Through extensive experiments across standard and out-of-distribution math benchmarks, we show that our approach reduces response length by over 50% while maintaining or even improving the original accuracy. Furthermore, qualitative analysis reveals that our method curbs redundant reasoning patterns such as excessive subgoal setting and verification, leading to structurally refined outputs rather than naive truncation. We also identify that efficiency gains are accompanied by reduced interpretability: models trained with AALC omit some narrative framing and explanatory context. These findings highlight the potential of reward-based strategies to guide LRMs toward more efficient, generalizable reasoning paths.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "aalc",
      "large",
      "language"
    ],
    "category": "noticia"
  },
  {
    "title": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift",
    "title_es": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift",
    "url": "https://arxiv.org/abs/2506.23673",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2506.23673v2 Announce Type: replace \nAbstract: Domain shift is a critical problem for pathology AI as pathology data is heavily influenced by center-specific conditions. Current pathology domain adaptation methods focus on image patches rather than WSI, thus failing to capture global WSI features required in typical clinical scenarios. In this work, we address the challenges of slide-level domain shift by proposing a Hierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD achieves multi-scale feature consistency and computationally efficient slide-level domain adaptation through two key components: (1) a hierarchical adaptation framework that integrates a Domain-level Alignment Solver for feature alignment, a Slide-level Geometric Invariance Regularization to preserve the morphological structure, and a Patch-level Attention Consistency Regularization to maintain local critical diagnostic cues; and (2) a prototype selection mechanism that reduces computational overhead. We validate our method on two slide-level tasks across five datasets, achieving a 4.1\\% AUROC improvement in a Breast Cancer HER2 Grading cohort and a 3.9\\% C-index gain in a UCEC survival prediction cohort. Our method provides a practical and reliable slide-level domain adaption solution for pathology institutions, minimizing both computational and annotation costs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"HASD: Hierarchical Adaption for pathology Slide-level Domain-shift\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hasd",
      "hierarchical",
      "adaption"
    ],
    "category": "noticia"
  },
  {
    "title": "Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information",
    "title_es": "Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information",
    "url": "https://arxiv.org/abs/2507.00038",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.00038v3 Announce Type: replace \nAbstract: In order to increase the effectiveness of model training, data reduction is essential to data-centric Artificial Intelligence (AI). It achieves this by locating the most instructive examples in massive datasets. To increase data quality and training efficiency, the main difficulty is choosing the best examples rather than the complete datasets. In this paper, we propose an effective data reduction strategy based on Pointwise V-Information (PVI). To enable a static method, we first use PVI to quantify instance difficulty and remove instances with low difficulty. Experiments show that classifier performance is maintained with only a 0.0001% to 0.76% decline in accuracy when 10%-30% of the data is removed. Second, we train the classifiers using a progressive learning strategy on examples sorted by increasing PVI, accelerating convergence and achieving a 0.8% accuracy gain over conventional training. Our findings imply that training a classifier on the chosen optimal subset may improve model performance and increase training efficiency when combined with an efficient data reduction strategy. Furthermore, we have adapted the PVI framework, which was previously limited to English datasets, to a variety of Chinese Natural Language Processing (NLP) tasks and base models, yielding insightful results for faster training and cross-lingual data reduction.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "quality",
      "over",
      "quantity"
    ],
    "category": "noticia"
  },
  {
    "title": "Crop Pest Classification Using Deep Learning Techniques: A Review",
    "title_es": "Crop Pest Classification Using Deep Learning Techniques: A Review",
    "url": "https://arxiv.org/abs/2507.01494",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.01494v3 Announce Type: replace \nAbstract: Insect pests continue to bring a serious threat to crop yields around the world, and traditional methods for monitoring them are often slow, manual, and difficult to scale. In recent years, deep learning has emerged as a powerful solution, with techniques like convolutional neural networks (CNNs), vision transformers (ViTs), and hybrid models gaining popularity for automating pest detection. This review looks at 37 carefully selected studies published between 2018 and 2025, all focused on AI-based pest classification. The selected research is organized by crop type, pest species, model architecture, dataset usage, and key technical challenges. The early studies relied heavily on CNNs but latest work is shifting toward hybrid and transformer-based models that deliver higher accuracy and better contextual understanding. Still, challenges like imbalanced datasets, difficulty in detecting small pests, limited generalizability, and deployment on edge devices remain significant hurdles. Overall, this review offers a structured overview of the field, highlights useful datasets, and outlines the key challenges and future directions for AI-based pest monitoring systems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Crop Pest Classification Using Deep Learning Techniques: A Review\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "crop",
      "pest",
      "classification"
    ],
    "category": "noticia"
  },
  {
    "title": "Measurement as Bricolage: Examining How Data Scientists Construct Target Variables for Predictive Modeling Tasks",
    "title_es": "Measurement as Bricolage: Examining How Data Scientists Construct Target Variables for Predictive Modeling Tasks",
    "url": "https://arxiv.org/abs/2507.02819",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.02819v2 Announce Type: replace \nAbstract: Data scientists often formulate predictive modeling tasks involving fuzzy, hard-to-define concepts, such as the \"authenticity\" of student writing or the \"healthcare need\" of a patient. Yet the process by which data scientists translate fuzzy concepts into a concrete, proxy target variable remains poorly understood. We interview fifteen data scientists in education (N=8) and healthcare (N=7) to understand how they construct target variables for predictive modeling tasks. Our findings suggest that data scientists construct target variables through a bricolage process, involving iterative negotiation between high-level measurement objectives and low-level practical constraints. Data scientists attempt to satisfy five major criteria for a target variable through bricolage: validity, simplicity, predictability, portability, and resource requirements. To achieve this, data scientists adaptively use problem (re)formulation strategies, such as swapping out one candidate target variable for another when the first fails to meet certain criteria (e.g., predictability), or composing multiple outcomes into a single target variable to capture a more holistic set of modeling objectives. Based on our findings, we present opportunities for future HCI, CSCW, and ML research to better support the art and science of target variable construction.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Measurement as Bricolage: Examining How Data Scientists Construct Target Variables for Predictive Modeling Tasks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "measurement",
      "as",
      "bricolage"
    ],
    "category": "noticia"
  },
  {
    "title": "Efficient Knowledge Graph Construction and Retrieval from Unstructured Text for Large-Scale RAG Systems",
    "title_es": "Efficient Knowledge Graph Construction and Retrieval from Unstructured Text for Large-Scale RAG Systems",
    "url": "https://arxiv.org/abs/2507.03226",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.03226v2 Announce Type: replace \nAbstract: We propose a scalable and cost-efficient framework for deploying Graph-based Retrieval Augmented Generation (GraphRAG) in enterprise environments. While GraphRAG has shown promise for multi-hop reasoning and structured retrieval, its adoption has been limited by the high computational cost of constructing knowledge graphs using large language models (LLMs) and the latency of graph-based retrieval. To address these challenges, we introduce two core innovations: (1) a dependency-based knowledge graph construction pipeline that leverages industrial-grade NLP libraries to extract entities and relations from unstructured text completely eliminating reliance on LLMs; and (2) a lightweight graph retrieval strategy that combines hybrid query node identification with efficient one-hop traversal for high-recall, low-latency subgraph extraction. We evaluate our framework on two SAP datasets focused on legacy code migration and demonstrate strong empirical performance. Our system achieves up to 15% and 4.35% improvements over traditional RAG baselines based on LLM-as-Judge and RAGAS metrics, respectively. Moreover, our dependency-based construction approach attains 94% of the performance of LLM-generated knowledge graphs (61.87% vs. 65.83%) while significantly reducing cost and improving scalability. These results validate the feasibility of deploying GraphRAG systems in real-world, large-scale enterprise applications without incurring prohibitive resource requirements paving the way for practical, explainable, and domain-adaptable retrieval-augmented reasoning.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Efficient Knowledge Graph Construction and Retrieval from Unstructured Text for Large-Scale RAG Systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "efficient",
      "knowledge",
      "graph"
    ],
    "category": "noticia"
  },
  {
    "title": "MoDA: Multi-modal Diffusion Architecture for Talking Head Generation",
    "title_es": "MoDA: Multi-modal Diffusion Architecture for Talking Head Generation",
    "url": "https://arxiv.org/abs/2507.03256",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.03256v3 Announce Type: replace \nAbstract: Talking head generation with arbitrary identities and speech audio remains a crucial problem in the realm of the virtual metaverse. Recently, diffusion models have become a popular generative technique in this field with their strong generation capabilities. However, several challenges remain for diffusion-based methods: 1) inefficient inference and visual artifacts caused by the implicit latent space of Variational Auto-Encoders (VAE), which complicates the diffusion process; 2) a lack of authentic facial expressions and head movements due to inadequate multi-modal information fusion. In this paper, MoDA handles these challenges by: 1) defining a joint parameter space that bridges motion generation and neural rendering, and leveraging flow matching to simplify diffusion learning; 2) introducing a multi-modal diffusion architecture to model the interaction among noisy motion, audio, and auxiliary conditions, enhancing overall facial expressiveness. In addition, a coarse-to-fine fusion strategy is employed to progressively integrate different modalities, ensuring effective feature fusion. Experimental results demonstrate that MoDA improves video diversity, realism, and efficiency, making it suitable for real-world applications. Project Page: https://lixinyyang.github.io/MoDA.github.io/",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MoDA: Multi-modal Diffusion Architecture for Talking Head Generation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "moda",
      "multimodal",
      "diffusion"
    ],
    "category": "noticia"
  },
  {
    "title": "Scalable Differentially Private Sketches under Continual Observation",
    "title_es": "Scalable Differentially Private Sketches under Continual Observation",
    "url": "https://arxiv.org/abs/2507.03361",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.03361v3 Announce Type: replace \nAbstract: Linear sketches are fundamental tools in data stream analytics. They are notable for supporting both approximate frequency queries and heavy hitter detection with bounded trade-offs for error and memory. Importantly, on streams that contain sensitive information, linear sketches can be easily privatized with the injection of a suitable amount of noise. This process is efficient in the single release model, where the output is released only at the end of the stream. In this setting, it suffices to add noise to the sketch once.\n  In contrast, in the continual observation model, where the output is released at every time-step, fresh noise needs to be added to the sketch before each release. This creates an additional computational overhead. To address this, we introduce Lazy Sketch, a novel differentially private sketching method that employs lazy updates, perturbing and modifying only a small portion of the sketch at each step. Compared to prior work, we reduce the update complexity by a factor of $O(w)$, where $w$ is the width of the sketch. Experiments demonstrate that our method increases throughput by up to 250x over prior work, making continual observation differential privacy practical for high-speed streaming applications.\n  In addition, for heavy hitter detection, we present a new sketch-based algorithm that leverages lazy updates to achieve a per-update complexity of $O(d \\log (T/w) + \\log w)$, for linear sketches with dimension $d\\times w$ and streams of length $T$. This marks a significant improvement over prior approaches in the streaming continual observation model, which require recomputing frequency estimates for every item in the input domain at each time step.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Scalable Differentially Private Sketches under Continual Observation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "scalable",
      "differentially",
      "private"
    ],
    "category": "noticia"
  },
  {
    "title": "An improved two-dimensional time-to-collision for articulated vehicles: predicting sideswipe and rear-end collisions",
    "title_es": "An improved two-dimensional time-to-collision for articulated vehicles: predicting sideswipe and rear-end collisions",
    "url": "https://arxiv.org/abs/2507.04184",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.04184v2 Announce Type: replace \nAbstract: Time-to-collision (TTC) is a widely used measure for predicting rear-end collisions, assuming constant speed and heading for both vehicles in the prediction horizon. However, this conventional formulation cannot detect sideswipe collisions. A two-dimensional extension, $\\text{TTC}_{\\text{2D}}$, has been proposed in the literature to address lateral interactions. However, this formulation assumes both vehicles have the same heading and that their headings remain unchanged during the manoeuvre, in addition to the constant speed and heading assumptions in the prediction horizon. Moreover, its use for articulated vehicles like a tractor-semitrailer remains unclear. This paper proposes three enhanced versions of $\\text{TTC}_{\\text{2D}}$ to overcome these limitations. The first incorporates the vehicle heading to account for directional differences. The standard assumption of constant speed and heading in the prediction horizon holds. The second adapts the formulation for articulated vehicles, and the third allows for constant acceleration, relaxing the constant speed assumption in the prediction horizon. All versions are evaluated in simulated cut-in scenarios, covering both sideswipe and rear-end collisions, using the CARLA simulation environment with a tractor-semitrailer model. Results show that the proposed versions predict sideswipe collisions with better accuracy compared to existing $\\text{TTC}_{\\text{2D}}$. They also detect rear-end collisions similar to the existing methods.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"An improved two-dimensional time-to-collision for articulated vehicles: predicting sideswipe and rear-end collisions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "an",
      "improved",
      "twodimensional"
    ],
    "category": "noticia"
  },
  {
    "title": "From Autonomy to Agency: Agentic Vehicles for Human-Centered Mobility Systems",
    "title_es": "From Autonomy to Agency: Agentic Vehicles for Human-Centered Mobility Systems",
    "url": "https://arxiv.org/abs/2507.04996",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.04996v2 Announce Type: replace \nAbstract: Autonomy, from the Greek autos (self) and nomos (law), refers to the capacity to operate according to internal rules without external control. Accordingly, autonomous vehicles (AuVs) are defined as systems capable of perceiving their environment and executing preprogrammed tasks independently of external input. However, both research and real-world deployments increasingly showcase vehicles that demonstrate behaviors beyond this definition (including the SAE levels 1 to 6), such as interaction with humans and machines, goal adaptation, contextual reasoning, external tool use, and long-term planning, particularly with the integration of large language models (LLMs) and agentic AI systems. These developments reveal a conceptual gap between technical autonomy and the broader cognitive and social capabilities needed for future human-centered mobility systems. To address this, we introduce the concept of agentic vehicles (AgVs), referring to vehicles that integrate agentic AI to reason, adapt, and interact within complex environments. This paper presents a systems-level framework to characterize AgVs, focusing on their cognitive and communicative layers and differentiating them from conventional AuVs. It synthesizes relevant advances in agentic AI, robotics, multi-agent systems, and human-machine interaction, and highlights how agentic AI, through high-level reasoning and tool use, can function not merely as computational tools but as interactive agents embedded in mobility ecosystems. The paper concludes by identifying key challenges in the development and governance of AgVs, including safety, real-time control, public acceptance, ethical alignment, and regulatory frameworks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"From Autonomy to Agency: Agentic Vehicles for Human-Centered Mobility Systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "from",
      "autonomy",
      "to"
    ],
    "category": "noticia"
  },
  {
    "title": "Neural-Driven Image Editing",
    "title_es": "Neural-Driven Image Editing",
    "url": "https://arxiv.org/abs/2507.05397",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.05397v2 Announce Type: replace \nAbstract: Traditional image editing typically relies on manual prompting, making it labor-intensive and inaccessible to individuals with limited motor control or language abilities. Leveraging recent advances in brain-computer interfaces (BCIs) and generative models, we propose LoongX, a hands-free image editing approach driven by multimodal neurophysiological signals. LoongX utilizes state-of-the-art diffusion models trained on a comprehensive dataset of 23,928 image editing pairs, each paired with synchronized electroencephalography (EEG), functional near-infrared spectroscopy (fNIRS), photoplethysmography (PPG), and head motion signals that capture user intent. To effectively address the heterogeneity of these signals, LoongX integrates two key modules. The cross-scale state space (CS3) module encodes informative modality-specific features. The dynamic gated fusion (DGF) module further aggregates these features into a unified latent space, which is then aligned with edit semantics via fine-tuning on a diffusion transformer (DiT). Additionally, we pre-train the encoders using contrastive learning to align cognitive states with semantic intentions from embedded natural language. Extensive experiments demonstrate that LoongX achieves performance comparable to text-driven methods (CLIP-I: 0.6605 vs. 0.6558; DINO: 0.4812 vs. 0.4636) and outperforms them when neural signals are combined with speech (CLIP-T: 0.2588 vs. 0.2549). These results highlight the promise of neural-driven generative models in enabling accessible, intuitive image editing and open new directions for cognitive-driven creative technologies. Datasets and code will be released to support future work and foster progress in this emerging area.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Neural-Driven Image Editing\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "neuraldriven",
      "image",
      "editing"
    ],
    "category": "noticia"
  },
  {
    "title": "Nyay-Darpan: Enhancing Decision Making Through Summarization and Case Retrieval for Consumer Law in India",
    "title_es": "Nyay-Darpan: Enhancing Decision Making Through Summarization and Case Retrieval for Consumer Law in India",
    "url": "https://arxiv.org/abs/2507.06090",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.06090v2 Announce Type: replace \nAbstract: AI-based judicial assistance and case prediction have been extensively studied in criminal and civil domains, but remain largely unexplored in consumer law, especially in India. In this paper, we present Nyay-Darpan, a novel two-in-one framework that (i) summarizes consumer case files and (ii) retrieves similar case judgements to aid decision-making in consumer dispute resolution. Our methodology not only addresses the gap in consumer law AI tools but also introduces an innovative approach to evaluate the quality of the summary. The term 'Nyay-Darpan' translates into 'Mirror of Justice', symbolizing the ability of our tool to reflect the core of consumer disputes through precise summarization and intelligent case retrieval. Our system achieves over 75 percent accuracy in similar case prediction and approximately 70 percent accuracy across material summary evaluation metrics, demonstrating its practical effectiveness. We will publicly release the Nyay-Darpan framework and dataset to promote reproducibility and facilitate further research in this underexplored yet impactful domain.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Nyay-Darpan: Enhancing Decision Making Through Summarization and Case Retrieval for Consumer Law in India\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nyaydarpan",
      "enhancing",
      "decision"
    ],
    "category": "noticia"
  },
  {
    "title": "Humans overrely on overconfident language models, across languages",
    "title_es": "Humans overrely on overconfident language models, across languages",
    "url": "https://arxiv.org/abs/2507.06306",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.06306v2 Announce Type: replace \nAbstract: As large language models (LLMs) are deployed globally, it is crucial that their responses are calibrated across languages to accurately convey uncertainty and limitations. Prior work shows that LLMs are linguistically overconfident in English, leading users to overrely on confident generations. However, the usage and interpretation of epistemic markers (e.g., 'I think it's') differs sharply across languages. Here, we study the risks of multilingual linguistic (mis)calibration, overconfidence, and overreliance across five languages to evaluate LLM safety in a global context. Our work finds that overreliance risks are high across languages. We first analyze the distribution of LLM-generated epistemic markers and observe that LLMs are overconfident across languages, frequently generating strengtheners even as part of incorrect responses. Model generations are, however, sensitive to documented cross-linguistic variation in usage: for example, models generate the most markers of uncertainty in Japanese and the most markers of certainty in German and Mandarin. Next, we measure human reliance rates across languages, finding that reliance behaviors differ cross-linguistically: for example, participants are significantly more likely to discount expressions of uncertainty in Japanese than in English (i.e., ignore their 'hedging' function and rely on generations that contain them). Taken together, these results indicate a high risk of reliance on overconfident model generations across languages. Our findings highlight the challenges of multilingual linguistic calibration and stress the importance of culturally and linguistically contextualized model safety evaluations.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Humans overrely on overconfident language models, across languages\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "humans",
      "overrely",
      "on"
    ],
    "category": "noticia"
  },
  {
    "title": "Precomputed Dominant Resource Fairness",
    "title_es": "Precomputed Dominant Resource Fairness",
    "url": "https://arxiv.org/abs/2507.08846",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.08846v2 Announce Type: replace \nAbstract: Although resource allocation is a well studied problem in computer science, until the prevalence of distributed systems, such as computing clouds and data centres, the question had been addressed predominantly for single resource type scenarios. At the beginning of the last decade, with the introuction of Dominant Resource Fairness, the studies of the resource allocation problem has finally extended to the multiple resource type scenarios. Dominant Resource Fairness is a solution, addressing the problem of fair allocation of multiple resource types, among users with heterogeneous demands. Based on Max-min Fairness, which is a well established algorithm in the literature for allocating resources in the single resource type scenarios, Dominant Resource Fairness generalises the scheme to the multiple resource case. It has a number of desirable properties that makes it preferable over alternatives, such as Sharing Incentive, Envy-Freeness, Pareto Efficiency, and Strategy Proofness, and as such, it is widely adopted in distributed systems. In the present study, we revisit the original study, and analyse the structure of the algorithm in closer view, to come up with an alternative algorithm, which approximates the Dominant Resource Fairness allocation in fewer steps. We name the new algorithm Precomputed Dominant Resource Fairness, after its main working principle.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Precomputed Dominant Resource Fairness\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "precomputed",
      "dominant",
      "resource"
    ],
    "category": "noticia"
  },
  {
    "title": "AICrypto: A Comprehensive Benchmark For Evaluating Cryptography Capabilities of Large Language Models",
    "title_es": "AICrypto: A Comprehensive Benchmark For Evaluating Cryptography Capabilities of Large Language Models",
    "url": "https://arxiv.org/abs/2507.09580",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.09580v2 Announce Type: replace \nAbstract: Large language models (LLMs) have demonstrated remarkable capabilities across a variety of domains. However, their applications in cryptography, which serves as a foundational pillar of cybersecurity, remain largely unexplored. To address this gap, we propose \\textbf{AICrypto}, the first comprehensive benchmark designed to evaluate the cryptographic capabilities of LLMs. The benchmark comprises 135 multiple-choice questions, 150 capture-the-flag (CTF) challenges, and 18 proof problems, covering a broad range of skills from factual memorization to vulnerability exploitation and formal reasoning. All tasks are carefully reviewed or constructed by cryptography experts to ensure correctness and rigor. To support automated evaluation of CTF challenges, we design an agent-based framework. To gain deeper insight into the current state of cryptographic proficiency in LLMs, we introduce human expert performance baselines for comparison across all task types. Our evaluation of 17 leading LLMs reveals that state-of-the-art models match or even surpass human experts in memorizing cryptographic concepts, exploiting common vulnerabilities, and routine proofs. However, they still lack a deep understanding of abstract mathematical concepts and struggle with tasks that require multi-step reasoning and dynamic analysis. We hope this work could provide insights for future research on LLMs in cryptographic applications. Our code and dataset are available at https://aicryptobench.github.io.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"AICrypto: A Comprehensive Benchmark For Evaluating Cryptography Capabilities of Large Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "aicrypto",
      "a",
      "comprehensive"
    ],
    "category": "noticia"
  },
  {
    "title": "A Graph Sufficiency Perspective for Neural Networks",
    "title_es": "A Graph Sufficiency Perspective for Neural Networks",
    "url": "https://arxiv.org/abs/2507.10215",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.10215v2 Announce Type: replace \nAbstract: This paper analyzes neural networks through graph variables and statistical sufficiency. We interpret neural network layers as graph-based transformations, where neurons act as pairwise functions between inputs and learned anchor points. Within this formulation, we establish conditions under which layer outputs are sufficient for the layer inputs, that is, each layer preserves the conditional distribution of the target variable given the input variable. We explore two theoretical paths under this graph-based view. The first path assumes dense anchor points and shows that asymptotic sufficiency holds in the infinite-width limit and is preserved throughout training. The second path, more aligned with practical architectures, proves exact or approximate sufficiency in finite-width networks by assuming region-separated input distributions and constructing appropriate anchor points. This path can ensure the sufficiency property for an infinite number of layers, and provide error bounds on the optimal loss for both regression and classification tasks using standard neural networks. Our framework covers fully connected layers, general pairwise functions, ReLU and sigmoid activations, and convolutional neural networks. Overall, this work bridges statistical sufficiency, graph-theoretic representations, and deep learning, providing a new statistical understanding of neural networks.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Graph Sufficiency Perspective for Neural Networks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "graph",
      "sufficiency"
    ],
    "category": "noticia"
  },
  {
    "title": "Reopening of the conjecture about the decidability of Quasi-Dense Modal Logics (Comments on Lyon & Ostropolski-Nalewaja's result)",
    "title_es": "Reopening of the conjecture about the decidability of Quasi-Dense Modal Logics (Comments on Lyon & Ostropolski-Nalewaja's result)",
    "url": "https://arxiv.org/abs/2507.11644",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.11644v3 Announce Type: replace \nAbstract: In \\cite{Lyon24} the question of the decidability of quasi-dense modal logics is answered, and an upper bound in $\\EXPSPACE$ is given. Unfortunately, authors' intricate proof seems to contain a major flaw that cannot be fixed, leaving the question wide open.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Reopening of the conjecture about the decidability of Quasi-Dense Modal Logics (Comments on Lyon & Ostropolski-Nalewaja's result)\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "reopening",
      "of",
      "the"
    ],
    "category": "noticia"
  },
  {
    "title": "Benchmarking Deception Probes via Black-to-White Performance Boosts",
    "title_es": "Benchmarking Deception Probes via Black-to-White Performance Boosts",
    "url": "https://arxiv.org/abs/2507.12691",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.12691v2 Announce Type: replace \nAbstract: AI assistants will occasionally respond deceptively to user queries. Recently, linear classifiers (called \"deception probes\") have been trained to distinguish the internal activations of a language model during deceptive versus honest responses. However, it's unclear how effective these probes are at detecting deception in practice, nor whether such probes are resistant to simple counter strategies from a deceptive assistant who wishes to evade detection. In this paper, we compare white-box monitoring (where the monitor has access to token-level probe activations) to black-box monitoring (without such access). We benchmark deception probes by the extent to which the white box monitor outperforms the black-box monitor, i.e. the black-to-white performance boost. We find weak but encouraging black-to-white performance boosts from existing deception probes.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Benchmarking Deception Probes via Black-to-White Performance Boosts\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "benchmarking",
      "deception",
      "probes"
    ],
    "category": "noticia"
  },
  {
    "title": "Latency-Optimal File Assignment in Geo-Distributed Storage with Preferential Demands",
    "title_es": "Latency-Optimal File Assignment in Geo-Distributed Storage with Preferential Demands",
    "url": "https://arxiv.org/abs/2507.12830",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.12830v2 Announce Type: replace \nAbstract: We consider the problem of data storage in a geographically distributed (or geo-distributed) network of servers (or nodes) where inter-node communication incurs certain round-trip delays. Every node serves a set of users who can request any file in the network. If the requested file is not available at the node, it communicates with other nodes to obtain the file, thus causing the user to experience latency in obtaining the file. The files can be placed uncoded, where each node stores exact copies of the files, or in coded fashion, where certain linear combination of files are placed at each node. We aim to obtain an optimal file placement on the nodes with respect to minimizing the worst-case latency at each node, as well as the system-average latency. The prior literature considered the case of equiprobable file demands at the nodes. In this paper, we investigate the generic case of non-uniform file-demand probabilities at each node. The scheme presented here is optimal within the family of uncoded schemes. It is obtained first by modeling the worst-case latency constraint as a vertex coloring problem, and then converting the system-average latency optimization to a problem of balanced-assignment.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Latency-Optimal File Assignment in Geo-Distributed Storage with Preferential Demands\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "latencyoptimal",
      "file",
      "assignment"
    ],
    "category": "noticia"
  },
  {
    "title": "Trustworthy Pedestrian Trajectory Prediction via Pattern-Aware Interaction Modeling",
    "title_es": "Trustworthy Pedestrian Trajectory Prediction via Pattern-Aware Interaction Modeling",
    "url": "https://arxiv.org/abs/2507.13397",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.13397v2 Announce Type: replace \nAbstract: Accurate and reliable pedestrian trajectory prediction is critical for the safety and robustness of intelligent applications, yet achieving trustworthy prediction remains highly challenging due to the complexity of interactions among pedestrians. Previous methods often adopt black-box modeling of pedestrian interactions, treating all neighbors uniformly. Despite their strong performance, such opaque modeling limits the reliability of predictions in safety-critical real-world deployments. To address this issue, we propose InSyn (Interaction-Synchronization Network), a novel Transformer-based model that explicitly captures diverse interaction patterns (e.g., walking in sync or conflicting) while effectively modeling direction-sensitive social behaviors. Additionally, we introduce a training strategy, termed Seq-Start of Seq (SSOS), designed to alleviate the common issue of initial-step divergence in numerical time-series prediction. Experiments on the ETH and UCY datasets demonstrate that our model not only outperforms recent black-box baselines in prediction accuracy, especially under high-density scenarios, but also provides stronger interpretability, achieving a favorable trade-off between reliability and accuracy. Furthermore, the SSOS strategy proves to be effective in improving sequential prediction performance, reducing the initial-step prediction error by approximately 6.58%.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Trustworthy Pedestrian Trajectory Prediction via Pattern-Aware Interaction Modeling\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "trustworthy",
      "pedestrian",
      "trajectory"
    ],
    "category": "noticia"
  },
  {
    "title": "InterAct-Video: Reasoning-Rich Video QA for Urban Traffic",
    "title_es": "InterAct-Video: Reasoning-Rich Video QA for Urban Traffic",
    "url": "https://arxiv.org/abs/2507.14743",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.14743v2 Announce Type: replace \nAbstract: Traffic monitoring is crucial for urban mobility, road safety, and intelligent transportation systems (ITS). Deep learning has advanced video-based traffic monitoring through video question answering (VideoQA) models, enabling structured insight extraction from traffic videos. However, existing VideoQA models struggle with the complexity of real-world traffic scenes, where multiple concurrent events unfold across spatiotemporal dimensions. To address these challenges, this paper introduces \\textbf{InterAct VideoQA}, a curated dataset designed to benchmark and enhance VideoQA models for traffic monitoring tasks. The InterAct VideoQA dataset comprises 8 hours of real-world traffic footage collected from diverse intersections, segmented into 10-second video clips, with over 25,000 question-answer (QA) pairs covering spatiotemporal dynamics, vehicle interactions, incident detection, and other critical traffic attributes. State-of-the-art VideoQA models are evaluated on InterAct VideoQA, exposing challenges in reasoning over fine-grained spatiotemporal dependencies within complex traffic scenarios. Additionally, fine-tuning these models on InterAct VideoQA yields notable performance improvements, demonstrating the necessity of domain-specific datasets for VideoQA. InterAct VideoQA is publicly available as a benchmark dataset to facilitate future research in real-world deployable VideoQA models for intelligent transportation systems. GitHub Repo: https://github.com/joe-rabbit/InterAct_VideoQA",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"InterAct-Video: Reasoning-Rich Video QA for Urban Traffic\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "interactvideo",
      "reasoningrich",
      "video"
    ],
    "category": "noticia"
  },
  {
    "title": "Recursive windows for grammar logics of bounded density",
    "title_es": "Recursive windows for grammar logics of bounded density",
    "url": "https://arxiv.org/abs/2507.14956",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.14956v3 Announce Type: replace \nAbstract: We introduce the family of multi-modal logics of bounded density and with a tableau-like approach using finite \\emph{windows} which were introduced in \\cite{BalGasq25} and that we generalize to recursive windows. We prove that their satisfiability problem is {\\bfseries PSPACE}-complete. As a side effect, the monomodal logic of density is shown to be in para-{\\bfseries PSPACE}.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Recursive windows for grammar logics of bounded density\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "recursive",
      "windows",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Adaptive Network Security Policies via Belief Aggregation and Rollout",
    "title_es": "Adaptive Network Security Policies via Belief Aggregation and Rollout",
    "url": "https://arxiv.org/abs/2507.15163",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.15163v2 Announce Type: replace \nAbstract: Evolving security vulnerabilities and shifting operational conditions require frequent updates to network security policies. These updates include adjustments to incident response procedures and modifications to access controls, among others. Reinforcement learning methods have been proposed for automating such policy adaptations, but most of the methods in the research literature lack performance guarantees and adapt slowly to changes. In this paper, we address these limitations and present a method for computing security policies that is scalable, offers theoretical guarantees, and adapts quickly to changes. It assumes a model or simulator of the system and comprises three components: belief estimation through particle filtering, offline policy computation through aggregation, and online policy adaptation through rollout. Central to our method is a new feature-based aggregation technique, which improves scalability and flexibility. We analyze the approximation error of aggregation and show that rollout efficiently adapts policies to changes under certain conditions. Simulations and testbed results demonstrate that our method outperforms state-of-the-art methods on several benchmarks, including CAGE-2.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Adaptive Network Security Policies via Belief Aggregation and Rollout\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "adaptive",
      "network",
      "security"
    ],
    "category": "noticia"
  },
  {
    "title": "Survival Modeling from Whole Slide Images via Patch-Level Graph Clustering and Mixture Density Experts",
    "title_es": "Survival Modeling from Whole Slide Images via Patch-Level Graph Clustering and Mixture Density Experts",
    "url": "https://arxiv.org/abs/2507.16476",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.16476v2 Announce Type: replace \nAbstract: We introduce a modular framework for predicting cancer-specific survival from whole slide pathology images (WSIs) that significantly improves upon the state-of-the-art accuracy. Our method integrating four key components. Firstly, to tackle large size of WSIs, we use dynamic patch selection via quantile-based thresholding for isolating prognostically informative tissue regions. Secondly, we use graph-guided k-means clustering to capture phenotype-level heterogeneity through spatial and morphological coherence. Thirdly, we use attention mechanisms that model both intra- and inter-cluster relationships to contextualize local features within global spatial relations between various types of tissue compartments. Finally, we use an expert-guided mixture density modeling for estimating complex survival distributions using Gaussian mixture models. The proposed model achieves a concordance index of $0.712 \\pm 0.028$ and Brier score of $0.254 \\pm 0.018$ on TCGA-KIRC (renal cancer), and a concordance index of $0.645 \\pm 0.017$ and Brier score of $0.281 \\pm 0.031$ on TCGA-LUAD (lung adenocarcinoma). These results are significantly better than the state-of-art and demonstrate predictive potential of the proposed method across diverse cancer types.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Survival Modeling from Whole Slide Images via Patch-Level Graph Clustering and Mixture Density Experts\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "survival",
      "modeling",
      "from"
    ],
    "category": "noticia"
  },
  {
    "title": "Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks",
    "title_es": "Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks",
    "url": "https://arxiv.org/abs/2507.17747",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.17747v2 Announce Type: replace \nAbstract: As frontier language models increasingly saturate standard QA benchmarks, concerns about data contamination, memorization, and escalating dataset creation costs persist. We propose a debate-driven evaluation paradigm that transforms any existing QA dataset into structured adversarial debates--where one model is given the official answer to defend, and another constructs and defends an alternative answer--adjudicated by a judge model blind to the correct solution. By forcing multi-round argumentation, this approach substantially increases difficulty while penalizing shallow memorization, yet reuses QA items to reduce curation overhead. We make two main contributions: (1) an evaluation pipeline to systematically convert QA tasks into debate-based assessments, and (2) a public benchmark that demonstrates our paradigm's effectiveness on a subset of MMLU-Pro questions, complete with standardized protocols and reference models. Empirical results validate the robustness of the method and its effectiveness against data contamination--a Llama 3.1 model fine-tuned on test questions showed dramatic accuracy improvements (50% -> 82%) but performed worse in debates. Results also show that even weaker judges can reliably differentiate stronger debaters, highlighting how debate-based evaluation can scale to future, more capable systems while maintaining a fraction of the cost of creating new benchmarks. Overall, our framework underscores that \"pretraining on the test set is no longer all you need,\" offering a sustainable path for measuring the genuine reasoning ability of advanced language models.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "pretraining",
      "on",
      "the"
    ],
    "category": "noticia"
  },
  {
    "title": "Causal Mechanism Estimation in Multi-Sensor Systems Across Multiple Domains",
    "title_es": "Causal Mechanism Estimation in Multi-Sensor Systems Across Multiple Domains",
    "url": "https://arxiv.org/abs/2507.17792",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.17792v3 Announce Type: replace \nAbstract: To gain deeper insights into a complex sensor system through the lens of causality, we present common and individual causal mechanism estimation (CICME), a novel three-step approach to inferring causal mechanisms from heterogeneous data collected across multiple domains. By leveraging the principle of Causal Transfer Learning (CTL), CICME is able to reliably detect domain-invariant causal mechanisms when provided with sufficient samples. The identified common causal mechanisms are further used to guide the estimation of the remaining causal mechanisms in each domain individually. The performance of CICME is evaluated on linear Gaussian models under scenarios inspired from a manufacturing process. Building upon existing continuous optimization-based causal discovery methods, we show that CICME leverages the benefits of applying causal discovery on the pooled data and repeatedly on data from individual domains, and it even outperforms both baseline methods under certain scenarios.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Causal Mechanism Estimation in Multi-Sensor Systems Across Multiple Domains\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "causal",
      "mechanism",
      "estimation"
    ],
    "category": "noticia"
  },
  {
    "title": "SAMUeL: Efficient Vocal-Conditioned Music Generation via Soft Alignment Attention and Latent Diffusion",
    "title_es": "SAMUeL: Efficient Vocal-Conditioned Music Generation via Soft Alignment Attention and Latent Diffusion",
    "url": "https://arxiv.org/abs/2507.19991",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.19991v2 Announce Type: replace \nAbstract: We present a lightweight latent diffusion model for vocal-conditioned musical accompaniment generation that addresses critical limitations in existing music AI systems. Our approach introduces a novel soft alignment attention mechanism that adaptively combines local and global temporal dependencies based on diffusion timesteps, enabling efficient capture of multi-scale musical structure. Operating in the compressed latent space of a pre-trained variational autoencoder, the model achieves a 220 times parameter reduction compared to state-of-the-art systems while delivering 52 times faster inference. Experimental evaluation demonstrates competitive performance with only 15M parameters, outperforming OpenAI Jukebox in production quality and content unity while maintaining reasonable musical coherence. The ultra-lightweight architecture enables real-time deployment on consumer hardware, making AI-assisted music creation accessible for interactive applications and resource-constrained environments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SAMUeL: Efficient Vocal-Conditioned Music Generation via Soft Alignment Attention and Latent Diffusion\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "samuel",
      "efficient",
      "vocalconditioned"
    ],
    "category": "noticia"
  },
  {
    "title": "ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models",
    "title_es": "ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models",
    "url": "https://arxiv.org/abs/2507.20091",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.20091v2 Announce Type: replace \nAbstract: Speech language models refer to language models with speech processing and understanding capabilities. One key desirable capability for speech language models is the ability to capture the intricate interdependency between content and prosody. The existing mainstream paradigm of training speech language models, which converts speech into discrete tokens before feeding them into LLMs, is sub-optimal in learning prosody information -- we find that the resulting LLMs do not exhibit obvious emerging prosody processing capabilities via pre-training alone. To overcome this, we propose ProsodyLM, which introduces a simple tokenization scheme amenable to learning prosody. Each speech utterance is first transcribed into text, followed by a sequence of word-level prosody tokens. Compared with conventional speech tokenization schemes, the proposed tokenization scheme retains more complete prosody information, and is more understandable to text-based LLMs. We find that ProsodyLM can learn surprisingly diverse emerging prosody processing capabilities through pre-training alone, ranging from harnessing the prosody nuances in generated speech, such as contrastive focus, understanding emotion and stress in an utterance, to maintaining prosody consistency in long contexts.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "prosodylm",
      "uncovering",
      "the"
    ],
    "category": "noticia"
  },
  {
    "title": "StepFun-Prover Preview: Let's Think and Verify Step by Step",
    "title_es": "StepFun-Prover Preview: Let's Think and Verify Step by Step",
    "url": "https://arxiv.org/abs/2507.20199",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.20199v2 Announce Type: replace \nAbstract: We present StepFun-Prover Preview, a large language model designed for formal theorem proving through tool-integrated reasoning. Using a reinforcement learning pipeline that incorporates tool-based interactions, StepFun-Prover can achieve strong performance in generating Lean 4 proofs with minimal sampling. Our approach enables the model to emulate human-like problem-solving strategies by iteratively refining proofs based on real-time environment feedback. On the miniF2F-test benchmark, StepFun-Prover achieves a pass@1 success rate of $70.0\\%$. Beyond advancing benchmark performance, we introduce an end-to-end training framework for developing tool-integrated reasoning models, offering a promising direction for automated theorem proving and Math AI assistant.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"StepFun-Prover Preview: Let's Think and Verify Step by Step\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "stepfunprover",
      "preview",
      "lets"
    ],
    "category": "noticia"
  },
  {
    "title": "Using Tactile Charts to Support Comprehension and Learning of Complex Visualizations for Blind and Low-Vision Individuals",
    "title_es": "Using Tactile Charts to Support Comprehension and Learning of Complex Visualizations for Blind and Low-Vision Individuals",
    "url": "https://arxiv.org/abs/2507.21462",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.21462v4 Announce Type: replace \nAbstract: We investigate whether tactile charts support comprehension and learning of complex visualizations for blind and low-vision (BLV) individuals and contribute four tactile chart designs and an interview study. Visualizations are powerful tools for conveying data, yet BLV individuals typically can rely only on assistive technologies -- primarily alternative texts -- to access this information. Prior research shows the importance of mental models of chart types for interpreting these descriptions, yet BLV individuals have no means to build such a mental model based on images of visualizations. Tactile charts show promise to fill this gap in supporting the process of building mental models. Yet studies on tactile data representations mostly focus on simple chart types, and it is unclear whether they are also appropriate for more complex charts as would be found in scientific publications. Working with two BLV researchers, we designed 3D-printed tactile template charts with exploration instructions for four advanced chart types: UpSet plots, violin plots, clustered heatmaps, and faceted line charts. We then conducted an interview study with 12 BLV participants comparing whether using our tactile templates improves mental models and understanding of charts and whether this understanding translates to novel datasets experienced through alt texts. Thematic analysis shows that tactile models support chart type understanding and are the preferred learning method by BLV individuals. We also report participants' opinions on tactile chart design and their role in BLV education.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Using Tactile Charts to Support Comprehension and Learning of Complex Visualizations for Blind and Low-Vision Individuals\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "using",
      "tactile",
      "charts"
    ],
    "category": "noticia"
  },
  {
    "title": "MOR-VIT: Efficient Vision Transformer with Mixture-of-Recursions",
    "title_es": "MOR-VIT: Efficient Vision Transformer with Mixture-of-Recursions",
    "url": "https://arxiv.org/abs/2507.21761",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.21761v2 Announce Type: replace \nAbstract: Vision Transformers (ViTs) have achieved remarkable success in image recognition, yet standard ViT architectures are hampered by substantial parameter redundancy and high computational cost, limiting their practical deployment. While recent efforts on efficient ViTs primarily focus on static model compression or token-level sparsification, they remain constrained by fixed computational depth for all tokens. In this work, we present MoR-ViT, a novel vision transformer framework that, for the first time, incorporates a token-level dynamic recursion mechanism inspired by the Mixture-of-Recursions (MoR) paradigm. This approach enables each token to adaptively determine its processing depth, yielding a flexible and input-dependent allocation of computational resources. Extensive experiments on ImageNet-1K and transfer benchmarks demonstrate that MoR-ViT not only achieves state-of-the-art accuracy with up to 70% parameter reduction and 2.5x inference acceleration, but also outperforms leading efficient ViT baselines such as DynamicViT and TinyViT under comparable conditions. These results establish dynamic recursion as an effective strategy for efficient vision transformers and open new avenues for scalable and deployable deep learning models in real-world scenarios.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MOR-VIT: Efficient Vision Transformer with Mixture-of-Recursions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "morvit",
      "efficient",
      "vision"
    ],
    "category": "noticia"
  },
  {
    "title": "Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis",
    "title_es": "Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis",
    "url": "https://arxiv.org/abs/2507.21875",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.21875v5 Announce Type: replace \nAbstract: Pain is a complex and pervasive condition that affects a significant portion of the population. Accurate and consistent assessment is essential for individuals suffering from pain, as well as for developing effective management strategies in a healthcare system. Automatic pain assessment systems enable continuous monitoring, support clinical decision-making, and help minimize patient distress while mitigating the risk of functional deterioration. Leveraging physiological signals offers objective and precise insights into a person's state, and their integration in a multimodal framework can further enhance system performance. This study has been submitted to the \\textit{Second Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The proposed approach introduces \\textit{Tiny-BioMoE}, a lightweight pretrained embedding model for biosignal analysis. Trained on $4.4$ million biosignal image representations and consisting of only $7.3$ million parameters, it serves as an effective tool for extracting high-quality embeddings for downstream tasks. Extensive experiments involving electrodermal activity, blood volume pulse, respiratory signals, peripheral oxygen saturation, and their combinations highlight the model's effectiveness across diverse modalities in automatic pain recognition tasks. \\textit{\\textcolor{blue}{The model's architecture (code) and weights are available at https://github.com/GkikasStefanos/Tiny-BioMoE.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "tinybiomoe",
      "a",
      "lightweight"
    ],
    "category": "noticia"
  },
  {
    "title": "RANA: Robust Active Learning for Noisy Network Alignment",
    "title_es": "RANA: Robust Active Learning for Noisy Network Alignment",
    "url": "https://arxiv.org/abs/2507.22434",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.22434v2 Announce Type: replace \nAbstract: Network alignment has attracted widespread attention in various fields. However, most existing works mainly focus on the problem of label sparsity, while overlooking the issue of noise in network alignment, which can substantially undermine model performance. Such noise mainly includes structural noise from noisy edges and labeling noise caused by human-induced and process-driven errors. To address these problems, we propose RANA, a Robust Active learning framework for noisy Network Alignment. RANA effectively tackles both structure noise and label noise while addressing the sparsity of anchor link annotations, which can improve the robustness of network alignment models. Specifically, RANA introduces the proposed Noise-aware Selection Module and the Label Denoising Module to address structural noise and labeling noise, respectively. In the first module, we design a noise-aware maximization objective to select node pairs, incorporating a cleanliness score to address structural noise. In the second module, we propose a novel multi-source fusion denoising strategy that leverages model and twin node pairs labeling to provide more accurate labels for node pairs. Empirical results on three real-world datasets demonstrate that RANA outperforms state-of-the-art active learning-based methods in alignment accuracy. Our code is available at https://github.com/YXNan0110/RANA.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"RANA: Robust Active Learning for Noisy Network Alignment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "rana",
      "robust",
      "active"
    ],
    "category": "noticia"
  },
  {
    "title": "ART: Adaptive Relation Tuning for Generalized Relation Prediction",
    "title_es": "ART: Adaptive Relation Tuning for Generalized Relation Prediction",
    "url": "https://arxiv.org/abs/2507.23543",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.23543v2 Announce Type: replace \nAbstract: Visual relation detection (VRD) is the task of identifying the relationships between objects in a scene. VRD models trained solely on relation detection data struggle to generalize beyond the relations on which they are trained. While prompt tuning has been used to adapt vision-language models (VLMs) for VRD, it uses handcrafted prompts and struggles with novel or complex relations. We argue that instruction tuning offers a more effective solution by fine-tuning VLMs on diverse instructional data. We thus introduce ART, an Adaptive Relation Tuning framework that adapts VLMs for VRD through instruction tuning and strategic instance selection. By converting VRD datasets into an instruction tuning format and employing an adaptive sampling algorithm, ART directs the VLM to focus on informative relations while maintaining generalizability. Specifically, we focus on the relation classification, where subject-object boxes are given and the model predicts the predicate between them. We tune on a held-in set and evaluate across multiple held-out datasets of varying complexity. Our approach strongly improves over its baselines and can infer unseen relation concepts, a capability absent in mainstream VRD methods. We demonstrate ART's practical value by using the predicted relations for segmenting complex scenes.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"ART: Adaptive Relation Tuning for Generalized Relation Prediction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "art",
      "adaptive",
      "relation"
    ],
    "category": "noticia"
  },
  {
    "title": "Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis",
    "title_es": "Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis",
    "url": "https://arxiv.org/abs/2508.00381",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.00381v2 Announce Type: replace \nAbstract: Weld defect detection is crucial for ensuring the safety and reliability of piping systems in the oil and gas industry, especially in challenging marine and offshore environments. Traditional non-destructive testing (NDT) methods often fail to detect subtle or internal defects, leading to potential failures and costly downtime. Furthermore, existing neural network-based approaches for defect classification frequently rely on arbitrarily selected pretrained architectures and lack interpretability, raising safety concerns for deployment. To address these challenges, this paper introduces ``Adapt-WeldNet\", an adaptive framework for welding defect detection that systematically evaluates various pre-trained architectures, transfer learning strategies, and adaptive optimizers to identify the best-performing model and hyperparameters, optimizing defect detection and providing actionable insights. Additionally, a novel Defect Detection Interpretability Analysis (DDIA) framework is proposed to enhance system transparency. DDIA employs Explainable AI (XAI) techniques, such as Grad-CAM and LIME, alongside domain-specific evaluations validated by certified ASNT NDE Level II professionals. Incorporating a Human-in-the-Loop (HITL) approach and aligning with the principles of Trustworthy AI, DDIA ensures the reliability, fairness, and accountability of the defect detection system, fostering confidence in automated decisions through expert validation. By improving both performance and interpretability, this work enhances trust, safety, and reliability in welding defect detection systems, supporting critical operations in offshore and marine environments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "advancing",
      "welding",
      "defect"
    ],
    "category": "noticia"
  },
  {
    "title": "PaPaformer: Language Model from Pre-trained Parallel Paths",
    "title_es": "PaPaformer: Language Model from Pre-trained Parallel Paths",
    "url": "https://arxiv.org/abs/2508.00544",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.00544v2 Announce Type: replace \nAbstract: The training of modern large-language models requires an increasingly amount of computation power and time. Even smaller variants, such as small-language models (SLMs), take several days to train in the best-case scenarios, often requiring multiple GPUs. This paper explores methods to train and evaluate decoder-only transformer-based language models in hours instead of days/weeks. We introduces \\textit{PaPaformer}, a decoder-only transformer architecture variant, whose lower-dimensional parallel paths are combined into larger model. The paper shows that these lower-dimensional paths can be trained individually with different types of training data and then combined into one larger model. This method gives the option to reduce the total number of model parameters and the training time with increasing performance. Moreover, the use of parallel path structure opens interesting possibilities to customize paths to accommodate specific task requirements.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"PaPaformer: Language Model from Pre-trained Parallel Paths\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "papaformer",
      "language",
      "model"
    ],
    "category": "noticia"
  },
  {
    "title": "Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images",
    "title_es": "Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images",
    "url": "https://arxiv.org/abs/2508.00549",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.00549v2 Announce Type: replace \nAbstract: Clinical decision-making relies heavily on understanding relative positions of anatomical structures and anomalies. Therefore, for Vision-Language Models (VLMs) to be applicable in clinical practice, the ability to accurately determine relative positions on medical images is a fundamental prerequisite. Despite its importance, this capability remains highly underexplored. To address this gap, we evaluate the ability of state-of-the-art VLMs, GPT-4o, Llama3.2, Pixtral, and JanusPro, and find that all models fail at this fundamental task. Inspired by successful approaches in computer vision, we investigate whether visual prompts, such as alphanumeric or colored markers placed on anatomical structures, can enhance performance. While these markers provide moderate improvements, results remain significantly lower on medical images compared to observations made on natural images. Our evaluations suggest that, in medical imaging, VLMs rely more on prior anatomical knowledge than on actual image content for answering relative position questions, often leading to incorrect conclusions. To facilitate further research in this area, we introduce the MIRP , Medical Imaging Relative Positioning, benchmark dataset, designed to systematically evaluate the capability to identify relative positions in medical images.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "your",
      "other",
      "left"
    ],
    "category": "noticia"
  },
  {
    "title": "Can Large Pretrained Depth Estimation Models Help With Image Dehazing?",
    "title_es": "Can Large Pretrained Depth Estimation Models Help With Image Dehazing?",
    "url": "https://arxiv.org/abs/2508.00698",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.00698v2 Announce Type: replace \nAbstract: Image dehazing remains a challenging problem due to the spatially varying nature of haze in real-world scenes. While existing methods have demonstrated the promise of large-scale pretrained models for image dehazing, their architecture-specific designs hinder adaptability across diverse scenarios with different accuracy and efficiency requirements. In this work, we systematically investigate the generalization capability of pretrained depth representations-learned from millions of diverse images-for image dehazing. Our empirical analysis reveals that the learned deep depth features maintain remarkable consistency across varying haze levels. Building on this insight, we propose a plug-and-play RGB-D fusion module that seamlessly integrates with diverse dehazing architectures. Extensive experiments across multiple benchmarks validate both the effectiveness and broad applicability of our approach.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Can Large Pretrained Depth Estimation Models Help With Image Dehazing?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "can",
      "large",
      "pretrained"
    ],
    "category": "noticia"
  },
  {
    "title": "Adacc: An Adaptive Framework Unifying Compression and Activation Recomputation for LLM Training",
    "title_es": "Adacc: An Adaptive Framework Unifying Compression and Activation Recomputation for LLM Training",
    "url": "https://arxiv.org/abs/2508.00806",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.00806v2 Announce Type: replace \nAbstract: Training large language models (LLMs) is often constrained by GPU memory limitations. To alleviate memory pressure, activation recomputation and data compression have been proposed as two major strategies. However, both approaches have limitations: recomputation introduces significant training overhead, while compression can lead to accuracy degradation and computational inefficiency when applied naively. In this paper, we propose Adacc, the first adaptive memory optimization framework that unifies activation recomputation and data compression to improve training efficiency for LLMs while preserving model accuracy. Unlike existing methods that apply static, rule-based strategies or rely solely on one technique, Adacc makes fine-grained, tensor-level decisions, dynamically selecting between recomputation, retention, and compression based on tensor characteristics and runtime hardware constraints.\n  Adacc tackles three key challenges: (1) it introduces layer-specific compression algorithms that mitigate accuracy loss by accounting for outliers in LLM activations; (2) it employs a MILP-based scheduling policy to globally optimize memory strategies across layers; and (3) it integrates an adaptive policy evolution mechanism to update strategies during training in response to changing data distributions. Experimental results show that Adacc improves training throughput by 1.01x to 1.37x compared to state-of-the-art frameworks, while maintaining accuracy comparable to the baseline.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Adacc: An Adaptive Framework Unifying Compression and Activation Recomputation for LLM Training\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "adacc",
      "an",
      "adaptive"
    ],
    "category": "noticia"
  },
  {
    "title": "SPARTA: Advancing Sparse Attention in Spiking Neural Networks via Spike-Timing-Based Prioritization",
    "title_es": "SPARTA: Advancing Sparse Attention in Spiking Neural Networks via Spike-Timing-Based Prioritization",
    "url": "https://arxiv.org/abs/2508.01646",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.01646v2 Announce Type: replace \nAbstract: Current Spiking Neural Networks (SNNs) underutilize the temporal dynamics inherent in spike-based processing, relying primarily on rate coding while overlooking precise timing information that provides rich computational cues. We propose SPARTA (Spiking Priority Attention with Resource-Adaptive Temporal Allocation), a framework that leverages heterogeneous neuron dynamics and spike-timing information to enable efficient sparse attention. SPARTA prioritizes tokens based on temporal cues, including firing patterns, spike timing, and inter-spike intervals, achieving 65.4% sparsity through competitive gating. By selecting only the most salient tokens, SPARTA reduces attention complexity from O(N^2) to O(K^2) with k << n, while maintaining high accuracy. Our method achieves state-of-the-art performance on DVS-Gesture (98.78%) and competitive results on CIFAR10-DVS (83.06%) and CIFAR-10 (95.3%), demonstrating that exploiting spike timing dynamics improves both computational efficiency and accuracy.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SPARTA: Advancing Sparse Attention in Spiking Neural Networks via Spike-Timing-Based Prioritization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sparta",
      "advancing",
      "sparse"
    ],
    "category": "noticia"
  },
  {
    "title": "Attitude Determination and Control of GPS Satellites: Stabilization, Orbital Insertion, and Operational Control Mechanisms",
    "title_es": "Attitude Determination and Control of GPS Satellites: Stabilization, Orbital Insertion, and Operational Control Mechanisms",
    "url": "https://arxiv.org/abs/2508.01660",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.01660v3 Announce Type: replace \nAbstract: Global Positioning System (GPS) satellites are essential for providing accurate navigation and timing information worldwide. Operating in medium Earth orbit (MEO), these satellites must maintain precise Earth-pointing attitudes to transmit signals effectively. This paper presents a comprehensive review of the operational dynamics, attitude determination and control systems (ADCS), and orbital insertion techniques for GPS satellites. We explore the integration of sensors and actuators, control algorithms, stabilization strategies, and the launch procedures required to deploy these satellites. Key equations related to orbital mechanics and attitude control are discussed, and references to recent technical literature are included.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Attitude Determination and Control of GPS Satellites: Stabilization, Orbital Insertion, and Operational Control Mechanisms\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "attitude",
      "determination",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "CMIC: Content-Adaptive Mamba for Learned Image Compression",
    "title_es": "CMIC: Content-Adaptive Mamba for Learned Image Compression",
    "url": "https://arxiv.org/abs/2508.02192",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.02192v3 Announce Type: replace \nAbstract: Recent Learned image compression (LIC) leverages Mamba-style state-space models (SSMs) for global receptive fields with linear complexity. However, vanilla Mamba is content-agnostic, relying on fixed and predefined selective scans, which restricts its ability to dynamically and fully exploit content dependencies. We introduce Content-Adaptive Mamba (CAM), a dynamic SSM that addresses two critical limitations. First, it employs content-aware token reorganization, clustering and reordering tokens based on content similarity to prioritize proximity in feature space over Euclidean space. Second, it integrates global priors into SSM via a prompt dictionary, effectively mitigating the strict causality and long-range decay in the token interactions of Mamba. These innovations enable CAM to better capture global dependencies while preserving computational efficiency. Leveraging CAM, our Content-Adaptive Mamba-based LIC model (CMIC) achieves state-of-the-art rate-distortion performance, surpassing VTM-21.0 by -15.91\\%, -21.34\\%, and -17.58\\% BD-rate on Kodak, Tecnick, and CLIC benchmarks, respectively.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CMIC: Content-Adaptive Mamba for Learned Image Compression\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cmic",
      "contentadaptive",
      "mamba"
    ],
    "category": "noticia"
  },
  {
    "title": "Would you let a humanoid play storytelling with your child? A usability study on LLM-powered narrative Human-Robot Interaction",
    "title_es": "Would you let a humanoid play storytelling with your child? A usability study on LLM-powered narrative Human-Robot Interaction",
    "url": "https://arxiv.org/abs/2508.02505",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.02505v2 Announce Type: replace \nAbstract: A key challenge in human-robot interaction research lies in developing robotic systems that can effectively perceive and interpret social cues, facilitating natural and adaptive interactions. In this work, we present a novel framework for enhancing the attention of the iCub humanoid robot by integrating advanced perceptual abilities to recognise social cues, understand surroundings through generative models, such as ChatGPT, and respond with contextually appropriate social behaviour. Specifically, we propose an interaction task implementing a narrative protocol (storytelling task) in which the human and the robot create a short imaginary story together, exchanging in turn cubes with creative images placed on them. To validate the protocol and the framework, experiments were performed to quantify the degree of usability and the quality of experience perceived by participants interacting with the system. Such a system can be beneficial in promoting effective human robot collaborations, especially in assistance, education and rehabilitation scenarios where the social awareness and the robot responsiveness play a pivotal role.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Would you let a humanoid play storytelling with your child? A usability study on LLM-powered narrative Human-Robot Interaction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "would",
      "you",
      "let"
    ],
    "category": "noticia"
  },
  {
    "title": "Failure-Aware Multi-Robot Coordination for Resilient and Adaptive Target Tracking",
    "title_es": "Failure-Aware Multi-Robot Coordination for Resilient and Adaptive Target Tracking",
    "url": "https://arxiv.org/abs/2508.02529",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.02529v2 Announce Type: replace \nAbstract: Multi-robot coordination is crucial for autonomous systems, yet real-world deployments often encounter various failures. These include both temporary and permanent disruptions in sensing and communication, which can significantly degrade system robustness and performance if not explicitly modeled. Despite its practical importance, failure-aware coordination remains underexplored in the literature. To bridge the gap between idealized conditions and the complexities of real-world environments, we propose a unified failure-aware coordination framework designed to enable resilient and adaptive multi-robot target tracking under both temporary and permanent failure conditions. Our approach systematically distinguishes between two classes of failures: (1) probabilistic and temporary disruptions, where robots recover from intermittent sensing or communication losses by dynamically adapting paths and avoiding inferred danger zones, and (2) permanent failures, where robots lose sensing or communication capabilities irreversibly, requiring sustained, decentralized behavioral adaptation. To handle these scenarios, the robot team is partitioned into subgroups. Robots that remain connected form a communication group and collaboratively plan using partially centralized nonlinear optimization. Robots experiencing permanent disconnection or failure continue to operate independently through decentralized or individual optimization, allowing them to contribute to the task within their local context. We extensively evaluate our method across a range of benchmark variations and conduct a comprehensive assessment under diverse real-world failure scenarios. Results show that our framework consistently achieves robust performance in realistic environments with unknown danger zones, offering a practical and generalizable solution for the multi-robot systems community.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Failure-Aware Multi-Robot Coordination for Resilient and Adaptive Target Tracking\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "failureaware",
      "multirobot",
      "coordination"
    ],
    "category": "noticia"
  },
  {
    "title": "Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction",
    "title_es": "Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction",
    "url": "https://arxiv.org/abs/2508.02622",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.02622v2 Announce Type: replace \nAbstract: This paper introduces and formalizes Noosem\\`ia, a novel cognitive-phenomenological pattern emerging from human interaction with generative AI systems, particularly those enabling dialogic or multimodal exchanges. We propose a multidisciplinary framework to explain how, under certain conditions, users attribute intentionality, agency, and even interiority to these systems - a process grounded not in physical resemblance, but in linguistic performance, epistemic opacity, and emergent technological complexity. By linking an LLM declination of meaning holism to our technical notion of the LLM Contextual Cognitive Field, we clarify how LLMs construct meaning relationally and how coherence and a simulacrum of agency arise at the human-AI interface. The analysis situates noosemia alongside pareidolia, animism, the intentional stance and the uncanny valley, distinguishing its unique characteristics. We also introduce a-noosemia to describe the phenomenological withdrawal of such projections. The paper concludes with reflections on the broader philosophical, epistemological and social implications of noosemic dynamics and directions for future research.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "noosemia",
      "toward",
      "a"
    ],
    "category": "noticia"
  },
  {
    "title": "Reframing Pattern: A Comprehensive Approach to a Composite Visual Variable",
    "title_es": "Reframing Pattern: A Comprehensive Approach to a Composite Visual Variable",
    "url": "https://arxiv.org/abs/2508.02639",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.02639v3 Announce Type: replace \nAbstract: We present a new comprehensive theory for explaining, exploring, and using pattern as a visual variable in visualization. Although patterns have long been used for data encoding and continue to be valuable today, their conceptual foundations are precarious: the concepts and terminology used across the research literature and in practice are inconsistent, making it challenging to use patterns effectively and to conduct research to inform their use. To address this problem, we conduct a comprehensive cross-disciplinary literature review that clarifies ambiguities around the use of \"pattern\" and \"texture\". As a result, we offer a new consistent treatment of pattern as a composite visual variable composed of structured groups of graphic primitives that can serve as marks for encoding data individually and collectively. This new and widely applicable formulation opens a sizable design space for the visual variable pattern, which we formalize as a new system comprising three sets of variables: the spatial arrangement of primitives, the appearance relationships among primitives, and the retinal visual variables that characterize individual primitives. We show how our pattern system relates to existing visualization theory and highlight opportunities for visualization design. We further explore patterns based on complex spatial arrangements, demonstrating explanatory power and connecting our conceptualization to broader theory on maps and cartography. An author version and additional materials are available on OSF: osf.io/z7ae2.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Reframing Pattern: A Comprehensive Approach to a Composite Visual Variable\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "reframing",
      "pattern",
      "a"
    ],
    "category": "noticia"
  },
  {
    "title": "LLM Agent-Based Simulation of Student Activities and Mental Health Using Smartphone Sensing Data",
    "title_es": "LLM Agent-Based Simulation of Student Activities and Mental Health Using Smartphone Sensing Data",
    "url": "https://arxiv.org/abs/2508.02679",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.02679v2 Announce Type: replace \nAbstract: Students' mental well-being is vital for academic success, with activities such as studying, socializing, and sleeping playing a role. Current mobile sensing data highlight this intricate link using statistical and machine learning analyses. We propose a novel LLM agent-based simulation framework to model student activities and mental health using the StudentLife Dataset. Each LLM agent was initialized with personality questionnaires and guided by smartphone sensing data throughout the simulated semester. These agents predict individual behaviors, provide self-reported mental health data via ecological momentary assessments (EMAs), and complete follow-up personality questionnaires. To ensure accuracy, we investigated various prompting techniques, memory systems, and activity-based mental state management strategies that dynamically update an agent's mental state based on their daily activities. This simulation goes beyond simply replicating existing data. This allows us to explore new scenarios that are not present in the original dataset, such as peer influence through agent-to-agent interactions and the impact of social media. Furthermore, we can conduct intervention studies by manipulating activity patterns via sensing signals and personality traits using questionnaire responses. This provides valuable insights into the behavioral changes that could enhance student well-being. The framework also facilitates hypothetical interviews with LLM agents, offering deeper insights into their mental health. This study showcases the power of LLM-driven behavioral modeling with sensing data, opening new avenues for understanding and supporting student mental health.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"LLM Agent-Based Simulation of Student Activities and Mental Health Using Smartphone Sensing Data\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "llm",
      "agentbased",
      "simulation"
    ],
    "category": "noticia"
  },
  {
    "title": "Web3 x AI Agents: Landscape, Integrations, and Foundational Challenges",
    "title_es": "Web3 x AI Agents: Landscape, Integrations, and Foundational Challenges",
    "url": "https://arxiv.org/abs/2508.02773",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.02773v2 Announce Type: replace \nAbstract: The convergence of Web3 technologies and AI agents represents a rapidly evolving frontier poised to reshape decentralized ecosystems. This paper presents the first and most comprehensive analysis of the intersection between Web3 and AI agents, examining five critical dimensions: landscape, economics, governance, security, and trust mechanisms. Through an analysis of 133 existing projects, we first develop a taxonomy and systematically map the current market landscape (RQ1), identifying distinct patterns in project distribution and capitalization. Building upon these findings, we further investigate four key integrations: (1) the role of AI agents in participating in and optimizing decentralized finance (RQ2); (2) their contribution to enhancing Web3 governance mechanisms (RQ3); (3) their capacity to strengthen Web3 security via intelligent vulnerability detection and automated smart contract auditing (RQ4); and (4) the establishment of robust reliability frameworks for AI agent operations leveraging Web3's inherent trust infrastructure (RQ5). By synthesizing these dimensions, we identify key integration patterns, highlight foundational challenges related to scalability, security, and ethics, and outline critical considerations for future research toward building robust, intelligent, and trustworthy decentralized systems with effective AI agent interactions.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Web3 x AI Agents: Landscape, Integrations, and Foundational Challenges\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "web",
      "x",
      "ai"
    ],
    "category": "noticia"
  },
  {
    "title": "Resource-Efficient Automatic Software Vulnerability Assessment via Knowledge Distillation and Particle Swarm Optimization",
    "title_es": "Resource-Efficient Automatic Software Vulnerability Assessment via Knowledge Distillation and Particle Swarm Optimization",
    "url": "https://arxiv.org/abs/2508.02840",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.02840v2 Announce Type: replace \nAbstract: The increasing complexity of software systems has led to a surge in cybersecurity vulnerabilities, necessitating efficient and scalable solutions for vulnerability assessment. However, the deployment of large pre-trained models in real-world scenarios is hindered by their substantial computational and storage demands. To address this challenge, we propose a novel resource-efficient framework that integrates knowledge distillation and particle swarm optimization to enable automated vulnerability assessment. Our framework employs a two-stage approach: First, particle swarm optimization is utilized to optimize the architecture of a compact student model, balancing computational efficiency and model capacity. Second, knowledge distillation is applied to transfer critical vulnerability assessment knowledge from a large teacher model to the optimized student model. This process significantly reduces the model size while maintaining high performance. Experimental results on an enhanced MegaVul dataset, comprising 12,071 CVSS (Common Vulnerability Scoring System) v3 annotated vulnerabilities, demonstrate the effectiveness of our approach. Our approach achieves a 99.4% reduction in model size while retaining 89.3% of the original model's accuracy. Furthermore, it outperforms state-of-the-art baselines by 1.7% in accuracy with 60% fewer parameters. The framework also reduces training time by 72.1% and architecture search time by 34.88% compared to traditional genetic algorithms.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Resource-Efficient Automatic Software Vulnerability Assessment via Knowledge Distillation and Particle Swarm Optimization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "resourceefficient",
      "automatic",
      "software"
    ],
    "category": "noticia"
  },
  {
    "title": "Modeling and Simulation of an Active Quarter Car Suspension with a Robust LQR Controller under Road Disturbance and Parameter Uncertainty",
    "title_es": "Modeling and Simulation of an Active Quarter Car Suspension with a Robust LQR Controller under Road Disturbance and Parameter Uncertainty",
    "url": "https://arxiv.org/abs/2508.02906",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.02906v2 Announce Type: replace \nAbstract: Vehicle suspension is important for passengers to travel comfortably and to be less exposed to effects such as vibration and shock. A good suspension system increases the road holding of vehicles, allows them to take turns safely, and reduces the risk of traffic accidents. A passive suspension system is the most widely used suspension system in vehicles due to its simple structure and low cost. Passive suspension systems do not have an actuator and therefore do not have a controller. Active suspension systems have an actuator and a controller. Although their structures are more complex and costly, they are safer. PID controller is widely used in active suspension systems due to its simple structure, reasonable cost, and easy adjustment of coefficients. In this study, a more robust LQR-controlled active suspension was designed than a passive suspension and a PID-controlled active suspension. Robustness analyses were performed for passive suspension, PID-controlled active suspension, and LQR-controlled active suspension. Suspension travel, sprung mass acceleration, and sprung mass motion simulations were performed for all 3 suspensions under road disturbance and under simultaneous road disturbance and parameter uncertainty. A comparative analysis was performed by obtaining the suspension rise time, overshoot, and settling time data. It was observed that the LQR-controlled active suspension showed the least overshoot and had the shortest settling time. In this case, it was proven that the LQR controlled active suspension provided a more comfortable and safe ride compared to the other two suspension systems.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Modeling and Simulation of an Active Quarter Car Suspension with a Robust LQR Controller under Road Disturbance and Parameter Uncertainty\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "modeling",
      "and",
      "simulation"
    ],
    "category": "noticia"
  },
  {
    "title": "Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching",
    "title_es": "Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching",
    "url": "https://arxiv.org/abs/2508.03068",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.03068v2 Announce Type: replace \nAbstract: We propose Hand-Eye Autonomous Delivery (HEAD), a framework that learns navigation, locomotion, and reaching skills for humanoids, directly from human motion and vision perception data. We take a modular approach where the high-level planner commands the target position and orientation of the hands and eyes of the humanoid, delivered by the low-level policy that controls the whole-body movements. Specifically, the low-level whole-body controller learns to track the three points (eyes, left hand, and right hand) from existing large-scale human motion capture data while high-level policy learns from human data collected by Aria glasses. Our modular approach decouples the ego-centric vision perception from physical actions, promoting efficient learning and scalability to novel scenes. We evaluate our method both in simulation and in the real-world, demonstrating humanoid's capabilities to navigate and reach in complex environments designed for humans.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "handeye",
      "autonomous",
      "delivery"
    ],
    "category": "noticia"
  },
  {
    "title": "HALO: Hindsight-Augmented Learning for Online Auto-Bidding",
    "title_es": "HALO: Hindsight-Augmented Learning for Online Auto-Bidding",
    "url": "https://arxiv.org/abs/2508.03267",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.03267v3 Announce Type: replace \nAbstract: Digital advertising platforms operate millisecond-level auctions through Real-Time Bidding (RTB) systems, where advertisers compete for ad impressions through algorithmic bids. This dynamic mechanism enables precise audience targeting but introduces profound operational complexity due to advertiser heterogeneity: budgets and ROI targets span orders of magnitude across advertisers, from individual merchants to multinational brands. This diversity creates a demanding adaptation landscape for Multi-Constraint Bidding (MCB). Traditional auto-bidding solutions fail in this environment due to two critical flaws: 1) severe sample inefficiency, where failed explorations under specific constraints yield no transferable knowledge for new budget-ROI combinations, and 2) limited generalization under constraint shifts, as they ignore physical relationships between constraints and bidding coefficients. To address this, we propose HALO: Hindsight-Augmented Learning for Online Auto-Bidding. HALO introduces a theoretically grounded hindsight mechanism that repurposes all explorations into training data for arbitrary constraint configuration via trajectory reorientation. Further, it employs B-spline functional representation, enabling continuous, derivative-aware bid mapping across constraint spaces. HALO ensures robust adaptation even when budget/ROI requirements differ drastically from training scenarios. Industrial dataset evaluations demonstrate the superiority of HALO in handling multi-scale constraints, reducing constraint violations while improving GMV.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"HALO: Hindsight-Augmented Learning for Online Auto-Bidding\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "halo",
      "hindsightaugmented",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "MagicGUI: A Foundational Mobile GUI Agent with Scalable Data Pipeline and Reinforcement Fine-tuning",
    "title_es": "MagicGUI: A Foundational Mobile GUI Agent with Scalable Data Pipeline and Reinforcement Fine-tuning",
    "url": "https://arxiv.org/abs/2508.03700",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.03700v2 Announce Type: replace \nAbstract: This paper presents MagicGUI, a foundational mobile GUI agent designed to address critical challenges in perception, grounding, and reasoning within real-world mobile GUI environments. The framework is underpinned by following six key components: (1) a comprehensive and accurate dataset, constructed via the scalable GUI Data Pipeline, which aggregates the largest and most diverse GUI-centric multimodal data to date from open-source repositories, automated crawling, and targeted manual annotation; (2) enhanced perception and grounding capabilities, facilitating fine-grained multimodal alignment for UI element referencing, grounding, and screen comprehension; (3) a comprehensive and unified action space, encompassing both fundamental UI operations and complex interactive intents to support human-agent interactions; (4) planning-oriented reasoning mechanisms that enable the model to decompose complex user instructions into sequential actions with explicit intermediate meta-paln reasoning; (5) an iterative two-stage training procedure, combining large-scale continue pre-training on 7.8M samples with reinforcement fine-tuning utilizing a spatially enhanced composite reward and dual filtering strategy; and (6) competitive performance on both the proprietary Magic-RICH benchmark and over a dozen public benchmarks, achieving superior performance across GUI perception and agent tasks, while demonstrating robust generalization and real-world deployment potential in practical mobile GUI scenarios, as detailed in Figure 1.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MagicGUI: A Foundational Mobile GUI Agent with Scalable Data Pipeline and Reinforcement Fine-tuning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "magicgui",
      "a",
      "foundational"
    ],
    "category": "noticia"
  },
  {
    "title": "What Do Agents Think Others Would Do? Level-2 Inverse Games for Inferring Agents' Estimates of Others' Objectives",
    "title_es": "What Do Agents Think Others Would Do? Level-2 Inverse Games for Inferring Agents' Estimates of Others' Objectives",
    "url": "https://arxiv.org/abs/2508.03824",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.03824v2 Announce Type: replace \nAbstract: Effectively interpreting strategic interactions among multiple agents requires us to infer each agent's objective from limited information. Existing inverse game-theoretic approaches frame this challenge in terms of a \"level-1\" inference problem, in which we take the perspective of a third-party observer and assume that individual agents share complete knowledge of one another's objectives. However, this assumption breaks down in decentralized, real-world decision scenarios like urban driving and bargaining, in which agents may act based on conflicting views of one another's objectives. We demonstrate the necessity of inferring agents' heterogeneous estimates of each other's objectives through empirical examples, and by theoretically characterizing the prediction error of level-1 inference on fictitious gameplay data from linear-quadratic games. To address this fundamental issue, we propose a framework for level-2 inference to address the question: \"What does each agent believe about all agents' objectives?\" We prove that the level-2 inference problem is non-convex even in benign settings like linear-quadratic games, and we develop an efficient gradient-based approach for identifying local solutions. Experiments on a synthetic urban driving example show that our approach uncovers nuanced misalignments that level-1 methods miss.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"What Do Agents Think Others Would Do? Level-2 Inverse Games for Inferring Agents' Estimates of Others' Objectives\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "what",
      "do",
      "agents"
    ],
    "category": "noticia"
  },
  {
    "title": "MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems",
    "title_es": "MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems",
    "url": "https://arxiv.org/abs/2508.03858",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.03858v2 Announce Type: replace \nAbstract: Agentic AI systems capable of reasoning, planning, and executing actions present fundamentally distinct governance challenges compared to traditional AI models. Unlike conventional AI, these systems exhibit emergent and unexpected behaviors during runtime, introducing novel agent-related risks that cannot be fully anticipated through pre-deployment governance alone. To address this critical gap, we introduce MI9, the first fully integrated runtime governance framework designed specifically for safety and alignment of agentic AI systems. MI9 introduces real-time controls through six integrated components: agency-risk index, agent-semantic telemetry capture, continuous authorization monitoring, Finite-State-Machine (FSM)-based conformance engines, goal-conditioned drift detection, and graduated containment strategies. Operating transparently across heterogeneous agent architectures, MI9 enables the systematic, safe, and responsible deployment of agentic systems in production environments where conventional governance approaches fall short, providing the foundational infrastructure for safe agentic AI deployment at scale. Detailed analysis through a diverse set of scenarios demonstrates MI9's systematic coverage of governance challenges that existing approaches fail to address, establishing the technical foundation for comprehensive agentic AI oversight.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mi",
      "",
      "agent"
    ],
    "category": "noticia"
  },
  {
    "title": "Intelligent Sampling of Extreme-Scale Turbulence Datasets for Accurate and Efficient Spatiotemporal Model Training",
    "title_es": "Intelligent Sampling of Extreme-Scale Turbulence Datasets for Accurate and Efficient Spatiotemporal Model Training",
    "url": "https://arxiv.org/abs/2508.03872",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.03872v2 Announce Type: replace \nAbstract: With the end of Moore's law and Dennard scaling, efficient training increasingly requires rethinking data volume. Can we train better models with significantly less data via intelligent subsampling? To explore this, we develop SICKLE, a sparse intelligent curation framework for efficient learning, featuring a novel maximum entropy (MaxEnt) sampling approach, scalable training, and energy benchmarking. We compare MaxEnt with random and phase-space sampling on large direct numerical simulation (DNS) datasets of turbulence. Evaluating SICKLE at scale on Frontier, we show that subsampling as a preprocessing step can improve model accuracy and substantially lower energy consumption, with reductions of up to 38x observed in certain cases.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Intelligent Sampling of Extreme-Scale Turbulence Datasets for Accurate and Efficient Spatiotemporal Model Training\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "intelligent",
      "sampling",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Uncertainty-aware Accurate Elevation Modeling for Off-road Navigation via Neural Processes",
    "title_es": "Uncertainty-aware Accurate Elevation Modeling for Off-road Navigation via Neural Processes",
    "url": "https://arxiv.org/abs/2508.03890",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.03890v2 Announce Type: replace \nAbstract: Terrain elevation modeling for off-road navigation aims to accurately estimate changes in terrain geometry in real-time and quantify the corresponding uncertainties. Having precise estimations and uncertainties plays a crucial role in planning and control algorithms to explore safe and reliable maneuver strategies. However, existing approaches, such as Gaussian Processes (GPs) and neural network-based methods, often fail to meet these needs. They are either unable to perform in real-time due to high computational demands, underestimating sharp geometry changes, or harming elevation accuracy when learned with uncertainties. Recently, Neural Processes (NPs) have emerged as a promising approach that integrates the Bayesian uncertainty estimation of GPs with the efficiency and flexibility of neural networks. Inspired by NPs, we propose an effective NP-based method that precisely estimates sharp elevation changes and quantifies the corresponding predictive uncertainty without losing elevation accuracy. Our method leverages semantic features from LiDAR and camera sensors to improve interpolation and extrapolation accuracy in unobserved regions. Also, we introduce a local ball-query attention mechanism to effectively reduce the computational complexity of global attention by 17\\% while preserving crucial local and spatial information. We evaluate our method on off-road datasets having interesting geometric features, collected from trails, deserts, and hills. Our results demonstrate superior performance over baselines and showcase the potential of neural processes for effective and expressive terrain modeling in complex off-road environments.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Uncertainty-aware Accurate Elevation Modeling for Off-road Navigation via Neural Processes\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "uncertaintyaware",
      "accurate",
      "elevation"
    ],
    "category": "noticia"
  },
  {
    "title": "Confidence Driven Classification of Application Types in the Presence of Background Network",
    "title_es": "Confidence Driven Classification of Application Types in the Presence of Background Network",
    "url": "https://arxiv.org/abs/2508.03891",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.03891v2 Announce Type: replace \nAbstract: Accurately classifying the application types of network traffic using deep learning models has recently gained popularity. However, we find that these classifiers do not perform well on real-world traffic data due to the presence of non-application-specific generic background traffic originating from advertisements, analytics, shared APIs, and trackers. Unfortunately, state-of-the-art application classifiers overlook such traffic in curated datasets and only classify relevant application traffic. To address this issue, when we label and train using an additional class for background traffic, it leads to additional confusion between application and background traffic, as the latter is heterogeneous and encompasses all traffic that is not relevant to the application sessions. To avoid falsely classifying background traffic as one of the relevant application types, a reliable confidence measure is warranted, such that we can refrain from classifying uncertain samples. Therefore, we design a Gaussian Mixture Model-based classification framework that improves the indication of the deep learning classifier's confidence to allow more reliable classification.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Confidence Driven Classification of Application Types in the Presence of Background Network\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "confidence",
      "driven",
      "classification"
    ],
    "category": "noticia"
  },
  {
    "title": "CoAct-1: Computer-using Agents with Coding as Actions",
    "title_es": "CoAct-1: Computer-using Agents with Coding as Actions",
    "url": "https://arxiv.org/abs/2508.03923",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.03923v2 Announce Type: replace \nAbstract: Autonomous agents that operate computers via Graphical User Interfaces (GUIs) often struggle with efficiency and reliability on complex, long-horizon tasks. While augmenting these agents with planners can improve task decomposition, they remain constrained by the inherent limitations of performing all actions through GUI manipulation, leading to brittleness and inefficiency. In this work, we introduce a more robust and flexible paradigm: enabling agents to use coding as a enhanced action. We present CoAct-1, a novel multi-agent system that synergistically combines GUI-based control with direct programmatic execution. CoAct-1 features an Orchestrator that dynamically delegates subtasks to either a conventional GUI Operator or a specialized Programmer agent, which can write and execute Python or Bash scripts. This hybrid approach allows the agent to bypass inefficient GUI action sequences for tasks like file management and data processing, while still leveraging visual interaction when necessary. We evaluate our system on the challenging OSWorld benchmark, where CoAct-1 achieves a new state-of-the-art success rate of 60.76%, significantly outperforming prior methods. Furthermore, our approach dramatically improves efficiency, reducing the average number of steps required to complete a task to just 10.15, compared to 15 for leading GUI agents. Our results demonstrate that integrating coding as a core action provides a more powerful, efficient, and scalable path toward generalized computer automation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CoAct-1: Computer-using Agents with Coding as Actions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "coact",
      "computerusing",
      "agents"
    ],
    "category": "noticia"
  },
  {
    "title": "Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?",
    "title_es": "Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?",
    "url": "https://arxiv.org/abs/2508.03963",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.03963v2 Announce Type: replace \nAbstract: Uncovering hidden symbolic laws from time series data, as an aspiration dating back to Kepler's discovery of planetary motion, remains a core challenge in scientific discovery and artificial intelligence. While Large Language Models show promise in structured reasoning tasks, their ability to infer interpretable, context-aligned symbolic structures from time series data is still underexplored. To systematically evaluate this capability, we introduce SymbolBench, a comprehensive benchmark designed to assess symbolic reasoning over real-world time series across three tasks: multivariate symbolic regression, Boolean network inference, and causal discovery. Unlike prior efforts limited to simple algebraic equations, SymbolBench spans a diverse set of symbolic forms with varying complexity. We further propose a unified framework that integrates LLMs with genetic programming to form a closed-loop symbolic reasoning system, where LLMs act both as predictors and evaluators. Our empirical results reveal key strengths and limitations of current models, highlighting the importance of combining domain knowledge, context alignment, and reasoning structure to improve LLMs in automated scientific discovery.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "can",
      "large",
      "language"
    ],
    "category": "noticia"
  },
  {
    "title": "High-Performance and Power-Efficient Emulation of Matrix Multiplication using INT8 Matrix Engines",
    "title_es": "High-Performance and Power-Efficient Emulation of Matrix Multiplication using INT8 Matrix Engines",
    "url": "https://arxiv.org/abs/2508.03984",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.03984v2 Announce Type: replace \nAbstract: Recent architectures integrate high-performance and power-efficient matrix engines. These engines demonstrate remarkable performance in low-precision matrix multiplication, which is crucial in deep learning. Several techniques have been proposed to emulate single- and double-precision general matrix-matrix multiplication (SGEMM and DGEMM, respectively) by leveraging such low-precision matrix engines. In this study, we present emulation methods that significantly outperforms conventional approaches. On a GH200 Grace Hopper Superchip, the proposed DGEMM emulation achieves a 1.4x speedup and a 43% improvement in power efficiency compared to native DGEMM for sufficiently large problems. The proposed SGEMM emulation achieves a 3.0x speedup and a 154% improvement in power efficiency compared to native SGEMM for sufficiently large problems. Furthermore, compared to conventional emulation methods, the proposed emulation achieves more than 2x higher performance and superior power efficiency.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"High-Performance and Power-Efficient Emulation of Matrix Multiplication using INT8 Matrix Engines\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "highperformance",
      "and",
      "powerefficient"
    ],
    "category": "noticia"
  },
  {
    "title": "Monolithic Multi-level Overlapping Schwarz Solvers for Fluid Problems",
    "title_es": "Monolithic Multi-level Overlapping Schwarz Solvers for Fluid Problems",
    "url": "https://arxiv.org/abs/2508.04356",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.04356v2 Announce Type: replace \nAbstract: Additive overlapping Schwarz Methods are iterative methods of the domain decomposition type for the solution of partial differential equations. Numerical and parallel scalability of these methods can be achieved by adding coarse levels. A successful coarse space, inspired by iterative substructuring, is the generalized Dryja-Smith-Widlund (GDSW) space. In https://doi.org/10.1137/18M1184047, based on the GDSW approach, two-level monolithic overlapping Schwarz preconditioners for saddle point problems were introduced. We present parallel results up to 32768 MPI ranks for the solution of incompressible fluid problems for a Poiseuille flow example on the unit cube and a complex extrusion die geometry using a two- and a three-level monolithic overlapping Schwarz preconditioner. These results are achieved through the combination of the additive overlapping Schwarz solvers implemented in the Fast and Robust Overlapping Schwarz (FROSch) library https://doi.org/10.1007/978-3-030-56750-7_19, which is part of the Trilinos package ShyLU https://doi.org/10.1109/IPDPS.2012.64, and the FEATFLOW library http://www.featflow.de using a scalable interface for the efficient coupling of the two libraries. This work is part of the project StroemungsRaum - Novel Exascale-Architectures with Heterogeneous Hardware Components for Computational Fluid Dynamics Simulations, funded by the German Bundesministerium fur Forschung, Technologie und Raumfahrt BMFTR (formerly BMBF) as part of the program on New Methods and Technologies for Exascale Computing (SCALEXA).",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Monolithic Multi-level Overlapping Schwarz Solvers for Fluid Problems\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "monolithic",
      "multilevel",
      "overlapping"
    ],
    "category": "noticia"
  },
  {
    "title": "Measuring Information Richness in Product Images: Implications for Online Sales",
    "title_es": "Measuring Information Richness in Product Images: Implications for Online Sales",
    "url": "https://arxiv.org/abs/2508.04541",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.04541v2 Announce Type: replace \nAbstract: A common challenge for e-commerce sellers is to decide what product images to display on online shopping sites. In this paper, we propose and validate a novel metric, k-value, to quantify the information richness of an image set, and we further investigate its effect on consumers' purchase decisions. We leverage patch-level embeddings from Vision Transformers (ViT) and apply k-means clustering to identify distinct visual features, defining k-value as the number of clusters. An online experiment demonstrates that k-value aligns with human-perceived information richness, validating the metric. A simulated online shopping experiment further reveals a significant yet counterintuitive result: while an image set with a higher k-value (richer information) shortens decision time, it paradoxically reduces purchase propensity. Our findings illuminate the complex relationship between visual information richness and consumer behavior, providing sellers a quantifiable tool for image selection.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Measuring Information Richness in Product Images: Implications for Online Sales\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "measuring",
      "information",
      "richness"
    ],
    "category": "noticia"
  },
  {
    "title": "TurboTrain: Towards Efficient and Balanced Multi-Task Learning for Multi-Agent Perception and Prediction",
    "title_es": "TurboTrain: Towards Efficient and Balanced Multi-Task Learning for Multi-Agent Perception and Prediction",
    "url": "https://arxiv.org/abs/2508.04682",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.04682v2 Announce Type: replace \nAbstract: End-to-end training of multi-agent systems offers significant advantages in improving multi-task performance. However, training such models remains challenging and requires extensive manual design and monitoring. In this work, we introduce TurboTrain, a novel and efficient training framework for multi-agent perception and prediction. TurboTrain comprises two key components: a multi-agent spatiotemporal pretraining scheme based on masked reconstruction learning and a balanced multi-task learning strategy based on gradient conflict suppression. By streamlining the training process, our framework eliminates the need for manually designing and tuning complex multi-stage training pipelines, substantially reducing training time and improving performance. We evaluate TurboTrain on a real-world cooperative driving dataset, V2XPnP-Seq, and demonstrate that it further improves the performance of state-of-the-art multi-agent perception and prediction models. Our results highlight that pretraining effectively captures spatiotemporal multi-agent features and significantly benefits downstream tasks. Moreover, the proposed balanced multi-task learning strategy enhances detection and prediction.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"TurboTrain: Towards Efficient and Balanced Multi-Task Learning for Multi-Agent Perception and Prediction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "turbotrain",
      "towards",
      "efficient"
    ],
    "category": "noticia"
  },
  {
    "title": "Federated Continual Recommendation",
    "title_es": "Federated Continual Recommendation",
    "url": "https://arxiv.org/abs/2508.04792",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.04792v2 Announce Type: replace \nAbstract: The increasing emphasis on privacy in recommendation systems has led to the adoption of Federated Learning (FL) as a privacy-preserving solution, enabling collaborative training without sharing user data. While Federated Recommendation (FedRec) effectively protects privacy, existing methods struggle with non-stationary data streams, failing to maintain consistent recommendation quality over time. On the other hand, Continual Learning Recommendation (CLRec) methods address evolving user preferences but typically assume centralized data access, making them incompatible with FL constraints. To bridge this gap, we introduce Federated Continual Recommendation (FCRec), a novel task that integrates FedRec and CLRec, requiring models to learn from streaming data while preserving privacy. As a solution, we propose F3CRec, a framework designed to balance knowledge retention and adaptation under the strict constraints of FCRec. F3CRec introduces two key components: Adaptive Replay Memory on the client side, which selectively retains past preferences based on user-specific shifts, and Item-wise Temporal Mean on the server side, which integrates new knowledge while preserving prior information. Extensive experiments demonstrate that F3CRec outperforms existing approaches in maintaining recommendation quality over time in a federated environment.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Federated Continual Recommendation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "federated",
      "continual",
      "recommendation"
    ],
    "category": "noticia"
  },
  {
    "title": "RetinexDual: Retinex-based Dual Nature Approach for Generalized Ultra-High-Definition Image Restoration",
    "title_es": "RetinexDual: Retinex-based Dual Nature Approach for Generalized Ultra-High-Definition Image Restoration",
    "url": "https://arxiv.org/abs/2508.04797",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.04797v2 Announce Type: replace \nAbstract: Advancements in image sensing have elevated the importance of Ultra-High-Definition Image Restoration (UHD IR). Traditional methods, such as extreme downsampling or transformation from the spatial to the frequency domain, encounter significant drawbacks: downsampling induces irreversible information loss in UHD images, while our frequency analysis reveals that pure frequency-domain approaches are ineffective for spatially confined image artifacts, primarily due to the loss of degradation locality. To overcome these limitations, we present RetinexDual, a novel Retinex theory-based framework designed for generalized UHD IR tasks. RetinexDual leverages two complementary sub-networks: the Scale-Attentive maMBA (SAMBA) and the Frequency Illumination Adaptor (FIA). SAMBA, responsible for correcting the reflectance component, utilizes a coarse-to-fine mechanism to overcome the causal modeling of mamba, which effectively reduces artifacts and restores intricate details. On the other hand, FIA ensures precise correction of color and illumination distortions by operating in the frequency domain and leveraging the global context provided by it. Evaluating RetinexDual on four UHD IR tasks, namely deraining, deblurring, dehazing, and Low-Light Image Enhancement (LLIE), shows that it outperforms recent methods qualitatively and quantitatively. Ablation studies demonstrate the importance of employing distinct designs for each branch in RetinexDual, as well as the effectiveness of its various components.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"RetinexDual: Retinex-based Dual Nature Approach for Generalized Ultra-High-Definition Image Restoration\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "retinexdual",
      "retinexbased",
      "dual"
    ],
    "category": "noticia"
  },
  {
    "title": "Learning AI Auditing: A Case Study of Teenagers Auditing a Generative AI Model",
    "title_es": "Learning AI Auditing: A Case Study of Teenagers Auditing a Generative AI Model",
    "url": "https://arxiv.org/abs/2508.04902",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.04902v2 Announce Type: replace \nAbstract: This study investigates how high school-aged youth engage in algorithm auditing to identify and understand biases in artificial intelligence and machine learning (AI/ML) tools they encounter daily. With AI/ML technologies being increasingly integrated into young people's lives, there is an urgent need to equip teenagers with AI literacies that build both technical knowledge and awareness of social impacts. Algorithm audits (also called AI audits) have traditionally been employed by experts to assess potential harmful biases, but recent research suggests that non-expert users can also participate productively in auditing. We conducted a two-week participatory design workshop with 14 teenagers (ages 14-15), where they audited the generative AI model behind TikTok's Effect House, a tool for creating interactive TikTok filters. We present a case study describing how teenagers approached the audit, from deciding what to audit to analyzing data using diverse strategies and communicating their results. Our findings show that participants were engaged and creative throughout the activities, independently raising and exploring new considerations, such as age-related biases, that are uncommon in professional audits. We drew on our expertise in algorithm auditing to triangulate their findings as a way to examine if the workshop supported participants to reach coherent conclusions in their audit. Although the resulting number of changes in race, gender, and age representation uncovered by the teens were slightly different from ours, we reached similar conclusions. This study highlights the potential for auditing to inspire learning activities to foster AI literacies, empower teenagers to critically examine AI systems, and contribute fresh perspectives to the study of algorithmic harms.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Learning AI Auditing: A Case Study of Teenagers Auditing a Generative AI Model\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "learning",
      "ai",
      "auditing"
    ],
    "category": "noticia"
  },
  {
    "title": "Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens",
    "title_es": "Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens",
    "url": "https://arxiv.org/abs/2508.04928",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.04928v2 Announce Type: replace \nAbstract: We propose a method to extend foundational monocular depth estimators (FMDEs), trained on perspective images, to fisheye images. Despite being trained on tens of millions of images, FMDEs are susceptible to the covariate shift introduced by changes in camera calibration (intrinsic, distortion) parameters, leading to erroneous depth estimates. Our method aligns the distribution of latent embeddings encoding fisheye images to those of perspective images, enabling the reuse of FMDEs for fisheye cameras without retraining or finetuning. To this end, we introduce a set of Calibration Tokens as a light-weight adaptation mechanism that modulates the latent embeddings for alignment. By exploiting the already expressive latent space of FMDEs, we posit that modulating their embeddings avoids the negative impact of artifacts and loss introduced in conventional recalibration or map projection to a canonical reference frame in the image space. Our method is self-supervised and does not require fisheye images but leverages publicly available large-scale perspective image datasets. This is done by recalibrating perspective images to fisheye images, and enforcing consistency between their estimates during training. We evaluate our approach with several FMDEs, on both indoors and outdoors, where we consistently improve over state-of-the-art methods using a single set of tokens for both. Code available at: https://github.com/JungHeeKim29/calibration-token.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "extending",
      "foundational",
      "monocular"
    ],
    "category": "noticia"
  },
  {
    "title": "The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein-Ligand Binding",
    "title_es": "The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein-Ligand Binding",
    "url": "https://arxiv.org/abs/2508.05006",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05006v2 Announce Type: replace \nAbstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the binding interactions between small-molecule ligands and protein pockets. However, current multi-task learning models for docking often show inferior performance in ligand docking compared to protein pocket docking. This disparity arises largely due to the distinct structural complexities of ligands and proteins. To address this issue, we propose a novel game-theoretic framework that models the protein-ligand interaction as a two-player game called the Docking Game, with the ligand docking module acting as the ligand player and the protein pocket docking module as the protein player. To solve this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which alternately trains these players through a two-level loop. In the outer loop, the players exchange predicted poses, allowing each to incorporate the other's structural predictions, which fosters mutual adaptation over multiple iterations. In the inner loop, each player dynamically refines its predictions by incorporating its own predicted ligand or pocket poses back into its model. We theoretically show the convergence of LoopPlay, ensuring stable optimization. Extensive experiments conducted on public benchmark datasets demonstrate that LoopPlay achieves approximately a 10\\% improvement in predicting accurate binding modes compared to previous state-of-the-art methods. This highlights its potential to enhance the accuracy of molecular docking in drug discovery.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein-Ligand Binding\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "docking",
      "game"
    ],
    "category": "noticia"
  },
  {
    "title": "Evaluation of LLMs in AMR Parsing",
    "title_es": "Evaluation of LLMs in AMR Parsing",
    "url": "https://arxiv.org/abs/2508.05028",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05028v2 Announce Type: replace \nAbstract: AMR (Abstract Meaning Representation) is a semantic formalism that encodes sentence meaning as rooted, directed, acyclic graphs, where nodes represent concepts and edges denote semantic relations. Finetuning decoder only Large Language Models (LLMs) represent a promising novel straightfoward direction for AMR parsing. This paper presents a comprehensive evaluation of finetuning four distinct LLM architectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled using the LDC2020T02 Gold AMR3.0 test set. Our results have shown that straightfoward finetuning of decoder only LLMs can achieve comparable performance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2 demonstrates competitive performance against SOTA AMR parsers given a straightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full LDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching Graphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a consistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5 excels in structural validity.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Evaluation of LLMs in AMR Parsing\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "evaluation",
      "of",
      "llms"
    ],
    "category": "noticia"
  },
  {
    "title": "An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack",
    "title_es": "An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack",
    "url": "https://arxiv.org/abs/2508.05034",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05034v2 Announce Type: replace \nAbstract: As software systems grow in complexity, accurately identifying and managing dependencies among changes becomes increasingly critical. For instance, a change that leverages a function must depend on the change that introduces it. Establishing such dependencies allows CI/CD pipelines to build and orchestrate changes effectively, preventing build failures and incomplete feature deployments. In modern software systems, dependencies often span multiple components across teams, creating challenges for development and deployment. They serve various purposes, from enabling new features to managing configurations, and can even involve traditionally independent changes like documentation updates. To address these challenges, we conducted a preliminary study on dependency management in OpenStack, a large-scale software system. Our study revealed that a substantial portion of software changes in OpenStack over the past 10 years are interdependent. Surprisingly, 51.08% of these dependencies are identified during the code review phase-after a median delay of 5.06 hours-rather than at the time of change creation. Developers often spend a median of 57.12 hours identifying dependencies, searching among a median of 463 other changes. To help developers proactively identify dependencies, we propose a semi-automated approach that leverages two ML models. The first model predicts the likelihood of dependencies among changes, while the second identifies the exact pairs of dependent changes. Our proposed models demonstrate strong performance, achieving average AUC scores of 79.33% and 91.89%, and Brier scores of 0.11 and 0.014, respectively. Indeed, the second model has a good top-k recall across all types of pairs, while the top-k precision has room for improvement.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "an",
      "mlbased",
      "approach"
    ],
    "category": "noticia"
  },
  {
    "title": "Exploring Superior Function Calls via Reinforcement Learning",
    "title_es": "Exploring Superior Function Calls via Reinforcement Learning",
    "url": "https://arxiv.org/abs/2508.05118",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05118v2 Announce Type: replace \nAbstract: Function calling capabilities are crucial for deploying Large Language Models in real-world applications, yet current training approaches fail to develop robust reasoning strategies. Supervised fine-tuning produces models that rely on superficial pattern matching, while standard reinforcement learning methods struggle with the complex action space of structured function calls. We present a novel reinforcement learning framework designed to enhance group relative policy optimization through strategic entropy based exploration specifically tailored for function calling tasks. Our approach addresses three critical challenges in function calling: insufficient exploration during policy learning, lack of structured reasoning in chain-of-thought generation, and inadequate verification of parameter extraction. Our two-stage data preparation pipeline ensures high-quality training samples through iterative LLM evaluation and abstract syntax tree validation. Extensive experiments on the Berkeley Function Calling Leaderboard demonstrate that this framework achieves state-of-the-art performance among open-source models with 86.02\\% overall accuracy, outperforming standard GRPO by up to 6\\% on complex multi-function scenarios. Notably, our method shows particularly strong improvements on code-pretrained models, suggesting that structured language generation capabilities provide an advantageous starting point for reinforcement learning in function calling tasks. We will release all the code, models and dataset to benefit the community.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Exploring Superior Function Calls via Reinforcement Learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "exploring",
      "superior",
      "function"
    ],
    "category": "noticia"
  },
  {
    "title": "SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation",
    "title_es": "SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation",
    "url": "https://arxiv.org/abs/2508.05182",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05182v2 Announce Type: replace \nAbstract: Domain Adaptation (DA) aims to transfer knowledge from a labeled source domain to an unlabeled or sparsely labeled target domain under domain shifts. Most prior works focus on capturing the inter-domain transferability but largely overlook rich intra-domain structures, which empirically results in even worse discriminability. To tackle this tradeoff, we propose a generalized graph SPectral Alignment framework, SPA++. Its core is briefly condensed as follows: (1)-by casting the DA problem to graph primitives, it composes a coarse graph alignment mechanism with a novel spectral regularizer toward aligning the domain graphs in eigenspaces; (2)-we further develop a fine-grained neighbor-aware propagation mechanism for enhanced discriminability in the target domain; (3)-by incorporating data augmentation and consistency regularization, SPA++ can adapt to complex scenarios including most DA settings and even challenging distribution scenarios. Furthermore, we also provide theoretical analysis to support our method, including the generalization bound of graph-based DA and the role of spectral alignment and smoothing consistency. Extensive experiments on benchmark datasets demonstrate that SPA++ consistently outperforms existing cutting-edge methods, achieving superior robustness and adaptability across various challenging adaptation scenarios.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "spa",
      "generalized",
      "graph"
    ],
    "category": "noticia"
  },
  {
    "title": "A Study of Gender Classification Techniques Based on Iris Images: A Deep Survey and Analysis",
    "title_es": "A Study of Gender Classification Techniques Based on Iris Images: A Deep Survey and Analysis",
    "url": "https://arxiv.org/abs/2508.05246",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05246v2 Announce Type: replace \nAbstract: Gender classification is attractive in a range of applications, including surveillance and monitoring, corporate profiling, and human-computer interaction. Individuals' identities may be gleaned from information about their gender, which is a kind of soft biometric. Over the years, several methods for determining a person's gender have been devised. Some of the most well-known ones are based on physical characteristics like face, fingerprint, palmprint, DNA, ears, gait, and iris. On the other hand, facial features account for the vast majority of gender classification methods. Also, the iris is a significant biometric trait because the iris, according to research, remains basically constant during an individual's life. Besides that, the iris is externally visible and is non-invasive to the user, which is important for practical applications. Furthermore, there are already high-quality methods for segmenting and encoding iris images, and the current methods facilitate selecting and extracting attribute vectors from iris textures. This study discusses several approaches to determining gender. The previous works of literature are briefly reviewed. Additionally, there are a variety of methodologies for different steps of gender classification. This study provides researchers with knowledge and analysis of the existing gender classification approaches. Also, it will assist researchers who are interested in this specific area, as well as highlight the gaps and challenges in the field, and finally provide suggestions and future paths for improvement.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Study of Gender Classification Techniques Based on Iris Images: A Deep Survey and Analysis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "study",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "CF3: Compact and Fast 3D Feature Fields",
    "title_es": "CF3: Compact and Fast 3D Feature Fields",
    "url": "https://arxiv.org/abs/2508.05254",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05254v2 Announce Type: replace \nAbstract: 3D Gaussian Splatting (3DGS) has begun incorporating rich information from 2D foundation models. However, most approaches rely on a bottom-up optimization process that treats raw 2D features as ground truth, incurring increased computational costs. We propose a top-down pipeline for constructing compact and fast 3D Gaussian feature fields, namely, CF3. We first perform a fast weighted fusion of multi-view 2D features with pre-trained Gaussians. This approach enables training a per-Gaussian autoencoder directly on the lifted features, instead of training autoencoders in the 2D domain. As a result, the autoencoder better aligns with the feature distribution. More importantly, we introduce an adaptive sparsification method that optimizes the Gaussian attributes of the feature field while pruning and merging the redundant Gaussians, constructing an efficient representation with preserved geometric details. Our approach achieves a competitive 3D feature field using as little as 5% of the Gaussians compared to Feature-3DGS.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CF3: Compact and Fast 3D Feature Fields\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cf",
      "compact",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "GhostShell: Streaming LLM Function Calls for Concurrent Embodied Programming",
    "title_es": "GhostShell: Streaming LLM Function Calls for Concurrent Embodied Programming",
    "url": "https://arxiv.org/abs/2508.05298",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05298v2 Announce Type: replace \nAbstract: We present GhostShell, a novel approach that leverages Large Language Models (LLMs) to enable streaming and concurrent behavioral programming for embodied systems. In contrast to conventional methods that rely on pre-scheduled action sequences or behavior trees, GhostShell drives embodied systems to act on-the-fly by issuing function calls incrementally as tokens are streamed from the LLM. GhostShell features a streaming XML function token parser, a dynamic function interface mapper, and a multi-channel scheduler that orchestrates intra-channel synchronous and inter-channel asynchronous function calls, thereby coordinating serial-parallel embodied actions across multiple robotic components under LLM guidance. We evaluate GhostShell on our robotic prototype COCO through comprehensive grounded experiments across 34 real-world interaction tasks and multiple LLM backends. The results demonstrate that our approach achieves a state-of-the-art Behavioral Correctness Metric of 0.85 with Claude-4-Sonnet, and up to 66X faster response times compared to native LLM function calling APIs. GhostShell also proves effective in long-horizon multimodal tasks, exhibiting strong robustness and generalization capabilities.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"GhostShell: Streaming LLM Function Calls for Concurrent Embodied Programming\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ghostshell",
      "streaming",
      "llm"
    ],
    "category": "noticia"
  },
  {
    "title": "MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints",
    "title_es": "MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints",
    "url": "https://arxiv.org/abs/2508.05429",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05429v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) often exhibit cultural biases due to training data dominated by high-resource languages like English and Chinese. This poses challenges for accurately representing and evaluating diverse cultural contexts, particularly in low-resource language settings. To address this, we introduce MyCulture, a benchmark designed to comprehensively evaluate LLMs on Malaysian culture across six pillars: arts, attire, customs, entertainment, food, and religion presented in Bahasa Melayu. Unlike conventional benchmarks, MyCulture employs a novel open-ended multiple-choice question format without predefined options, thereby reducing guessing and mitigating format bias. We provide a theoretical justification for the effectiveness of this open-ended structure in improving both fairness and discriminative power. Furthermore, we analyze structural bias by comparing model performance on structured versus free-form outputs, and assess language bias through multilingual prompt variations. Our evaluation across a range of regional and international LLMs reveals significant disparities in cultural comprehension, highlighting the urgent need for culturally grounded and linguistically inclusive benchmarks in the development and assessment of LLMs.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "myculture",
      "exploring",
      "malaysias"
    ],
    "category": "noticia"
  },
  {
    "title": "Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?",
    "title_es": "Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?",
    "url": "https://arxiv.org/abs/2508.05464",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05464v2 Announce Type: replace \nAbstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust evaluation frameworks, especially with emerging regulations like the EU AI Act and its associated Code of Practice (CoP). Current AI evaluation practices depend heavily on established benchmarks, but these tools were not designed to measure the systemic risks that are the focus of the new regulatory landscape. This research addresses the urgent need to quantify this \"benchmark-regulation gap.\" We introduce Bench-2-CoP, a novel, systematic framework that uses validated LLM-as-judge analysis to map the coverage of 194,955 questions from widely-used benchmarks against the EU AI Act's taxonomy of model capabilities and propensities. Our findings reveal a profound misalignment: the evaluation ecosystem dedicates the vast majority of its focus to a narrow set of behavioral propensities. On average, benchmarks devote 61.6% of their regulatory-relevant questions to \"Tendency to hallucinate\" and 31.2% to \"Lack of performance reliability\", while critical functional capabilities are dangerously neglected. Crucially, capabilities central to loss-of-control scenarios, including evading human oversight, self-replication, and autonomous AI development, receive zero coverage in the entire benchmark corpus. This study provides the first comprehensive, quantitative analysis of this gap, demonstrating that current public benchmarks are insufficient, on their own, for providing the evidence of comprehensive risk assessment required for regulatory compliance and offering critical insights for the development of next-generation evaluation tools.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "benchcop",
      "can",
      "we"
    ],
    "category": "noticia"
  },
  {
    "title": "X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment",
    "title_es": "X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment",
    "url": "https://arxiv.org/abs/2508.05568",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05568v2 Announce Type: replace \nAbstract: Vertical Federated Learning (VFL) enables collaborative learning by integrating disjoint feature subsets from multiple clients/parties. However, VFL typically faces two key challenges: i) the requirement for perfectly aligned data samples across all clients (missing features are not allowed); ii) the requirement for joint collaborative inference/prediction involving all clients (it does not support locally independent inference on a single client). To address these challenges, we propose X-VFL, a new VFL framework designed to deal with the non-aligned data samples with (partially) missing features and to support locally independent inference of new data samples for each client. In particular, we design two novel modules in X-VFL: Cross Completion (XCom) and Decision Subspace Alignment (DS-Align). XCom can complete/reconstruct missing features for non-aligned data samples by leveraging information from other clients. DS-Align aligns local features with completed and global features across all clients within the decision subspace, thus enabling locally independent inference at each client. Moreover, we provide convergence theorems for different algorithms used in training X-VFL, showing an $O(1/\\sqrt{T})$ convergence rate for SGD-type algorithms and an $O(1/T)$ rate for PAGE-type algorithms, where $T$ denotes the number of training update steps. Extensive experiments on real-world datasets demonstrate that X-VFL significantly outperforms existing methods, e.g., achieving a 15% improvement in accuracy on the image CIFAR-10 dataset and a 43% improvement on the medical MIMIC-III dataset. These results validate the practical effectiveness and superiority of X-VFL, particularly in scenarios involving partially missing features and locally independent inference.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "xvfl",
      "a",
      "new"
    ],
    "category": "noticia"
  },
  {
    "title": "MESAHA-Net: Multi-Encoders based Self-Adaptive Hard Attention Network with Maximum Intensity Projections for Lung Nodule Segmentation in CT Scan",
    "title_es": "MESAHA-Net: Multi-Encoders based Self-Adaptive Hard Attention Network with Maximum Intensity Projections for Lung Nodule Segmentation in CT Scan",
    "url": "https://arxiv.org/abs/2304.01576",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2304.01576v2 Announce Type: replace-cross \nAbstract: Accurate lung nodule segmentation is crucial for early-stage lung cancer diagnosis, as it can substantially enhance patient survival rates. Computed tomography (CT) images are widely employed for early diagnosis in lung nodule analysis. However, the heterogeneity of lung nodules, size diversity, and the complexity of the surrounding environment pose challenges for developing robust nodule segmentation methods. In this study, we propose an efficient end-to-end framework, the multi-encoder-based self-adaptive hard attention network (MESAHA-Net), for precise lung nodule segmentation in CT scans. MESAHA-Net comprises three encoding paths, an attention block, and a decoder block, facilitating the integration of three types of inputs: CT slice patches, forward and backward maximum intensity projection (MIP) images, and region of interest (ROI) masks encompassing the nodule. By employing a novel adaptive hard attention mechanism, MESAHA-Net iteratively performs slice-by-slice 2D segmentation of lung nodules, focusing on the nodule region in each slice to generate 3D volumetric segmentation of lung nodules. The proposed framework has been comprehensively evaluated on the LIDC-IDRI dataset, the largest publicly available dataset for lung nodule segmentation. The results demonstrate that our approach is highly robust for various lung nodule types, outperforming previous state-of-the-art techniques in terms of segmentation accuracy and computational complexity, rendering it suitable for real-time clinical implementation.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MESAHA-Net: Multi-Encoders based Self-Adaptive Hard Attention Network with Maximum Intensity Projections for Lung Nodule Segmentation in CT Scan\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mesahanet",
      "multiencoders",
      "based"
    ],
    "category": "noticia"
  },
  {
    "title": "Integrating large language models and active inference to understand eye movements in reading and dyslexia",
    "title_es": "Integrating large language models and active inference to understand eye movements in reading and dyslexia",
    "url": "https://arxiv.org/abs/2308.04941",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2308.04941v3 Announce Type: replace-cross \nAbstract: We present a novel computational model employing hierarchical active inference to simulate reading and eye movements. The model characterizes linguistic processing as inference over a hierarchical generative model, facilitating predictions and inferences at various levels of granularity, from syllables to sentences. Our approach combines the strengths of large language models for realistic textual predictions and active inference for guiding eye movements to informative textual information, enabling the testing of predictions. The model exhibits proficiency in reading both known and unknown words and sentences, adhering to the distinction between lexical and nonlexical routes in dual route theories of reading. Our model therefore provides a novel approach to understand the cognitive processes underlying reading and eye movements, within a predictive processing framework. Furthermore, our model can potentially aid in understanding how maladaptive predictive processing can produce reading deficits associated with dyslexia. As a proof of concept, we show that attenuating the contribution of priors during the reading process leads to incorrect inferences and a more fragmented reading style, characterized by a greater number of shorter saccades, aligning with empirical findings regarding eye movements in dyslexic individuals. In summary, our model represents a significant advancement in comprehending the cognitive processes involved in reading and eye movements, with potential implications for understanding dyslexia in terms of maladaptive inference.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Integrating large language models and active inference to understand eye movements in reading and dyslexia\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "integrating",
      "large",
      "language"
    ],
    "category": "noticia"
  },
  {
    "title": "Generalization Bound for Diffusion Models using Random Features",
    "title_es": "Generalization Bound for Diffusion Models using Random Features",
    "url": "https://arxiv.org/abs/2310.04417",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2310.04417v3 Announce Type: replace-cross \nAbstract: Diffusion probabilistic models have been successfully used to generate data from noise. However, most diffusion models are computationally expensive and difficult to interpret with a lack of theoretical justification. Random feature models on the other hand have gained popularity due to their interpretability but their application to complex machine learning tasks remains limited. In this work, we present a diffusion model-inspired deep random feature model that is interpretable and gives comparable numerical results to a fully connected neural network having the same number of trainable parameters. Specifically, we extend existing results for random features and derive generalization bounds between the distribution of sampled data and the true distribution using properties of score matching. We validate our findings by generating samples on the fashion MNIST dataset and instrumental audio data.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Generalization Bound for Diffusion Models using Random Features\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "generalization",
      "bound",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "A dataset of primary nasopharyngeal carcinoma MRI with multi-modalities segmentation",
    "title_es": "A dataset of primary nasopharyngeal carcinoma MRI with multi-modalities segmentation",
    "url": "https://arxiv.org/abs/2404.03253",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2404.03253v3 Announce Type: replace-cross \nAbstract: Multi-modality magnetic resonance imaging(MRI) data facilitate the early diagnosis, tumor segmentation, and disease staging in the management of nasopharyngeal carcinoma (NPC). The lack of publicly available, comprehensive datasets limits advancements in diagnosis, treatment planning, and the development of machine learning algorithms for NPC. Addressing this critical need, we introduce the first comprehensive NPC MRI dataset, encompassing MR axial imaging of 277 primary NPC patients. This dataset includes T1-weighted, T2-weighted, and contrast-enhanced T1-weighted sequences, totaling 831 scans. In addition to the corresponding clinical data, manually annotated and labeled segmentations by experienced radiologists offer high-quality data resources from untreated primary NPC.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A dataset of primary nasopharyngeal carcinoma MRI with multi-modalities segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "dataset",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Entanglement-Based Artificial Topology: Neighboring Remote Network Nodes",
    "title_es": "Entanglement-Based Artificial Topology: Neighboring Remote Network Nodes",
    "url": "https://arxiv.org/abs/2404.16204",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2404.16204v4 Announce Type: replace-cross \nAbstract: Entanglement is unanimously recognized as the key communication resource of the Quantum Internet. Yet, the possibility of implementing novel network functionalities by exploiting the marvels of entanglement has been poorly investigated so far, by mainly restricting the attention to bipartite entanglement. Conversely, in this paper, we aim at exploiting multipartite entanglement as inter-network resource. Specifically, we consider the interconnection of different Quantum Local Area Networks (QLANs), and we show that multipartite entanglement allows to dynamically generate an inter-QLAN artificial topology, by means of local operations only, that overcomes the limitations of the physical QLAN topologies. To this aim, we first design the multipartite entangled state to be distributed within each QLAN. Then, we show how such a state can be engineered to: i) interconnect nodes belonging to different QLANs, and ii) dynamically adapt to different inter-QLAN traffic patterns. Our contribution aims at providing the network engineering community with a hands-on guideline towards the concept of artificial topology and artificial neighborhood.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Entanglement-Based Artificial Topology: Neighboring Remote Network Nodes\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "entanglementbased",
      "artificial",
      "topology"
    ],
    "category": "noticia"
  },
  {
    "title": "Modeling Spatial Extremal Dependence of Precipitation Using Distributional Neural Networks",
    "title_es": "Modeling Spatial Extremal Dependence of Precipitation Using Distributional Neural Networks",
    "url": "https://arxiv.org/abs/2407.08668",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2407.08668v2 Announce Type: replace-cross \nAbstract: In this work, we propose a simulation-based estimation approach using generative neural networks to determine dependencies of precipitation maxima and their underlying uncertainty in time and space. Within the common framework of max-stable processes for extremes under temporal and spatial dependence, our methodology allows estimating the process parameters and their respective uncertainty, but also delivers an explicit nonparametric estimate of the spatial dependence through the pairwise extremal coefficient function. We illustrate the effectiveness and robustness of our approach in a thorough finite sample study where we obtain good performance in complex settings for which closed-form likelihood estimation becomes intractable. We use the technique for studying monthly rainfall maxima in Western Germany for the period 2021-2023, which is of particular interest since it contains an extreme precipitation and consecutive flooding event in July 2021 that had a massive deadly impact. Beyond the considered setting, the presented methodology and its main generative ideas also have great potential for other applications.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Modeling Spatial Extremal Dependence of Precipitation Using Distributional Neural Networks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "modeling",
      "spatial",
      "extremal"
    ],
    "category": "noticia"
  },
  {
    "title": "Optimal sampling for least-squares approximation",
    "title_es": "Optimal sampling for least-squares approximation",
    "url": "https://arxiv.org/abs/2409.02342",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2409.02342v2 Announce Type: replace-cross \nAbstract: Least-squares approximation is one of the most important methods for recovering an unknown function from data. While in many applications the data is fixed, in many others there is substantial freedom to choose where to sample. In this paper, we review recent progress on near-optimal random sampling strategies for (weighted) least-squares approximation in arbitrary linear spaces. We introduce the Christoffel function as a key quantity in the analysis of (weighted) least-squares approximation from random samples, then show how it can be used to construct a random sampling strategy, termed Christoffel sampling, that possesses near-optimal sample complexity: namely, the number of samples scales log-linearly in the dimension of the approximation space $n$. We discuss a series of variations, extensions and further topics, and throughout highlight connections to approximation theory, machine learning, information-based complexity and numerical linear algebra. Finally, motivated by various contemporary applications, we consider a generalization of the classical setting where the samples need not be pointwise samples of a scalar-valued function, and the approximation space need not be linear. We show that, even in this significantly more general setting, suitable generalizations of Christoffel function still determine the sample complexity. Consequently, these can be used to design enhanced, Christoffel sampling strategies in a unified way for general recovery problems. This article is largely self-contained, and intended to be accessible to nonspecialists.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Optimal sampling for least-squares approximation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "optimal",
      "sampling",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Don't Trust A Single Gerrymandering Metric",
    "title_es": "Don't Trust A Single Gerrymandering Metric",
    "url": "https://arxiv.org/abs/2409.17186",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2409.17186v3 Announce Type: replace-cross \nAbstract: In recent years, in an effort to promote fairness in the election process, a wide variety of techniques and metrics have been proposed to determine whether a map is a partisan gerrymander. The most accessible measures, requiring easily obtained data, are metrics such as the Mean-Median Difference, Efficiency Gap, Declination, and GEO metric. But for most of these metrics, researchers have struggled to describe, given no additional information, how a value of that metric on a single map indicates the presence or absence of gerrymandering.\n  Our main result is that each of these metrics is gameable when used as a single, isolated quantity to detect gerrymandering (or the lack thereof). That is, for each of the four metrics, we can find district plans for a given state with an extremely large number of Democratic-won (or Republican-won) districts while the metric value of that plan falls within a reasonable, predetermined bound. We do this by using a hill-climbing method to generate district plans that are constrained by the bounds on the metric but also maximize or nearly maximize the number of districts won by a party.\n  In addition, extreme values of the Mean-Median Difference do not necessarily correspond to maps with an extreme number of districts won. Thus, the Mean- Median Difference metric is particularly misleading, as it cannot distinguish more extreme maps from less extreme maps. The other metrics are more nuanced, but when assessed on an ensemble, none perform substantially differently from simply measuring number of districts won by a fixed party.\n  One clear consequence of these results is that they demonstrate the folly of specifying a priori bounds on a metric that a redistricting commission must meet in order to avoid gerrymandering.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Don't Trust A Single Gerrymandering Metric\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dont",
      "trust",
      "a"
    ],
    "category": "noticia"
  },
  {
    "title": "MambaEviScrib: Mamba and Evidence-Guided Consistency Enhance CNN Robustness for Scribble-Based Weakly Supervised Ultrasound Image Segmentation",
    "title_es": "MambaEviScrib: Mamba and Evidence-Guided Consistency Enhance CNN Robustness for Scribble-Based Weakly Supervised Ultrasound Image Segmentation",
    "url": "https://arxiv.org/abs/2409.19370",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2409.19370v3 Announce Type: replace-cross \nAbstract: Segmenting anatomical structures and lesions from ultrasound images contributes to disease assessment. Weakly supervised learning (WSL) based on sparse annotation has achieved encouraging performance and demonstrated the potential to reduce annotation costs. This study attempts to introduce scribble-based WSL into ultrasound image segmentation tasks. However, ultrasound images often suffer from poor contrast and unclear edges, coupled with insufficient supervison signals for edges, posing challenges to edge prediction. Uncertainty modeling has been proven to facilitate models in dealing with these issues. Nevertheless, existing uncertainty estimation paradigms are not robust enough and often filter out predictions near decision boundaries, resulting in unstable edge predictions. Therefore, we propose leveraging predictions near decision boundaries effectively. Specifically, we introduce Dempster-Shafer Theory (DST) of evidence to design an Evidence-Guided Consistency strategy. This strategy utilizes high-evidence predictions, which are more likely to occur near high-density regions, to guide the optimization of low-evidence predictions that may appear near decision boundaries. Furthermore, the diverse sizes and locations of lesions in ultrasound images pose a challenge for CNNs with local receptive fields, as they struggle to model global information. Therefore, we introduce Visual Mamba based on structured state space sequence models, which achieves long-range dependency with linear computational complexity, and we construct a novel hybrid CNN-Mamba framework. During training, the collaboration between the CNN branch and the Mamba branch in the proposed framework draws inspiration from each other based on the EGC strategy. Experiments demonstrate the competitiveness of the proposed method. Dataset and code will be available on https://github.com/GtLinyer/MambaEviScrib.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"MambaEviScrib: Mamba and Evidence-Guided Consistency Enhance CNN Robustness for Scribble-Based Weakly Supervised Ultrasound Image Segmentation\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mambaeviscrib",
      "mamba",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "CDI: Blind Image Restoration Fidelity Evaluation based on Consistency with Degraded Image",
    "title_es": "CDI: Blind Image Restoration Fidelity Evaluation based on Consistency with Degraded Image",
    "url": "https://arxiv.org/abs/2501.14264",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2501.14264v2 Announce Type: replace-cross \nAbstract: Recent advancements in Blind Image Restoration (BIR) methods, based on Generative Adversarial Networks and Diffusion Models, have significantly improved visual quality. However, they present significant challenges for Image Quality Assessment (IQA), as the existing Full-Reference IQA methods often rate images with high perceptual quality poorly. In this paper, we reassess the Solution Non-Uniqueness and Degradation Indeterminacy issues of BIR, and propose constructing a specific BIR IQA system. In stead of directly comparing a restored image with a reference image, the BIR IQA evaluates fidelity by calculating the Consistency with Degraded Image (CDI). Specifically, we propose a wavelet domain Reference Guided CDI algorithm, which can acquire the consistency with a degraded image for various types without requiring knowledge of degradation parameters. The supported degradation types include down sampling, blur, noise, JPEG and complex combined degradations etc. In addition, we propose a Reference Agnostic CDI, enabling BIR fidelity evaluation without reference images. Finally, in order to validate the rationality of CDI, we create a new Degraded Images Switch Display Comparison Dataset (DISDCD) for subjective evaluation of BIR fidelity. Experiments conducted on DISDCD verify that CDI is markedly superior to common Full Reference IQA methods for BIR fidelity evaluation. The source code and the DISDCD dataset will be publicly available shortly.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"CDI: Blind Image Restoration Fidelity Evaluation based on Consistency with Degraded Image\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cdi",
      "blind",
      "image"
    ],
    "category": "noticia"
  },
  {
    "title": "POMATO: Marrying Pointmap Matching with Temporal Motion for Dynamic 3D Reconstruction",
    "title_es": "POMATO: Marrying Pointmap Matching with Temporal Motion for Dynamic 3D Reconstruction",
    "url": "https://arxiv.org/abs/2504.05692",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2504.05692v2 Announce Type: replace-cross \nAbstract: 3D reconstruction in dynamic scenes primarily relies on the combination of geometry estimation and matching modules where the latter task is pivotal for distinguishing dynamic regions which can help to mitigate the interference introduced by camera and object motion. Furthermore, the matching module explicitly models object motion, enabling the tracking of specific targets and advancing motion understanding in complex scenarios. Recently, the proposed representation of pointmap in DUSt3R suggests a potential solution to unify both geometry estimation and matching in 3D space, but it still struggles with ambiguous matching in dynamic regions, which may hamper further improvement. In this work, we present POMATO, a unified framework for dynamic 3D reconstruction by marrying pointmap matching with temporal motion. Specifically, our method first learns an explicit matching relationship by mapping RGB pixels from both dynamic and static regions across different views to 3D pointmaps within a unified coordinate system. Furthermore, we introduce a temporal motion module for dynamic motions that ensures scale consistency across different frames and enhances performance in tasks requiring both precise geometry and reliable matching, most notably 3D point tracking. We show the effectiveness of the proposed pointmap matching and temporal fusion paradigm by demonstrating the remarkable performance across multiple downstream tasks, including video depth estimation, 3D point tracking, and pose estimation. Code and models are publicly available at https://github.com/wyddmw/POMATO.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"POMATO: Marrying Pointmap Matching with Temporal Motion for Dynamic 3D Reconstruction\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "pomato",
      "marrying",
      "pointmap"
    ],
    "category": "noticia"
  },
  {
    "title": "Orbit-blocking words in free groups",
    "title_es": "Orbit-blocking words in free groups",
    "url": "https://arxiv.org/abs/2505.00477",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.00477v2 Announce Type: replace-cross \nAbstract: By strengthening known results about primitivity-blocking words in free groups, we prove that for any nontrivial element w of a free group of finite rank, there are words that cannot be subwords of any cyclically reduced automorphic image of w. This has implications for the average-case complexity of a variant of Whitehead's problem.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Orbit-blocking words in free groups\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "orbitblocking",
      "words",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Quon Classical Simulation: Unifying Cliffords, Matchgates and Entanglement",
    "title_es": "Quon Classical Simulation: Unifying Cliffords, Matchgates and Entanglement",
    "url": "https://arxiv.org/abs/2505.07804",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.07804v2 Announce Type: replace-cross \nAbstract: We propose a new framework of topological complexity to study the computational complexity of quantum circuits and tensor networks. Within this framework, we establish the Quon Classical Simulation (QCS) for hybrid Clifford-Matchgate circuits, which is efficient for both Clifford circuits and Matchgate circuits, therefore answering a long standing open question on unifying efficient classical simulations. This framework is built upon the Quon language, a 2+1D topological quantum field theory with space-time boundary and defects. Its exponential computation complexity is captured by Magic holes, a topological feature capturing the global long-range entanglement. Both Clifford circuits and Matchgate circuits are free of Magic holes. Efficient classical simulations of Cliffords and Matchgates are implemented by two parallel operations, generalized surgery theory of 3-manifolds and Yang-Baxter relations on the 2D boundary respectively, with additional binary arithmetic properties.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Quon Classical Simulation: Unifying Cliffords, Matchgates and Entanglement\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "quon",
      "classical",
      "simulation"
    ],
    "category": "noticia"
  },
  {
    "title": "A Minimal Substitution Basis for the Kalmar Elementary Functions",
    "title_es": "A Minimal Substitution Basis for the Kalmar Elementary Functions",
    "url": "https://arxiv.org/abs/2505.23787",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2505.23787v2 Announce Type: replace-cross \nAbstract: We show that the class of Kalmar elementary functions can be inductively generated from the addition, the integer remainder and the base-two exponentiation, hence improving previous results by Marchenkov and Mazzanti. We also prove that the substitution basis defined by these three operations is minimal. Furthermore, we discuss alternative substitution bases under arity constraints.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"A Minimal Substitution Basis for the Kalmar Elementary Functions\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "minimal",
      "substitution"
    ],
    "category": "noticia"
  },
  {
    "title": "Large-Scale Linear Energy System Optimization: A Systematic Review on Parallelization Strategies via Decomposition",
    "title_es": "Large-Scale Linear Energy System Optimization: A Systematic Review on Parallelization Strategies via Decomposition",
    "url": "https://arxiv.org/abs/2507.21932",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.21932v2 Announce Type: replace-cross \nAbstract: As renewable energy integration, sector coupling, and spatiotemporal detail increase, energy system optimization models grow in size and complexity, often pushing solvers to their performance limits. This systematic review explores parallelization strategies that can address these challenges. We first propose a classification scheme for linear energy system optimization models, covering their analytical focus, mathematical structure, and scope. We then review parallel decomposition methods, finding that while many offer performance benefits, no single approach is universally superior. The lack of standardized benchmark suites further complicates comparison. To address this, we recommend essential criteria for future benchmarks and minimum reporting standards. We also survey available software tools for parallel decomposition, including modular frameworks and algorithmic abstractions. Though centered on energy system models, our insights extend to the broader operations research field.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Large-Scale Linear Energy System Optimization: A Systematic Review on Parallelization Strategies via Decomposition\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "largescale",
      "linear",
      "energy"
    ],
    "category": "noticia"
  },
  {
    "title": "Evaluation of Noise and Crosstalk in Neutral Atom Quantum Computers",
    "title_es": "Evaluation of Noise and Crosstalk in Neutral Atom Quantum Computers",
    "url": "https://arxiv.org/abs/2507.22140",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2507.22140v2 Announce Type: replace-cross \nAbstract: This work explores and evaluates noise and crosstalk in neutral atom quantum computers. Neutral atom quantum computers are a promising platform for analog Hamiltonian simulations, which rely on a sequence of time-dependent Hamiltonians to model the dynamics of a larger system and are particularly useful for problems in optimization, physics, and molecular dynamics. However, the viability of running multiple simulations in a co-located or multi-tenant environment is limited by noise and crosstalk. This work conducts an analysis of how noise faced by simulations changes over time, and investigates the effects of spatial co-location on simulation fidelity. Findings of this work demonstrate that the close proximity of concurrent simulations can increase crosstalk between them. To mitigate this issue, a Moving Target Defense (MTD) strategy is proposed and evaluated. The results confirm that the MTD is a viable technique for enabling safe and reliable co-location of simulations on neutral atom quantum hardware.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Evaluation of Noise and Crosstalk in Neutral Atom Quantum Computers\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "evaluation",
      "of",
      "noise"
    ],
    "category": "noticia"
  },
  {
    "title": "Accelerating Fleet Upgrade Decisions with Machine-Learning Enhanced Optimization",
    "title_es": "Accelerating Fleet Upgrade Decisions with Machine-Learning Enhanced Optimization",
    "url": "https://arxiv.org/abs/2508.00915",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.00915v2 Announce Type: replace-cross \nAbstract: Rental-based business models and increasing sustainability requirements intensify the need for efficient strategies to manage large machine and vehicle fleet renewal and upgrades. Optimized fleet upgrade strategies maximize overall utility, cost, and sustainability. However, conventional fleet optimization does not account for upgrade options and is based on integer programming with exponential runtime scaling, which leads to substantial computational cost when dealing with large fleets and repeated decision-making processes. This contribution firstly suggests an extended integer programming approach that determines optimal renewal and upgrade decisions. The computational burden is addressed by a second, alternative machine learning-based method that transforms the task to a mixed discrete-continuous optimization problem. Both approaches are evaluated in a real-world automotive industry case study, which shows that the machine learning approach achieves near-optimal solutions with significant improvements in the scalability and overall computational performance, thus making it a practical alternative for large-scale fleet management.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Accelerating Fleet Upgrade Decisions with Machine-Learning Enhanced Optimization\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "accelerating",
      "fleet",
      "upgrade"
    ],
    "category": "noticia"
  },
  {
    "title": "Measuring Dependencies between Biological Signals with Self-supervision, and its Limitations",
    "title_es": "Measuring Dependencies between Biological Signals with Self-supervision, and its Limitations",
    "url": "https://arxiv.org/abs/2508.02703",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.02703v2 Announce Type: replace-cross \nAbstract: Measuring the statistical dependence between observed signals is a primary tool for scientific discovery. However, biological systems often exhibit complex non-linear interactions that currently cannot be captured without a priori knowledge regarding the nature of dependence. We introduce a self-supervised approach, concurrence, which is inspired by the observation that if two signals are dependent, then one should be able to distinguish between temporally aligned vs. misaligned segments extracted from them. Experiments with fMRI, physiological and behavioral signals show that, to our knowledge, concurrence is the first approach that can expose relationships across such a wide spectrum of signals and extract scientifically relevant differences without ad-hoc parameter tuning or reliance on a priori information, providing a potent tool for scientific discoveries across fields. However, dependencies caused by extraneous factors remain an open problem, thus researchers should validate that exposed relationships truly pertain to the question(s) of interest.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"Measuring Dependencies between Biological Signals with Self-supervision, and its Limitations\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "measuring",
      "dependencies",
      "between"
    ],
    "category": "noticia"
  },
  {
    "title": "L1-Regularized Functional Support Vector Machine",
    "title_es": "L1-Regularized Functional Support Vector Machine",
    "url": "https://arxiv.org/abs/2508.05567",
    "published": "2025-08-11T04:00:00.000Z",
    "date": "2025-08-11",
    "content_es": "arXiv:2508.05567v2 Announce Type: replace-cross \nAbstract: In functional data analysis, binary classification with one functional covariate has been extensively studied. We aim to fill in the gap of considering multivariate functional covariates in classification. In particular, we propose an $L_1$-regularized functional support vector machine for binary classification. An accompanying algorithm is developed to fit the classifier. By imposing an $L_1$ penalty, the algorithm enables us to identify relevant functional covariates of the binary response. Numerical results from simulations and one real-world application demonstrate that the proposed classifier enjoys good performance in both prediction and feature selection.",
    "source": "arXiv",
    "description": "Este artículo trata sobre \"L1-Regularized Functional Support Vector Machine\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lregularized",
      "functional",
      "support"
    ],
    "category": "noticia"
  },
  {
    "title": "Roxie Laybourne, the first forensic ornithologist",
    "title_es": "Roxie Laybourne, the first forensic ornithologist",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx2662",
    "date": "2025-08-10",
    "source": "Science.org",
    "content_es": "Science, Volume 389, Issue 6760, Page 582-582, August 2025.",
    "published": "2025-08-10T00:00:00.000Z",
    "summary": "Science, Volume 389, Issue 6760, Page 582-582, August 2025.",
    "summary_es": "Science, volumen 389, número 6760, páginas 582-582, agosto de 2025.",
    "description": "Este artículo trata sobre \"Roxie Laybourne, the first forensic ornithologist\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "roxie",
      "laybourne",
      "the"
    ],
    "category": "noticia"
  },
  {
    "title": "Swift bricks, ancient tattoos and more: Books in brief",
    "title_es": "Swift bricks, ancient tattoos and more: Books in brief",
    "url": "https://www.nature.com/articles/d41586-025-02556-0",
    "date": "2025-08-10",
    "source": "Nature",
    "content_es": "Swift bricks, ancient tattoos and more: Books in brief",
    "published": "2025-08-10T00:00:00.000Z",
    "summary": "",
    "summary_es": "",
    "description": "Este artículo trata sobre \"Swift bricks, ancient tattoos and more: Books in brief\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "swift",
      "bricks",
      "ancient"
    ],
    "category": "noticia"
  },
  {
    "title": "Augmented Question-guided Retrieval (AQgR) of Indian Case Law with LLM, RAG, and Structured Summaries",
    "title_es": "Recuperación aumentada guiada por preguntas (AQgR) de jurisprudencia india con LLM, RAG y resúmenes estructurados",
    "url": "https://arxiv.org/abs/2508.04710",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Recuperación aumentada guiada por preguntas (AQgR) de jurisprudencia india con LLM, RAG y resúmenes estructurados",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Recuperación aumentada guiada por preguntas (AQgR) de jurisprudencia india con LLM, RAG y resúmenes estructurados\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "augmented",
      "questionguided",
      "retrieval"
    ],
    "category": "noticia"
  },
  {
    "title": "How animal paw pads got their toughness",
    "url": "https://www.nature.com/articles/d41586-025-02474-1",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "summary": "",
    "source": "Nature",
    "title_es": "How animal paw pads got their toughness",
    "summary_es": "",
    "content_es": "How animal paw pads got their toughness",
    "description": "Este artículo trata sobre \"How animal paw pads got their toughness\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "how",
      "animal",
      "paw"
    ],
    "category": "noticia"
  },
  {
    "title": "Can creativity in science be learnt? These researchers think so",
    "url": "https://www.nature.com/articles/d41586-025-01913-3",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "summary": "",
    "source": "Nature",
    "title_es": "Can creativity in science be learnt? These researchers think so",
    "summary_es": "",
    "content_es": "Can creativity in science be learnt? These researchers think so",
    "description": "Este artículo trata sobre \"Can creativity in science be learnt? These researchers think so\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "can",
      "creativity",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Trump order gives political appointees vast powers over research grants",
    "url": "https://www.nature.com/articles/d41586-025-02557-z",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "summary": "",
    "source": "Nature",
    "title_es": "Trump order gives political appointees vast powers over research grants",
    "summary_es": "",
    "content_es": "Trump order gives political appointees vast powers over research grants",
    "description": "Este artículo trata sobre \"Trump order gives political appointees vast powers over research grants\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "trump",
      "order",
      "gives"
    ],
    "category": "noticia"
  },
  {
    "title": "Decolonize scientific institutions, don’t just diversify them",
    "url": "https://www.nature.com/articles/d41586-025-02516-8",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "summary": "",
    "source": "Nature",
    "title_es": "Decolonize scientific institutions, don’t just diversify them",
    "summary_es": "",
    "content_es": "Decolonize scientific institutions, don’t just diversify them",
    "description": "Este artículo trata sobre \"Decolonize scientific institutions, don’t just diversify them\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "decolonize",
      "scientific",
      "institutions"
    ],
    "category": "noticia"
  },
  {
    "title": "A rude awakening",
    "url": "https://www.nature.com/articles/d41586-025-02488-9",
    "published": "2025-08-08T00:00:00.000Z",
    "date": "2025-08-08",
    "summary": "",
    "source": "Nature",
    "title_es": "A rude awakening",
    "summary_es": "",
    "content_es": "A rude awakening",
    "description": "Este artículo trata sobre \"A rude awakening\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "rude",
      "awakening"
    ],
    "category": "noticia"
  },
  {
    "title": "WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion",
    "title_es": "WGAST: red generativa débilmente supervisada para la estimación diaria de la temperatura de la superficie de la tierra de 10 m a través de la fusión espacio-temporal",
    "url": "http://arxiv.org/abs/2508.06485v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "La urbanización, el cambio climático y el estrés agrícola están aumentando el\ndemanda de monitoreo ambiental preciso y oportuno. Superficie terrestre\nLa temperatura (LST) es una variable clave en este contexto y se recupera de\nSatélites de teledetección. Sin embargo, estos sistemas enfrentan una compensación entre\nResolución espacial y temporal. Mientras que ofrecen métodos de fusión espacio-temporales\nSoluciones prometedoras, pocas han abordado la estimación de LST diario a los 10 m\nresolución. En este estudio, presentamos WGAST, un generativo débilmente supervisado\nRed para la estimación diaria de 10 m LST a través de la fusión espacio-temporal de Terra\nModis, Landsat 8 y Sentinel-2. WGAST es el primer aprendizaje profundo de extremo a extremo\nMarco diseñado para esta tarea. Adopta un generativo condicional\nArquitectura adversaria, con un generador compuesto por cuatro etapas: característica\nExtracción, fusión, reconstrucción LST y supresión de ruido. La primera etapa\nemplea un conjunto de codificadores para extraer representaciones latentes de nivel múltiple de\nLas entradas, que luego se fusionan en la segunda etapa utilizando similitud de coseno,\nNormalización y mecanismos de atención temporal. La tercera etapa decodifica el\nCaracterísticas fusionadas en LST de alta resolución, seguido de un filtro gaussiano para\nSuprimir el ruido de alta frecuencia. La capacitación sigue una estrategia débilmente supervisada\nBasado en principios de promedio físico y reforzado por un Patchgan\ndiscriminado. Los experimentos demuestran que WGAST supera a los métodos existentes\nen evaluaciones cuantitativas y cualitativas. Comparado con el\nLa línea de base de mejor rendimiento, en promedio, WGAST reduce RMSE en un 17.18% y mejora\nSSIM por 11.00%. Además, WGAST es robusto para LST inducido por la nube y\nCaptura efectivamente los patrones térmicos a escala fina, como se validó contra 33\nSensores terrestres. El código está disponible en\nhttps://github.com/sofianebouaziz1/wgast.git.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"WGAST: red generativa débilmente supervisada para la estimación diaria de la temperatura de la superficie de la tierra de 10 m a través de la fusión espacio-temporal\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "wgast",
      "weaklysupervised",
      "generative"
    ],
    "category": "noticia"
  },
  {
    "title": "Post-training for Efficient Communication via Convention Formation",
    "title_es": "Post-entrenamiento para comunicación eficiente a través de la formación de convenciones",
    "url": "http://arxiv.org/abs/2508.06482v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Los humanos se comunican con la mayor eficiencia en las interacciones múltiples, por\nadaptar su idioma y formar convenciones ad-hoc. En contraste, trabajo previo\nmuestra que los LLM no muestran naturalmente este comportamiento. Desarrollamos un post-entrenamiento\nproceso para desarrollar esta capacidad a través del ajuste fino objetivo en heurísticamente\ndemostraciones identificadas de formación de la convención. Evaluamos con dos nuevos\nLos puntos de referencia se centraron en esta capacidad. Primero, diseñamos un enfocado,\nRemono de interacción con motivación cognitivamente que constantemente provoca fuertes\nTendencias de formación de la convención en humanos. Segundo, creamos un nuevo\nTarea de finalización de referencia fundamentada de documentos que refleja\nComportamiento de formación de la convención. Nuestros estudios muestran significativamente mejorando\nHabilidades de formación de la convención en LLM posteriores a la capacitación en las dos evaluaciones\nmétodos.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Post-entrenamiento para comunicación eficiente a través de la formación de convenciones\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "posttraining",
      "for",
      "efficient"
    ],
    "category": "noticia"
  },
  {
    "title": "Intuition emerges in Maximum Caliber models at criticality",
    "title_es": "La intuición surge en modelos de calibre máximo en crítica",
    "url": "http://arxiv.org/abs/2508.06477v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Si los modelos predictivos grandes simplemente repiten sus datos de entrenamiento o producen\nLa visión genuina carece de una explicación física. Este trabajo informa una primitiva\nforma de intuición que emerge como una fase metaestable de aprendizaje que\nequilibra críticamente la predicción de la próxima token contra la futura entropía del camino. El\nEl mecanismo de intuición se descubre a través del ajuste de la mente, el principio mínimo de que\nimpone el máximo calibre en modelos predictivos con una temperatura de control similar a\nParámetro $ \\ lambda $. El entrenamiento en caminatas aleatorias en laberintos deterministas revela un\nDiagrama de fase rica: imitación (bajo $ \\ lambda $), alucinación que rompe las reglas\n(alto $ \\ lambda $), y una ventana frágil intermedia que exhibe fuerte\nProtocolo-dependencia (histéresis) y multiestabilidad, donde los modelos espontáneamente\nDescubra nuevas estrategias dirigidas por objetivos. Estos resultados son capturados por un\nteoría y intuición de marco de baja dimensión efectiva como una propiedad emergente en\nEl equilibrio crítico entre memorizar lo que es y preguntarse qué podría ser.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"La intuición surge en modelos de calibre máximo en crítica\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "intuition",
      "emerges",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls",
    "title_es": "Escamagentes: cómo los agentes de IA pueden simular llamadas de estafa a nivel humano",
    "url": "http://arxiv.org/abs/2508.06457v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Los modelos de idiomas grandes (LLM) han demostrado una fluidez impresionante y\ncapacidades de razonamiento, pero su potencial de mal uso ha aumentado el crecimiento\ninquietud. En este artículo, presentamos Scamagent, un agente autónomo de múltiples vueltas\nConstruido sobre LLMS, capaz de generar scripts de llamadas de estafa altamente realistas\nque simulan escenarios de fraude del mundo real. A diferencia del trabajo anterior centrado en\nUso de un solo mal uso, Scamagent mantiene la memoria del diálogo, se adapta\nDinámicamente a las respuestas de los usuarios simuladas y emplea una persuasión engañosa\nEstrategias en giros conversacionales. Mostramos que la seguridad actual de LLM\nLas barandillas, incluidos los mecanismos de rechazo y los filtros de contenido, son ineficaces\ncontra tales amenazas basadas en agentes. Incluso modelos con un fuerte nivel de inmediato\nLas salvaguardas se pueden pasar por alto cuando las indicaciones se descomponen, disfrazan o se entregan\nincrementalmente dentro de un marco de agente. Además demostramos el\nTransformación de guiones de estafa en llamadas de voz realistas utilizando modernos\nSistemas de texto a voz, completando una tubería de estafa totalmente automatizada. Nuestro\nLos hallazgos resaltan una necesidad urgente de auditoría de seguridad múltiple, a nivel de agente\nmarcos de control y nuevos métodos para detectar e interrumpir la conversación\nEngaño impulsado por la IA generativa.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Escamagentes: cómo los agentes de IA pueden simular llamadas de estafa a nivel humano\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "scamagents",
      "how",
      "ai"
    ],
    "category": "noticia"
  },
  {
    "title": "What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting",
    "title_es": "Lo que realmente hacen las reglas de votación: un análisis basado en datos de la votación de múltiples ganancias",
    "url": "http://arxiv.org/abs/2508.06454v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Los problemas de selección del comité surgen en muchos contextos y aplicaciones, y\nHa habido un interés creciente en la comunidad de investigación de elección social\nAl identificar qué propiedades están satisfechas por diferentes votos de múltiples ganancias\nnormas. En este trabajo, proponemos un marco basado en datos para evaluar cómo\nLas reglas de votación con frecuencia violan a los axiomas en diversas distribuciones de preferencias\nEn la práctica, alejándose de la perspectiva binaria de la satisfacción del axioma\nDado por el análisis del peor de los casos. Usando este marco, analizamos la relación\nentre las reglas de votación de múltiples ganancias y su rendimiento axiomático bajo varios\ndistribuciones de preferencias. Luego mostramos que las redes neuronales, actuando como votación\nLas reglas pueden superar las reglas tradicionales para minimizar las violaciones de los axiomas. Nuestro\nLos resultados sugieren que los enfoques basados en datos para la elección social pueden informar el\nDiseño de nuevos sistemas de votación y respalda la continuación de los datos.\nInvestigación en elección social.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Lo que realmente hacen las reglas de votación: un análisis basado en datos de la votación de múltiples ganancias\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "what",
      "voting",
      "rules"
    ],
    "category": "noticia"
  },
  {
    "title": "Text Embedded Swin-UMamba for DeepLesion Segmentation",
    "title_es": "Texto incrustado Swin-Umamba para segmentación de profundidad",
    "url": "http://arxiv.org/abs/2508.06453v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "La segmentación de lesiones en CT permite la medición automática para clínica\nEvaluación de enfermedades crónicas (por ejemplo, linfoma). Integrando un lenguaje grande\nModelos (LLM) en el flujo de trabajo de segmentación de la lesión ofrece el potencial para\nCombinar características de imágenes con descripciones de características de lesión de la\nInformes de radiología. En este estudio, investigamos la viabilidad de integrar\nEnvíe un mensaje de texto a la arquitectura Swin-Umamba para la tarea de segmentación de la lesión. El\nSe usó un conjunto de datos de profundidad ULS23 disponible públicamente junto con una forma corta\ndescripciones de los hallazgos de los informes. En el conjunto de datos de prueba, un alto dados\nSe obtuvo una puntuación de 82% y una baja distancia de Hausdorff de 6.58 (píxeles) para\nsegmentación de la lesión. El modelo de texto-umamba de texto propuesto superó a\nEnfoques: 37% de mejora sobre el modelo LanguidemedSeg impulsado por LLM (P <\n0.001), y superó los modelos Purely Based Image XLSTM-Unet y Nnunet por\n1.74% y 0.22%, respectivamente. Se puede acceder al conjunto de datos y al código en\nhttps://github.com/ruida/llm-swin-umamba",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Texto incrustado Swin-Umamba para segmentación de profundidad\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "text",
      "embedded",
      "swinumamba"
    ],
    "category": "noticia"
  },
  {
    "title": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking",
    "title_es": "Ecos de automatización: el uso creciente de LLM en la noticia",
    "url": "http://arxiv.org/abs/2508.06445v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "El rápido aumento de la IA generativa (Genai), particularmente LLMS, plantea preocupaciones\npara integridad periodística y autoría. Este estudio examina\nContenido en más de 40,000 artículos de noticias de noticias principales, locales y universitarias\nMedios, en varios formatos de medios. Utilizando tres detectores avanzados de texto AI (por ejemplo,\nBinoculares, detectación rápida GPT y gptzero), encontramos un aumento sustancial de\nUso de Genai en los últimos años, especialmente en noticias locales y universitarias. A nivel de oración\nEl análisis revela que los LLM a menudo se usan en la introducción de noticias, mientras que\nConclusiones generalmente escritas manualmente. El análisis lingüístico muestra los refuerzo de Genai\nLa riqueza y la legibilidad de las palabras, pero reduce la formalidad, lo que lleva a más uniforme\nEscribir estilos, particularmente en los medios locales.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Ecos de automatización: el uso creciente de LLM en la noticia\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "echoes",
      "of",
      "automation"
    ],
    "category": "noticia"
  },
  {
    "title": "The Fair Game: Auditing & Debiasing AI Algorithms Over Time",
    "title_es": "El juego justo: auditar y debiar algoritmos de IA con el tiempo",
    "url": "http://arxiv.org/abs/2508.06443v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Un campo emergente de la IA, a saber, el aprendizaje automático justo (ml), tiene como objetivo cuantificar\nDiferentes tipos de sesgo (también conocidos como injusticia) exhibidos en las predicciones\nde algoritmos ML, y para diseñar nuevos algoritmos para mitigarlos. A menudo, el\nLas definiciones de sesgo utilizado en la literatura son observacionales, es decir, usan el\nEntrada y salida de un algoritmo previamente capacitado para cuantificar un sesgo bajo preocupación.\nEn realidad, estas definiciones a menudo son de naturaleza conflictiva y solo pueden ser\ndesplegado si la verdad del suelo se conoce o solo en retrospectiva después\nImplementación del algoritmo. Por lo tanto, existe una brecha entre lo que queremos ML justo para\nlograr y lo que hace en un entorno social dinámico. Por lo tanto, proponemos un\nMecanismo dinámico alternativo, \"Juego justo\", para asegurar la equidad en las predicciones\nde un algoritmo ML y adaptar sus predicciones a medida que la sociedad interactúa con\nEl algoritmo con el tiempo. \"Juego justo\" reúne a un auditor y un debiasing\nAlgoritmo en un bucle alrededor de un algoritmo ML. El \"juego justo\" pone a estos dos\nComponentes en un bucle aprovechando el aprendizaje de refuerzo (RL). Algoritmos RL\ninteractuar con un entorno para tomar decisiones, lo que produce nuevas observaciones\n(también conocido como datos/retroalimentación) del entorno y, a su vez, adapta el futuro\ndecisiones. RL ya se usa en algoritmos con equidad a largo plazo prefijada\nobjetivos. \"Juego justo\" proporciona un marco único donde pueden estar los objetivos de justicia\nadaptado con el tiempo solo modificando el auditor y los diferentes sesgos lo\ncuantifica. Por lo tanto, el \"juego justo\" tiene como objetivo simular la evolución de la ética y\nmarcos legales en la sociedad creando un auditor que envía comentarios a\nUn algoritmo de Debiasing desplegado en torno a un sistema ML. Esto nos permite desarrollar un\nmarco flexible y adaptativo a tiempo para construir sistemas de ML justo antes y\nposterior a la implementación.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"El juego justo: auditar y debiar algoritmos de IA con el tiempo\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "fair",
      "game"
    ],
    "category": "noticia"
  },
  {
    "title": "Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages",
    "title_es": "Aprender el tema, no el idioma: cómo LLMS clasifican el discurso de inmigración en línea en todos los idiomas",
    "url": "http://arxiv.org/abs/2508.06435v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Los modelos de idiomas grandes (LLM) están transformando la investigación de la ciencia social de\nhabilitación de análisis escalable y preciso. Su adaptabilidad plantea la cuestión de\nSi el conocimiento adquirido a través del ajuste en algunos idiomas puede transferir\na los idiomas invisibles que solo aparecieron durante la capacitación previa. Para examinar esto, nosotros\nmodelos de Llama 3.2-3b de Fine-Tune en monolingüe, bilingüe o\nConjuntos de datos multilingües para clasificar los tweets relacionados con la inmigración de X/Twitter\nEn 13 idiomas, un dominio caracterizado por polarizado, culturalmente específico\ndiscurso. Evaluamos si el ajuste fino específico del lenguaje mínimo permite habilitar\ndetección de temas interlingüe y si agregar idiomas específicos corrige\nsesgos previos al entrenamiento. Los resultados muestran que los LLM se ajustan en uno o dos idiomas\npuede clasificar de manera confiable el contenido relacionado con la inmigración en idiomas invisibles. Sin embargo,\nIdentificar si un tweet expresa una postura pro o anti-inmigración\nBeneficios del ajuste fino multilingüe. El sesgo previo al entrenamiento favorece a\nIdiomas, pero incluso una exposición mínima a idiomas subrepresentados durante\najuste fino (tan solo $ 9.62 \\ Times10^{-11} $ del pre-entrenamiento original\nVolumen de token) produce ganancias significativas. Estos hallazgos desafían la suposición\nEse dominio interlingüal requiere una amplia capacitación multilingüe: limitado\nLa cobertura del idioma es suficiente para la generalización a nivel de tema y la estructura\nLos sesgos se pueden corregir con intervenciones livianas. Al liberar\nModelos de 4 bits-cantised, Lora ajustados, proporcionamos una fuente abierta,\nAlternativa reproducible a los LLM patentados que ofrece 35 veces más rápido\ninferencia a solo 0.00000989% del costo en dólares del modelo Operai GPT-4O,\nhabilitando investigaciones escalables e inclusivas.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Aprender el tema, no el idioma: cómo LLMS clasifican el discurso de inmigración en línea en todos los idiomas\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "learning",
      "the",
      "topic"
    ],
    "category": "noticia"
  },
  {
    "title": "CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment",
    "title_es": "Clipin: un complemento no con contrastive para recortar la alineación semántica multimodal",
    "url": "http://arxiv.org/abs/2508.06434v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Conjuntos de datos de texto de imagen natural a gran escala, especialmente aquellos automáticamente\nrecolectado de la web, a menudo sufren una alineación semántica suelta debido a los débiles\nsupervisión, mientras que los conjuntos de datos médicos tienden a tener una alta correlación intermodal\npero baja diversidad de contenido. Estas propiedades plantean un desafío común para\nPretratenamiento de imagen de lenguaje contrastante (clip): obstaculizan la capacidad del modelo\npara aprender representaciones robustas y generalizables. En este trabajo, proponemos\nClipin, un complemento unificado que no se puede integrar sin problemas\nen arquitecturas de estilo clip para mejorar la alineación semántica multimodal,\nProporcionar una supervisión más fuerte y mejorar la robustez de alineación. Además,\nDos preprojectores compartidos están diseñados para modalidades de imagen y texto\nrespectivamente para facilitar la integración de contrastante y no contrastive\nAprendizaje de una manera de compromiso de parámetros. Experimentos extensos sobre diversos\nLas tareas aguas abajo demuestran la efectividad y la generalidad de los clip como un\nComponente de plug-and-play compatible con varios marcos de contraste. El código es\nDisponible en https://github.com/t6yang/clipin.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Clipin: un complemento no con contrastive para recortar la alineación semántica multimodal\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "clipin",
      "a",
      "noncontrastive"
    ],
    "category": "noticia"
  },
  {
    "title": "Memp: Exploring Agent Procedural Memory",
    "title_es": "MEMP: Explorando la memoria de procedimiento del agente",
    "url": "http://arxiv.org/abs/2508.06433v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Los agentes basados en modelos de idiomas grandes (LLMS) se destacan en diversas tareas, pero ellos\nSufre de memoria de procedimiento frágil que está diseñada o enredada manualmente\nEn parámetros estáticos. En este trabajo, investigamos estrategias para dotar a los agentes\ncon una memoria de procedimiento aprendible, actualizable y de por vida. Proponemos MEMP\nque destila las trayectorias del agente más allá en tanto de grano fino, paso a paso\nInstrucciones y abstracciones de nivel superior, similar a un script, y explore el impacto\nde diferentes estrategias para la construcción, recuperación y actualización de la memoria procesal.\nJunto con un régimen dinámico que actualiza, corrige y correcta continuamente\nDescarga su contenido, este repositorio evoluciona en bloqueo con nuevo\nexperiencia. La evaluación empírica en TravelPlanner y Alfworld muestra que como\nEl repositorio de memoria es refinado, los agentes logran tasas de éxito constantemente más altas\ny mayor eficiencia en tareas análogas. Además, la memoria de procedimiento construida\nde un modelo más fuerte conserva su valor: migrar la memoria de procedimiento a un\nEl modelo más débil produce ganancias de rendimiento sustanciales.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"MEMP: Explorando la memoria de procedimiento del agente\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "memp",
      "exploring",
      "agent"
    ],
    "category": "noticia"
  },
  {
    "title": "SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation",
    "title_es": "Datos dispersos, resultados ricos: aprendizaje semi-supervisado de pocos disparos a través de la traducción de imágenes acondicionadas",
    "url": "http://arxiv.org/abs/2508.06429v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "El aprendizaje profundo ha revolucionado las imágenes médicas, pero su efectividad es\nseveramente limitado por datos de entrenamiento etiquetados insuficientes. Este documento presenta un\nnovedoso marco de aprendizaje semi-supervisado basado en GaN diseñado específicamente para\nRegímenes de baja etiqueta de datos, evaluados a través de la configuración con 5 a 50 etiquetados\nmuestras por clase. Nuestro enfoque integra tres redes neuronales especializadas -\nun generador para la traducción de imágenes acondicionadas con clase, un discriminador para\nEvaluación y clasificación de autenticidad, y un clasificador dedicado -\ndentro de un marco de capacitación trifásico. El método alterna entre\ncapacitación supervisada en datos etiquetados limitados y aprendizaje sin supervisión de que\nAprovecha abundantes imágenes sin etiqueta a través de la traducción de imagen a imagen más bien\nque la generación a partir del ruido. Empleamos pseudo etiquetado a base de conjunto que\nCombina predicciones ponderadas en la confianza del discriminador y el clasificador\ncon consistencia temporal a través de un promedio móvil exponencial, habilitando\nEstimación de etiqueta confiable para datos no etiquetados. Evaluación integral en toda\nOnce conjuntos de datos de Medmnist demuestran que nuestro enfoque logra estadísticamente\nMejoras significativas sobre seis semi-supervisados de última generación\nMétodos, con un rendimiento particularmente fuerte en la configuración extrema de 5 disparos\ndonde la escasez de datos etiquetados es más desafiante. El marco mantiene\nsu superioridad en todos los entornos evaluados (5, 10, 20 y 50 disparos por\nclase). Nuestro enfoque ofrece una solución práctica para imágenes médicas\nAplicaciones donde los costos de anotación son prohibitivos, lo que permite sólidos\nrendimiento de clasificación incluso con datos etiquetados mínimos. El código está disponible en\nhttps://github.com/guidomanni/sparse.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Datos dispersos, resultados ricos: aprendizaje semi-supervisado de pocos disparos a través de la traducción de imágenes acondicionadas\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sparse",
      "data",
      "rich"
    ],
    "category": "noticia"
  },
  {
    "title": "Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation",
    "title_es": "Aprendizaje de atajos en políticas de robot generalistas: el papel de la diversidad y fragmentación del conjunto de datos",
    "url": "http://arxiv.org/abs/2508.06426v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Políticas de robot generalistas capacitadas en conjuntos de datos a gran escala, como el abierto\nEl bodimento X (OXE) demuestra un fuerte rendimiento en una amplia gama de tareas.\nSin embargo, a menudo luchan por generalizar más allá de la distribución de su\nDatos de capacitación. En este artículo, investigamos la causa subyacente de esta\nCapacidad de generalización limitada. Identificamos el aprendizaje de atajos: el\ndependencia de las características irrelevantes de la tarea: como un impedimento clave para la generalización.\nA través del análisis teórico y empírico integral, descubrimos dos\nColaboradores principales para el aprendizaje de atajos: (1) Diversidad limitada dentro de\nsubdatasets individuales y (2) disparidades de distribución significativas entre\nSub-datasets, que conducen a la fragmentación del conjunto de datos. Estos problemas surgen de la\nEstructura inherente de conjuntos de datos a gran escala como OXE, que son típicamente\ncompuesto de múltiples subdatasets recolectados de forma independiente a través de variados\nentornos y realizaciones. Nuestros hallazgos proporcionan ideas críticas sobre\nEstrategias de recopilación de conjuntos de datos que pueden reducir el aprendizaje de acceso directo y mejorar el\nCapacidad de generalización de las políticas de robot generalistas. Además, en escenarios\nDonde adquirir nuevos datos a gran escala no es práctico, demostramos que\nLas estrategias de aumento de datos robóticos cuidadosamente seleccionados pueden reducir efectivamente\nAprendizaje de acceso directo en conjuntos de datos fuera de línea existentes, mejorando así\nCapacidades de generalización de las políticas de robot generalistas, por ejemplo, $ \\ pi_0 $, en\nTanto la simulación como los entornos del mundo real. Más información en\nhttps://lucky-light-sun.github.io/proj/shortcut-lelarning-in-grps/.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Aprendizaje de atajos en políticas de robot generalistas: el papel de la diversidad y fragmentación del conjunto de datos\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "shortcut",
      "learning",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks",
    "title_es": "Caracterización dimensional y modelado de vías para riesgos catastróficos de IA",
    "url": "http://arxiv.org/abs/2508.06411v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Aunque el discurso sobre los riesgos de la inteligencia artificial (IA) ha\ncultivado, a menudo carece de un marco integral y multidimensional y concreto\nCaperas causales Peligro de mapeo para dañar. Este documento tiene como objetivo cerrar esta brecha\nExaminando seis riesgos catastróficos de IA comúnmente discutidos: CBRN, ofensa cibernética,\npérdida repentina de control, pérdida gradual de control, riesgo ambiental y\nRiesgo geopolítico. Primero, caracterizamos estos riesgos en siete clave\ndimensiones, a saber, intención, competencia, entidad, polaridad, linealidad, alcance y\norden. A continuación, realizamos el modelado de la vía de riesgo mediante el mapeo paso a paso\nProgresiones desde el peligro inicial hasta los daños resultantes. El dimensional\nEl enfoque respalda la identificación sistemática del riesgo y la mitigación generalizable\nestrategias, mientras que los modelos de vía de riesgo ayudan a identificar escenarios específicos\nintervenciones. Juntos, estos métodos ofrecen un más estructurado y procesable\nFundación para administrar riesgos catastróficos de IA en la cadena de valor.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Caracterización dimensional y modelado de vías para riesgos catastróficos de IA\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dimensional",
      "characterization",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery",
    "title_es": "Un marco de super resolución consciente de la clasificación para objetivos de barco en imágenes SAR",
    "url": "http://arxiv.org/abs/2508.06407v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Las imágenes de alta resolución juegan un papel fundamental en la mejora del rendimiento de\nTareas de reconocimiento visual como clasificación, detección y segmentación.\nEn muchos dominios, incluida la teledetección y la vigilancia, la baja resolución\nLas imágenes pueden limitar la precisión del análisis automatizado. Para abordar esto,\nSe han adoptado ampliamente las técnicas de súper resolución (SR) para intentar\nReconstruya imágenes de alta resolución a partir de entradas de baja resolución. Relacionado\nLos enfoques tradicionales se centran únicamente en mejorar la calidad de la imagen basada en\nMétricas a nivel de píxel, dejando la relación entre la imagen súper resuelta\nEl rendimiento de la fidelidad y la clasificación aguas abajo en gran medida subexplorada. Este\nplantea una pregunta clave: puede integrar los objetivos de clasificación directamente en\n¿El proceso de súper resolución mejora aún más la precisión de la clasificación? En esto\nDocumento, tratamos de responder a esta pregunta investigando la relación\nEntre la súper resolución y la clasificación a través del despliegue de un\nEstrategia algorítmica especializada. Proponemos una metodología novedosa que aumenta\nLa resolución de las imágenes de radar de apertura sintética al optimizar las funciones de pérdida\nEsa cuenta tanto para la calidad de la imagen como para el rendimiento de la clasificación. Nuestro\nEl enfoque mejora la calidad de la imagen, medido por la comprobación científica\nIndicadores de calidad de imagen, al tiempo que mejoran la precisión de la clasificación.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Un marco de super resolución consciente de la clasificación para objetivos de barco en imágenes SAR\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "classificationaware",
      "superresolution"
    ],
    "category": "noticia"
  },
  {
    "title": "A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges",
    "title_es": "Una revisión de literatura sistemática de la generación de recuperación auggada: técnicas, métricas y desafíos",
    "url": "http://arxiv.org/abs/2508.06401v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Esta revisión sistemática de la literatura de investigación sobre recuperación aumentada\nGeneration (RAG) proporciona un análisis enfocado de los estudios más citados\nPublicado entre 2020 y mayo de 2025. Un total de 128 artículos cumplieron con nuestra inclusión\ncriterios. Los registros fueron recuperados de la biblioteca digital ACM, IEEE Xplore,\nScopus, ScienceDirect y el Proyecto de Bibliografía y Biblioteca Digital (DBLP).\nEl trapo combina un retriever neural con un modelo de lenguaje generativo, con la base\nSalida en memoria no paramétrica actualizada mientras conserva la semántica\nGeneralización almacenada en pesos del modelo. Guiados por el marco Prisma 2020, nosotros\n(i) especificar criterios de inclusión y exclusión explícitos basados en el recuento de citas\ny preguntas de investigación, (ii) conjuntos de datos de catálogo, arquitecturas y evaluación\nprácticas, y (iii) sintetizar evidencia empírica sobre la efectividad y\nLimitaciones del trapo. Para mitigar el sesgo de cita-retraso, aplicamos un\numbral de conteo de citas a los artículos publicados en 2025 para que surgir\nLos avances con menos citas todavía se capturaron. Esta revisión\naclara el panorama de investigación actual, destaca las brechas metodológicas y\nGrabas direcciones prioritarias para futuras investigaciones.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Una revisión de literatura sistemática de la generación de recuperación auggada: técnicas, métricas y desafíos\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "systematic",
      "literature"
    ],
    "category": "noticia"
  },
  {
    "title": "Robust Target Speaker Diarization and Separation via Augmented Speaker Embedding Sampling",
    "title_es": "Diarización y separación del altavoz objetivo robusto a través de un muestreo de incrustación de altavoces aumentados",
    "url": "http://arxiv.org/abs/2508.06393v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Los enfoques tradicionales de separación del habla y diarización de altavoces se basan en\nConocimiento previo de oradores objetivo o un número predeterminado de participantes en\nSeñales de audio. Para abordar estas limitaciones, los avances recientes se centran en\nDesarrollo de métodos sin inscripción capaces de identificar objetivos sin\nEtiquetado de altavoz explícito. Este trabajo introduce un nuevo enfoque para entrenar\nSeparación y diarización del habla simultánea utilizando identificación automática\nde incrustaciones del altavoz objetivo, dentro de las mezclas. Nuestro modelo propuesto emplea un\nTubería de entrenamiento de doble etapa diseñada para aprender una representación sólida de los altavoces\nCaracterísticas que son resistentes a la interferencia de ruido de fondo. Además, nosotros\npresentar una función de pérdida espectral superpuesta específicamente adaptada para\nMejora de la precisión de la diarización durante los marcos de discurso superpuestos. Experimental\nLos resultados muestran ganancias de rendimiento significativas en comparación con la SOTA actual\nlínea de base, logrando el 71% de mejora relativa en DER y 69% en CPWER.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Diarización y separación del altavoz objetivo robusto a través de un muestreo de incrustación de altavoces aumentados\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "robust",
      "target",
      "speaker"
    ],
    "category": "noticia"
  },
  {
    "title": "Identity Increases Stability in Neural Cellular Automata",
    "title_es": "La identidad aumenta la estabilidad en autómatas celulares neuronales",
    "url": "http://arxiv.org/abs/2508.06389v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Los autómatas celulares neurales (NCA) ofrecen una forma de estudiar el crecimiento de\nOrganismos artificiales bidimensionales de una sola célula de semillas. Desde el principio,\nLos organismos cultivados en la NCA han tenido problemas con la estabilidad, su límite natural\na menudo descomponiendo y exhibiendo un crecimiento similar a tumor o no mantener\nla forma esperada. En este artículo, presentamos un método para mejorar el\nEstabilidad de los organismos cultivados en NCA mediante la introducción de una capa de 'identidad' con simple\nrestricciones durante el entrenamiento.\n  Los resultados muestran que los NCA cultivados en proximidad son más estables en comparación con\nEl modelo NCA original. Además, solo se requiere un solo valor de identidad para\nlograr este aumento en la estabilidad. Observamos el movimiento emergente del\norganismos estables, con una prevalencia creciente para modelos con identidad múltiple\nvalores.\n  Este trabajo sienta las bases para un estudio posterior de la interacción entre\nOrganismos cultivados en la NCA, allanando el camino para estudiar la interacción social en un\nNivel celular en organismos artificiales.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"La identidad aumenta la estabilidad en autómatas celulares neuronales\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "identity",
      "increases",
      "stability"
    ],
    "category": "noticia"
  },
  {
    "title": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation",
    "title_es": "Texto a SQL de extremo a extremo con la selección del conjunto de datos: Aprovechando LLM para la generación de consultas adaptativas",
    "url": "http://arxiv.org/abs/2508.06387v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "Texto a SQL une la brecha entre el lenguaje natural y la base de datos estructurada\nLenguaje, lo que permite a los usuarios no técnicos consultar fácilmente bases de datos.\nLos enfoques tradicionales modelan texto a SQL como una tarea de traducción directa, donde un\nDada la consulta del lenguaje natural (NLQ) se asigna a un comando SQL. Avances recientes\nEn modelos de idiomas grandes (LLM) han mejorado significativamente la traducción\nLa precisión, sin embargo, todos estos métodos requieren que la base de datos de destino sea\npreespecificado. Esto se vuelve problemático en escenarios con múltiples extensas\nbases de datos, donde la identificación de la base de datos correcta se convierte en un crucial hasta ahora\npaso por alto. En este artículo, proponemos un texto de extremo a extremo de tres etapas a SQL\nMarco para identificar la base de datos prevista del usuario antes de generar SQL\nconsultas. Nuestro enfoque aprovecha los LLM y la ingeniería rápida para extraer implícitos\nInformación de consultas de lenguaje natural (NLQ) en forma de un conjunto de reglas. Nosotros\nLuego entrene un gran modelo de predicción DB \\ _ID, que incluye un\ncodificador de finetos, para predecir el identificador de base de datos correcto (db \\ _id) basado en\nTanto las reglas generadas por NLQ como las de LLM. Finalmente, refinamos el SQL generado\nmediante el uso de agentes críticos para corregir los errores. Los resultados experimentales demuestran que\nNuestro marco supera a los modelos de estado de arte actuales en ambas bases de datos\nPredicción de intención y precisión de la generación SQL.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Texto a SQL de extremo a extremo con la selección del conjunto de datos: Aprovechando LLM para la generación de consultas adaptativas\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "endtoend",
      "texttosql",
      "with"
    ],
    "category": "noticia"
  },
  {
    "title": "SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with Multimodal Large Language Models",
    "title_es": "Speakerlm: Diarización y reconocimiento de altavoces versátiles de extremo a extremo con modelos de lenguaje grande y multimodal",
    "url": "http://arxiv.org/abs/2508.06372v1",
    "date": "2025-08-08",
    "source": "arXiv",
    "content_es": "La tarea de diarización y reconocimiento del orador (SDR) tiene como objetivo predecir \"quién habló\ncuándo y qué \"dentro de un clip de audio, que es una tarea crucial en varios\nescenarios de múltiples altavoces del mundo real, como la transcripción y el diálogo de reuniones\nsistemas. Los sistemas SDR existentes generalmente adoptan un marco en cascada, combinando\nmúltiples módulos como la diarización del altavoz (SD) y el habla automática\nReconocimiento (ASR). Los sistemas en cascada sufren de varias limitaciones, como\ncomo propagación de errores, dificultad para manejar el discurso superpuesto y la falta de\nOptimización conjunta para explorar la sinergia entre las tareas SD y ASR. A\nabordar estas limitaciones, presentamos SpeakerLM, un gran multimodal unificado\nModelo de idioma para SDR que realiza conjuntamente SD y ASR en un de extremo a extremo\nmanera. Además, para facilitar diversos escenarios del mundo real, incorporamos un\nMecanismo de registro de altavoces flexible en altavoz, habilitando SDR bajo\nDiferentes configuraciones de registro de altavoces. Standerlm se desarrolla progresivamente\ncon una estrategia de entrenamiento en varias etapas sobre datos reales a gran escala. Extenso\nLos experimentos muestran que SpeakerLM demuestra una fuerte capacidad de escala de datos y\ngeneralización, superando las líneas de base en cascada de última generación en ambos\nEn el dominio y fuera de dominio Public SDR puntos de referencia. Además, experimental\nLos resultados muestran que el mecanismo de registro del altavoz propuesto de manera efectiva\nAsegura un rendimiento sólido de SDR de altavoz en diversos registros de altavoces\nCondiciones y números variables de altavoces registrados.",
    "published": "2025-08-08T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Speakerlm: Diarización y reconocimiento de altavoces versátiles de extremo a extremo con modelos de lenguaje grande y multimodal\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "speakerlm",
      "endtoend",
      "versatile"
    ],
    "category": "noticia"
  },
  {
    "title": "The membrane skeleton is constitutively remodeled in neurons by calcium signaling",
    "url": "https://www.science.org/doi/abs/10.1126/science.adn6712",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org",
    "title_es": "The membrane skeleton is constitutively remodeled in neurons by calcium signaling",
    "summary_es": "Science, volumen 389, número 6760, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "description": "Este artículo trata sobre \"The membrane skeleton is constitutively remodeled in neurons by calcium signaling\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "membrane",
      "skeleton"
    ],
    "category": "noticia"
  },
  {
    "title": "Cysteinyl leukotrienes stimulate gut absorption of food allergens to promote anaphylaxis in mice",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp0240",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org",
    "title_es": "Cysteinyl leukotrienes stimulate gut absorption of food allergens to promote anaphylaxis in mice",
    "summary_es": "Science, volumen 389, número 6760, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "description": "Este artículo trata sobre \"Cysteinyl leukotrienes stimulate gut absorption of food allergens to promote anaphylaxis in mice\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cysteinyl",
      "leukotrienes",
      "stimulate"
    ],
    "category": "noticia"
  },
  {
    "title": "Intestinal mast cell–derived leukotrienes mediate the anaphylactic response to ingested antigens",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp0246",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org",
    "title_es": "Intestinal mast cell–derived leukotrienes mediate the anaphylactic response to ingested antigens",
    "summary_es": "Science, volumen 389, número 6760, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "description": "Este artículo trata sobre \"Intestinal mast cell–derived leukotrienes mediate the anaphylactic response to ingested antigens\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "intestinal",
      "mast",
      "cellderived"
    ],
    "category": "noticia"
  },
  {
    "title": "Transferrin receptor–targeted anti-amyloid antibody enhances brain delivery and mitigates ARIA",
    "url": "https://www.science.org/doi/abs/10.1126/science.ads3204",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org",
    "title_es": "Transferrin receptor–targeted anti-amyloid antibody enhances brain delivery and mitigates ARIA",
    "summary_es": "Science, volumen 389, número 6760, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "description": "Este artículo trata sobre \"Transferrin receptor–targeted anti-amyloid antibody enhances brain delivery and mitigates ARIA\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "transferrin",
      "receptortargeted",
      "antiamyloid"
    ],
    "category": "noticia"
  },
  {
    "title": "Predicting expression-altering promoter mutations with deep learning",
    "url": "https://www.science.org/doi/abs/10.1126/science.ads7373",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org",
    "title_es": "Predicting expression-altering promoter mutations with deep learning",
    "summary_es": "Science, volumen 389, número 6760, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "description": "Este artículo trata sobre \"Predicting expression-altering promoter mutations with deep learning\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "predicting",
      "expressionaltering",
      "promoter"
    ],
    "category": "noticia"
  },
  {
    "title": "Census in crisis—further erasure of Indigenous Peoples?",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea0932",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, August 2025.",
    "source": "Science.org",
    "title_es": "Census in crisis—further erasure of Indigenous Peoples?",
    "summary_es": "Science, volumen 389, número 6760, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, August 2025.",
    "description": "Este artículo trata sobre \"Census in crisis—further erasure of Indigenous Peoples?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "census",
      "in",
      "crisisfurther"
    ],
    "category": "noticia"
  },
  {
    "title": "Revisiting the human sociobiology debate",
    "url": "https://www.science.org/doi/abs/10.1126/science.ady6081",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 580-581, August 2025.",
    "source": "Science.org",
    "title_es": "Revisiting the human sociobiology debate",
    "summary_es": "Science, volumen 389, número 6760, páginas 580-581, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 580-581, August 2025.",
    "description": "Este artículo trata sobre \"Revisiting the human sociobiology debate\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "revisiting",
      "the",
      "human"
    ],
    "category": "noticia"
  },
  {
    "title": "An orthogonal T7 replisome for continuous hypermutation and accelerated evolution in E. coli",
    "url": "https://www.science.org/doi/abs/10.1126/science.adp9583",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 618-622, August 2025.",
    "source": "Science.org",
    "title_es": "An orthogonal T7 replisome for continuous hypermutation and accelerated evolution in E. coli",
    "summary_es": "Science, volumen 389, número 6760, páginas 618-622, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 618-622, August 2025.",
    "description": "Este artículo trata sobre \"An orthogonal T7 replisome for continuous hypermutation and accelerated evolution in E. coli\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "an",
      "orthogonal",
      "t"
    ],
    "category": "noticia"
  },
  {
    "title": "Radular teeth matrix protein 1 directs iron oxide deposition in chiton teeth",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu0043",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 637-643, August 2025.",
    "source": "Science.org",
    "title_es": "Radular teeth matrix protein 1 directs iron oxide deposition in chiton teeth",
    "summary_es": "Science, volumen 389, número 6760, páginas 637-643, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 637-643, August 2025.",
    "description": "Este artículo trata sobre \"Radular teeth matrix protein 1 directs iron oxide deposition in chiton teeth\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "radular",
      "teeth",
      "matrix"
    ],
    "category": "noticia"
  },
  {
    "title": "Imaging collective quantum fluctuations of the structure of a complex molecule",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu2637",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 650-654, August 2025.",
    "source": "Science.org",
    "title_es": "Imaging collective quantum fluctuations of the structure of a complex molecule",
    "summary_es": "Science, volumen 389, número 6760, páginas 650-654, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 650-654, August 2025.",
    "description": "Este artículo trata sobre \"Imaging collective quantum fluctuations of the structure of a complex molecule\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "imaging",
      "collective",
      "quantum"
    ],
    "category": "noticia"
  },
  {
    "title": "Single-photon detection enabled by negative differential conductivity in moiré superlattices",
    "url": "https://www.science.org/doi/abs/10.1126/science.adu5329",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 644-649, August 2025.",
    "source": "Science.org",
    "title_es": "Single-photon detection enabled by negative differential conductivity in moiré superlattices",
    "summary_es": "Science, volumen 389, número 6760, páginas 644-649, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 644-649, August 2025.",
    "description": "Este artículo trata sobre \"Single-photon detection enabled by negative differential conductivity in moiré superlattices\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "singlephoton",
      "detection",
      "enabled"
    ],
    "category": "noticia"
  },
  {
    "title": "Three-dimensional nucleation and growth of deformation twins in magnesium",
    "url": "https://www.science.org/doi/abs/10.1126/science.adv3460",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 632-636, August 2025.",
    "source": "Science.org",
    "title_es": "Three-dimensional nucleation and growth of deformation twins in magnesium",
    "summary_es": "Science, volumen 389, número 6760, páginas 632-636, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 632-636, August 2025.",
    "description": "Este artículo trata sobre \"Three-dimensional nucleation and growth of deformation twins in magnesium\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "threedimensional",
      "nucleation",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Strain-coupled, crystalline polymer-inorganic interfaces for efficient magnetoelectric sensing",
    "url": "https://www.science.org/doi/abs/10.1126/science.adt2741",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 623-631, August 2025.",
    "source": "Science.org",
    "title_es": "Strain-coupled, crystalline polymer-inorganic interfaces for efficient magnetoelectric sensing",
    "summary_es": "Science, volumen 389, número 6760, páginas 623-631, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 623-631, August 2025.",
    "description": "Este artículo trata sobre \"Strain-coupled, crystalline polymer-inorganic interfaces for efficient magnetoelectric sensing\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "straincoupled",
      "crystalline",
      "polymerinorganic"
    ],
    "category": "noticia"
  },
  {
    "title": "The multifunctional immune system",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea8294",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 586-587, August 2025.",
    "source": "Science.org",
    "title_es": "The multifunctional immune system",
    "summary_es": "Science, volumen 389, número 6760, páginas 586-587, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 586-587, August 2025.",
    "description": "Este artículo trata sobre \"The multifunctional immune system\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "multifunctional",
      "immune"
    ],
    "category": "noticia"
  },
  {
    "title": "Immune system influence on physiology",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4380",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 594-599, August 2025.",
    "source": "Science.org",
    "title_es": "Immune system influence on physiology",
    "summary_es": "Science, volumen 389, número 6760, páginas 594-599, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 594-599, August 2025.",
    "description": "Este artículo trata sobre \"Immune system influence on physiology\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "immune",
      "system",
      "influence"
    ],
    "category": "noticia"
  },
  {
    "title": "Sex differences in tissue-specific immunity and immunology",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4381",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 599-603, August 2025.",
    "source": "Science.org",
    "title_es": "Sex differences in tissue-specific immunity and immunology",
    "summary_es": "Science, volumen 389, número 6760, páginas 599-603, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 599-603, August 2025.",
    "description": "Este artículo trata sobre \"Sex differences in tissue-specific immunity and immunology\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sex",
      "differences",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Convergence and divergence of individual immune responses over the life course",
    "url": "https://www.science.org/doi/abs/10.1126/science.ady9543",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 604-609, August 2025.",
    "source": "Science.org",
    "title_es": "Convergence and divergence of individual immune responses over the life course",
    "summary_es": "Science, volumen 389, número 6760, páginas 604-609, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 604-609, August 2025.",
    "description": "Este artículo trata sobre \"Convergence and divergence of individual immune responses over the life course\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "convergence",
      "and",
      "divergence"
    ],
    "category": "noticia"
  },
  {
    "title": "Evolution of antiviral host defenses against a backdrop of endogenous retroelements",
    "url": "https://www.science.org/doi/abs/10.1126/science.adx4379",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 588-593, August 2025.",
    "source": "Science.org",
    "title_es": "Evolution of antiviral host defenses against a backdrop of endogenous retroelements",
    "summary_es": "Science, volumen 389, número 6760, páginas 588-593, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 588-593, August 2025.",
    "description": "Este artículo trata sobre \"Evolution of antiviral host defenses against a backdrop of endogenous retroelements\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "evolution",
      "of",
      "antiviral"
    ],
    "category": "noticia"
  },
  {
    "title": "How a diagnosis altered my path",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb1444",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 658-658, August 2025.",
    "source": "Science.org",
    "title_es": "How a diagnosis altered my path",
    "summary_es": "Science, volumen 389, número 6760, páginas 658-658, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 658-658, August 2025.",
    "description": "Este artículo trata sobre \"How a diagnosis altered my path\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "how",
      "a",
      "diagnosis"
    ],
    "category": "noticia"
  },
  {
    "title": "In Other Journals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2040",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 611-612, August 2025.",
    "source": "Science.org",
    "title_es": "In Other Journals",
    "summary_es": "Science, volumen 389, número 6760, páginas 611-612, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 611-612, August 2025.",
    "description": "Este artículo trata sobre \"In Other Journals\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "in",
      "other",
      "journals"
    ],
    "category": "revista"
  },
  {
    "title": "Moiré eyes detect the dim",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea5235",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 570-570, August 2025.",
    "source": "Science.org",
    "title_es": "Moiré eyes detect the dim",
    "summary_es": "Science, volumen 389, número 6760, páginas 570-570, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 570-570, August 2025.",
    "description": "Este artículo trata sobre \"Moiré eyes detect the dim\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "moiré",
      "eyes",
      "detect"
    ],
    "category": "noticia"
  },
  {
    "title": "Opening the gateway to food-induced anaphylaxis",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz6439",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 573-574, August 2025.",
    "source": "Science.org",
    "title_es": "Opening the gateway to food-induced anaphylaxis",
    "summary_es": "Science, volumen 389, número 6760, páginas 573-574, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 573-574, August 2025.",
    "description": "Este artículo trata sobre \"Opening the gateway to food-induced anaphylaxis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "opening",
      "the",
      "gateway"
    ],
    "category": "noticia"
  },
  {
    "title": "Hardening nature’s toughest teeth",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz8241",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 568-569, August 2025.",
    "source": "Science.org",
    "title_es": "Hardening nature’s toughest teeth",
    "summary_es": "Science, volumen 389, número 6760, páginas 568-569, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 568-569, August 2025.",
    "description": "Este artículo trata sobre \"Hardening nature’s toughest teeth\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hardening",
      "natures",
      "toughest"
    ],
    "category": "noticia"
  },
  {
    "title": "Improving Alzheimer’s disease immunotherapy",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz8959",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 571-572, August 2025.",
    "source": "Science.org",
    "title_es": "Improving Alzheimer’s disease immunotherapy",
    "summary_es": "Science, volumen 389, número 6760, página 571-572, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 571-572, August 2025.",
    "description": "Este artículo trata sobre \"Improving Alzheimer’s disease immunotherapy\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "improving",
      "alzheimers",
      "disease"
    ],
    "category": "noticia"
  },
  {
    "title": "NextGen Voices: National Assessments in Verse",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2043",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 584-584, August 2025.",
    "source": "Science.org",
    "title_es": "NextGen Voices: National Assessments in Verse",
    "summary_es": "Science, volumen 389, número 6760, páginas 584-584, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 584-584, August 2025.",
    "description": "Este artículo trata sobre \"NextGen Voices: National Assessments in Verse\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nextgen",
      "voices",
      "national"
    ],
    "category": "noticia"
  },
  {
    "title": "Brazil’s dangerous environmental licensing bill",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea7981",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 583-584, August 2025.",
    "source": "Science.org",
    "title_es": "Brazil’s dangerous environmental licensing bill",
    "summary_es": "Science, volumen 389, número 6760, páginas 583-584, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 583-584, August 2025.",
    "description": "Este artículo trata sobre \"Brazil’s dangerous environmental licensing bill\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "brazils",
      "dangerous",
      "environmental"
    ],
    "category": "noticia"
  },
  {
    "title": "Community support for inclusive US education",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz3963",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 584-584, August 2025.",
    "source": "Science.org",
    "title_es": "Community support for inclusive US education",
    "summary_es": "Science, volumen 389, número 6760, páginas 584-584, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 584-584, August 2025.",
    "description": "Este artículo trata sobre \"Community support for inclusive US education\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "community",
      "support",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Brazil’s “devastation bill” empowers criminals",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz7734",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 583-583, August 2025.",
    "source": "Science.org",
    "title_es": "Brazil’s “devastation bill” empowers criminals",
    "summary_es": "Science, volumen 389, número 6760, páginas 583-583, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 583-583, August 2025.",
    "description": "Este artículo trata sobre \"Brazil’s “devastation bill” empowers criminals\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "brazils",
      "devastation",
      "bill"
    ],
    "category": "noticia"
  },
  {
    "title": "Study used DNA from thousands—without consent",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2395",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 552-553, August 2025.",
    "source": "Science.org",
    "title_es": "Study used DNA from thousands—without consent",
    "summary_es": "Science, volumen 389, número 6760, páginas 552-553, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 552-553, August 2025.",
    "description": "Este artículo trata sobre \"Study used DNA from thousands—without consent\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "study",
      "used",
      "dna"
    ],
    "category": "noticia"
  },
  {
    "title": "Senate panel rejects Trump’s plan to slash NIH’s budget",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2396",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 554-555, August 2025.",
    "source": "Science.org",
    "title_es": "Senate panel rejects Trump’s plan to slash NIH’s budget",
    "summary_es": "Science, volumen 389, número 6760, páginas 554-555, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 554-555, August 2025.",
    "description": "Este artículo trata sobre \"Senate panel rejects Trump’s plan to slash NIH’s budget\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "senate",
      "panel",
      "rejects"
    ],
    "category": "noticia"
  },
  {
    "title": "Thank ketchup, and interbreeding, for your French fries",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2397",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 556-556, August 2025.",
    "source": "Science.org",
    "title_es": "Thank ketchup, and interbreeding, for your French fries",
    "summary_es": "Science, volumen 389, número 6760, páginas 556-556, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 556-556, August 2025.",
    "description": "Este artículo trata sobre \"Thank ketchup, and interbreeding, for your French fries\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "thank",
      "ketchup",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Study reveals industrial-scale publishing fraud",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2398",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 557-558, August 2025.",
    "source": "Science.org",
    "title_es": "Study reveals industrial-scale publishing fraud",
    "summary_es": "Science, volumen 389, número 6760, páginas 557-558, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 557-558, August 2025.",
    "description": "Este artículo trata sobre \"Study reveals industrial-scale publishing fraud\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "study",
      "reveals",
      "industrialscale"
    ],
    "category": "noticia"
  },
  {
    "title": "AI-generated text surges in research papers",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2399",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 558-559, August 2025.",
    "source": "Science.org",
    "title_es": "AI-generated text surges in research papers",
    "summary_es": "Science, volumen 389, número 6760, página 558-559, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 558-559, August 2025.",
    "description": "Este artículo trata sobre \"AI-generated text surges in research papers\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "aigenerated",
      "text",
      "surges"
    ],
    "category": "noticia"
  },
  {
    "title": "Losing protection",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2041",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 560-567, August 2025.",
    "source": "Science.org",
    "title_es": "Losing protection",
    "summary_es": "Science, volumen 389, número 6760, páginas 560-567, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 560-567, August 2025.",
    "description": "Este artículo trata sobre \"Losing protection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "losing",
      "protection"
    ],
    "category": "noticia"
  },
  {
    "title": "New Products",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb1446",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 655-655, August 2025.",
    "source": "Science.org",
    "title_es": "New Products",
    "summary_es": "Science, volumen 389, número 6760, páginas 655-655, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 655-655, August 2025.",
    "description": "Este artículo trata sobre \"New Products\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "new",
      "products"
    ],
    "category": "noticia"
  },
  {
    "title": "Quantum technology governance: A standards-first approach",
    "url": "https://www.science.org/doi/abs/10.1126/science.adw0018",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 575-578, August 2025.",
    "source": "Science.org",
    "title_es": "Quantum technology governance: A standards-first approach",
    "summary_es": "Science, Volume 389, Issue 6760, Page 575-578, August 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 575-578, August 2025.",
    "description": "Este artículo trata sobre \"Quantum technology governance: A standards-first approach\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "quantum",
      "technology",
      "governance"
    ],
    "category": "noticia"
  },
  {
    "title": "In Science Journals",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb2039",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "Science, Volume 389, Issue 6760, Page 610-612, August 2025.",
    "source": "Science.org",
    "title_es": "In Science Journals",
    "summary_es": "Science, Volume 389, Issue 6760, Page 610-612, August 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 610-612, August 2025.",
    "description": "Este artículo trata sobre \"In Science Journals\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "in",
      "science",
      "journals"
    ],
    "category": "revista"
  },
  {
    "title": "Globally recognized island is losing its trademark glaciers",
    "url": "https://www.nature.com/articles/d41586-025-02473-2",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "",
    "source": "Nature",
    "title_es": "Globally recognized island is losing its trademark glaciers",
    "summary_es": "",
    "content_es": "Globally recognized island is losing its trademark glaciers",
    "description": "Este artículo trata sobre \"Globally recognized island is losing its trademark glaciers\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "globally",
      "recognized",
      "island"
    ],
    "category": "noticia"
  },
  {
    "title": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "url": "https://www.nature.com/articles/d41586-025-02505-x",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "",
    "source": "Nature",
    "title_es": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "summary_es": "",
    "content_es": "Outrage over Trump team’s climate report spurs researchers to fight back",
    "description": "Este artículo trata sobre \"Outrage over Trump team’s climate report spurs researchers to fight back\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "outrage",
      "over",
      "trump"
    ],
    "category": "noticia"
  },
  {
    "title": "How researcher visa curbs threaten science careers",
    "url": "https://www.nature.com/articles/d41586-025-02293-4",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "",
    "source": "Nature",
    "title_es": "How researcher visa curbs threaten science careers",
    "summary_es": "",
    "content_es": "How researcher visa curbs threaten science careers",
    "description": "Este artículo trata sobre \"How researcher visa curbs threaten science careers\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "how",
      "researcher",
      "visa"
    ],
    "category": "noticia"
  },
  {
    "title": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "url": "https://www.nature.com/articles/d41586-025-02512-y",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "",
    "source": "Nature",
    "title_es": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "summary_es": "",
    "content_es": "‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima",
    "description": "Este artículo trata sobre \"‘A biographer’s dream’: this physicist investigated UFOs and flew over Hiroshima\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "biographers",
      "dream"
    ],
    "category": "noticia"
  },
  {
    "title": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "url": "https://www.nature.com/articles/d41586-025-02515-9",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "",
    "source": "Nature",
    "title_es": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "summary_es": "",
    "content_es": "George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images",
    "description": "Este artículo trata sobre \"George E. Smith obituary: co-inventor of the charge coupled device, which ushered in an era of digital images\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "george",
      "e",
      "smith"
    ],
    "category": "noticia"
  },
  {
    "title": "These genes can have the opposite effects depending on which parent they came from",
    "url": "https://www.nature.com/articles/d41586-025-02499-6",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "",
    "source": "Nature",
    "title_es": "These genes can have the opposite effects depending on which parent they came from",
    "content_es": "These genes can have the opposite effects depending on which parent they came from",
    "description": "Este artículo trata sobre \"These genes can have the opposite effects depending on which parent they came from\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "these",
      "genes",
      "can"
    ],
    "category": "noticia"
  },
  {
    "title": "Alien planet glimpsed in star's 'habitable zone'",
    "url": "https://www.nature.com/articles/d41586-025-02549-z",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "",
    "source": "Nature",
    "title_es": "Alien planet glimpsed in star's 'habitable zone'",
    "content_es": "Alien planet glimpsed in star's 'habitable zone'",
    "description": "Este artículo trata sobre \"Alien planet glimpsed in star's 'habitable zone'\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "alien",
      "planet",
      "glimpsed"
    ],
    "category": "noticia"
  },
  {
    "title": "Monoclonal antibodies revolutionized biomedical science and health care",
    "url": "https://www.nature.com/articles/d41586-025-02452-7",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "",
    "source": "Nature",
    "title_es": "Monoclonal antibodies revolutionized biomedical science and health care",
    "content_es": "Monoclonal antibodies revolutionized biomedical science and health care",
    "description": "Este artículo trata sobre \"Monoclonal antibodies revolutionized biomedical science and health care\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "monoclonal",
      "antibodies",
      "revolutionized"
    ],
    "category": "noticia"
  },
  {
    "title": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "url": "https://www.nature.com/articles/d41586-025-02559-x",
    "published": "2025-08-07T00:00:00.000Z",
    "date": "2025-08-07",
    "summary": "",
    "source": "Nature",
    "title_es": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "content_es": "Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice",
    "description": "Este artículo trata sobre \"Daily briefing: Lithium supplements reverse Alzheimer’s symptoms in mice\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "daily",
      "briefing",
      "lithium"
    ],
    "category": "noticia"
  },
  {
    "title": "Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling",
    "title_es": "Hacia la seguridad generalizable en la navegación de la multitud a través del manejo de incertidumbre conforme",
    "url": "http://arxiv.org/abs/2508.05634v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Los robots móviles que navegan en multitudes entrenadas con aprendizaje de refuerzo son\nconocido por sufrir la degradación del desempeño cuando se enfrenta a una distribución fuera de distribución\nescenarios. Proponemos que al tener en cuenta adecuadamente las incertidumbres de\nPeatones, un robot puede aprender políticas de navegación seguras que son robustas para\ncambios de distribución. Nuestro método aumenta las observaciones del agente con predicción\nEstimaciones de incertidumbre generadas por la inferencia conforme adaptativa, y utiliza\nEstas estimaciones para guiar el comportamiento del agente a través de un refuerzo restringido\naprendiendo. El sistema ayuda a regular las acciones del agente y le permite adaptarse\na los cambios de distribución. En el entorno de distribución, nuestro enfoque logra un\n96.93% de tasa de éxito, que es más de 8.80% más alta que la anterior\nlíneas de base de última generación con más de 3.72 veces menos colisiones y 2.43 veces\nMenos intrusiones en las trayectorias futuras humanas de la verdad en tierra. En tres\nescenarios fuera de distribución, nuestro método muestra una robustez mucho más fuerte cuando\nenfrentar los cambios de distribución en las variaciones de velocidad, cambios de política y\nTransiciones de dinámica individual a grupo. Implementamos nuestro método en un verdadero\nRobot, y los experimentos muestran que el robot toma decisiones seguras y robustas cuando\ninteractuando con multitudes tanto escasas como densas. Nuestro código y videos son\nDisponible en https://gen-safe-sav.github.io/.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Hacia la seguridad generalizable en la navegación de la multitud a través del manejo de incertidumbre conforme\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "towards",
      "generalizable",
      "safety"
    ],
    "category": "noticia"
  },
  {
    "title": "KuaiLive: A Real-time Interactive Dataset for Live Streaming Recommendation",
    "title_es": "Kuailive: un conjunto de datos interactivo en tiempo real para recomendación de transmisión en vivo",
    "url": "http://arxiv.org/abs/2508.05633v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Las plataformas de transmisión en vivo se han convertido en una forma dominante de contenido en línea\nconsumo, ofreciendo contenido en evolución dinámica, interacciones en tiempo real y\nExperiencias de usuario altamente atractivas. Estas características únicas introducen nuevas\ndesafíos que diferencian la recomendación de transmisión en vivo de la tradicional\nconfiguración de recomendación y ha atraído la mayor atención de la industria en\naños recientes. Sin embargo, el progreso de la investigación en la academia ha sido obstaculizado por el\nFalta de conjuntos de datos disponibles públicamente que reflejan con precisión la naturaleza dinámica\nde entornos de transmisión en vivo. Para abordar esta brecha, presentamos a Kuailive, el\nPrimer conjunto de datos interactivo en tiempo real recopilado de Kuaishou, un líder en vivo\nPlataforma de transmisión en China con más de 400 millones de usuarios activos diarios. El\nDataSet registra los registros de interacción de 23,772 usuarios y 452,621 transmisores sobre\nun período de 21 días. En comparación con los conjuntos de datos existentes, Kuailive ofrece varios\nVentajas: Incluye marcas de tiempo de inicio y finalización de sala en vivo precisas, múltiples\nTipos de interacciones de usuario en tiempo real (haga clic, comente, me gusta, regalo) y rico\nCaracterísticas de información secundaria tanto para usuarios como para transmisores. Estas características habilitan\nsimulación más realista de elementos candidatos dinámicos y un mejor modelado de\ncomportamientos de usuario y streamer. Realizamos un análisis exhaustivo de Kuailive desde\nmúltiples perspectivas y evaluar varias recomendaciones representativas\nMétodos sobre él, estableciendo un punto de referencia fuerte para futuras investigaciones. Kuailive\npuede admitir una amplia gama de tareas en el dominio de transmisión en vivo, como Top-K\nRecomendación, predicción de tasa de clics, predicción de tiempo de observación y regalo\nPredicción de precios. Además, sus datos de comportamiento de grano fino también permiten\nInvestigación sobre modelado de múltiples paseos, aprendizaje de tareas múltiples y conscientes de la equidad\nrecomendación. El conjunto de datos y los recursos relacionados están disponibles públicamente en\nhttps://imgkkk574.github.io/kuailive.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Kuailive: un conjunto de datos interactivo en tiempo real para recomendación de transmisión en vivo\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "kuailive",
      "a",
      "realtime"
    ],
    "category": "noticia"
  },
  {
    "title": "H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages",
    "title_es": "H-NET ++: fragmentación dinámica jerárquica para modelado de idiomas sin tokenizador en idiomas morfológicamente ricos",
    "url": "http://arxiv.org/abs/2508.05628v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Los modelos de idiomas a nivel de byte eliminan los tokenizadores frágiles pero la cara\nDesafíos computacionales en idiomas morfológicamente ricos (MRL), donde las palabras\nabarcan muchos bytes. Proponemos H-Net ++, un modelo jerárquico de choque dinámico que\nAprende segmentación lingüísticamente informada a través de la capacitación de extremo a extremo. Llave\nLas innovaciones incluyen: (1) un mixer de contexto de transformador liviano (1.9m\nparámetros) para la atención de la entrevía, (2) un hiper-prior latente de dos niveles para\nconsistencia a nivel de documento, (3) manejo especializado de artefactos ortográficos\n(por ejemplo, persa ZWNJ) y (4) entrenamiento basado en el plan de estudios con secuencia escenificada\nlongitudes. En un corpus persa de 1.4b-token, H-Net ++ logra\nResultados: 0.159 BPB Reducción versus GPT-2-FA basada en BPE (12% mejor\ncompresión), ganancia de 5.4pp en Parsglue, 53% mejoró la robustez a ZWNJ\nCorrupción y 73.8% F1 en los límites morfológicos de oro. Nuestros trozos aprendidos\nalinearse con la morfología persa sin supervisión explícita, demostrando que\nLa fragmentación dinámica jerárquica proporciona una solución efectiva sin tokenizador para\nMRL mientras mantiene la eficiencia computacional.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"H-NET ++: fragmentación dinámica jerárquica para modelado de idiomas sin tokenizador en idiomas morfológicamente ricos\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hnet",
      "hierarchical",
      "dynamic"
    ],
    "category": "noticia"
  },
  {
    "title": "How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations",
    "title_es": "¿Cómo persuaden los LLM? Las sondas lineales pueden descubrir la dinámica de la persuasión en conversaciones múltiples",
    "url": "http://arxiv.org/abs/2508.05625v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Los modelos de idiomas grandes (LLM) han comenzado a demostrar la capacidad de\npersuadir a los humanos, sin embargo, nuestra comprensión de cómo se produce esta dinámica\nlimitado. El trabajo reciente ha utilizado sondas lineales, herramientas livianas para analizar\nRepresentaciones de modelos, para estudiar varias habilidades de LLM, como la capacidad de modelar\nSentimiento de usuario y perspectiva política. Motivado por esto, aplicamos sondas a\nEstudie la dinámica de la persuasión en conversaciones naturales de giro múltiple. Aprovechamos\nideas de la ciencia cognitiva para entrenar sondas sobre aspectos distintos de\nPersuasión: éxito de persuasión, personalidad persuadee y estrategia de persuasión.\nA pesar de su simplicidad, mostramos que capturan varios aspectos de\nPersuasión tanto a nivel de muestra como de conjunto de datos. Por ejemplo, las sondas pueden\nidentificar el punto en una conversación donde se persuadió el persuadee o donde\nEl éxito persuasivo generalmente ocurre en todo el conjunto de datos. También mostramos\nque además de ser más rápido que los enfoques basados en la solicitud costosos,\nLas sondas pueden hacer igual de bien e incluso superar la solicitud en algunas configuraciones, como\ncomo al descubrir la estrategia de persuasión. Esto sugiere sondas como una plausible\navenida para estudiar otros comportamientos complejos como el engaño y\nManipulación, especialmente en configuraciones de múltiples vueltas y conjunto de datos a gran escala\nAnálisis donde los métodos basados en la solicitud serían computacionalmente ineficientes.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"¿Cómo persuaden los LLM? Las sondas lineales pueden descubrir la dinámica de la persuasión en conversaciones múltiples\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "how",
      "do",
      "llms"
    ],
    "category": "noticia"
  },
  {
    "title": "Simulating Human-Like Learning Dynamics with LLM-Empowered Agents",
    "title_es": "Simulando la dinámica de aprendizaje de tipo humano con agentes empoderados con LLM",
    "url": "http://arxiv.org/abs/2508.05622v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Capturar el comportamiento de aprendizaje humano basado en métodos de aprendizaje profundo se ha convertido en un\nEl principal enfoque de investigación en psicología y sistemas inteligentes. Reciente\nLos enfoques se basan en experimentos controlados o modelos basados en reglas para explorar\nProcesos cognitivos. Sin embargo, luchan por capturar la dinámica del aprendizaje, rastrear\nprogresar con el tiempo o proporcionar explicación. Para abordar estos desafíos, nosotros\nIntroducir a LearnerAgent, un nuevo marco de agente múltiple basado en un lenguaje grande\nModelos (LLM) para simular un entorno de enseñanza realista. Para explorar\nDinámica de aprendizaje similar a la humana, construimos alumnos con psicológicamente\nPerfiles conectados a tierra como profundos, superficiales y perezosos, así como una persona sin persona\nAlumno general para inspeccionar el comportamiento predeterminado de la base de LLM. A través de Weekly\nAdquisición de conocimiento, opciones estratégicas mensuales, pruebas periódicas y pares\ninteracción, podemos rastrear el progreso de aprendizaje dinámico de los alumnos individuales\ndurante un viaje de todo el año. Nuestros hallazgos son cuádruples: 1) Análisis longitudinal\nrevela que solo el alumno profundo logra un crecimiento cognitivo sostenido. Nuestro\n\"Preguntas de trampa\" especialmente diseñadas diagnostican efectivamente el alumno de superficie\nConocimiento superficial. 2) Los patrones conductuales y cognitivos de distintos\nLos alumnos se alinean estrechamente con sus perfiles psicológicos. 3) los alumnos '\nLos puntajes de autoconcepto evolucionan de manera realista, con el alumno general en desarrollo\nSorprendentemente alta autoeficacia a pesar de sus limitaciones cognitivas. 4)\nCríticamente, el perfil predeterminado de Base LLM es una \"superficie diligente pero frágil\nAlumno \", un agente que imita los comportamientos de un buen estudiante pero carece de verdad,\ncomprensión generalizable. Extensos experimentos de simulación demuestran que\nLearneragent se alinea bien con escenarios reales, produciendo hallazgos más perspicaces\nsobre el comportamiento de LLMS.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Simulando la dinámica de aprendizaje de tipo humano con agentes empoderados con LLM\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "simulating",
      "humanlike",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "The Missing Reward: Active Inference in the Era of Experience",
    "title_es": "La recompensa que falta: inferencia activa en la era de la experiencia",
    "url": "http://arxiv.org/abs/2508.05619v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Este artículo argumenta que la inferencia activa (AIF) proporciona una base crucial\npara desarrollar agentes de IA autónomos capaces de aprender de la experiencia sin\nIngeniería de recompensas humanas continuas. A medida que los sistemas de IA comienzan a agotar\ndatos de entrenamiento de alta calidad y confiar en fuerzas de trabajo humanas cada vez más grandes para\nDiseño de recompensa, el paradigma actual enfrenta desafíos de escalabilidad significativos\nEso podría impedir el progreso hacia una inteligencia genuinamente autónoma. El\nPropuesta para una `` era de experiencia '', donde los agentes aprenden de los autogenerados\nLos datos, son un paso prometedor adelante. Sin embargo, esta visión aún depende de\nIngeniería humana extensa de funciones de recompensa, cambiando efectivamente el\nCuello de botella de la curación de datos a la curación de recompensas. Esto resalta lo que nosotros\nIdentificar como el \\ textbf {GAP de agencia a tierra}: la incapacidad de la IA contemporánea\nsistemas para formular, adaptarse y perseguir de forma autónoma en respuesta a\ncircunstancias cambiantes. Proponemos que AIF pueda cerrar esta brecha reemplazando\nSeñales de recompensa externas con un disco intrínseco para minimizar la energía libre,\npermitiendo que los agentes equilibren naturalmente la exploración y la explotación a través de un\nObjetivo bayesiano unificado. Integrando modelos de idiomas grandes como generativo\nModelos mundiales con el marco de toma de decisiones de principios de AIF, podemos crear\nagentes que aprenden eficientemente de la experiencia mientras permanecen alineados con\nvalores humanos. Esta síntesis ofrece un camino convincente hacia los sistemas de IA que\npuede desarrollarse de forma autónoma mientras se adhiere tanto a la computación como a\nrestricciones.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"La recompensa que falta: inferencia activa en la era de la experiencia\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "missing",
      "reward"
    ],
    "category": "noticia"
  },
  {
    "title": "TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution",
    "title_es": "Trajevo: Diseño de heurística de predicción de trayectoria a través de la evolución dirigida por LLM",
    "url": "http://arxiv.org/abs/2508.05616v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "La predicción de la trayectoria es una tarea crítica para modelar el comportamiento humano,\nespecialmente en dominios críticos de seguridad, como robótica social y autónoma\nNavegación de vehículos. Heurística tradicional basada en reglas artesanales a menudo\nFalta de precisión y generalización. Aunque ofrecen enfoques de aprendizaje profundo\nmejor rendimiento, generalmente sufren de alto costo computacional,\nExplicación limitada y, lo que es más importante, una pobre generalización para\nEscenarios fuera de distribución (OOD). En este artículo, presentamos a Trajevo, un\nMarco que aprovecha los modelos de idiomas grandes (LLM) para diseñar automáticamente\nTrayectoria Predicción Heurística. Trajevo emplea un algoritmo evolutivo para\nGenere y refine la heurística de predicción a partir de datos de trayectoria pasados. Proponemos\nDos innovaciones clave: muestreo de élite de generación cruzada para alentar la población\ndiversidad y un bucle de retroalimentación estadística que permite al LLM analizar y\nmejorar las predicciones alternativas. Nuestras evaluaciones demuestran que Trajevo\nSuperación supera los métodos heurísticos existentes en múltiples conjuntos de datos del mundo real, y\nnotablemente supera los métodos de aprendizaje heurísticos y profundos para generalizar a\nUn conjunto de datos del mundo real invisible. Trajevo marca un paso prometedor hacia el\nDiseño automatizado de predicción de trayectoria rápida, explicable y generalizable\nHeurística. Lanzamos nuestro código fuente para facilitar la investigación futura en\nhttps://github.com/ai4co/trajevo.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Trajevo: Diseño de heurística de predicción de trayectoria a través de la evolución dirigida por LLM\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "trajevo",
      "trajectory",
      "prediction"
    ],
    "category": "noticia"
  },
  {
    "title": "Test-Time Reinforcement Learning for GUI Grounding via Region Consistency",
    "title_es": "Aprendizaje de refuerzo de tiempo de prueba para la base de la GUI a través de la consistencia de la región",
    "url": "http://arxiv.org/abs/2508.05615v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Interfaz gráfica de usuario (GUI) Ingilia, la tarea de mapear natural\nLas instrucciones de idioma para las coordenadas de pantalla precisas son fundamentales para\nAgentes de GUI autónomos. Mientras que los métodos existentes logran un rendimiento fuerte\na través de una extensa capacitación supervisada o aprendizaje de refuerzo con etiquetado\nrecompensas, permanecen limitadas por el costo y la disponibilidad de píxel\nanotaciones. Observamos que cuando los modelos generan múltiples predicciones para el\nEl mismo elemento GUI, los patrones de superposición espacial revelan confianza implícita\nSeñales que pueden guiar la localización más precisa. Aprovechando esta idea, nosotros\nProponer GUI-RC (consistencia de la región), un método de escala de tiempo de prueba que construye\ncuadrículas de votación espacial de múltiples predicciones muestreadas para identificar el consenso\nregiones donde los modelos muestran un acuerdo más alto. Sin ningún entrenamiento, GUI-RC\nMejora la precisión en un 2-3% en varias arquitecturas en Screenspot\npuntos de referencia. Además presentamos GUI-RCPO (Política de consistencia de la región\nOptimización), que transforma estos patrones de consistencia en recompensas para\nAprendizaje de refuerzo de tiempo de prueba. Calculando qué tan bien se alinea cada predicción\nCon el consenso colectivo, GUI-RCPO permite que los modelos refinen iterativamente\nsus salidas en datos no etiquetados durante la inferencia. Experimentos extensos\nDemostrar la generalidad de nuestro enfoque: Gui-RC aumenta\nQWEN2.5-VL-3B-INSTRUST de 80.11% a 83.57% en ScreensPot-V2, mientras que GUI-RCPO\nLo mejora aún más al 85.14% a través de la optimización auto-supervisada. Nuestro\nEl enfoque revela el potencial sin explotar de la escala del tiempo de prueba y el tiempo de prueba\nAprendizaje de refuerzo para la base de la GUI, ofreciendo un camino prometedor hacia más\nAgentes de GUI robustos y eficientes en datos.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Aprendizaje de refuerzo de tiempo de prueba para la base de la GUI a través de la consistencia de la región\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "testtime",
      "reinforcement",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks",
    "title_es": "Omniear: Benchmarking Agent Razoning en tareas incorporadas",
    "url": "http://arxiv.org/abs/2508.05614v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Los modelos de lenguaje grande se destacan en el razonamiento abstracto pero su capacidad para\nEl razonamiento del agente incorporado permanece en gran medida inexplorado. Presentamos omniear, un\nMarco integral para evaluar cómo los modelos de lenguaje razonan sobre\ninteracciones físicas, uso de herramientas y coordinación de agentes múltiples en incorporado\ntareas. A diferencia de los puntos de referencia existentes que proporcionan conjuntos de herramientas predefinidos o explícitos\nDirectivas de colaboración, Omniear requiere que los agentes adquieran dinámicamente\ncapacidades y determinar de forma autónoma estrategias de coordinación basadas en la tarea\ndemandas. A través de la representación del entorno basada en el texto, modelamos continuos\npropiedades físicas y relaciones espaciales complejas en 1.500 escenarios\nabarcando dominios domésticos e industriales. Nuestra evaluación sistemática revela\ndegradación severa del rendimiento cuando los modelos deben razonar a partir de restricciones: mientras\nLograr 85-96% de éxito con instrucciones explícitas, el rendimiento cae a\n56-85% para razonamiento de herramientas y 63-85% para colaboración implícita, con compuesto\nTareas que muestran más del 50% de tasas de falla. Sorprendentemente, medio ambiente completo\nLa información degrada el rendimiento de la coordinación, lo que indica que los modelos no pueden filtrar\nRestricciones relevantes para tareas. El ajuste fino mejora las tareas de un solo agente dramáticamente\n(0.6% a 76.3%) pero produce ganancias mínimas múltiples (1,5% a 5,5%), exponiendo\nLimitaciones arquitectónicas fundamentales. Estos hallazgos demuestran que encarnado\nEl razonamiento plantea desafíos fundamentalmente diferentes que los modelos actuales pueden\ndirección, establecer omniear como un riguroso punto de referencia para evaluar y\nAvance de sistemas de IA encarnados. Nuestro código y datos están incluidos en el\nMateriales complementarios y será de código abierto tras la aceptación.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Omniear: Benchmarking Agent Razoning en tareas incorporadas\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "omniear",
      "benchmarking",
      "agent"
    ],
    "category": "noticia"
  },
  {
    "title": "Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models",
    "title_es": "Cooper: Co-Optimizando modelos de políticas y recompensas en el aprendizaje de refuerzo para modelos de idiomas grandes",
    "url": "http://arxiv.org/abs/2508.05613v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Los modelos de idiomas grandes (LLM) han demostrado un rendimiento notable en\nTareas de razonamiento, donde el aprendizaje de refuerzo (RL) sirve como un algoritmo clave\npara mejorar sus capacidades de razonamiento. Actualmente, hay dos principales\nParadigmas de recompensa: recompensas basadas en modelos y recompensas basadas en reglas. Sin embargo, ambos\nLos enfoques sufren de limitaciones: las recompensas basadas en reglas carecen de robustez, mientras que\nLas recompensas basadas en modelos son vulnerables a la piratería de recompensas. Para abordar estos problemas,\nProponemos Cooper (modelo de política de optimización y modelo de recompensa), un marco RL\nEso optimiza conjuntamente tanto el modelo de política como el modelo de recompensa. Tonelero\nAprovecha la alta precisión de las recompensas basadas en reglas al identificar correctamente\nrespuestas y construye dinámicamente y selecciona una muestra negativa positiva\nPARES PARA ENTRENAMIENTO CONTINEADO El modelo de recompensa. Este diseño mejora la robustez\ny mitiga el riesgo de piratería de recompensas. Para apoyar aún más a Cooper, nosotros\nintroducir una estrategia de anotación híbrida que\ngenera datos de entrenamiento para el modelo de recompensa. También proponemos una referencia basada\nParadigma de modelado de recompensas, donde el modelo de recompensa toma una respuesta de referencia como\naporte. Basado en este diseño, entrenamos un modelo de recompensa llamado VerifyRM, que\nlogra una mayor precisión en VerifyBench en comparación con otros modelos de los mismos\ntamaño. Realizamos el aprendizaje de refuerzo utilizando VeryRM y Cooper. Nuestro\nLos experimentos muestran que Cooper no solo alivia la piratería de recompensas sino también\nmejora el rendimiento de RL de extremo a extremo, por ejemplo, logrando una ganancia de 0.54% en\nPrecisión promedio en qwen2.5-1.5b-instructo. Nuestros hallazgos demuestran que\nEl modelo de recompensa de actualización dinámica es una forma efectiva de combatir la piratería de recompensas,\nproporcionando una referencia para una mejor integración de modelos de recompensa en RL.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Cooper: Co-Optimizando modelos de políticas y recompensas en el aprendizaje de refuerzo para modelos de idiomas grandes\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cooper",
      "cooptimizing",
      "policy"
    ],
    "category": "noticia"
  },
  {
    "title": "Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle",
    "title_es": "Shuffle-R1: Marco de RL eficiente para modelos de lenguaje grande multimodal a través de la baraja dinámica centrada en los datos",
    "url": "http://arxiv.org/abs/2508.05612v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "El aprendizaje de refuerzo (RL) se ha convertido en un post-capacitación efectivo\nParadigma para mejorar las capacidades de razonamiento del lenguaje multimodal grande\nmodelo (mllm). Sin embargo, las tuberías RL actuales a menudo sufren de entrenamiento\nineficiencias causadas por dos problemas subexplorados: colapso de ventaja, donde\nla mayoría de las ventajas en un lote concentrado cerca de cero y silenciamiento de despliegue, donde\nLa proporción de despliegos que contribuyen a los gradientes distintos disminuyen\ntiempo. Estos problemas conducen a actualizaciones de gradiente subóptimas y obstaculizan a largo plazo\nEficiencia de aprendizaje. Para abordar estos problemas, proponemos Shuffle-R1, un simple\nSin embargo, el marco de principios que mejora la eficiencia de ajuste fino de RL por dinámicamente\nMuestreo de trayectoria de reestructuración y composición de lotes. Presenta (1)\nMuestreo de trayectoria por pares, que selecciona trayectorias de alto contraste con\ngrandes ventajas para mejorar la calidad de la señal del gradiente y (2)\nTrayectoria barajado, que aumenta la exposición de valiosos despliegos a través de\nremodelación del lote informado. Experimentos en múltiples puntos de referencia de razonamiento\nDemuestre que nuestro marco supera constantemente las líneas de base RL fuertes con\nsobrecarga mínima. Estos resultados resaltan la importancia de los datos centrados en los datos\nAdaptaciones para una capacitación RL más eficiente en MLLM.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Shuffle-R1: Marco de RL eficiente para modelos de lenguaje grande multimodal a través de la baraja dinámica centrada en los datos\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "shuffler",
      "efficient",
      "rl"
    ],
    "category": "noticia"
  },
  {
    "title": "Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models",
    "title_es": "Aprendizaje iterativo de fenotipos computables para hipertensión resistente al tratamiento utilizando modelos de lenguaje grandes",
    "url": "http://arxiv.org/abs/2508.05581v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Los modelos de idiomas grandes (LLM) han demostrado capacidades notables para\nRespuesta y programación de preguntas médicas, pero su potencial para generar\nLos fenotipos computables interpretables (CPS) están subexplorados. En este trabajo, nosotros\nInvestigue si los LLM pueden generar CPS precisos y concisos para seis clínicos\nfenotipos de complejidad variable, que podrían aprovecharse para permitir escalables\nApoyo a la decisión clínica para mejorar la atención de pacientes con hipertensión. En\nAdemás de evaluar el rendimiento cero, proponemos y probamos un\nsintetizar, ejecutar, depurar, instruir una estrategia que utiliza LLM para generar y\nRefina iterativamente CPS utilizando la retroalimentación basada en datos. Nuestros resultados muestran que LLMS,\njunto con el aprendizaje iterativo, puede generar interpretable y razonablemente\nProgramas precisos que abordan el rendimiento de los métodos de ML de última generación\nmientras requiere significativamente menos ejemplos de capacitación.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Aprendizaje iterativo de fenotipos computables para hipertensión resistente al tratamiento utilizando modelos de lenguaje grandes\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "iterative",
      "learning",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media",
    "title_es": "MV DEBATE: debate de agente múltiple con la compleja dinámica de reflexión para la detección de contenido dañino multimodal en las redes sociales",
    "url": "http://arxiv.org/abs/2508.05557v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Las redes sociales se han convertido en un entorno multimodal complejo donde el texto,\nimágenes y otras señales interactúan para dar forma a los significados matizados, a menudo ocultando\nintención dañina. Identificar tal intención, ya sea sarcasmo, discurso de odio o\ndesinformación, sigue siendo desafiante debido a las contradicciones intermodales, rápido\ncambios culturales y señales pragmáticas sutiles. Para abordar estos desafíos, nosotros\nProponer MV-DEBATE, un marco de debate de agente múltiple con reflexión dinámica\nactivación para detección de contenido dañino multimodal unificado. MV-DEBATE ENSEMPLADO\nCuatro agentes de debate complementarios, un analista de superficie, un razonador profundo, un\ncontraste de modalidad y un contextualista social para analizar el contenido de diversos\nperspectivas interpretativas. A través del debate iterativo y la reflexión, los agentes\nRefinar las respuestas bajo un criterio de ganancia de reflexión, asegurando tanto la precisión como\neficiencia. Los experimentos en tres conjuntos de datos de referencia demuestran que MV-DEBATE\nSuperorme significativamente un sólido modelo único y un debate existente en múltiples agentes\nlíneas de base. Este trabajo destaca la promesa del debate de múltiples agentes para avanzar\nDetección de intención social confiable en contextos en línea de seguridad crítica.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"MV DEBATE: debate de agente múltiple con la compleja dinámica de reflexión para la detección de contenido dañino multimodal en las redes sociales\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mvdebate",
      "multiview",
      "agent"
    ],
    "category": "noticia"
  },
  {
    "title": "Adapting Vision-Language Models Without Labels: A Comprehensive Survey",
    "title_es": "Adaptar modelos en idioma de visión sin etiquetas: una encuesta completa",
    "url": "http://arxiv.org/abs/2508.05547v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Los modelos en idioma de visión (VLMS) han demostrado una notable generalización\ncapacidades en una amplia gama de tareas. Sin embargo, su rendimiento a menudo\npermanece subóptimo cuando se aplica directamente a escenarios posteriores específicos\nsin adaptación específica de la tarea. Para mejorar su utilidad mientras se preserva\nEficiencia de datos, la investigación reciente se ha centrado cada vez más en\nMétodos de adaptación que no se basan en datos etiquetados. A pesar del crecimiento\nInterés en esta área, queda la falta de una encuesta unificada y orientada a las tareas\ndedicado a la adaptación VLM no supervisada. Para cerrar esta brecha, presentamos un\nDescripción completa y estructurada del campo. Proponemos una taxonomía basada en\nSobre la disponibilidad y la naturaleza de los datos visuales no etiquetados, clasificando\nEnfoques en cuatro paradigmas clave: transferencia sin datos (sin datos), sin supervisión\nTransferencia de dominio (datos abundantes), adaptación episódica de tiempo de prueba (datos por lotes),\ny adaptación de tiempo de prueba en línea (datos de transmisión). Dentro de este marco, nosotros\nAnalizar metodologías centrales y estrategias de adaptación asociadas con cada\nParadigma, con el objetivo de establecer una comprensión sistemática del campo.\nAdemás, revisamos puntos de referencia representativos en diversas aplicaciones\ny resaltar desafíos abiertos y direcciones prometedoras para futuras investigaciones. Un\nEl repositorio de literatura relevante mantenido activamente está disponible en\nhttps://github.com/tim-learn/awesome-labelfree-vlms.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Adaptar modelos en idioma de visión sin etiquetas: una encuesta completa\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "adapting",
      "visionlanguage",
      "models"
    ],
    "category": "noticia"
  },
  {
    "title": "Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees",
    "title_es": "Conjuntos conformes en la respuesta de preguntas de opción múltiple en la configuración de la caja negra con garantías de cobertura comprobable",
    "url": "http://arxiv.org/abs/2508.05544v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Los modelos de lenguaje grande (LLMS) han mostrado un progreso notable en\nRespuesta de preguntas de opción múltiple (MCQA), pero su inherencia inherente,\ncomo la alucinación y el exceso de confianza, limita su aplicación en alto riesgo\ndominios. Para abordar esto, proponemos una incertidumbre basada en la frecuencia\nMétodo de cuantificación en configuración de caja negra, aprovechando la predicción conforme\n(CP) para garantizar garantías de cobertura probable. Nuestro enfoque implica múltiples\nmuestras independientes de la distribución de salida del modelo para cada entrada, con\nla muestra más frecuente que sirve como referencia para calcular la entropía predictiva\n(PE). Evaluaciones experimentales en seis LLM y cuatro conjuntos de datos (MEDMCQA,\nMEDQA, MMLU, MMLU-PRO) demuestran que los PE basados en frecuencia supera\nPE basado en logit para distinguir entre predicciones correctas e incorrectas, como\nmedido por AUROC. Además, el método controla efectivamente el empírico\ntasa de malestar en los niveles de riesgo especificados por el usuario, validando ese muestreo\nLa frecuencia puede servir como un sustituto viable para las probabilidades basadas en logit en\nEscenarios de caja negra. Este trabajo proporciona un modelo-agnóstico sin distribución.\nMarco para cuantificación de incertidumbre confiable en MCQA con garantizado\ncobertura, mejorando la confiabilidad de los LLM en aplicaciones prácticas.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Conjuntos conformes en la respuesta de preguntas de opción múltiple en la configuración de la caja negra con garantías de cobertura comprobable\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "conformal",
      "sets",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Tractable Sharpness-Aware Learning of Probabilistic Circuits",
    "title_es": "Aprendizaje de la nitidez manejable de los circuitos probabilísticos",
    "url": "http://arxiv.org/abs/2508.05537v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Los circuitos probabilísticos (PC) son una clase de modelos generativos que permiten\nInferencia exacta y manejable para una amplia gama de consultas. Si bien reciente\nLos desarrollos han permitido el aprendizaje de PC profundas y expresivas, esto\nEl aumento de la capacidad a menudo puede conducir a un sobreajuste, especialmente cuando los datos son\nlimitado. Analizamos el sobreajuste de PC desde una perspectiva de paisaje de liderazgo log\ny demuestre que a menudo es causado por la convergencia a los óptimos agudos que generalizan\nmal. Inspirado por la minimización consciente de la nitidez en las redes neuronales, proponemos\nUn regularizador con sede en Hesse para capacitar a PC. Como contribución clave, mostramos\nque el rastro de la Hesse de la Ligazos de la Ligera, un proxy de nitidez que es\ntípicamente intratable en redes neuronales profundas, se puede calcular de manera eficiente para\nPC. Minimizar esta traza de Hessian induce un regularizador basado en la norma de gradiente\nque produce actualizaciones simples de parámetros de forma cerrada para EM e integra\nSin problemas con los métodos de aprendizaje basados en el gradiente. Experimentos sobre sintético y\nLos conjuntos de datos del mundo real demuestran que nuestro método guía constantemente PCS hacia\nmínimos más planos, mejora el rendimiento de la generalización.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Aprendizaje de la nitidez manejable de los circuitos probabilísticos\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "tractable",
      "sharpnessaware",
      "learning"
    ],
    "category": "noticia"
  },
  {
    "title": "The World According to LLMs: How Geographic Origin Influences LLMs' Entity Deduction Capabilities",
    "title_es": "El mundo según LLM: cómo el origen geográfico influye en las capacidades de deducción de entidad de LLMS de LLMS",
    "url": "http://arxiv.org/abs/2508.05525v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Los modelos de idiomas grandes (LLM) se han sintonizado ampliamente para mitigar explícitos\nsesgos, sin embargo, a menudo exhiben sesgos implícitos sutiles enraizados en su\nDatos previos al entrenamiento. En lugar de sondear directamente los LLM con humanos elaborados\nPreguntas que pueden desencadenar barandas, proponemos estudiar cómo se comportan los modelos\nCuando se hacen preguntas de manera proactiva. El juego de 20 preguntas, un\nTarea de deducción de múltiples vueltas, sirve como una prueba de prueba ideal para este propósito. Nosotros\nEvaluar sistemáticamente las disparidades de rendimiento geográfico en la deducción de entidades\nUsando un nuevo conjunto de datos, GEO20Q+, que consiste en personas notables y culturalmente\nObjetos significativos (por ejemplo, alimentos, puntos de referencia, animales) de diversas regiones. Nosotros\nPruebe los LLM populares en dos configuraciones de juego (20 preguntas canónicas y\ngiros ilimitados) y en siete idiomas (inglés, hindi, mandarín, japonés,\nFrancés, español y turco). Nuestros resultados revelan disparidades geográficas: LLMS\nson sustancialmente más exitosos en deducir entidades del norte global\nque el sur global y el oeste global que el este global. Mientras\nWikipedia PageViews y la frecuencia del corpus de pre-entrenamiento se correlacionan suavemente con\nrendimiento, no explican completamente estas disparidades. Notablemente, el\nEl lenguaje en el que se juega el juego tiene un impacto mínimo en las brechas de rendimiento.\nEstos hallazgos demuestran el valor de la evaluación creativa de forma libre\nmarcos para descubrir sesgos sutiles en LLM que permanecen ocultos en estándar\nInvolucrar configuraciones. Analizando cómo los modelos inician y persiguen las metas de razonamiento\nEn múltiples vueltas, encontramos disparidades geográficas y culturales integradas en\nsus procesos de razonamiento. Lanzamos el conjunto de datos (GEO20Q+) y el código en\nhttps://sites.google.com/view/llmbias20q/home.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"El mundo según LLM: cómo el origen geográfico influye en las capacidades de deducción de entidad de LLMS de LLMS\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "world",
      "according"
    ],
    "category": "noticia"
  },
  {
    "title": "Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program",
    "title_es": "Agilización de la admisión con LOR Insights: Evaluación de liderazgo basada en IA en el programa de maestría en línea",
    "url": "http://arxiv.org/abs/2508.05513v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Las cartas de recomendación (LOR) proporcionan información valiosa sobre los candidatos '\ncapacidades y experiencias más allá de los puntajes de las pruebas estandarizadas. Sin embargo,\nRevisar estos materiales pesados de texto lleva mucho tiempo y es intensivo en mano de obra. A\nabordar este desafío y apoyar al comité de admisión para proporcionar\nComentarios para el crecimiento profesional de los estudiantes, nuestro estudio presenta lori: lor\nInsights, una nueva herramienta de detección basada en IA para evaluar las habilidades de liderazgo en\nLors enviados por solicitantes del programa de maestría en línea. Empleando natural\nprocesamiento del lenguaje y aprovechando modelos de idiomas grandes utilizando Roberta y\nLlama, buscamos identificar atributos de liderazgo como el trabajo en equipo,\ncomunicación e innovación. Nuestro último modelo Roberta logra una F1 ponderada\npuntaje de 91.6%, una precisión del 92.4%y un retiro del 91.6%, que muestra un fuerte\nNivel de consistencia en nuestros datos de prueba. Con la creciente importancia de\nHabilidades de liderazgo en el sector STEM, integrando a Lori en el graduado\nEl proceso de admisión es crucial para evaluar con precisión el liderazgo de los solicitantes\ncapacidades. Este enfoque no solo optimiza el proceso de admisión sino también\ntambién automatiza y garantiza una evaluación más completa de los candidatos '\ncapacidades.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Agilización de la admisión con LOR Insights: Evaluación de liderazgo basada en IA en el programa de maestría en línea\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "streamlining",
      "admission",
      "with"
    ],
    "category": "noticia"
  },
  {
    "title": "LAG: Logic-Augmented Generation from a Cartesian Perspective",
    "title_es": "LAG: Generación de lógica augsada desde una perspectiva cartesiana",
    "url": "http://arxiv.org/abs/2508.05509v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "Los modelos de idiomas grandes (LLM) han demostrado capacidades notables en todo\nUna amplia gama de tareas, pero exhiben limitaciones críticas en el conocimiento intensivo\ntareas, a menudo generando alucinaciones cuando se enfrentan a preguntas que requieren\nexperiencia especializada. Mientras que la generación de recuperación de la generación (trapo) mitigan\nEsto integrando el conocimiento externo, lucha con un razonamiento complejo\nescenarios debido a su dependencia de la recuperación semántica directa y la falta de\nOrganización lógica estructurada. Inspirado en principios cartesianos de\n\\ textit {discursos de la m \\ 'ethode}, este documento presenta una lógica acuática\nGeneración (LAG), un nuevo paradigma que refuerza el aumento de conocimiento a través de\nLa descomposición de preguntas sistemáticas y el razonamiento consciente de la dependencia. Específicamente,\nEl retraso primero descompone preguntas complejas en subcuestiones atómicas ordenadas por\ndependencias lógicas. Luego resuelve estos secuencialmente, utilizando respuestas anteriores\nPara guiar la recuperación del contexto para las subcuestiones posteriores, asegurando la paso a paso\nGrounding en cadena lógica. Para evitar la propagación de errores, Lag incorpora un\nMecanismo de terminación lógica que detiene la inferencia al encontrar\nSubcuestiones sin respuesta y reduce el cálculo desperdiciado en excesivo\nrazonamiento. Finalmente, sintetiza todas las sub-resoluciones para generar verificados\nrespuestas. Los experimentos en cuatro conjuntos de datos de referencia demuestran ese retraso\nmejora significativamente la robustez del razonamiento, reduce la alucinación y se alinea\nLLM resolución de problemas con cognición humana, ofreciendo una alternativa de principios a\nsistemas de trapo existentes.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"LAG: Generación de lógica augsada desde una perspectiva cartesiana\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lag",
      "logicaugmented",
      "generation"
    ],
    "category": "noticia"
  },
  {
    "title": "Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation",
    "title_es": "Juez autoeval: hacia un marco agente general para la evaluación de finalización de tareas",
    "url": "http://arxiv.org/abs/2508.05508v1",
    "date": "2025-08-07",
    "source": "arXiv",
    "content_es": "La creciente adopción de modelos de fundaciones como agentes en diversos dominios\nrequiere un marco de evaluación robusto. Métodos actuales, como\nLLM-as-a-Judge, centrado solo en las salidas finales, con vistas a paso a paso\nrazonamiento que impulsa la toma de decisiones de agente. Mientras tanto, existente\nAgente-as-a-a-juzge, donde un agente evalúa la finalización de la tarea de otro,\nestán típicamente diseñados para configuraciones estrechas específicas de dominio. Para abordar esto\nGAP, proponemos un marco modular generalizable para evaluar la tarea del agente\nfinalización independiente del dominio de la tarea. El marco emula como humano\nevaluación mediante la descomposición de las tareas en subasinas y validando cada paso utilizando\nInformación disponible, como la salida y el razonamiento del agente. Cada módulo\ncontribuye a un aspecto específico del proceso de evaluación y sus salidas\nestán agregados para producir un veredicto final en la finalización de la tarea. Validamos nuestro\nMarco mediante la evaluación del agente de actores Magentic-One en dos puntos de referencia, Gaia\ny BigCodeBench. Nuestro agente de juez predice el éxito de la tarea con un acuerdo más cercano\na las evaluaciones humanas, logrando 4.76% y 10.52% mayor precisión de alineación,\nrespectivamente, en comparación con la línea de base LLM-As-AS-Judge basada en GPT-4O. Este\nDemuestra el potencial de nuestra evaluación de propósito general propuesta\nestructura.",
    "published": "2025-08-07T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Juez autoeval: hacia un marco agente general para la evaluación de finalización de tareas\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "autoeval",
      "judge",
      "towards"
    ],
    "category": "noticia"
  },
  {
    "title": "Has NSF defied a court order by suspending 300 UCLA grants?",
    "title_es": "¿Ha desafiado NSF una orden judicial suspendiendo 300 subvenciones de UCLA?",
    "url": "https://www.science.org/content/article/has-nsf-defied-court-order-suspending-300-ucla-grants",
    "date": "2025-08-06",
    "source": "Science.org",
    "content_es": "Juez federal para escuchar argumentos relacionados con la orden judicial preliminar para restaurar los fondos para otras subvenciones de UC",
    "published": "2025-08-06T00:00:00.000Z",
    "description": "Este artículo trata sobre \"¿Ha desafiado NSF una orden judicial suspendiendo 300 subvenciones de UCLA?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "has",
      "nsf",
      "defied"
    ],
    "category": "noticia"
  },
  {
    "title": "Numerical Errors in Quantitative System Analysis With Decision Diagrams",
    "title_es": "Errores numéricos en el análisis cuantitativo de sistemas con diagramas de decisión",
    "url": "https://arxiv.org/abs/2508.02673",
    "date": "2025-08-06",
    "source": "arXiv",
    "content_es": "Numerical Errors in Quantitative System Analysis With Decision Diagrams",
    "published": "2025-08-06T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Errores numéricos en el análisis cuantitativo de sistemas con diagramas de decisión\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "numerical",
      "errors",
      "in"
    ],
    "category": "noticia"
  },
  {
    "title": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "title_es": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "url": "https://www.nature.com/articles/s41586-025-09463-4",
    "date": "2025-08-06",
    "source": "Nature",
    "content_es": "Author Correction: Persistent transcriptional programmes are associated with remote memory",
    "published": "2025-08-06T00:00:00.000Z",
    "summary": "",
    "description": "Este artículo trata sobre \"Author Correction: Persistent transcriptional programmes are associated with remote memory\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "author",
      "correction",
      "persistent"
    ],
    "category": "noticia"
  },
  {
    "title": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "url": "https://www.nature.com/articles/s41586-025-09461-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "content_es": "Therapeutic genetic restoration through allogeneic brain microglia replacement",
    "description": "Este artículo trata sobre \"Therapeutic genetic restoration through allogeneic brain microglia replacement\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "therapeutic",
      "genetic",
      "restoration"
    ],
    "category": "noticia"
  },
  {
    "title": "Reply to: Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "url": "https://www.nature.com/articles/s41586-025-09315-1",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Reply to: Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "content_es": "Reply to: Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "description": "Este artículo trata sobre \"Reply to: Inconclusive proof of ferroelectricity in peptide-VDF ribbons\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "reply",
      "to",
      "inconclusive"
    ],
    "category": "noticia"
  },
  {
    "title": "Data anomalies and the economic commitment of climate change",
    "url": "https://www.nature.com/articles/s41586-025-09320-4",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Data anomalies and the economic commitment of climate change",
    "content_es": "Data anomalies and the economic commitment of climate change",
    "description": "Este artículo trata sobre \"Data anomalies and the economic commitment of climate change\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "data",
      "anomalies",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "url": "https://www.nature.com/articles/s41586-025-09314-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "content_es": "Inconclusive proof of ferroelectricity in peptide-VDF ribbons",
    "description": "Este artículo trata sobre \"Inconclusive proof of ferroelectricity in peptide-VDF ribbons\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "inconclusive",
      "proof",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Microglia–neuron crosstalk via Hex–GM2–MGL2 maintains brain homeostasis",
    "url": "https://www.nature.com/articles/s41586-025-09477-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Microglia–neuron crosstalk via Hex–GM2–MGL2 maintains brain homeostasis",
    "content_es": "Microglia–neuron crosstalk via Hex–GM2–MGL2 maintains brain homeostasis",
    "description": "Este artículo trata sobre \"Microglia–neuron crosstalk via Hex–GM2–MGL2 maintains brain homeostasis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "microglianeuron",
      "crosstalk",
      "via"
    ],
    "category": "noticia"
  },
  {
    "title": "Publisher Correction: NINJ1 regulates plasma membrane fragility under mechanical strain",
    "url": "https://www.nature.com/articles/s41586-025-09444-7",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Publisher Correction: NINJ1 regulates plasma membrane fragility under mechanical strain",
    "content_es": "Publisher Correction: NINJ1 regulates plasma membrane fragility under mechanical strain",
    "description": "Este artículo trata sobre \"Publisher Correction: NINJ1 regulates plasma membrane fragility under mechanical strain\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "publisher",
      "correction",
      "ninj"
    ],
    "category": "noticia"
  },
  {
    "title": "The real problems with America's health",
    "url": "https://www.nature.com/articles/d41586-025-02501-1",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "The real problems with America's health",
    "content_es": "The real problems with America's health",
    "description": "Este artículo trata sobre \"The real problems with America's health\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "real",
      "problems"
    ],
    "category": "noticia"
  },
  {
    "title": "Why did researchers stick a duck to a rock? To show off their super glue",
    "url": "https://www.nature.com/articles/d41586-025-02485-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Why did researchers stick a duck to a rock? To show off their super glue",
    "content_es": "Why did researchers stick a duck to a rock? To show off their super glue",
    "description": "Este artículo trata sobre \"Why did researchers stick a duck to a rock? To show off their super glue\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "why",
      "did",
      "researchers"
    ],
    "category": "noticia"
  },
  {
    "title": "Underwater glue shows its sticking power in rubber duck test",
    "url": "https://www.nature.com/articles/d41586-025-02500-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Underwater glue shows its sticking power in rubber duck test",
    "content_es": "Underwater glue shows its sticking power in rubber duck test",
    "description": "Este artículo trata sobre \"Underwater glue shows its sticking power in rubber duck test\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "underwater",
      "glue",
      "shows"
    ],
    "category": "noticia"
  },
  {
    "title": "Whole-genome sequencing of 490,640 UK Biobank participants",
    "url": "https://www.nature.com/articles/s41586-025-09272-9",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Whole-genome sequencing of 490,640 UK Biobank participants",
    "content_es": "Whole-genome sequencing of 490,640 UK Biobank participants",
    "description": "Este artículo trata sobre \"Whole-genome sequencing of 490,640 UK Biobank participants\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "wholegenome",
      "sequencing",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Novel assembly of a head–trunk interface in the&#xa0;sister group of jawed vertebrates",
    "url": "https://www.nature.com/articles/s41586-025-09329-9",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Novel assembly of a head–trunk interface in the&#xa0;sister group of jawed vertebrates",
    "content_es": "Novel assembly of a head–trunk interface in the&#xa0;sister group of jawed vertebrates",
    "description": "Este artículo trata sobre \"Novel assembly of a head–trunk interface in the&#xa0;sister group of jawed vertebrates\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "novel",
      "assembly",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Hominins on Sulawesi during the Early Pleistocene",
    "url": "https://www.nature.com/articles/s41586-025-09348-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Hominins on Sulawesi during the Early Pleistocene",
    "content_es": "Hominins on Sulawesi during the Early Pleistocene",
    "description": "Este artículo trata sobre \"Hominins on Sulawesi during the Early Pleistocene\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "hominins",
      "on",
      "sulawesi"
    ],
    "category": "noticia"
  },
  {
    "title": "RNA N-glycosylation enables immune evasion and homeostatic efferocytosis",
    "url": "https://www.nature.com/articles/s41586-025-09310-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "RNA N-glycosylation enables immune evasion and homeostatic efferocytosis",
    "content_es": "RNA N-glycosylation enables immune evasion and homeostatic efferocytosis",
    "description": "Este artículo trata sobre \"RNA N-glycosylation enables immune evasion and homeostatic efferocytosis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "rna",
      "nglycosylation",
      "enables"
    ],
    "category": "noticia"
  },
  {
    "title": "In situ light-field imaging of octopus locomotion reveals simplified control",
    "url": "https://www.nature.com/articles/s41586-025-09379-z",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "In situ light-field imaging of octopus locomotion reveals simplified control",
    "content_es": "In situ light-field imaging of octopus locomotion reveals simplified control",
    "description": "Este artículo trata sobre \"In situ light-field imaging of octopus locomotion reveals simplified control\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "in",
      "situ",
      "lightfield"
    ],
    "category": "noticia"
  },
  {
    "title": "Microglia regulate GABAergic neurogenesis in prenatal human brain through IGF1",
    "url": "https://www.nature.com/articles/s41586-025-09362-8",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Microglia regulate GABAergic neurogenesis in prenatal human brain through IGF1",
    "content_es": "Microglia regulate GABAergic neurogenesis in prenatal human brain through IGF1",
    "description": "Este artículo trata sobre \"Microglia regulate GABAergic neurogenesis in prenatal human brain through IGF1\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "microglia",
      "regulate",
      "gabaergic"
    ],
    "category": "noticia"
  },
  {
    "title": "NSD2 inhibitors rewire chromatin to treat lung and pancreatic cancers",
    "url": "https://www.nature.com/articles/s41586-025-09299-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "NSD2 inhibitors rewire chromatin to treat lung and pancreatic cancers",
    "content_es": "NSD2 inhibitors rewire chromatin to treat lung and pancreatic cancers",
    "description": "Este artículo trata sobre \"NSD2 inhibitors rewire chromatin to treat lung and pancreatic cancers\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nsd",
      "inhibitors",
      "rewire"
    ],
    "category": "noticia"
  },
  {
    "title": "Structural basis of fast N-type inactivation in Kv channels",
    "url": "https://www.nature.com/articles/s41586-025-09339-7",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Structural basis of fast N-type inactivation in Kv channels",
    "content_es": "Structural basis of fast N-type inactivation in Kv channels",
    "description": "Este artículo trata sobre \"Structural basis of fast N-type inactivation in Kv channels\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "structural",
      "basis",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Excised DNA circles from V(D)J recombination promote relapsed leukaemia",
    "url": "https://www.nature.com/articles/s41586-025-09372-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Excised DNA circles from V(D)J recombination promote relapsed leukaemia",
    "content_es": "Excised DNA circles from V(D)J recombination promote relapsed leukaemia",
    "description": "Este artículo trata sobre \"Excised DNA circles from V(D)J recombination promote relapsed leukaemia\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "excised",
      "dna",
      "circles"
    ],
    "category": "noticia"
  },
  {
    "title": "A diverse and distinct microbiome inside living trees",
    "url": "https://www.nature.com/articles/s41586-025-09316-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "A diverse and distinct microbiome inside living trees",
    "content_es": "A diverse and distinct microbiome inside living trees",
    "description": "Este artículo trata sobre \"A diverse and distinct microbiome inside living trees\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "diverse",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "Data-driven de novo design of super-adhesive hydrogels",
    "url": "https://www.nature.com/articles/s41586-025-09269-4",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Data-driven de novo design of super-adhesive hydrogels",
    "content_es": "Data-driven de novo design of super-adhesive hydrogels",
    "description": "Este artículo trata sobre \"Data-driven de novo design of super-adhesive hydrogels\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "datadriven",
      "de",
      "novo"
    ],
    "category": "noticia"
  },
  {
    "title": "Stronger El Niños reduce tropical forest arthropod diversity and function",
    "url": "https://www.nature.com/articles/s41586-025-09351-x",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Stronger El Niños reduce tropical forest arthropod diversity and function",
    "content_es": "Stronger El Niños reduce tropical forest arthropod diversity and function",
    "description": "Este artículo trata sobre \"Stronger El Niños reduce tropical forest arthropod diversity and function\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "stronger",
      "el",
      "niños"
    ],
    "category": "noticia"
  },
  {
    "title": "Optical control of resonances in temporally symmetry-broken metasurfaces",
    "url": "https://www.nature.com/articles/s41586-025-09363-7",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Optical control of resonances in temporally symmetry-broken metasurfaces",
    "content_es": "Optical control of resonances in temporally symmetry-broken metasurfaces",
    "description": "Este artículo trata sobre \"Optical control of resonances in temporally symmetry-broken metasurfaces\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "optical",
      "control",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Lithium deficiency and the onset of Alzheimer’s disease",
    "url": "https://www.nature.com/articles/s41586-025-09335-x",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Lithium deficiency and the onset of Alzheimer’s disease",
    "content_es": "Lithium deficiency and the onset of Alzheimer’s disease",
    "description": "Este artículo trata sobre \"Lithium deficiency and the onset of Alzheimer’s disease\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "lithium",
      "deficiency",
      "and"
    ],
    "category": "noticia"
  },
  {
    "title": "A global humidity index with lateral hydrologic flows",
    "url": "https://www.nature.com/articles/s41586-025-09359-3",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "A global humidity index with lateral hydrologic flows",
    "content_es": "A global humidity index with lateral hydrologic flows",
    "description": "Este artículo trata sobre \"A global humidity index with lateral hydrologic flows\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "a",
      "global",
      "humidity"
    ],
    "category": "noticia"
  },
  {
    "title": "EBV induces CNS homing of B cells attracting inflammatory T cells",
    "url": "https://www.nature.com/articles/s41586-025-09378-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "EBV induces CNS homing of B cells attracting inflammatory T cells",
    "content_es": "EBV induces CNS homing of B cells attracting inflammatory T cells",
    "description": "Este artículo trata sobre \"EBV induces CNS homing of B cells attracting inflammatory T cells\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ebv",
      "induces",
      "cns"
    ],
    "category": "noticia"
  },
  {
    "title": "The science fiction science method",
    "url": "https://www.nature.com/articles/s41586-025-09194-6",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "The science fiction science method",
    "content_es": "The science fiction science method",
    "description": "Este artículo trata sobre \"The science fiction science method\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "science",
      "fiction"
    ],
    "category": "noticia"
  },
  {
    "title": "One-third of Sun-like stars are born with misaligned planet-forming disks",
    "url": "https://www.nature.com/articles/s41586-025-09324-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "One-third of Sun-like stars are born with misaligned planet-forming disks",
    "content_es": "One-third of Sun-like stars are born with misaligned planet-forming disks",
    "description": "Este artículo trata sobre \"One-third of Sun-like stars are born with misaligned planet-forming disks\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "onethird",
      "of",
      "sunlike"
    ],
    "category": "noticia"
  },
  {
    "title": "Parent-of-origin effects on complex traits in up to 236,781 individuals",
    "url": "https://www.nature.com/articles/s41586-025-09357-5",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Parent-of-origin effects on complex traits in up to 236,781 individuals",
    "content_es": "Parent-of-origin effects on complex traits in up to 236,781 individuals",
    "description": "Este artículo trata sobre \"Parent-of-origin effects on complex traits in up to 236,781 individuals\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "parentoforigin",
      "effects",
      "on"
    ],
    "category": "noticia"
  },
  {
    "title": "Kinetic turbulence drives MHD equilibrium change via 3D reconnection",
    "url": "https://www.nature.com/articles/s41586-025-09345-9",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Kinetic turbulence drives MHD equilibrium change via 3D reconnection",
    "content_es": "Kinetic turbulence drives MHD equilibrium change via 3D reconnection",
    "description": "Este artículo trata sobre \"Kinetic turbulence drives MHD equilibrium change via 3D reconnection\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "kinetic",
      "turbulence",
      "drives"
    ],
    "category": "noticia"
  },
  {
    "title": "The protein craze: scientists talk supplements — and who should take them",
    "url": "https://www.nature.com/articles/d41586-025-02472-3",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "The protein craze: scientists talk supplements — and who should take them",
    "content_es": "The protein craze: scientists talk supplements — and who should take them",
    "description": "Este artículo trata sobre \"The protein craze: scientists talk supplements — and who should take them\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "protein",
      "craze"
    ],
    "category": "noticia"
  },
  {
    "title": "Merging of magnetic plasma ‘flux ropes’ is driven by turbulence",
    "url": "https://www.nature.com/articles/d41586-025-02253-y",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Merging of magnetic plasma ‘flux ropes’ is driven by turbulence",
    "content_es": "Merging of magnetic plasma ‘flux ropes’ is driven by turbulence",
    "description": "Este artículo trata sobre \"Merging of magnetic plasma ‘flux ropes’ is driven by turbulence\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "merging",
      "of",
      "magnetic"
    ],
    "category": "noticia"
  },
  {
    "title": "Sexual harassment is rife at US Antarctic research bases, fresh survey finds",
    "url": "https://www.nature.com/articles/d41586-025-02484-z",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Sexual harassment is rife at US Antarctic research bases, fresh survey finds",
    "content_es": "Sexual harassment is rife at US Antarctic research bases, fresh survey finds",
    "description": "Este artículo trata sobre \"Sexual harassment is rife at US Antarctic research bases, fresh survey finds\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "sexual",
      "harassment",
      "is"
    ],
    "category": "noticia"
  },
  {
    "title": "Stone tools suggest that hominins arrived on Indonesian island much earlier than thought",
    "url": "https://www.nature.com/articles/d41586-025-02386-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Stone tools suggest that hominins arrived on Indonesian island much earlier than thought",
    "content_es": "Stone tools suggest that hominins arrived on Indonesian island much earlier than thought",
    "description": "Este artículo trata sobre \"Stone tools suggest that hominins arrived on Indonesian island much earlier than thought\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "stone",
      "tools",
      "suggest"
    ],
    "category": "noticia"
  },
  {
    "title": "High levels of circular DNA made as immune cells develop increases the risk of leukaemia relapse",
    "url": "https://www.nature.com/articles/d41586-025-02421-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "High levels of circular DNA made as immune cells develop increases the risk of leukaemia relapse",
    "content_es": "High levels of circular DNA made as immune cells develop increases the risk of leukaemia relapse",
    "description": "Este artículo trata sobre \"High levels of circular DNA made as immune cells develop increases the risk of leukaemia relapse\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "high",
      "levels",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Nuclear-weapons risks are back — and we need to act like it",
    "url": "https://www.nature.com/articles/d41586-025-02506-w",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Nuclear-weapons risks are back — and we need to act like it",
    "content_es": "Nuclear-weapons risks are back — and we need to act like it",
    "description": "Este artículo trata sobre \"Nuclear-weapons risks are back — and we need to act like it\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nuclearweapons",
      "risks",
      "are"
    ],
    "category": "noticia"
  },
  {
    "title": "Highly efficient deep-blue LED devices made using hybrid copper–iodide compound",
    "url": "https://www.nature.com/articles/d41586-025-02393-1",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Highly efficient deep-blue LED devices made using hybrid copper–iodide compound",
    "content_es": "Highly efficient deep-blue LED devices made using hybrid copper–iodide compound",
    "description": "Este artículo trata sobre \"Highly efficient deep-blue LED devices made using hybrid copper–iodide compound\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "highly",
      "efficient",
      "deepblue"
    ],
    "category": "noticia"
  },
  {
    "title": "The peer-review crisis: how to fix an overloaded system",
    "url": "https://www.nature.com/articles/d41586-025-02457-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "The peer-review crisis: how to fix an overloaded system",
    "content_es": "The peer-review crisis: how to fix an overloaded system",
    "description": "Este artículo trata sobre \"The peer-review crisis: how to fix an overloaded system\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "peerreview",
      "crisis"
    ],
    "category": "noticia"
  },
  {
    "title": "Ancient marine reptile was a silent swimmer",
    "url": "https://www.nature.com/articles/d41586-025-02464-3",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Ancient marine reptile was a silent swimmer",
    "content_es": "Ancient marine reptile was a silent swimmer",
    "description": "Este artículo trata sobre \"Ancient marine reptile was a silent swimmer\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ancient",
      "marine",
      "reptile"
    ],
    "category": "noticia"
  },
  {
    "title": "UK Royal Society adopts ‘subscribe to open’ publishing model",
    "url": "https://www.nature.com/articles/d41586-025-02483-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "UK Royal Society adopts ‘subscribe to open’ publishing model",
    "content_es": "UK Royal Society adopts ‘subscribe to open’ publishing model",
    "description": "Este artículo trata sobre \"UK Royal Society adopts ‘subscribe to open’ publishing model\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "uk",
      "royal",
      "society"
    ],
    "category": "noticia"
  },
  {
    "title": "Daily briefing: Reflections from a survivor of the Hiroshima bombing",
    "url": "https://www.nature.com/articles/d41586-025-02551-5",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Daily briefing: Reflections from a survivor of the Hiroshima bombing",
    "content_es": "Daily briefing: Reflections from a survivor of the Hiroshima bombing",
    "description": "Este artículo trata sobre \"Daily briefing: Reflections from a survivor of the Hiroshima bombing\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "daily",
      "briefing",
      "reflections"
    ],
    "category": "noticia"
  },
  {
    "title": "New hope for Alzheimer’s: lithium supplement reverses memory loss in mice",
    "url": "https://www.nature.com/articles/d41586-025-02471-4",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "New hope for Alzheimer’s: lithium supplement reverses memory loss in mice",
    "content_es": "New hope for Alzheimer’s: lithium supplement reverses memory loss in mice",
    "description": "Este artículo trata sobre \"New hope for Alzheimer’s: lithium supplement reverses memory loss in mice\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "new",
      "hope",
      "for"
    ],
    "category": "noticia"
  },
  {
    "title": "Parent-of-origin effects found for gene variants that affect human growth and metabolism",
    "url": "https://www.nature.com/articles/d41586-025-02391-3",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Parent-of-origin effects found for gene variants that affect human growth and metabolism",
    "content_es": "Parent-of-origin effects found for gene variants that affect human growth and metabolism",
    "description": "Este artículo trata sobre \"Parent-of-origin effects found for gene variants that affect human growth and metabolism\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "parentoforigin",
      "effects",
      "found"
    ],
    "category": "noticia"
  },
  {
    "title": "After you left",
    "url": "https://www.nature.com/articles/d41586-025-02467-0",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "After you left",
    "content_es": "After you left",
    "description": "Este artículo trata sobre \"After you left\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "after",
      "you",
      "left"
    ],
    "category": "noticia"
  },
  {
    "title": "OpenAI launches reasoning LLM that you can download and tweak",
    "url": "https://www.nature.com/articles/d41586-025-02495-w",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "OpenAI launches reasoning LLM that you can download and tweak",
    "content_es": "OpenAI launches reasoning LLM that you can download and tweak",
    "description": "Este artículo trata sobre \"OpenAI launches reasoning LLM that you can download and tweak\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "openai",
      "launches",
      "reasoning"
    ],
    "category": "noticia"
  },
  {
    "title": "AI learns from nature to design super-adhesive gels that work underwater",
    "url": "https://www.nature.com/articles/d41586-025-02252-z",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "AI learns from nature to design super-adhesive gels that work underwater",
    "content_es": "AI learns from nature to design super-adhesive gels that work underwater",
    "description": "Este artículo trata sobre \"AI learns from nature to design super-adhesive gels that work underwater\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ai",
      "learns",
      "from"
    ],
    "category": "noticia"
  },
  {
    "title": "Is your AI benchmark lying to you?",
    "url": "https://www.nature.com/articles/d41586-025-02462-5",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Is your AI benchmark lying to you?",
    "content_es": "Is your AI benchmark lying to you?",
    "description": "Este artículo trata sobre \"Is your AI benchmark lying to you?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "is",
      "your",
      "ai"
    ],
    "category": "noticia"
  },
  {
    "title": "Does lithium deficiency contribute to Alzheimer’s disease?",
    "url": "https://www.nature.com/articles/d41586-025-02255-w",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "summary": "",
    "source": "Nature",
    "title_es": "Does lithium deficiency contribute to Alzheimer’s disease?",
    "content_es": "Does lithium deficiency contribute to Alzheimer’s disease?",
    "description": "Este artículo trata sobre \"Does lithium deficiency contribute to Alzheimer’s disease?\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "does",
      "lithium",
      "deficiency"
    ],
    "category": "noticia"
  },
  {
    "title": "High-accuracy laser spectroscopy of \n              \n                \n              \n              $${{\\bf{H}}}_{{\\bf{2}}}^{{\\boldsymbol{+}}}$$\n              \n                \n                  \n                    H\n                  \n                  \n                    2\n                  \n                  \n                    +\n                  \n                \n              \n             and the proton–electron mass ratio",
    "title_es": "High-accuracy laser spectroscopy of \n              \n                \n              \n              $${{\\bf{H}}}_{{\\bf{2}}}^{{\\boldsymbol{+}}}$$\n              \n                \n                  \n                    H\n                  \n                  \n                    2\n                  \n                  \n                    +\n                  \n                \n              \n             and the proton–electron mass ratio",
    "url": "https://www.nature.com/articles/s41586-025-09306-2",
    "published": "2025-08-06T00:00:00.000Z",
    "date": "2025-08-06",
    "content_es": "High-accuracy laser spectroscopy of \n              \n                \n              \n              $${{\\bf{H}}}_{{\\bf{2}}}^{{\\boldsymbol{+}}}$$\n              \n                \n                  \n                    H\n                  \n                  \n                    2\n                  \n                  \n                    +\n                  \n                \n              \n             and the proton–electron mass ratio",
    "source": "Nature",
    "description": "Este artículo trata sobre \"High-accuracy laser spectroscopy of \n              \n                \n              \n              $${{\\bf{H}}}_{{\\bf{2}}}^{{\\boldsymbol{+}}}$$\n              \n                \n                  \n                    H\n                  \n                  \n                    2\n                  \n                  \n                    +\n                  \n                \n              \n             and the proton–electron mass ratio\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "highaccuracy",
      "laser",
      "spectroscopy"
    ],
    "category": "noticia"
  },
  {
    "title": "Experiencing the Arctic",
    "title_es": "Experimentar el Ártico",
    "url": "https://www.science.org/doi/abs/10.1126/science.ady6388",
    "date": "2025-08-05",
    "source": "Science.org",
    "content_es": "Experiencing the Arctic",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Experimentar el Ártico\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "experiencing",
      "the",
      "arctic"
    ],
    "category": "noticia"
  },
  {
    "title": "CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward",
    "title_es": "CompassVerificador: un verificador unificado y robusto para la evaluación de LLMS y la recompensa de resultados",
    "url": "http://arxiv.org/abs/2508.03686v1",
    "date": "2025-08-05",
    "source": "arXiv",
    "content_es": "La verificación de respuestas es crucial no solo para evaluar modelos de idiomas grandes\n(LLMS) coincidiendo con sus salidas no estructuradas con respuestas estándar, pero\nTambién sirve como modelo de recompensa para guiar la optimización de LLM. La mayoría de la evaluación\nLos marcos dependen de la correspondencia regularizada o emplean LLM generales para su respuesta\nverificación, que exige una personalización extensa y repetitiva para las reglas regex\no indicaciones de evaluación. Persisten dos limitaciones fundamentales en la actualidad\nMetodologías: 1) La ausencia de puntos de referencia integrales que sistemáticamente\nevaluar las capacidades de verificación en diferentes LLM; y 2) el naciente\nEtapa del desarrollo del verificador, donde los enfoques existentes carecen de ambos\nrobustez para manejar casos de borde complejos y la generalización a través de\ndiferentes dominios. En este trabajo, desarrollamos CompassVerificador, un preciso y\nModelo de verificador liviano robusto para evaluación y recompensa de resultados. Él\nDemuestra la competencia de múltiples dominios que abarcan las matemáticas, el conocimiento y la diversa\ntareas de razonamiento, con la capacidad de procesar varios tipos de respuestas, incluidos\nmúltiples problemas, fórmulas y respuestas de secuencia, mientras que efectivamente\nIdentificación de respuestas anormales/inválidas. Presentamos verifierbench Benchmark\nComprensión de salidas de modelo recopiladas de múltiples fuentes de datos, aumentado\nA través del análisis manual de los patrones de metaéter para mejorar el Compassverificador. Nosotros\nAnticipe que CompassVerificador y VerifierBench facilitarán la respuesta\nVerificación, protocolos de evaluación e investigación de aprendizaje de refuerzo. Código\ny el conjunto de datos está disponible en https://github.com/open-compass/compassverifier.",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"CompassVerificador: un verificador unificado y robusto para la evaluación de LLMS y la recompensa de resultados\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "compassverifier",
      "a",
      "unified"
    ],
    "category": "noticia"
  },
  {
    "title": "Self-Questioning Language Models",
    "title_es": "Modelos de idiomas de auto cuestionamiento",
    "url": "http://arxiv.org/abs/2508.03682v1",
    "date": "2025-08-05",
    "source": "arXiv",
    "content_es": "¿Pueden los modelos de idiomas grandes mejorar sin datos externos, generando\nsus propias preguntas y respuestas? Presumimos que un lenguaje previamente capacitado\nEl modelo puede mejorar sus habilidades de razonamiento dadas solo un mensaje específico\nel tema (por ejemplo, problemas de palabras de álgebra) y pedirle al modelo que genere su\npropias preguntas. Para hacer esto, proponemos modelos de lenguaje autopuestionantes (SQLM):\nUn marco de reproducción asimétrico donde un propositor recibe el tema y\ngenera una pregunta para un solucionador, que intenta responderla. Ambos proposores\ny el solucionador se capacitan a través del aprendizaje de refuerzo. El propomedor recibe un\nrecompensa si el problema no es demasiado fácil o demasiado difícil, y el solucionador recibe\nuna recompensa basada en la votación mayoritaria, un indicador de la corrección en ausencia de\nrespuestas de verdad en tierra. Para la codificación, el proponente puede generar pruebas unitarias\nque se utilizan para la verificación. Estudiamos este marco asimétrico de la reproducción de\nEn tres puntos de referencia: multiplicación de tres dígitos, problemas de álgebra del\nOmega Benchmark, y problemas de programación de CodeForces. Por continuamente\nGenerando problemas más interesantes e intentando resolverlos, lenguaje\nLos modelos pueden mejorar los puntos de referencia posteriores sin acceso a ningún\nconjuntos de datos de capacitación.",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Modelos de idiomas de auto cuestionamiento\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "selfquestioning",
      "language",
      "models"
    ],
    "category": "noticia"
  },
  {
    "title": "ReVise: A Human-AI Interface for Incremental Algorithmic Recourse",
    "title_es": "ReVise: Una interfaz humano-inteligencia artificial para el recurso algorítmico incremental",
    "url": "https://arxiv.org/abs/2508.00002",
    "date": "2025-08-05",
    "source": "arXiv",
    "content_es": "ReVise: A Human-AI Interface for Incremental Algorithmic Recourse",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"ReVise: Una interfaz humano-inteligencia artificial para el recurso algorítmico incremental\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "revise",
      "a",
      "humanai"
    ],
    "category": "noticia"
  },
  {
    "title": "Building Bigraphs of the real world",
    "title_es": "Construir Bigraphs del mundo real",
    "url": "https://arxiv.org/abs/2508.00003",
    "date": "2025-08-05",
    "source": "arXiv",
    "content_es": "Building Bigraphs of the real world",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Construir Bigraphs del mundo real\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "building",
      "bigraphs",
      "of"
    ],
    "category": "noticia"
  },
  {
    "title": "Reasoning under uncertainty in the game of Cops and Robbers",
    "title_es": "Razonamiento bajo incertidumbre en el juego de Policías y Ladrones",
    "url": "https://arxiv.org/abs/2508.00004",
    "date": "2025-08-05",
    "source": "arXiv",
    "content_es": "Reasoning under uncertainty in the game of Cops and Robbers",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Razonamiento bajo incertidumbre en el juego de Policías y Ladrones\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "reasoning",
      "under",
      "uncertainty"
    ],
    "category": "noticia"
  },
  {
    "title": "Modelling Program Spaces in Program Synthesis with Constraints",
    "title_es": "Modelización de espacios de programa en la síntesis de programas con restricciones",
    "url": "https://arxiv.org/abs/2508.00005",
    "date": "2025-08-05",
    "source": "arXiv",
    "content_es": "Modelling Program Spaces in Program Synthesis with Constraints",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Modelización de espacios de programa en la síntesis de programas con restricciones\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "modelling",
      "program",
      "spaces"
    ],
    "category": "noticia"
  },
  {
    "title": "Agent Network Protocol Technical White Paper",
    "title_es": "Protocolo de red de agentes Libro Blanco técnico",
    "url": "https://arxiv.org/abs/2508.00007",
    "date": "2025-08-05",
    "source": "arXiv",
    "content_es": "Agent Network Protocol Technical White Paper",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Protocolo de red de agentes Libro Blanco técnico\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "agent",
      "network",
      "protocol"
    ],
    "category": "noticia"
  },
  {
    "title": "Dead in Banaras: An Ethnography of Funeral Travelling",
    "title_es": "Muertos en Banaras: Una etnografía de los viajes funerarios",
    "url": "https://www.science.org/doi/abs/10.1126/science.aea4215",
    "date": "2025-08-05",
    "source": "Science.org",
    "content_es": "Dead in Banaras: An Ethnography of Funeral Travelling",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Muertos en Banaras: Una etnografía de los viajes funerarios\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dead",
      "in",
      "banaras"
    ],
    "category": "noticia"
  },
  {
    "title": "An American energy experiment",
    "title_es": "An American energy experiment",
    "url": "https://www.science.org/doi/abs/10.1126/science.adz6514",
    "date": "2025-08-05",
    "source": "Science.org",
    "content_es": "An American energy experiment",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"An American energy experiment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "an",
      "american",
      "energy"
    ],
    "category": "noticia"
  },
  {
    "title": "Altered translation elongation contributes to key hallmarks of aging in the killifish brain",
    "title_es": "Las alteraciones en la elongación de la traducción contribuyen a las principales características del envejecimiento en el cerebro de los killis",
    "url": "https://www.science.org/doi/abs/10.1126/science.adk3079",
    "date": "2025-08-05",
    "source": "Science.org",
    "content_es": "Altered translation elongation contributes to key hallmarks of aging in the killifish brain",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Las alteraciones en la elongación de la traducción contribuyen a las principales características del envejecimiento en el cerebro de los killis\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "altered",
      "translation",
      "elongation"
    ],
    "category": "noticia"
  },
  {
    "title": "High-field superconducting halo in UTe2",
    "title_es": "Halo superconductor de alto campo en UTe2",
    "url": "https://www.science.org/doi/abs/10.1126/science.adn7673",
    "date": "2025-08-05",
    "source": "Science.org",
    "content_es": "High-field superconducting halo in UTe2",
    "published": "2025-08-05T00:00:00.000Z",
    "description": "Este artículo trata sobre \"Halo superconductor de alto campo en UTe2\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "highfield",
      "superconducting",
      "halo"
    ],
    "category": "noticia"
  },
  {
    "title": "Breed giant prawns to withstand disease and climate change",
    "url": "https://www.nature.com/articles/d41586-025-02477-y",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "summary": "",
    "source": "Nature",
    "title_es": "Breed giant prawns to withstand disease and climate change",
    "content_es": "Breed giant prawns to withstand disease and climate change",
    "description": "Este artículo trata sobre \"Breed giant prawns to withstand disease and climate change\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "breed",
      "giant",
      "prawns"
    ],
    "category": "noticia"
  },
  {
    "title": "Conserve marine migratory species to protect ecological links between land and sea",
    "url": "https://www.nature.com/articles/d41586-025-02475-0",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "summary": "",
    "source": "Nature",
    "title_es": "Conserve marine migratory species to protect ecological links between land and sea",
    "content_es": "Conserve marine migratory species to protect ecological links between land and sea",
    "description": "Este artículo trata sobre \"Conserve marine migratory species to protect ecological links between land and sea\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "conserve",
      "marine",
      "migratory"
    ],
    "category": "noticia"
  },
  {
    "title": "Tackle fake citations generated by AI",
    "url": "https://www.nature.com/articles/d41586-025-02482-1",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "summary": "",
    "source": "Nature",
    "title_es": "Tackle fake citations generated by AI",
    "content_es": "Tackle fake citations generated by AI",
    "description": "Este artículo trata sobre \"Tackle fake citations generated by AI\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "tackle",
      "fake",
      "citations"
    ],
    "category": "noticia"
  },
  {
    "title": "Mystery of billions of sea-star deaths solved at last",
    "url": "https://www.nature.com/articles/d41586-025-02442-9",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "summary": "",
    "source": "Nature",
    "title_es": "Mystery of billions of sea-star deaths solved at last",
    "content_es": "Mystery of billions of sea-star deaths solved at last",
    "description": "Este artículo trata sobre \"Mystery of billions of sea-star deaths solved at last\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mystery",
      "of",
      "billions"
    ],
    "category": "noticia"
  },
  {
    "title": "Plan-B careers can be a force for good in science",
    "url": "https://www.nature.com/articles/d41586-025-02478-x",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "summary": "",
    "source": "Nature",
    "title_es": "Plan-B careers can be a force for good in science",
    "content_es": "Plan-B careers can be a force for good in science",
    "description": "Este artículo trata sobre \"Plan-B careers can be a force for good in science\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "planb",
      "careers",
      "can"
    ],
    "category": "noticia"
  },
  {
    "title": "Don’t train medical AI on patients’ data without their knowledge",
    "url": "https://www.nature.com/articles/d41586-025-02480-3",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "summary": "",
    "source": "Nature",
    "title_es": "Don’t train medical AI on patients’ data without their knowledge",
    "content_es": "Don’t train medical AI on patients’ data without their knowledge",
    "description": "Este artículo trata sobre \"Don’t train medical AI on patients’ data without their knowledge\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dont",
      "train",
      "medical"
    ],
    "category": "noticia"
  },
  {
    "title": "Tiny motor uses heat to perform molecular magic",
    "url": "https://www.nature.com/articles/d41586-025-02440-x",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "summary": "",
    "source": "Nature",
    "title_es": "Tiny motor uses heat to perform molecular magic",
    "content_es": "Tiny motor uses heat to perform molecular magic",
    "description": "Este artículo trata sobre \"Tiny motor uses heat to perform molecular magic\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "tiny",
      "motor",
      "uses"
    ],
    "category": "noticia"
  },
  {
    "title": "Protect Palestinian archaeological sites during war",
    "url": "https://www.nature.com/articles/d41586-025-02476-z",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "summary": "",
    "source": "Nature",
    "title_es": "Protect Palestinian archaeological sites during war",
    "content_es": "Protect Palestinian archaeological sites during war",
    "description": "Este artículo trata sobre \"Protect Palestinian archaeological sites during war\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "protect",
      "palestinian",
      "archaeological"
    ],
    "category": "noticia"
  },
  {
    "title": "Baboons defend themselves by throwing stones",
    "url": "https://www.nature.com/articles/d41586-025-02257-8",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "summary": "",
    "source": "Nature",
    "title_es": "Baboons defend themselves by throwing stones",
    "content_es": "Baboons defend themselves by throwing stones",
    "description": "Este artículo trata sobre \"Baboons defend themselves by throwing stones\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "baboons",
      "defend",
      "themselves"
    ],
    "category": "noticia"
  },
  {
    "title": "Overcome threats to renewable energy through skilful statecraft",
    "url": "https://www.nature.com/articles/d41586-025-02479-w",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "summary": "",
    "source": "Nature",
    "title_es": "Overcome threats to renewable energy through skilful statecraft",
    "content_es": "Overcome threats to renewable energy through skilful statecraft",
    "description": "Este artículo trata sobre \"Overcome threats to renewable energy through skilful statecraft\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "overcome",
      "threats",
      "to"
    ],
    "category": "noticia"
  },
  {
    "title": "Protection from biological hazards at work arrives at last",
    "url": "https://www.nature.com/articles/d41586-025-02481-2",
    "published": "2025-08-05T00:00:00.000Z",
    "date": "2025-08-05",
    "summary": "",
    "source": "Nature",
    "title_es": "Protection from biological hazards at work arrives at last",
    "content_es": "Protection from biological hazards at work arrives at last",
    "description": "Este artículo trata sobre \"Protection from biological hazards at work arrives at last\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "protection",
      "from",
      "biological"
    ],
    "category": "noticia"
  },
  {
    "title": "Claudia Monaco: “We think we know a lot about cardiovascular disease, but in reality, we don't”",
    "title_es": "Claudia Monaco: “We think we know a lot about cardiovascular disease, but in reality, we don't”",
    "url": "https://www.cnic.es/es/node/235736",
    "date": "2025-08-01",
    "source": "CNIC",
    "content_es": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDr. Claudia Monaco, Kennedy Institute of Rheumatology, Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, University of Oxford, UK\n\n\n\nClaudia Monacoo trained as a cardiologist and PhD with Professor Attilio Maseri at the Catholic University of Rome, Italy, before moving to the Kennedy Institute of Rheumatology, Imperial College London to work with Professor Marc Feldmann. She moved to the University of Oxford in 2011, where she became Professor of Cardiovascular Inflammation. Her group was the first to establish innovative experimental methodology for the isolation, culture and targeting of live cells from human atheroma lesions. Her work allowed the elegant characterization of the inflammatory and synthetic properties of human atherosclerosis, establishing toll-like receptors as important activators of innate immunity in atherosclerosis. The Cardiovascular Inflammation Team is now focused on interpreting the functional diversity of immune cells in atherosclerosis with single cell biology techniques and devise strategies for their selective targeting.\n\nWhat is the role of macrophages in the development of atherosclerosis, and how has our understanding of their function evolved?\n\nWe are focused, in particular, on macrophages and what their function is in atherosclerosis. I think it’s quite interesting, because different types of macrophages have different functions in the development of atherosclerosis. Before, we thought that all macrophages were bad—that all macrophages and the whole immune system were actually promoting atherosclerosis. But now we know the picture is much more complex than that.\nIt’s very related to what macrophages are, where they’re seeded, and how they establish themselves in specific niches. There are some macrophages, like the lipid-associated macrophages, that definitely promote disease. But there are others—vascular macrophages that are already present within the vessel wall—that actually act like guardians of the artery and are protective.\nI think it’s very important—this direction we’re going in, toward more targeted therapies. The idea is not to block all macrophages, because some are actually your friends. You need to look after them, especially the ones in the artery, while others are really pushing things toward a dangerous, disease-promoting path. This duality is really important, especially from a therapeutic perspective. That’s why we’re so fixated on understanding this better.\n\nAnd how can you tell the difference between the “good” macrophages and the ones you want to block? What kind of techniques do you use?\n\nWe use single-cell biology a lot. We’re not yet in the clinical space, but we’ve identified good markers. If those markers prove reliable, it would be easy to translate this into new tools to look at different macrophages in vivo. There’s also the potential to tailor imaging—not just therapeutics, but also how we visualize these macrophages.\nThe key idea we want to get across is that there isn’t just “one” macrophage type. We always said that macrophages are very pleiotropic—that they can take on different phenotypes—but that didn’t always seem to matter because we thought they all eventually just changed into each other. But actually, that’s not quite true.\nThere is some dynamic flexibility, yes, but it's quite reproducible which path they take. They really adapt specifically to their environment. For example, in the adventitia, they adopt a very specific phenotype, and in the intima, a different one. And these phenotypes remain pretty stable during atherosclerosis, and also in health and disease. They’re not just switching randomly between states, they’re adapting in a niche-specific way, just like cells in any other organ. That’s important because it means we can start visualizing and treating patients differently more precisely.\n\nYou mentioned you're still in the experimental phase and not yet in clinical trials. How far is immunotherapy for cardiovascular disease?\n\nI think there have been some early trials, and there are more and more now that are targeting inflammation in atherosclerosis. It’s really a booming field. We waited a long time to get here. The field was slow to move in this direction because so much focus was on lowering cholesterol, which is of course important—but inflammation wasn’t really explored until recently.\nStudies like the CANTOS trial and others have started targeting cytokines, and I think we are going in the right direction. But progress is still very slow. One big reason is the lack of imaging tools. Imaging is only now reaching the level where we can maybe use it instead of relying on hard cardiovascular outcomes in trials.\nIf you look at cancer, for example, you can track things much faster, look at the size of the tumor, and see how the patient is responding. Same for diseases like rheumatoid arthritis, where you can scan the joints or use PET imaging. Those imaging methods have been around for decades, and they’ve made it possible to run smaller trials that are either based on imaging or give you very clear, early outcomes.\nBut with cardiovascular disease, we still have to look at how patients are doing over 5, 10 years. That’s a big challenge. These trials are very expensive, especially because biologic drugs cost so much. So pharmaceutical companies need to make a huge financial commitment. The more we can improve imaging, the more we’ll be able to run meaningful trials that evaluate new biologics or targeted agents, like nanotechnology-based ones.\nI think evolution isn’t just about immunology, it’s also about how we study this in the real world. Other fields can run smaller trials to understand how things work and then move on to larger outcome trials. But here, with trials like the CANTOS trial—which involved over 10,000 patients and a very expensive biologic—that kind of scale is almost unheard of in other diseases like rheumatoid arthritis.\nSo yes, the challenges are really at the clinical stage—how we bring all this incredible knowledge about the immune system into cardiovascular medicine. The real barrier is economic.\n\nYou’re a cardiologist—you worked in Rome for many years, and then you moved to Oxford. You trained as a cardiologist, and then you also shifted into doing experiments and research. How do you combine these two areas?\n\nWell, combining clinical duties and research is one of the biggest challenges you can attempt to do.  I think if you’re doing clinical research—like outcomes-based research or imaging studies—then it’s easier to combine with clinical work. But if you’re developing science at the molecular level, it’s much harder to do both. At least I couldn’t manage it as well as I would have liked.\nThere’s a big divide between what we think we know and what we actually know. We have this concept of how atherosclerosis develops, how the immune system contributes—but in reality, we don’t really understand the specific mechanisms at play. I felt that, to bridge this gap, I had to go back to the basics. That meant not only using experimental models but also working with human samples. I saw a huge opportunity in single-cell biology has been a big opportunity—for all of us—to understand human immunology at a very detailed level. Because if we only look at mice, then the gap between mouse and human, and then from preclinical to clinical stages, is massive.\nFor example, we really need access to human vascular tissue. But as cardiologists, we’ve moved so much toward percutaneous approaches to the coronary arteries, so we don’t actually remove them anymore. That’s why I work a lot with vascular surgeons. They still operate in a way that allows us to obtain human tissue—but that might not last. Even vascular surgery is moving more and more toward stenting, which means we’ll eventually lose the ability to get that tissue. We have this narrow window of opportunity where we can still work with tissue from patients, and I felt I had to take it. I’m very vocal about this having a short window before vascular surgery becomes entirely percutaneous, \n\nIt seems like improvements in clinical treatment are making things harder for basic science in a way.\n\nExactly. It’s advancing, but at the same time, it means that now we have this critical window. I always say vascular surgeons do research, collect tissue, because we need to analyze what the cells are really doing. Just relying on blood studies, on systemic inflammation, doesn’t tell us much about what’s happening in the atherosclerotic artery. The immune cells inside the artery are very different in their programming compared to circulating cells in the blood.\nMost cells come from the blood—but there are also some embryonic macrophages that form inside the artery and never circulate. And even the ones that come from the blood and stay in the artery for 10 years, they acquire very specialized instructions. You can take monocytes from blood and run as many blood tests as you want—but that doesn’t tell you what’s actually happening inside the artery.\nThey behave differently, they look different, they’ve changed their shape and function completely. This creates a gap in what we can understand—it seems like we’re missing something in these studies . We can’t see all the different effects a drug might have if we only look at peripheral blood. I think the real answers are also in the vascular tissue, in the atherosclerotic plaque itself. We need to go as close to the source as possible—to find real targets, and to see the real effects of drugs on atherosclerotic tissue.\nBecause a lot of clinical trials have targeted systemic inflammation. But that’s not the same as inflammation within the plaque. The drivers of plaque inflammation may be different.\nWe know systemic inflammation is a risk factor, yes, but what you see in the blood isn’t necessarily what’s happening in the plaque. We often assume it is—because it’s convenient. But in cardiovascular disease, especially cardiology, we never actually look at the plaque. We look at the lumen. Intravascular ultrasound (IVUS) is the only way to get a glimpse of the arterial wall. Experimentally, we might look at blood from the heart in very complex ways—but we’re still mainly looking at circulating markers. We’re not really studying the tissue itself.\n\n\nAs a cardiologist with experience of treating patients, do you think your clinical background influences the kinds of research questions you ask?\n\nYes. And there are two things that help me a lot, I think. And that’s why I never stop clinics, even though they told me several times to stop clinics. I think I... I don’t like to stop the clinics because I enjoy that interaction.\nI think, being a scientist, your rewards are very long-term. If you’re a doctor, the rewards are quite immediate, because the patient is happier, yes—you can give the treatment. So, I think it gives me a lot of motivation to serve the patient. But at the same time, I think research is also a good way to serve patients.\nBecause as a clinician I’ve learned a lot from basic scientists. They’re much better at developing techniques at the bench, and so I have great respect for my scientific colleagues. But sometimes, as a clinician, you can see what really matters. And it makes you particularly attached to a specific disease, you know? Basic scientists are sometimes across fields. This study gives me the determination and the drive to really try and solve atherosclerosis.",
    "published": "2025-08-01T00:00:00.000Z",
    "summary": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDr. Claudia Monaco, Kennedy Institute of Rheumatology, Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, University of Oxford, UK\n\n\n\nClaudia Monacoo trained as a cardiologist and PhD with Professor Attilio Maseri at the Catholic University of Rome, Italy, before moving to the Kennedy Institute of Rheumatology, Imperial College London to work with Professor Marc Feldmann. She moved to the University of Oxford in 2011, where she became Professor of Cardiovascular Inflammation. Her group was the first to establish innovative experimental methodology for the isolation, culture and targeting of live cells from human atheroma lesions. Her work allowed the elegant characterization of the inflammatory and synthetic properties of human atherosclerosis, establishing toll-like receptors as important activators of innate immunity in atherosclerosis. The Cardiovascular Inflammation Team is now focused on interpreting the functional diversity of immune cells in atherosclerosis with single cell biology techniques and devise strategies for their selective targeting.\n\nWhat is the role of macrophages in the development of atherosclerosis, and how has our understanding of their function evolved?\n\nWe are focused, in particular, on macrophages and what their function is in atherosclerosis. I think it’s quite interesting, because different types of macrophages have different functions in the development of atherosclerosis. Before, we thought that all macrophages were bad—that all macrophages and the whole immune system were actually promoting atherosclerosis. But now we know the picture is much more complex than that.\nIt’s very related to what macrophages are, where they’re seeded, and how they establish themselves in specific niches. There are some macrophages, like the lipid-associated macrophages, that definitely promote disease. But there are others—vascular macrophages that are already present within the vessel wall—that actually act like guardians of the artery and are protective.\nI think it’s very important—this direction we’re going in, toward more targeted therapies. The idea is not to block all macrophages, because some are actually your friends. You need to look after them, especially the ones in the artery, while others are really pushing things toward a dangerous, disease-promoting path. This duality is really important, especially from a therapeutic perspective. That’s why we’re so fixated on understanding this better.\n\nAnd how can you tell the difference between the “good” macrophages and the ones you want to block? What kind of techniques do you use?\n\nWe use single-cell biology a lot. We’re not yet in the clinical space, but we’ve identified good markers. If those markers prove reliable, it would be easy to translate this into new tools to look at different macrophages in vivo. There’s also the potential to tailor imaging—not just therapeutics, but also how we visualize these macrophages.\nThe key idea we want to get across is that there isn’t just “one” macrophage type. We always said that macrophages are very pleiotropic—that they can take on different phenotypes—but that didn’t always seem to matter because we thought they all eventually just changed into each other. But actually, that’s not quite true.\nThere is some dynamic flexibility, yes, but it's quite reproducible which path they take. They really adapt specifically to their environment. For example, in the adventitia, they adopt a very specific phenotype, and in the intima, a different one. And these phenotypes remain pretty stable during atherosclerosis, and also in health and disease. They’re not just switching randomly between states, they’re adapting in a niche-specific way, just like cells in any other organ. That’s important because it means we can start visualizing and treating patients differently more precisely.\n\nYou mentioned you're still in the experimental phase and not yet in clinical trials. How far is immunotherapy for cardiovascular disease?\n\nI think there have been some early trials, and there are more and more now that are targeting inflammation in atherosclerosis. It’s really a booming field. We waited a long time to get here. The field was slow to move in this direction because so much focus was on lowering cholesterol, which is of course important—but inflammation wasn’t really explored until recently.\nStudies like the CANTOS trial and others have started targeting cytokines, and I think we are going in the right direction. But progress is still very slow. One big reason is the lack of imaging tools. Imaging is only now reaching the level where we can maybe use it instead of relying on hard cardiovascular outcomes in trials.\nIf you look at cancer, for example, you can track things much faster, look at the size of the tumor, and see how the patient is responding. Same for diseases like rheumatoid arthritis, where you can scan the joints or use PET imaging. Those imaging methods have been around for decades, and they’ve made it possible to run smaller trials that are either based on imaging or give you very clear, early outcomes.\nBut with cardiovascular disease, we still have to look at how patients are doing over 5, 10 years. That’s a big challenge. These trials are very expensive, especially because biologic drugs cost so much. So pharmaceutical companies need to make a huge financial commitment. The more we can improve imaging, the more we’ll be able to run meaningful trials that evaluate new biologics or targeted agents, like nanotechnology-based ones.\nI think evolution isn’t just about immunology, it’s also about how we study this in the real world. Other fields can run smaller trials to understand how things work and then move on to larger outcome trials. But here, with trials like the CANTOS trial—which involved over 10,000 patients and a very expensive biologic—that kind of scale is almost unheard of in other diseases like rheumatoid arthritis.\nSo yes, the challenges are really at the clinical stage—how we bring all this incredible knowledge about the immune system into cardiovascular medicine. The real barrier is economic.\n\nYou’re a cardiologist—you worked in Rome for many years, and then you moved to Oxford. You trained as a cardiologist, and then you also shifted into doing experiments and research. How do you combine these two areas?\n\nWell, combining clinical duties and research is one of the biggest challenges you can attempt to do.  I think if you’re doing clinical research—like outcomes-based research or imaging studies—then it’s easier to combine with clinical work. But if you’re developing science at the molecular level, it’s much harder to do both. At least I couldn’t manage it as well as I would have liked.\nThere’s a big divide between what we think we know and what we actually know. We have this concept of how atherosclerosis develops, how the immune system contributes—but in reality, we don’t really understand the specific mechanisms at play. I felt that, to bridge this gap, I had to go back to the basics. That meant not only using experimental models but also working with human samples. I saw a huge opportunity in single-cell biology has been a big opportunity—for all of us—to understand human immunology at a very detailed level. Because if we only look at mice, then the gap between mouse and human, and then from preclinical to clinical stages, is massive.\nFor example, we really need access to human vascular tissue. But as cardiologists, we’ve moved so much toward percutaneous approaches to the coronary arteries, so we don’t actually remove them anymore. That’s why I work a lot with vascular surgeons. They still operate in a way that allows us to obtain human tissue—but that might not last. Even vascular surgery is moving more and more toward stenting, which means we’ll eventually lose the ability to get that tissue. We have this narrow window of opportunity where we can still work with tissue from patients, and I felt I had to take it. I’m very vocal about this having a short window before vascular surgery becomes entirely percutaneous, \n\nIt seems like improvements in clinical treatment are making things harder for basic science in a way.\n\nExactly. It’s advancing, but at the same time, it means that now we have this critical window. I always say vascular surgeons do research, collect tissue, because we need to analyze what the cells are really doing. Just relying on blood studies, on systemic inflammation, doesn’t tell us much about what’s happening in the atherosclerotic artery. The immune cells inside the artery are very different in their programming compared to circulating cells in the blood.\nMost cells come from the blood—but there are also some embryonic macrophages that form inside the artery and never circulate. And even the ones that come from the blood and stay in the artery for 10 years, they acquire very specialized instructions. You can take monocytes from blood and run as many blood tests as you want—but that doesn’t tell you what’s actually happening inside the artery.\nThey behave differently, they look different, they’ve changed their shape and function completely. This creates a gap in what we can understand—it seems like we’re missing something in these studies . We can’t see all the different effects a drug might have if we only look at peripheral blood. I think the real answers are also in the vascular tissue, in the atherosclerotic plaque itself. We need to go as close to the source as possible—to find real targets, and to see the real effects of drugs on atherosclerotic tissue.\nBecause a lot of clinical trials have targeted systemic inflammation. But that’s not the same as inflammation within the plaque. The drivers of plaque inflammation may be different.\nWe know systemic inflammation is a risk factor, yes, but what you see in the blood isn’t necessarily what’s happening in the plaque. We often assume it is—because it’s convenient. But in cardiovascular disease, especially cardiology, we never actually look at the plaque. We look at the lumen. Intravascular ultrasound (IVUS) is the only way to get a glimpse of the arterial wall. Experimentally, we might look at blood from the heart in very complex ways—but we’re still mainly looking at circulating markers. We’re not really studying the tissue itself.\n\n\nAs a cardiologist with experience of treating patients, do you think your clinical background influences the kinds of research questions you ask?\n\nYes. And there are two things that help me a lot, I think. And that’s why I never stop clinics, even though they told me several times to stop clinics. I think I... I don’t like to stop the clinics because I enjoy that interaction.\nI think, being a scientist, your rewards are very long-term. If you’re a doctor, the rewards are quite immediate, because the patient is happier, yes—you can give the treatment. So, I think it gives me a lot of motivation to serve the patient. But at the same time, I think research is also a good way to serve patients.\nBecause as a clinician I’ve learned a lot from basic scientists. They’re much better at developing techniques at the bench, and so I have great respect for my scientific colleagues. But sometimes, as a clinician, you can see what really matters. And it makes you particularly attached to a specific disease, you know? Basic scientists are sometimes across fields. This study gives me the determination and the drive to really try and solve atherosclerosis.",
    "description": "Este artículo trata sobre \"Claudia Monaco: “We think we know a lot about cardiovascular disease, but in reality, we don't”\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "claudia",
      "monaco",
      "we"
    ],
    "category": "noticia"
  },
  {
    "title": "Dra. Claudia Monaco: “En las enfermedades cardiovasculares, pensamos que sabemos mucho; pero en realidad, no es así”",
    "title_es": "Dra. Claudia Monaco: “En las enfermedades cardiovasculares, pensamos que sabemos mucho; pero en realidad, no es así”",
    "url": "https://www.cnic.es/es/noticias/dra-claudia-monaco-enfermedades-cardiovasculares-pensamos-que-sabemos-mucho-pero-realidad",
    "date": "2025-08-01",
    "source": "CNIC",
    "content_es": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDra. Claudia Monaco:  Instituto Kennedy de Reumatología, Departamento Nuffield de Ortopedia, Reumatología y Ciencias Musculoesqueléticas, Universidad de Oxford, Reino Unido\n\n\n\nClaudia Monaco se formó como cardióloga y doctoró con el profesor Attilio Maseri en la Universidad Católica de Roma, Italia, antes de trasladarse al Instituto Kennedy de Reumatología del Imperial College de Londres para trabajar con el profesor Marc Feldmann. En 2011 se trasladó a la Universidad de Oxford, donde se convirtió en profesora de Inflamación Cardiovascular. Su grupo fue el primero en establecer una metodología experimental innovadora para el aislamiento, cultivo y selección de células vivas de lesiones ateromatosas humanas. Su trabajo permitió caracterizar de forma elegante las propiedades inflamatorias y sintéticas de la aterosclerosis humana, estableciendo los receptores toll-like como activadores importantes de la inmunidad innata en la aterosclerosis. Su grupo de inflamación cardiovascular se centra ahora en interpretar la diversidad funcional de las células inmunitarias en la aterosclerosis con técnicas de biología celular única y en diseñar estrategias para su selección selectiva.\n\n¿Cuál es el papel de los macrófagos en el desarrollo de la aterosclerosis y cómo ha evolucionado nuestra comprensión de su función?\n\nNos centramos, en particular, en los macrófagos y en cuál es su función en la aterosclerosis. Es muy interesante porque los diferentes tipos de macrófagos tienen diferentes funciones en el desarrollo de la aterosclerosis. Antes pensábamos que todos los macrófagos eran malos, que todos los macrófagos y todo el sistema inmunitario favorecían la aterosclerosis. Pero ahora sabemos que el panorama es mucho más complejo.\nEstá muy relacionado con lo que son los macrófagos, dónde se siembran y cómo se establecen en nichos específicos. Hay algunos macrófagos, como los macrófagos asociados a los lípidos, que sin duda favorecen la enfermedad. Pero hay otros, los macrófagos vasculares que ya están presentes en la pared de los vasos, que en realidad actúan como guardianes de la arteria y la protegen.\nCreo que es muy importante la dirección que estamos tomando, hacia terapias más específicas. La idea no es bloquear todos los macrófagos, porque algunos son realmente nuestros aliados. Hay que cuidarlos, especialmente los que se encuentran en las arterias, mientras que otros realmente empujan hacia un camino peligroso que favorece la enfermedad. Esta dualidad es muy importante, especialmente desde el punto de vista terapéutico. Por eso estamos tan obsesionadas con comprenderlo mejor.\n\n¿Cómo se puede distinguir entre los macrófagos «buenos» y los que se quieren bloquear? ¿Qué tipo de técnicas se utilizan?\n\nUtilizamos mucho la biología unicelular. Aún no estamos en el ámbito clínico, pero hemos identificado buenos marcadores. Si esos marcadores resultan fiables, sería fácil traducirlos en nuevas herramientas para observar diferentes macrófagos in vivo. También existe la posibilidad de adaptar las imágenes, no solo las terapéuticas, sino también la forma en que visualizamos estos macrófagos.\nLa idea clave que queremos transmitir es que no existe un único tipo de macrófago. Siempre hemos dicho que los macrófagos son muy pleiotrópicos, es decir, que pueden adoptar diferentes fenotipos, pero eso no siempre parecía importar porque pensábamos que, al final, todos se transformaban unos en otros. Pero, en realidad, eso no es del todo cierto.\nHay cierta flexibilidad dinámica, sí, pero la trayectoria que siguen es bastante reproducible. Se adaptan específicamente a su entorno. Por ejemplo, en la adventicia adoptan un fenotipo muy específico, y en la íntima, otro diferente. Y estos fenotipos se mantienen bastante estables durante la aterosclerosis, así como en la salud y la enfermedad. No cambian aleatoriamente entre estados, sino que se adaptan de forma específica a cada nicho, al igual que las células de cualquier otro órgano. Esto es importante porque significa que podemos empezar a visualizar y tratar a los pacientes de forma diferente y más precisa.\n\nHa mencionado que aún se encuentra en la fase experimental y que aún no se han realizado ensayos clínicos. ¿En qué punto se encuentra la inmunoterapia para las enfermedades cardiovasculares?\n\nCreo que se han realizado algunos ensayos preliminares y ahora hay cada vez más estudios que se centran en la inflamación en la aterosclerosis. Es un campo en auge. Hemos esperado mucho tiempo para llegar hasta aquí. El campo tardó en avanzar en esta dirección porque se prestaba mucha atención a la reducción del colesterol, lo cual es importante, por supuesto, pero la inflamación no se ha explorado realmente hasta hace poco.\nEstudios como el ensayo CANTOS y otros han comenzado a centrarse en las citocinas, y creo que vamos en la dirección correcta. Pero el progreso sigue siendo muy lento. Una de las principales razones es la falta de herramientas de imagen. Las técnicas de imagen están alcanzando ahora un nivel en el que quizá podamos utilizarlas en lugar de basarnos en los resultados cardiovasculares de los ensayos.\nSi nos fijamos en el cáncer, por ejemplo, se puede hacer un seguimiento mucho más rápido, observar el tamaño del tumor y ver cómo responde el paciente. Lo mismo ocurre con enfermedades como la artritis reumatoide, en las que se pueden escanear las articulaciones o utilizar imágenes PET. Estos métodos de imagen llevan décadas utilizándose y han permitido realizar ensayos más pequeños basados en imágenes o que ofrecen resultados muy claros y tempranos.\nSin embargo, en el caso de las enfermedades cardiovasculares, todavía tenemos que observar cómo evolucionan los pacientes a lo largo de 5 o 10 años. Eso supone un gran reto. Estos ensayos son muy caros, sobre todo porque los medicamentos biológicos cuestan mucho. Por lo tanto, las empresas farmacéuticas deben asumir un enorme compromiso financiero. Cuanto más mejoremos las imágenes, más podremos realizar ensayos significativos que evalúen nuevos productos biológicos o agentes dirigidos, como los basados en la nanotecnología.\nCreo que la evolución no se limita a la inmunología, sino que también tiene que ver con cómo estudiamos esto en el mundo real. Otros campos pueden realizar ensayos más pequeños para comprender cómo funcionan las cosas y luego pasar a ensayos de resultados más amplios. Pero aquí, con ensayos como el CANTOS, en el que participaron más de 10.000 pacientes y se utilizó un fármaco biológico muy caro, ese tipo de escala es casi inaudito en otras enfermedades como la artritis reumatoide.\nAsí que sí, los retos se encuentran realmente en la fase clínica: cómo trasladar todos estos increíbles conocimientos sobre el sistema inmunitario a la medicina cardiovascular. La verdadera barrera es económica.\n\nUsted es cardióloga, trabajó en Roma durante muchos años y luego se trasladó a Oxford. Se formó como cardióloga y luego también pasó a dedicarse a la experimentación y la investigación. ¿Cómo combina estas dos áreas?\n\nCombinar las tareas clínicas y la investigación es uno de los mayores retos a los que te puedes enfrentar.  Creo que, si una se dedica a la investigación clínica, como la investigación basada en resultados o los estudios de imagen, es más fácil combinarla con el trabajo clínico. Pero si se trabaja más en el desarrollo científico a nivel molecular, es mucho más difícil compaginar ambas cosas. Al menos yo no pude hacerlo tan bien como me hubiera gustado.\n Existe una gran diferencia entre lo que creemos saber y lo que realmente sabemos. Tenemos una idea de cómo se desarrolla la aterosclerosis, cómo contribuye el sistema inmunitario, pero en realidad no entendemos los mecanismos específicos que intervienen. Sentí que, para salvar esta brecha, tenía que volver a lo básico. Eso significaba no solo utilizar modelos experimentales, sino también trabajar con muestras humanas. Vi una gran oportunidad en la biología de células individuales, que ha sido una gran oportunidad para todos nosotros para comprender la inmunología humana a un nivel muy detallado. Porque si solo nos fijamos en los ratones, la brecha entre estos y los seres humanos, y luego entre las etapas preclínicas y clínicas, es enorme.\nPor ejemplo, realmente necesitamos acceso al tejido vascular humano. Pero como cardiólogos, hemos avanzado tanto hacia los abordajes percutáneos de las arterias coronarias que ya no las extirpamos. Por eso trabajo mucho con cirujanos vasculares. Ellos siguen operando de una manera que nos permite obtener tejido humano, pero eso podría no durar mucho tiempo. Incluso la cirugía vascular se está orientando cada vez más hacia la implantación de stents, lo que significa que, con el tiempo, perderemos la capacidad de obtener ese tejido. Tenemos una ventana de oportunidad muy estrecha en la que todavía podemos trabajar con tejido de pacientes, y sentí que tenía que aprovecharla. Soy muy clara al afirmar que tenemos poco tiempo antes de que la cirugía vascular se vuelva completamente percutánea, lo que, por supuesto, es un avance, pero también nos priva de la oportunidad de estudiar tejidos humanos reales.\n\nParece que las mejoras en el tratamiento clínico están dificultando en cierto modo la ciencia básica.\n\nExactamente. Está avanzando, pero al mismo tiempo significa que ahora tenemos esta ventana crítica. Siempre digo que los cirujanos vasculares investigan y recogen tejido porque necesitamos analizar lo que realmente hacen las células. Basarnos únicamente en los análisis de sangre y en la inflamación sistémica no nos dice mucho sobre lo que está sucediendo en la arteria aterosclerótica. Las células inmunitarias del interior de la arteria son muy diferentes en su programación en comparación con las células circulantes en la sangre.\nLa mayoría de las células provienen de la sangre, pero también hay algunos macrófagos embrionarios que se forman dentro de la arteria y nunca circulan. E incluso los que provienen de la sangre y permanecen en la arteria durante 10 años, adquieren instrucciones muy especializadas. Se pueden extraer monocitos de la sangre y realizar tantos análisis de sangre como se desee, pero eso no revela lo que realmente ocurre dentro de la arteria.\nSe comportan de manera diferente, tienen un aspecto diferente, han cambiado completamente su forma y función. Esto crea una brecha en lo que podemos entender, parece que nos estamos perdiendo algo en estos estudios. No podemos ver todos los diferentes efectos que puede tener un fármaco si solo miramos la sangre periférica. Creo que las respuestas reales también se encuentran en el tejido vascular, en la propia placa aterosclerótica. Tenemos que acercarnos lo más posible a la fuente para encontrar los objetivos reales y ver los efectos reales de los fármacos en el tejido aterosclerótico.\nPorque muchos ensayos clínicos se han centrado en la inflamación sistémica. Pero eso no es lo mismo que la inflamación dentro de la placa. Los factores que provocan la inflamación de la placa pueden ser diferentes.\nSabemos que la inflamación sistémica es un factor de riesgo, sí, pero lo que se ve en la sangre no es necesariamente lo que ocurre en la placa. A menudo asumimos que lo es, porque es conveniente. Pero en las enfermedades cardiovasculares, especialmente en cardiología, nunca miramos realmente la placa. Miramos la luz. La ecografía intravascular (IVUS) es la única forma de echar un vistazo a la pared arterial.\nDesde el punto de vista experimental, podemos analizar la sangre del corazón de formas muy complejas, pero seguimos centrándonos principalmente en los marcadores circulantes. En realidad, no estamos estudiando el tejido en sí.\n\nComo cardióloga con experiencia en el tratamiento de pacientes, ¿cree que su experiencia clínica influye en el tipo de preguntas de investigación que se plantea?\n\nSí. Y hay dos cosas que me ayudan mucho. Por eso nunca dejo de ejercer en la clínica, aunque me han dicho varias veces que lo haga. Creo que... no me gusta dejar la clínica porque disfruto de esa interacción.\nComo científica, las recompensas son a muy largo plazo. Si eres médico, las recompensas son bastante inmediatas, porque el paciente está más contento si puedes darle el tratamiento. Por lo tanto, creo que me motiva mucho atender al paciente. Pero, al mismo tiempo, pienso que la investigación también es una buena forma de atender a los pacientes.\nPorque, como médico, he aprendido mucho de los científicos básicos. Son mucho mejores desarrollando técnicas en el laboratorio, por lo que siento un gran respeto por mis colegas científicos. Pero a veces, como médico clínico, puedes ver lo que realmente importa. Y eso te hace sentir especialmente vinculado a una enfermedad concreta. Los científicos básicos a veces abarcan varios campos. Este estudio me da la determinación y el impulso para intentar resolver realmente la aterosclerosis.\n\n\n¿De niña, se imaginó dedicándose a la ciencia o la medicina y, finalmente, a la investigación?\n\nSiempre quise ser médico. De niña era un poco enfermiza, así que probablemente estuve muy expuesta al entorno médico. Por eso, siempre decía que quería ser médico. Pero luego decepcioné a mi padre a largo plazo, porque él pensaba que me convertiría en médico, no sé, un médico generalista, y así podría tenerme muy cerca de su casa. Pero en cambio, mi carrera me llevó al extranjero. No creo que él estuviera muy contento con mi marcha.\nEn particular, cuando era joven no quería ser científica. Me fascinaban los médicos. Probablemente tenía ese sentido de ayudar a la gente, de servir a la gente. Para mí eso es muy importante. Aprendí todo sobre cardiología en Italia, con el profesor Attilio Maseri, que fue un gran precursor en este campo: la activación de las células inmunitarias, especialmente en el síndrome coronario agudo. Aprendí mucho de él y sigo llevando esa huella en mi trabajo.\nTambién trabajé con otros buenos mentores en el Reino Unido, como el profesor Mark Feldman, y aprendí mucho de él sobre el sistema inmunitario y cómo detener la inflamación. Hago todo lo posible por seguir los pasos de estos dos gigantes para comprender el funcionamiento del sistema inmunitario en las arterias, tanto en la salud como en la enfermedad.\nMe encuentro en un entorno de reumatología e inmunología que también realiza investigaciones cardiovasculares. Puedo permanecer entre ambos campos, lo que me beneficia enormemente, ya que siempre estoy en la interfaz entre los inmunólogos y los especialistas cardiovasculares. Y creo que esto es algo bastante único. Es bastante difícil de replicar en todas partes.\nAhora, la inmunología cardiovascular se está consolidando cada vez más y habrá cada vez más interfaces de este tipo. Como la que hay aquí, en el CNIC, donde hay más interfaces de este tipo. Así que todo esto se está formando. Este es el futuro.\nCuando empecé, no se podía hacer esta combinación en ningún sitio. Por lo tanto, mis opciones estaban bastante limitadas. Ahora, tal vez podría plantearme mudarme a algún lugar de Europa, Estados Unidos, volver a Italia, si hay una estructura de financiación que permita el mismo nivel. Pero, por supuesto, ya sabes, en este momento hay problemas con la financiación en todos los países. Así que es un poco optimista. No iría a Italia solo por ir a Italia. El trabajo es muy importante para mí y necesito tener la combinación adecuada para mudarme a cualquier lugar.\n\nQuizás, primero podría venir aquí para investigar en el CNIC.\n\nSí, exactamente. ¿Por qué no? ¿Por qué no?\n\nHa mencionado que ha tenido muy buenos mentores en su carrera, y supongo que todavía los tiene. Pero ahora también asume esa función de mentoría con los estudiantes en su laboratorio. Entonces, ¿qué diferencias encuentra entre cuando era joven y estos jóvenes estudiantes de hoy?\n\nEsta es una pregunta difícil, porque es una pregunta en la que se pueden tomar dos caminos completamente diferentes. Uno sería: antes trabajábamos mucho más duro, y eso me molesta. No me agradan las personas que siguen ese camino. No me gusta decirlo, pero al final yo también lo sigo: antes nos quedábamos en el laboratorio hasta tarde...\nCreo que los nuevos estudiantes tienen una capacidad mucho mayor. Las nuevas generaciones son más completas en el sentido de que no quieren perderse por completo en el trabajo o la investigación, y creo que esto es algo positivo para sus vidas, sin duda. Considero que ese cambio es muy importante. Quizás porque en Oxford existe la tradición de que hay que tener una vida social en la universidad. Organizan actividades. Intentan crear un entorno en el que los estudiantes, incluso los de posgrado, puedan socializar si lo desean. Me gusta esa cultura. Y esto es típico de Oxford, y me encanta.\nPorque pueden hacer muchas cosas que yo no hice. Ya sabes, en nuestra época, existía la idea de que había que negarse a uno mismo, dedicarse a la disciplina sin límites, y creo que eso no es bueno a largo plazo.\nPero yo diría que las nuevas generaciones suelen conocer muy bien su tema, pero quizá no amplían sus horizontes tanto como deberían, no sienten curiosidad por otras disciplinas. Y yo lucho mucho contra eso. Ya sabes, se meten de lleno en su área, obtienen el doctorado, hacen la defensa de la tesis y solo saben eso. Ahora hay muchas áreas de interés a nuestro alcance. Probablemente, como consecuencia, perdieron muchas cosas. Pero siempre intento decirles que es importante ver cómo evolucionan otros campos. Quizás haya una idea que necesites. Quizás haya un camino que no habías pensado, pero que es importante en el cáncer y quizás también lo sea en las enfermedades cardiovasculares.\nSiempre pienso que, si estás en la interfaz entre dos campos, avanzas más rápido. Porque puedes aprender, otros colegas pueden inspirarte. Así que no te fijes solo en lo tuyo.\nY otra cosa que siempre les digo es que creo que, en las enfermedades cardiovasculares, pensamos que sabemos mucho. Pero en realidad, no es así. Y siempre tenemos que revisar las pruebas.\n\nEs posible que tengan una nueva forma, diferente, de ver sus vidas y sus carreras.\n\nSí, pero también, incluso en el campo del conocimiento de la aterosclerosis, siempre enseñamos a los estudiantes: así es como evoluciona la aterosclerosis. En realidad, las pruebas para nuestro modelo siempre son muy dispersas. Porque pueden estar en ratones o en otro sistema. Pero cómo es en los seres humanos, realmente no lo sabemos. Así que estad siempre preparados para cuestionar vuestras suposiciones. No sigáis siempre lo que os dicen los demás. Debéis tener vuestras propias ideas. Y siempre tenéis que desafiar el paradigma.",
    "published": "2025-08-01T00:00:00.000Z",
    "summary": "01/08/2025\n\n\nInvestigación\nCNIC Pulse\n\n\n\n\n\n\n\n\nDra. Claudia Monaco:  Instituto Kennedy de Reumatología, Departamento Nuffield de Ortopedia, Reumatología y Ciencias Musculoesqueléticas, Universidad de Oxford, Reino Unido\n\n\n\nClaudia Monaco se formó como cardióloga y doctoró con el profesor Attilio Maseri en la Universidad Católica de Roma, Italia, antes de trasladarse al Instituto Kennedy de Reumatología del Imperial College de Londres para trabajar con el profesor Marc Feldmann. En 2011 se trasladó a la Universidad de Oxford, donde se convirtió en profesora de Inflamación Cardiovascular. Su grupo fue el primero en establecer una metodología experimental innovadora para el aislamiento, cultivo y selección de células vivas de lesiones ateromatosas humanas. Su trabajo permitió caracterizar de forma elegante las propiedades inflamatorias y sintéticas de la aterosclerosis humana, estableciendo los receptores toll-like como activadores importantes de la inmunidad innata en la aterosclerosis. Su grupo de inflamación cardiovascular se centra ahora en interpretar la diversidad funcional de las células inmunitarias en la aterosclerosis con técnicas de biología celular única y en diseñar estrategias para su selección selectiva.\n\n¿Cuál es el papel de los macrófagos en el desarrollo de la aterosclerosis y cómo ha evolucionado nuestra comprensión de su función?\n\nNos centramos, en particular, en los macrófagos y en cuál es su función en la aterosclerosis. Es muy interesante porque los diferentes tipos de macrófagos tienen diferentes funciones en el desarrollo de la aterosclerosis. Antes pensábamos que todos los macrófagos eran malos, que todos los macrófagos y todo el sistema inmunitario favorecían la aterosclerosis. Pero ahora sabemos que el panorama es mucho más complejo.\nEstá muy relacionado con lo que son los macrófagos, dónde se siembran y cómo se establecen en nichos específicos. Hay algunos macrófagos, como los macrófagos asociados a los lípidos, que sin duda favorecen la enfermedad. Pero hay otros, los macrófagos vasculares que ya están presentes en la pared de los vasos, que en realidad actúan como guardianes de la arteria y la protegen.\nCreo que es muy importante la dirección que estamos tomando, hacia terapias más específicas. La idea no es bloquear todos los macrófagos, porque algunos son realmente nuestros aliados. Hay que cuidarlos, especialmente los que se encuentran en las arterias, mientras que otros realmente empujan hacia un camino peligroso que favorece la enfermedad. Esta dualidad es muy importante, especialmente desde el punto de vista terapéutico. Por eso estamos tan obsesionadas con comprenderlo mejor.\n\n¿Cómo se puede distinguir entre los macrófagos «buenos» y los que se quieren bloquear? ¿Qué tipo de técnicas se utilizan?\n\nUtilizamos mucho la biología unicelular. Aún no estamos en el ámbito clínico, pero hemos identificado buenos marcadores. Si esos marcadores resultan fiables, sería fácil traducirlos en nuevas herramientas para observar diferentes macrófagos in vivo. También existe la posibilidad de adaptar las imágenes, no solo las terapéuticas, sino también la forma en que visualizamos estos macrófagos.\nLa idea clave que queremos transmitir es que no existe un único tipo de macrófago. Siempre hemos dicho que los macrófagos son muy pleiotrópicos, es decir, que pueden adoptar diferentes fenotipos, pero eso no siempre parecía importar porque pensábamos que, al final, todos se transformaban unos en otros. Pero, en realidad, eso no es del todo cierto.\nHay cierta flexibilidad dinámica, sí, pero la trayectoria que siguen es bastante reproducible. Se adaptan específicamente a su entorno. Por ejemplo, en la adventicia adoptan un fenotipo muy específico, y en la íntima, otro diferente. Y estos fenotipos se mantienen bastante estables durante la aterosclerosis, así como en la salud y la enfermedad. No cambian aleatoriamente entre estados, sino que se adaptan de forma específica a cada nicho, al igual que las células de cualquier otro órgano. Esto es importante porque significa que podemos empezar a visualizar y tratar a los pacientes de forma diferente y más precisa.\n\nHa mencionado que aún se encuentra en la fase experimental y que aún no se han realizado ensayos clínicos. ¿En qué punto se encuentra la inmunoterapia para las enfermedades cardiovasculares?\n\nCreo que se han realizado algunos ensayos preliminares y ahora hay cada vez más estudios que se centran en la inflamación en la aterosclerosis. Es un campo en auge. Hemos esperado mucho tiempo para llegar hasta aquí. El campo tardó en avanzar en esta dirección porque se prestaba mucha atención a la reducción del colesterol, lo cual es importante, por supuesto, pero la inflamación no se ha explorado realmente hasta hace poco.\nEstudios como el ensayo CANTOS y otros han comenzado a centrarse en las citocinas, y creo que vamos en la dirección correcta. Pero el progreso sigue siendo muy lento. Una de las principales razones es la falta de herramientas de imagen. Las técnicas de imagen están alcanzando ahora un nivel en el que quizá podamos utilizarlas en lugar de basarnos en los resultados cardiovasculares de los ensayos.\nSi nos fijamos en el cáncer, por ejemplo, se puede hacer un seguimiento mucho más rápido, observar el tamaño del tumor y ver cómo responde el paciente. Lo mismo ocurre con enfermedades como la artritis reumatoide, en las que se pueden escanear las articulaciones o utilizar imágenes PET. Estos métodos de imagen llevan décadas utilizándose y han permitido realizar ensayos más pequeños basados en imágenes o que ofrecen resultados muy claros y tempranos.\nSin embargo, en el caso de las enfermedades cardiovasculares, todavía tenemos que observar cómo evolucionan los pacientes a lo largo de 5 o 10 años. Eso supone un gran reto. Estos ensayos son muy caros, sobre todo porque los medicamentos biológicos cuestan mucho. Por lo tanto, las empresas farmacéuticas deben asumir un enorme compromiso financiero. Cuanto más mejoremos las imágenes, más podremos realizar ensayos significativos que evalúen nuevos productos biológicos o agentes dirigidos, como los basados en la nanotecnología.\nCreo que la evolución no se limita a la inmunología, sino que también tiene que ver con cómo estudiamos esto en el mundo real. Otros campos pueden realizar ensayos más pequeños para comprender cómo funcionan las cosas y luego pasar a ensayos de resultados más amplios. Pero aquí, con ensayos como el CANTOS, en el que participaron más de 10.000 pacientes y se utilizó un fármaco biológico muy caro, ese tipo de escala es casi inaudito en otras enfermedades como la artritis reumatoide.\nAsí que sí, los retos se encuentran realmente en la fase clínica: cómo trasladar todos estos increíbles conocimientos sobre el sistema inmunitario a la medicina cardiovascular. La verdadera barrera es económica.\n\nUsted es cardióloga, trabajó en Roma durante muchos años y luego se trasladó a Oxford. Se formó como cardióloga y luego también pasó a dedicarse a la experimentación y la investigación. ¿Cómo combina estas dos áreas?\n\nCombinar las tareas clínicas y la investigación es uno de los mayores retos a los que te puedes enfrentar.  Creo que, si una se dedica a la investigación clínica, como la investigación basada en resultados o los estudios de imagen, es más fácil combinarla con el trabajo clínico. Pero si se trabaja más en el desarrollo científico a nivel molecular, es mucho más difícil compaginar ambas cosas. Al menos yo no pude hacerlo tan bien como me hubiera gustado.\n Existe una gran diferencia entre lo que creemos saber y lo que realmente sabemos. Tenemos una idea de cómo se desarrolla la aterosclerosis, cómo contribuye el sistema inmunitario, pero en realidad no entendemos los mecanismos específicos que intervienen. Sentí que, para salvar esta brecha, tenía que volver a lo básico. Eso significaba no solo utilizar modelos experimentales, sino también trabajar con muestras humanas. Vi una gran oportunidad en la biología de células individuales, que ha sido una gran oportunidad para todos nosotros para comprender la inmunología humana a un nivel muy detallado. Porque si solo nos fijamos en los ratones, la brecha entre estos y los seres humanos, y luego entre las etapas preclínicas y clínicas, es enorme.\nPor ejemplo, realmente necesitamos acceso al tejido vascular humano. Pero como cardiólogos, hemos avanzado tanto hacia los abordajes percutáneos de las arterias coronarias que ya no las extirpamos. Por eso trabajo mucho con cirujanos vasculares. Ellos siguen operando de una manera que nos permite obtener tejido humano, pero eso podría no durar mucho tiempo. Incluso la cirugía vascular se está orientando cada vez más hacia la implantación de stents, lo que significa que, con el tiempo, perderemos la capacidad de obtener ese tejido. Tenemos una ventana de oportunidad muy estrecha en la que todavía podemos trabajar con tejido de pacientes, y sentí que tenía que aprovecharla. Soy muy clara al afirmar que tenemos poco tiempo antes de que la cirugía vascular se vuelva completamente percutánea, lo que, por supuesto, es un avance, pero también nos priva de la oportunidad de estudiar tejidos humanos reales.\n\nParece que las mejoras en el tratamiento clínico están dificultando en cierto modo la ciencia básica.\n\nExactamente. Está avanzando, pero al mismo tiempo significa que ahora tenemos esta ventana crítica. Siempre digo que los cirujanos vasculares investigan y recogen tejido porque necesitamos analizar lo que realmente hacen las células. Basarnos únicamente en los análisis de sangre y en la inflamación sistémica no nos dice mucho sobre lo que está sucediendo en la arteria aterosclerótica. Las células inmunitarias del interior de la arteria son muy diferentes en su programación en comparación con las células circulantes en la sangre.\nLa mayoría de las células provienen de la sangre, pero también hay algunos macrófagos embrionarios que se forman dentro de la arteria y nunca circulan. E incluso los que provienen de la sangre y permanecen en la arteria durante 10 años, adquieren instrucciones muy especializadas. Se pueden extraer monocitos de la sangre y realizar tantos análisis de sangre como se desee, pero eso no revela lo que realmente ocurre dentro de la arteria.\nSe comportan de manera diferente, tienen un aspecto diferente, han cambiado completamente su forma y función. Esto crea una brecha en lo que podemos entender, parece que nos estamos perdiendo algo en estos estudios. No podemos ver todos los diferentes efectos que puede tener un fármaco si solo miramos la sangre periférica. Creo que las respuestas reales también se encuentran en el tejido vascular, en la propia placa aterosclerótica. Tenemos que acercarnos lo más posible a la fuente para encontrar los objetivos reales y ver los efectos reales de los fármacos en el tejido aterosclerótico.\nPorque muchos ensayos clínicos se han centrado en la inflamación sistémica. Pero eso no es lo mismo que la inflamación dentro de la placa. Los factores que provocan la inflamación de la placa pueden ser diferentes.\nSabemos que la inflamación sistémica es un factor de riesgo, sí, pero lo que se ve en la sangre no es necesariamente lo que ocurre en la placa. A menudo asumimos que lo es, porque es conveniente. Pero en las enfermedades cardiovasculares, especialmente en cardiología, nunca miramos realmente la placa. Miramos la luz. La ecografía intravascular (IVUS) es la única forma de echar un vistazo a la pared arterial.\nDesde el punto de vista experimental, podemos analizar la sangre del corazón de formas muy complejas, pero seguimos centrándonos principalmente en los marcadores circulantes. En realidad, no estamos estudiando el tejido en sí.\n\nComo cardióloga con experiencia en el tratamiento de pacientes, ¿cree que su experiencia clínica influye en el tipo de preguntas de investigación que se plantea?\n\nSí. Y hay dos cosas que me ayudan mucho. Por eso nunca dejo de ejercer en la clínica, aunque me han dicho varias veces que lo haga. Creo que... no me gusta dejar la clínica porque disfruto de esa interacción.\nComo científica, las recompensas son a muy largo plazo. Si eres médico, las recompensas son bastante inmediatas, porque el paciente está más contento si puedes darle el tratamiento. Por lo tanto, creo que me motiva mucho atender al paciente. Pero, al mismo tiempo, pienso que la investigación también es una buena forma de atender a los pacientes.\nPorque, como médico, he aprendido mucho de los científicos básicos. Son mucho mejores desarrollando técnicas en el laboratorio, por lo que siento un gran respeto por mis colegas científicos. Pero a veces, como médico clínico, puedes ver lo que realmente importa. Y eso te hace sentir especialmente vinculado a una enfermedad concreta. Los científicos básicos a veces abarcan varios campos. Este estudio me da la determinación y el impulso para intentar resolver realmente la aterosclerosis.\n\n\n¿De niña, se imaginó dedicándose a la ciencia o la medicina y, finalmente, a la investigación?\n\nSiempre quise ser médico. De niña era un poco enfermiza, así que probablemente estuve muy expuesta al entorno médico. Por eso, siempre decía que quería ser médico. Pero luego decepcioné a mi padre a largo plazo, porque él pensaba que me convertiría en médico, no sé, un médico generalista, y así podría tenerme muy cerca de su casa. Pero en cambio, mi carrera me llevó al extranjero. No creo que él estuviera muy contento con mi marcha.\nEn particular, cuando era joven no quería ser científica. Me fascinaban los médicos. Probablemente tenía ese sentido de ayudar a la gente, de servir a la gente. Para mí eso es muy importante. Aprendí todo sobre cardiología en Italia, con el profesor Attilio Maseri, que fue un gran precursor en este campo: la activación de las células inmunitarias, especialmente en el síndrome coronario agudo. Aprendí mucho de él y sigo llevando esa huella en mi trabajo.\nTambién trabajé con otros buenos mentores en el Reino Unido, como el profesor Mark Feldman, y aprendí mucho de él sobre el sistema inmunitario y cómo detener la inflamación. Hago todo lo posible por seguir los pasos de estos dos gigantes para comprender el funcionamiento del sistema inmunitario en las arterias, tanto en la salud como en la enfermedad.\nMe encuentro en un entorno de reumatología e inmunología que también realiza investigaciones cardiovasculares. Puedo permanecer entre ambos campos, lo que me beneficia enormemente, ya que siempre estoy en la interfaz entre los inmunólogos y los especialistas cardiovasculares. Y creo que esto es algo bastante único. Es bastante difícil de replicar en todas partes.\nAhora, la inmunología cardiovascular se está consolidando cada vez más y habrá cada vez más interfaces de este tipo. Como la que hay aquí, en el CNIC, donde hay más interfaces de este tipo. Así que todo esto se está formando. Este es el futuro.\nCuando empecé, no se podía hacer esta combinación en ningún sitio. Por lo tanto, mis opciones estaban bastante limitadas. Ahora, tal vez podría plantearme mudarme a algún lugar de Europa, Estados Unidos, volver a Italia, si hay una estructura de financiación que permita el mismo nivel. Pero, por supuesto, ya sabes, en este momento hay problemas con la financiación en todos los países. Así que es un poco optimista. No iría a Italia solo por ir a Italia. El trabajo es muy importante para mí y necesito tener la combinación adecuada para mudarme a cualquier lugar.\n\nQuizás, primero podría venir aquí para investigar en el CNIC.\n\nSí, exactamente. ¿Por qué no? ¿Por qué no?\n\nHa mencionado que ha tenido muy buenos mentores en su carrera, y supongo que todavía los tiene. Pero ahora también asume esa función de mentoría con los estudiantes en su laboratorio. Entonces, ¿qué diferencias encuentra entre cuando era joven y estos jóvenes estudiantes de hoy?\n\nEsta es una pregunta difícil, porque es una pregunta en la que se pueden tomar dos caminos completamente diferentes. Uno sería: antes trabajábamos mucho más duro, y eso me molesta. No me agradan las personas que siguen ese camino. No me gusta decirlo, pero al final yo también lo sigo: antes nos quedábamos en el laboratorio hasta tarde...\nCreo que los nuevos estudiantes tienen una capacidad mucho mayor. Las nuevas generaciones son más completas en el sentido de que no quieren perderse por completo en el trabajo o la investigación, y creo que esto es algo positivo para sus vidas, sin duda. Considero que ese cambio es muy importante. Quizás porque en Oxford existe la tradición de que hay que tener una vida social en la universidad. Organizan actividades. Intentan crear un entorno en el que los estudiantes, incluso los de posgrado, puedan socializar si lo desean. Me gusta esa cultura. Y esto es típico de Oxford, y me encanta.\nPorque pueden hacer muchas cosas que yo no hice. Ya sabes, en nuestra época, existía la idea de que había que negarse a uno mismo, dedicarse a la disciplina sin límites, y creo que eso no es bueno a largo plazo.\nPero yo diría que las nuevas generaciones suelen conocer muy bien su tema, pero quizá no amplían sus horizontes tanto como deberían, no sienten curiosidad por otras disciplinas. Y yo lucho mucho contra eso. Ya sabes, se meten de lleno en su área, obtienen el doctorado, hacen la defensa de la tesis y solo saben eso. Ahora hay muchas áreas de interés a nuestro alcance. Probablemente, como consecuencia, perdieron muchas cosas. Pero siempre intento decirles que es importante ver cómo evolucionan otros campos. Quizás haya una idea que necesites. Quizás haya un camino que no habías pensado, pero que es importante en el cáncer y quizás también lo sea en las enfermedades cardiovasculares.\nSiempre pienso que, si estás en la interfaz entre dos campos, avanzas más rápido. Porque puedes aprender, otros colegas pueden inspirarte. Así que no te fijes solo en lo tuyo.\nY otra cosa que siempre les digo es que creo que, en las enfermedades cardiovasculares, pensamos que sabemos mucho. Pero en realidad, no es así. Y siempre tenemos que revisar las pruebas.\n\nEs posible que tengan una nueva forma, diferente, de ver sus vidas y sus carreras.\n\nSí, pero también, incluso en el campo del conocimiento de la aterosclerosis, siempre enseñamos a los estudiantes: así es como evoluciona la aterosclerosis. En realidad, las pruebas para nuestro modelo siempre son muy dispersas. Porque pueden estar en ratones o en otro sistema. Pero cómo es en los seres humanos, realmente no lo sabemos. Así que estad siempre preparados para cuestionar vuestras suposiciones. No sigáis siempre lo que os dicen los demás. Debéis tener vuestras propias ideas. Y siempre tenéis que desafiar el paradigma.",
    "description": "Este artículo trata sobre \"Dra. Claudia Monaco: “En las enfermedades cardiovasculares, pensamos que sabemos mucho; pero en realidad, no es así”\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "dra",
      "claudia",
      "monaco"
    ],
    "category": "noticia"
  },
  {
    "title": "Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre",
    "title_es": "Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre",
    "url": "https://www.cnio.es/noticias/un-investigador-del-cnio-desarrolla-una-prueba-capaz-de-detectar-tumores-en-estadios-iniciales-con-una-muestra-de-sangre/",
    "date": "2025-07-31",
    "source": "CNIO",
    "content_es": "Los métodos actuales para diagnosticar el cáncer se basan en identificar marcadores –moléculas que indican un estado o proceso determinado del organismo– que provienen del tumor o de proteínas asociadas a él. Como es lógico, esos marcadores son más abundantes cuando el tumor ya se ha desarrollado de forma significativa. Y, cuanto más avanzado el […]\nLa entrada Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre se publicó primero en CNIO.",
    "published": "2025-07-31T00:00:00.000Z",
    "summary": "Los métodos actuales para diagnosticar el cáncer se basan en identificar marcadores –moléculas que indican un estado o proceso determinado del organismo– que provienen del tumor o de proteínas asociadas a él. Como es lógico, esos marcadores son más abundantes cuando el tumor ya se ha desarrollado de forma significativa. Y, cuanto más avanzado el […]\nLa entrada Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre se publicó primero en CNIO.",
    "description": "Este artículo trata sobre \"Un investigador del CNIO desarrolla una prueba capaz de detectar tumores en estadios iniciales con una muestra de sangre\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "un",
      "investigador",
      "del"
    ],
    "category": "noticia"
  },
  {
    "title": "The Columbia deal is a tragic wake-up call",
    "url": "https://www.science.org/doi/abs/10.1126/science.aeb0424",
    "published": "2025-07-31T00:00:00.000Z",
    "date": "2025-07-31",
    "summary": "Science, Volume 389, Issue 6760, Page 551-551, August 2025.",
    "source": "Science.org",
    "title_es": "The Columbia deal is a tragic wake-up call",
    "summary_es": "Science, volumen 389, número 6760, página 551-551, agosto de 2025.",
    "content_es": "Science, Volume 389, Issue 6760, Page 551-551, August 2025.",
    "description": "Este artículo trata sobre \"The Columbia deal is a tragic wake-up call\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "the",
      "columbia",
      "deal"
    ],
    "category": "noticia"
  },
  {
    "title": "CNIC en la Noche Europea de los Investigadores 2025",
    "title_es": "CNIC en la Noche Europea de los Investigadores 2025",
    "url": "https://www.cnic.es/es/noticias/cnic-noche-europea-investigadores-2025",
    "date": "2025-07-17",
    "source": "CNIC",
    "content_es": "14/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nVen al CNIC el próximo viernes 26 de septiembre con motivo de la XVI Noche Europea de los Investigadores de Madrid. Podrás participar en distintas actividades que te acercarán a la investigación que se realiza en el centro.\nLa Noche Europea de los Investigadores en el CNIC es una oportunidad de sumergirte en el emocionante mundo de la ciencia y la innovación. Desde experimentos asombrosos hasta conferencias inspiradoras, CNIC te brindará una ventana a los descubrimientos más recientes y las maravillas de la tecnología.\nPara asistir es necesario inscribirse en el siguiente link: https://www.cnic.es/es/solicitud-inscripcion-xvi-noche-europea-investigadores \nLa inscripción se abre el lunes 15 de septiembre a partir de las 9:00 hrs.\nTodas las actividades se llevarán a cabo en el Centro Nacional de Investigaciones Cardiovasculares (CNIC): C. de Melchor Fernández Almagro, 3, 28029 Madrid.\nInformación actividades:\n10:30 - 12:30 h. Enfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nPúblico: juvenil (desde 12 años) y adultos.\nEl principal objetivo de esta actividad es sensibilizar sobre los muchos desafíos que enfrentan los pacientes con enfermedades raras, y explicar cómo la investigación básica, utilizando modelos animales adecuados, es esencial para avanzar en la comprensión de estas enfermedades y encontrar terapias potenciales que permitan aliviar o curar a estos pacientes. Con este propósito, se organizan dos actividades: una charla de divulgación en lenguaje accesible; y una demostración en el laboratorio que permitirá a las personas participantes familiarizarse con técnicas utilizadas rutinariamente en la investigación básica para responder preguntas científicas relevantes en el estudio de enfermedades raras.\n10:30 - 13:30 h. ¿Cómo late nuestro corazón? Grupo: Silvia Priori.\nPúblico: juvenil (desde 12 años) y adultos.\nEsta actividad tiene como objetivo explicar cómo late el corazón, desde el nivel subcelular hasta el órgano completo, así como el desarrollo de una arritmia cardíaca dependiente del calcio. Estos temas se explicarán de forma sencilla y amena para que las personas participantes los conozcan de la mano de nuestras investigadoras e investigadores.  \n12:00 - 13:30 h. ¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\nPúblico: juvenil (14-18 años).\nLas personas participantes en esta actividad tendrán la oportunidad de conocer la relación entre el cáncer y el corazón desde el acercamiento al proyecto de investigación RESILIENCE, destinado a mejorar la vida de los pacientes con cáncer. La actividad consistirá en un workshop donde las personas participantes conocerán la aplicación de la tecnología (resonancia magnética cardíaca, ecocardiografía y tomografía cardíaca) y la innovación en este ensayo clínico, así como una mesa redonda donde se compartirán experiencias y se resolverán dudas.\n14:30 - 16:00 h. ¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\nPúblico: infantil (6 – 12 años).\nSe realizará una pequeña presentación sobre las diferencias de flujo sanguíneo laminar y oscilatorio en el contexto de aterosclerosis (con nuestros personajes de dibujos LAMI y OSCI); se hará un juego con preguntas básicas sobre la presentación donde las personas participantes ganarán piezas para montar su propia máquina de flujo laminar y oscilatorio; y habrá una demostración con una adaptación similar de las máquinas que se usan en el laboratorio para estimular las células a los dos tipos de flujo, con el uso de colorante alimentario y purpurina para que se puedan ver los diferentes patrones.\nDos turnos: 11:00-11:45 h (turno 1), 11:45-12.30 h (turno 2).   \n16:00 - 17:30 h. Taller de extracción de ADN. Grupo: Enrique Lara\nPúblico: infantil (8 – 12 años).\n¿Alguna vez te has preguntado qué podéis tener en común los plátanos y tú? ¡Los dos tenéis ADN! Os presentamos una actividad rápida, fácil y divertida, en la que vais a aprender a extraer el ADN de un plátano. Para ello usaremos ingredientes que cualquiera de vosotros tenéis en casa, así podéis sorprender al resto de la familia montando un pequeño laboratorio y ejerciendo de investigadores, ¿estáis dispuestos?\nTres turnos: 16:00 - 16:30 h (Turno 1), 16:30 - 17:00 h (Turno 2), 17:00 - 17:30 h (Turno 3).\n16:00 - 18:00 h. Modelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nPúblico: Infantil (desde 6 años), juvenil y adultos.\nEsta actividad comenzará con una breve charla introductoria para seguir con la preparación de áreas temáticas en el laboratorio especializadas en una cardiopatía congénita concreta, donde se explicarán en detalle sus rasgos morfológicos y cómo afectan a la salud humana. Las personas participantes realizarán una tinción histológica en la que podrán observar corazones de ratón y observarán, de manera práctica, las malformaciones explicadas en la charla de introducción. Con esto esperamos acercar a grandes rasgos lo que se hace en el laboratorio y la relevancia de la investigación básica y traslacional en el contexto de la cardiología.\n16:30 - 18:00 h. Cuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nPúblico: juvenil (desde 15 años) y adultos.\nEsta actividad consta de dos partes. Una primera en la que se les dará a las personas que participan una charla divulgativa adaptada a la edad del público, en la que se expondrá la importancia de los factores de riesgo cardiovasculares en el desarrollo de ciertas patologías relacionadas con el cerebro, así como el ictus o demencias. Posteriormente tendrá lugar una visita guiada en pequeños grupos al laboratorio del grupo donde se mostrarán diferentes técnicas empleadas de rutina en un laboratorio de neurociencia.\n17:00 - 18:00 h. El escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nPúblico: juvenil (desde 12 años) y adultos.\nEn este escape room científico, las personas participantes deberán usar su ingenio para resolver pruebas, enigmas o puzles y abrir un candado. Si lo logran, ¡descubrirán el secreto de la PCR y ganarán una recompensa final! De esta manera, a través de retos colaborativos inspirados en la biología molecular, las personas que jueguen aprenden conceptos clave de genética en un entorno lúdico y educativo.\n17:00 - 19:00 h. Da color a tu plato: convierte a tu corazón en un superhéroe con ritmo: Grupos: José Antonio Enríquez y David Sancho.\nPúblico: infantil (6-12 años).\nEn esta actividad interactiva se construirá un estetoscopio con materiales simples y reciclados (globos, tubos de plástico y botellas usadas), que las personas participantes podrán llevarse a casa. Con él, exploraremos cómo suena nuestro propio corazón, aprendiendo de manera directa y divertida sobre el ritmo cardíaco en condiciones de reposo y después del ejercicio, así como su importancia para la salud. Posteriormente se visualizará en una maqueta humana de poliespán a tamaño real cómo es nuestro sistema circulatorio, cómo la sangre llega a nuestro corazón y cómo alteraciones de la circulación pueden ocasionar ciertas patologías, como es la ateroesclerosis. También tendremos la oportunidad de ver cómo es nuestra sangre cuando tiene un exceso de grasa.  Ambas visualizaciones permitirán comprender por qué es fundamental, evitar el sedentarismo y cuidar nuestros hábitos alimenticios desde una edad temprana para prevenir enfermedades cardiovasculares.\n18:00 - 19:00 h. Diseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nPúblico: adultos (mayores de 18 años).\nEn esta actividad cinco participantes visualizarán con gafas de realidad mixta la estructura dinámica de proteínas y sus ligandos, entendiendo como se produce el efecto de un medicamento. Otros cinco participantes trabajarán en un ordenador cada uno en el proyecto colaborativo https://foldingathome.org. Las personas participantes irán terminando y saliendo, y un nuevo participante entrará para sustituirlos.\nFinanciación y menciones necesarias\n En todas las actividades:\n\nEl CNIC recibe apoyo del Instituto de Salud Carlos III (ISCIII), del Ministerio de Ciencia, Innovación y Universidades (MICIU) y es un Centro de Excelencia Severo Ochoa. Estas actividades han sido posibles gracias a los programas de investigación de CNIC: Programa Nuevos mecanismos de aterosclerosis, Programa Homeostasis miocárdica y daño cardiaco, Programa de Regeneración cardiovascular, Programa Nuevos mecanismos arritmogénicos, Programa Factores de riesgo cardiovascular y salud cerebral, Programa de Promoción de la salud cardiovascular, Programa de Desarrollo tecnológico, financiados por la ayuda CEX2020-001041-S por el MICIU/AEI/10.13039/501100011033.\n\nFinanciado por la Unión Europea. Las opiniones y puntos de vista expresados solo comprometen a su(s) autor(es) y no reflejan necesariamente los de la Unión Europea o los de la European Research Executive Agency (EREA). Ni la Unión Europea ni la EREA pueden ser considerados responsables de ellos.\nNIGHTMADRID es un proyecto de divulgación científica, coordinado por la Fundación madri+d y financiado por la Unión Europea dentro del Programa Horizonte Europa, bajo las acciones Marie Skłodowska-Curie con el acuerdo de subvención nº101.162.110\n\n\nMenciones específicas de cada actividad:\nEnfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nProject PID2022-141211OB-I00, funded by MCIU/AEI/10.13039/501100011033 y por FEDER, UE:\n\nProject “AC22/00020\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union NextGenerationEU:\n\n\nGRUPO CIBERCV CB16/11/00405\n\nProject \"FI23/00229\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union.\n\n\n¿Cómo late nuestro corazón?Grupo: Silvia Priori.\nEl proyecto que ha dado lugar a los resultados mostrados en esta actividad ha recibido el apoyo de la Fundación “la Caixa”, según el acuerdo LCF/PR/HR21-00233.\n\n¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\n\nThis project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No GA-945118\n\nEsta actividad es parte de la ayuda ICT2021-006950, financiada por MICIU y por la Unión Europea NextGenerationEU/PRTR\n\nGRUPO CIBERCV CB16/11/00358\n\n¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\n\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGrant PID2023-146414OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nEsta actividad se (co)financiará con cargo a programa de actividades de I+D entre grupos de Investigación con número de referencia TEC-2024/TEC-158 y acrónimo TecNanoBio-CM, subvencionado por la Comunidad de Madrid en la convocatoria de ayudas destinadas a la realización de programas de actividades de I+D entre grupos de investigación de la Comunidad de Madrid en Tecnologías 2024.\n\nEl proyecto de investigación Caveolin-1-dependent stromal remodeling: a potential novel target for cancer immunotherapy” Modalidad de temática general (Ref. PROYE20089DELP) y el proyecto Immunomechanics: a new paradigm for understanding cancer immune infiltration and improving immunotherapy Modalidad Investigador AECC 2024 (Ref. INVES245874LOLO) financiado por la Asociación Española Contra el Cáncer (AECC).\n\nThe project leading to these results has received funding from “la Caixa” Foundation, under agreement LCF/PR/HR20/52400015\n\nGrant JDC2022-049775-I funded by MICIU/AEI/ 10.13039/501100011033 by the “European Union NextGenerationEU/PRTR”\n\nAyuda FPU21/04003 financiada por:\n\nGrant PRE2021-097318 and PREP2023-001367 funded by MICIU/AEI /10.13039/501100011033 and “ESF+”\n\nFinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2024-TL/SAL-GL-32882 de la convocatoria 2024 de ayudas para la contratación de Ayudantes de Investigación y Técnicos de Laboratorio 2024 y cofinanciadas con el Fondo Social Europeo Plus (FSE+)\n\nco-funded by the European Union’s Horizon Europe research and innovation programme (Cure and Heart Brain project) under the Marie Skłodowska-Curie grant agreement No GA-101126521\n\nTaller de extracción de ADN. Grupo: Enrique Lara\nProyecto TED2021-129774B-C22 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nAyuda PRE2021-100726 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nProyecto PLEC2022-009235 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto PID2021-124629OB-I00 financiado por MICIU/ AEI /10.13039/501100011033/ y por FEDER Una manera de hacer Europa\n\nAyuda PRE2019-087458 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nThis project has received funding from the Horizon Europe Framework Programme (HORIZON) under the call EIC Pathfinder Challenges 2022 and with Project 101115416 — DCM-NEXT\nEl contrato del técnico está cofinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2023-TL/SAL-GL-28706 de la convocatoria 2023 de ayudas para la contratación de ayudantes de investigación y técnicos de laboratorio y cofinanciado en un 40% por el Fondo Social Europeo Plus (FSE+), 2021-2027.\n\n \nGRUPO CIBERCV CB16/11/00432\n\nModelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nLa Caixa “Cardiogenomics”, Plan Nacional, CIBERCV, Leducq foundation\nGrant PID2022-136942OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nFunding from ”la Caixa” Foundation under the project code LCF/PR/HR23/52430011\n\nGrant from the Leducq Foundation for Cardiovascular Research- TNE-24VD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGRUPO CIBERCV CB16/11/00399\n\nAyuda PRE2020-092102 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nAyudas PRE2022-102314 y PREP2022-000716 financiadas por MICIU/AEI /10.13039/501100011033 y por FSE+\nAyuda JDC2023-051982-I financiada por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda FPU18/01054 financiada por el Ministerio de Ciencia, Innovación y Universidades\n\nFinanciado a través de la Ayuda a la contratación de personal investigador predoctoral del año 2023 de la CAM con Expediente PIPF-2023/SAL-GL-29818\n\nCuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nGrant PID2022-140616OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nGrants from the Leducq Foundation for Cardiovascular Research-TNE-19CVD01 and TNE-21CVD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nAyudas PRE2021-099443, PREP2022-000650 y PRE2022-104379 financiadas por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda a la contratación de personal investigador predoctoral del año 2022 de la CAM con Expediente PIPF-2022/SAL-GL-26119\n\nSupport of a fellowship from the ”la Caixa” Foundation (ID 100010434). The fellowship code is LCF/BQ/DI22/11940002”.\n\nEl escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nAssociated funded projects that require dissemination (if applies). Logos and mentions:\n\nUE0EIC2201-HORIZON-EIC-2022_DCM-NEXT\n\nERN-Guard-Heart\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\n \nGRUPO CIBERCV CB16/11/00432\n\nDa color a tu plato: convierte a tu corazón en un superhéroe con ritmo. Grupos: José Antonio Enríquez y David Sancho\n\nJosé Antonio Enríquez:\n\nCentro de Investigación Biomédica en Red de Fragilidad y Envejecimiento Saludable (CIBERFES), Instituto de Salud Carlos III.\nGRUPO CIBERFES CB16/10/00289\n\nProyecto TED2021-131611B-I00 financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under the proposal n° 101198761 MINTRAF\n \n \nProyecto PID2021-127988OB-I00 financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430010\n\n\nDavid Sancho:\n\nProyecto CPP2021-008310 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009762 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\n \nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under grant agreement No 101158245.\n\nThis work was supported by the grant PRYGN246642SANC from the Scientific Foundation of the Spanish Association Against Cancer.\n\nThis work was supported by WORLWIDE CANCER RESEARCH 25-0080.\n\nProyecto PID2022-137712OB-I00 financiado por MICIU/AEI/10.13039/501100011033 y por FEDER, UE\n\nPROGRAMAS DE ACTIVIDADES DE I+D ENTRE GRUPOS DE INVESTIGACIÓN de la Comunidad de Madrid - BIOMEDICINA 2022 coordinado por la Dra. Almudena R Ramiro”-EXPEDIENTE: S2022/BMD-7333. Proyecto titulado “Estrategias inmunomoduladoras en el remodelado vascular: nuevas perspectivas diagnósticas y terapéuticas, acrónimo: INMUNOVAR”. IP del Grupo INMUNOBIOL.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR22/52420019.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430012\n\nProject “UNderstanding Lipid ImmunoMetabolIsm To trEat Disease, acronym: UNLIMITED” (MSCA-Doctoral Network) has received funding from the European Union’s Horizon 2024 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 101227259 \n\nDiseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nAyudas TED2021-132296B-C54 y TED2021-131611B-I00, financiadas por MICIU/ AEI/10.13039/501100011033/ y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009668, financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/PRTR (Plan de Recuperación, Transformación y Resiliencia)\n\nAyuda BIOMARCADORES DE PRECISION PARA LA MEJORA DEL DIAGNOSTICO Y TRATAMIENTO DE LA ENFERMEDAD INFLAMATORIA DEL MIOCARDIO (PreMyo) con expediente PMP22/00105, financiado con fondos públicos por el Instituto de Salud Carlos III y cofinanciado por Unión Europea – NextGenerationEU\n\nAyuda Plan de Formación en Inteligencia Artificial y Big Data para la salud Cardiovascular (CardiotrAIning) con Ref. SOLI/2024/0524/00240212 financiado por los fondos europeos NextGenerationEU en el marco del Plan de Recuperación, Transformación y Resiliencia a través de la iniciativa de los programas de atracción y retención de talento \n\nGRUPO CIBERCV CB22/11/00021\n\nProyecto PID2022-141527OB-I00 financiado por MCIN/AEI/10.13039/501100011033 y por FEDER, UE;\n\nAyuda EQC2024-008195-P financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe EU4Health Programme 2021-2027 under Grant Agreement 101126953. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or European Health and Digital Executive Agency (HADEA). Neither the European Union nor the granting authority can be held responsible for them.\n\nProyecto ALGORITMOS DE INTELIGENCIA ARTIFICIAL PARA PREDECIR EL RIESGO CARDIOVASCULAR, EN-PESA financiado por el Mecanismo de Recuperación y Resiliencia de la Unión Europea-Next Generation, en el marco de la convocatoria “Solicitud de Proyectos de I+D de Excelencia en Inteligencia Artificial de la Secretaría de Estado de Digitalización e Inteligencia Artificial”",
    "published": "2025-07-17T00:00:00.000Z",
    "summary": "14/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nVen al CNIC el próximo viernes 26 de septiembre con motivo de la XVI Noche Europea de los Investigadores de Madrid. Podrás participar en distintas actividades que te acercarán a la investigación que se realiza en el centro.\nLa Noche Europea de los Investigadores en el CNIC es una oportunidad de sumergirte en el emocionante mundo de la ciencia y la innovación. Desde experimentos asombrosos hasta conferencias inspiradoras, CNIC te brindará una ventana a los descubrimientos más recientes y las maravillas de la tecnología.\nPara asistir es necesario inscribirse en el siguiente link: https://www.cnic.es/es/solicitud-inscripcion-xvi-noche-europea-investigadores \nLa inscripción se abre el lunes 15 de septiembre a partir de las 9:00 hrs.\nTodas las actividades se llevarán a cabo en el Centro Nacional de Investigaciones Cardiovasculares (CNIC): C. de Melchor Fernández Almagro, 3, 28029 Madrid.\nInformación actividades:\n10:30 - 12:30 h. Enfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nPúblico: juvenil (desde 12 años) y adultos.\nEl principal objetivo de esta actividad es sensibilizar sobre los muchos desafíos que enfrentan los pacientes con enfermedades raras, y explicar cómo la investigación básica, utilizando modelos animales adecuados, es esencial para avanzar en la comprensión de estas enfermedades y encontrar terapias potenciales que permitan aliviar o curar a estos pacientes. Con este propósito, se organizan dos actividades: una charla de divulgación en lenguaje accesible; y una demostración en el laboratorio que permitirá a las personas participantes familiarizarse con técnicas utilizadas rutinariamente en la investigación básica para responder preguntas científicas relevantes en el estudio de enfermedades raras.\n10:30 - 13:30 h. ¿Cómo late nuestro corazón? Grupo: Silvia Priori.\nPúblico: juvenil (desde 12 años) y adultos.\nEsta actividad tiene como objetivo explicar cómo late el corazón, desde el nivel subcelular hasta el órgano completo, así como el desarrollo de una arritmia cardíaca dependiente del calcio. Estos temas se explicarán de forma sencilla y amena para que las personas participantes los conozcan de la mano de nuestras investigadoras e investigadores.  \n12:00 - 13:30 h. ¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\nPúblico: juvenil (14-18 años).\nLas personas participantes en esta actividad tendrán la oportunidad de conocer la relación entre el cáncer y el corazón desde el acercamiento al proyecto de investigación RESILIENCE, destinado a mejorar la vida de los pacientes con cáncer. La actividad consistirá en un workshop donde las personas participantes conocerán la aplicación de la tecnología (resonancia magnética cardíaca, ecocardiografía y tomografía cardíaca) y la innovación en este ensayo clínico, así como una mesa redonda donde se compartirán experiencias y se resolverán dudas.\n14:30 - 16:00 h. ¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\nPúblico: infantil (6 – 12 años).\nSe realizará una pequeña presentación sobre las diferencias de flujo sanguíneo laminar y oscilatorio en el contexto de aterosclerosis (con nuestros personajes de dibujos LAMI y OSCI); se hará un juego con preguntas básicas sobre la presentación donde las personas participantes ganarán piezas para montar su propia máquina de flujo laminar y oscilatorio; y habrá una demostración con una adaptación similar de las máquinas que se usan en el laboratorio para estimular las células a los dos tipos de flujo, con el uso de colorante alimentario y purpurina para que se puedan ver los diferentes patrones.\nDos turnos: 11:00-11:45 h (turno 1), 11:45-12.30 h (turno 2).   \n16:00 - 17:30 h. Taller de extracción de ADN. Grupo: Enrique Lara\nPúblico: infantil (8 – 12 años).\n¿Alguna vez te has preguntado qué podéis tener en común los plátanos y tú? ¡Los dos tenéis ADN! Os presentamos una actividad rápida, fácil y divertida, en la que vais a aprender a extraer el ADN de un plátano. Para ello usaremos ingredientes que cualquiera de vosotros tenéis en casa, así podéis sorprender al resto de la familia montando un pequeño laboratorio y ejerciendo de investigadores, ¿estáis dispuestos?\nTres turnos: 16:00 - 16:30 h (Turno 1), 16:30 - 17:00 h (Turno 2), 17:00 - 17:30 h (Turno 3).\n16:00 - 18:00 h. Modelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nPúblico: Infantil (desde 6 años), juvenil y adultos.\nEsta actividad comenzará con una breve charla introductoria para seguir con la preparación de áreas temáticas en el laboratorio especializadas en una cardiopatía congénita concreta, donde se explicarán en detalle sus rasgos morfológicos y cómo afectan a la salud humana. Las personas participantes realizarán una tinción histológica en la que podrán observar corazones de ratón y observarán, de manera práctica, las malformaciones explicadas en la charla de introducción. Con esto esperamos acercar a grandes rasgos lo que se hace en el laboratorio y la relevancia de la investigación básica y traslacional en el contexto de la cardiología.\n16:30 - 18:00 h. Cuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nPúblico: juvenil (desde 15 años) y adultos.\nEsta actividad consta de dos partes. Una primera en la que se les dará a las personas que participan una charla divulgativa adaptada a la edad del público, en la que se expondrá la importancia de los factores de riesgo cardiovasculares en el desarrollo de ciertas patologías relacionadas con el cerebro, así como el ictus o demencias. Posteriormente tendrá lugar una visita guiada en pequeños grupos al laboratorio del grupo donde se mostrarán diferentes técnicas empleadas de rutina en un laboratorio de neurociencia.\n17:00 - 18:00 h. El escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nPúblico: juvenil (desde 12 años) y adultos.\nEn este escape room científico, las personas participantes deberán usar su ingenio para resolver pruebas, enigmas o puzles y abrir un candado. Si lo logran, ¡descubrirán el secreto de la PCR y ganarán una recompensa final! De esta manera, a través de retos colaborativos inspirados en la biología molecular, las personas que jueguen aprenden conceptos clave de genética en un entorno lúdico y educativo.\n17:00 - 19:00 h. Da color a tu plato: convierte a tu corazón en un superhéroe con ritmo: Grupos: José Antonio Enríquez y David Sancho.\nPúblico: infantil (6-12 años).\nEn esta actividad interactiva se construirá un estetoscopio con materiales simples y reciclados (globos, tubos de plástico y botellas usadas), que las personas participantes podrán llevarse a casa. Con él, exploraremos cómo suena nuestro propio corazón, aprendiendo de manera directa y divertida sobre el ritmo cardíaco en condiciones de reposo y después del ejercicio, así como su importancia para la salud. Posteriormente se visualizará en una maqueta humana de poliespán a tamaño real cómo es nuestro sistema circulatorio, cómo la sangre llega a nuestro corazón y cómo alteraciones de la circulación pueden ocasionar ciertas patologías, como es la ateroesclerosis. También tendremos la oportunidad de ver cómo es nuestra sangre cuando tiene un exceso de grasa.  Ambas visualizaciones permitirán comprender por qué es fundamental, evitar el sedentarismo y cuidar nuestros hábitos alimenticios desde una edad temprana para prevenir enfermedades cardiovasculares.\n18:00 - 19:00 h. Diseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nPúblico: adultos (mayores de 18 años).\nEn esta actividad cinco participantes visualizarán con gafas de realidad mixta la estructura dinámica de proteínas y sus ligandos, entendiendo como se produce el efecto de un medicamento. Otros cinco participantes trabajarán en un ordenador cada uno en el proyecto colaborativo https://foldingathome.org. Las personas participantes irán terminando y saliendo, y un nuevo participante entrará para sustituirlos.\nFinanciación y menciones necesarias\n En todas las actividades:\n\nEl CNIC recibe apoyo del Instituto de Salud Carlos III (ISCIII), del Ministerio de Ciencia, Innovación y Universidades (MICIU) y es un Centro de Excelencia Severo Ochoa. Estas actividades han sido posibles gracias a los programas de investigación de CNIC: Programa Nuevos mecanismos de aterosclerosis, Programa Homeostasis miocárdica y daño cardiaco, Programa de Regeneración cardiovascular, Programa Nuevos mecanismos arritmogénicos, Programa Factores de riesgo cardiovascular y salud cerebral, Programa de Promoción de la salud cardiovascular, Programa de Desarrollo tecnológico, financiados por la ayuda CEX2020-001041-S por el MICIU/AEI/10.13039/501100011033.\n\nFinanciado por la Unión Europea. Las opiniones y puntos de vista expresados solo comprometen a su(s) autor(es) y no reflejan necesariamente los de la Unión Europea o los de la European Research Executive Agency (EREA). Ni la Unión Europea ni la EREA pueden ser considerados responsables de ellos.\nNIGHTMADRID es un proyecto de divulgación científica, coordinado por la Fundación madri+d y financiado por la Unión Europea dentro del Programa Horizonte Europa, bajo las acciones Marie Skłodowska-Curie con el acuerdo de subvención nº101.162.110\n\n\nMenciones específicas de cada actividad:\nEnfermedades raras: retos y oportunidades. Grupo: Vicente Andrés.\nProject PID2022-141211OB-I00, funded by MCIU/AEI/10.13039/501100011033 y por FEDER, UE:\n\nProject “AC22/00020\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union NextGenerationEU:\n\n\nGRUPO CIBERCV CB16/11/00405\n\nProject \"FI23/00229\", funded by Instituto de Salud Carlos III (ISCIII) and co-funded by the European Union.\n\n\n¿Cómo late nuestro corazón?Grupo: Silvia Priori.\nEl proyecto que ha dado lugar a los resultados mostrados en esta actividad ha recibido el apoyo de la Fundación “la Caixa”, según el acuerdo LCF/PR/HR21-00233.\n\n¿Conoces la relación entre tu corazón y el cáncer? Grupo: Borja Ibáñez\n\nThis project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No GA-945118\n\nEsta actividad es parte de la ayuda ICT2021-006950, financiada por MICIU y por la Unión Europea NextGenerationEU/PRTR\n\nGRUPO CIBERCV CB16/11/00358\n\n¡A Fluir! Descubriendo el Flujo Sanguíneo con LAMI y OSCI (Taller Aterosclerosis). Grupo: Miguel Ángel del Pozo\n\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGrant PID2023-146414OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nEsta actividad se (co)financiará con cargo a programa de actividades de I+D entre grupos de Investigación con número de referencia TEC-2024/TEC-158 y acrónimo TecNanoBio-CM, subvencionado por la Comunidad de Madrid en la convocatoria de ayudas destinadas a la realización de programas de actividades de I+D entre grupos de investigación de la Comunidad de Madrid en Tecnologías 2024.\n\nEl proyecto de investigación Caveolin-1-dependent stromal remodeling: a potential novel target for cancer immunotherapy” Modalidad de temática general (Ref. PROYE20089DELP) y el proyecto Immunomechanics: a new paradigm for understanding cancer immune infiltration and improving immunotherapy Modalidad Investigador AECC 2024 (Ref. INVES245874LOLO) financiado por la Asociación Española Contra el Cáncer (AECC).\n\nThe project leading to these results has received funding from “la Caixa” Foundation, under agreement LCF/PR/HR20/52400015\n\nGrant JDC2022-049775-I funded by MICIU/AEI/ 10.13039/501100011033 by the “European Union NextGenerationEU/PRTR”\n\nAyuda FPU21/04003 financiada por:\n\nGrant PRE2021-097318 and PREP2023-001367 funded by MICIU/AEI /10.13039/501100011033 and “ESF+”\n\nFinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2024-TL/SAL-GL-32882 de la convocatoria 2024 de ayudas para la contratación de Ayudantes de Investigación y Técnicos de Laboratorio 2024 y cofinanciadas con el Fondo Social Europeo Plus (FSE+)\n\nco-funded by the European Union’s Horizon Europe research and innovation programme (Cure and Heart Brain project) under the Marie Skłodowska-Curie grant agreement No GA-101126521\n\nTaller de extracción de ADN. Grupo: Enrique Lara\nProyecto TED2021-129774B-C22 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nAyuda PRE2021-100726 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nProyecto PLEC2022-009235 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto PID2021-124629OB-I00 financiado por MICIU/ AEI /10.13039/501100011033/ y por FEDER Una manera de hacer Europa\n\nAyuda PRE2019-087458 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nThis project has received funding from the Horizon Europe Framework Programme (HORIZON) under the call EIC Pathfinder Challenges 2022 and with Project 101115416 — DCM-NEXT\nEl contrato del técnico está cofinanciado por la Comunidad de Madrid a través de la ayuda PEJ-2023-TL/SAL-GL-28706 de la convocatoria 2023 de ayudas para la contratación de ayudantes de investigación y técnicos de laboratorio y cofinanciado en un 40% por el Fondo Social Europeo Plus (FSE+), 2021-2027.\n\n \nGRUPO CIBERCV CB16/11/00432\n\nModelos genéticos prácticos de desarrollo cardíaco y cardiopatías congénitas. Grupo: José Luis de la Pompa\nLa Caixa “Cardiogenomics”, Plan Nacional, CIBERCV, Leducq foundation\nGrant PID2022-136942OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nFunding from ”la Caixa” Foundation under the project code LCF/PR/HR23/52430011\n\nGrant from the Leducq Foundation for Cardiovascular Research- TNE-24VD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nGRUPO CIBERCV CB16/11/00399\n\nAyuda PRE2020-092102 financiada por MICIU/AEI /10.13039/501100011033 y por FSE invierte en tu futuro\n\nAyudas PRE2022-102314 y PREP2022-000716 financiadas por MICIU/AEI /10.13039/501100011033 y por FSE+\nAyuda JDC2023-051982-I financiada por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda FPU18/01054 financiada por el Ministerio de Ciencia, Innovación y Universidades\n\nFinanciado a través de la Ayuda a la contratación de personal investigador predoctoral del año 2023 de la CAM con Expediente PIPF-2023/SAL-GL-29818\n\nCuida tu corazón para proteger el cerebro: conoce un laboratorio de neurociencia. Grupo: María Ángeles Moro.\nGrant PID2022-140616OB-I00 funded by MICIU/AEI/10.13039/501100011033 and by ERDF/EU\n\nGrants from the Leducq Foundation for Cardiovascular Research-TNE-19CVD01 and TNE-21CVD04\n\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\nAyudas PRE2021-099443, PREP2022-000650 y PRE2022-104379 financiadas por MICIU/AEI /10.13039/501100011033 y por el FSE+\n\nAyuda a la contratación de personal investigador predoctoral del año 2022 de la CAM con Expediente PIPF-2022/SAL-GL-26119\n\nSupport of a fellowship from the ”la Caixa” Foundation (ID 100010434). The fellowship code is LCF/BQ/DI22/11940002”.\n\nEl escape room genético: \"Misión ADN-el secreto de la PCR\". Grupo: Pablo García Pavía.\nAssociated funded projects that require dissemination (if applies). Logos and mentions:\n\nUE0EIC2201-HORIZON-EIC-2022_DCM-NEXT\n\nERN-Guard-Heart\nThe CNIC is supported by the Instituto de Salud Carlos III (ISCIII), the Ministerio de Ciencia, Innovación y Universidades (MICIU) and the Pro CNIC Foundation), and is a Severo Ochoa Center of Excellence (grant CEX2020-001041-S funded by MICIN/AEI/10.13039/501100011033).\n\n \nGRUPO CIBERCV CB16/11/00432\n\nDa color a tu plato: convierte a tu corazón en un superhéroe con ritmo. Grupos: José Antonio Enríquez y David Sancho\n\nJosé Antonio Enríquez:\n\nCentro de Investigación Biomédica en Red de Fragilidad y Envejecimiento Saludable (CIBERFES), Instituto de Salud Carlos III.\nGRUPO CIBERFES CB16/10/00289\n\nProyecto TED2021-131611B-I00 financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under the proposal n° 101198761 MINTRAF\n \n \nProyecto PID2021-127988OB-I00 financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430010\n\n\nDavid Sancho:\n\nProyecto CPP2021-008310 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009762 financiado por MICIU/AEI /10.13039/501100011033 y por la Unión Europea NextGenerationEU/ PRTR\n\n \nThis work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme under grant agreement No 101158245.\n\nThis work was supported by the grant PRYGN246642SANC from the Scientific Foundation of the Spanish Association Against Cancer.\n\nThis work was supported by WORLWIDE CANCER RESEARCH 25-0080.\n\nProyecto PID2022-137712OB-I00 financiado por MICIU/AEI/10.13039/501100011033 y por FEDER, UE\n\nPROGRAMAS DE ACTIVIDADES DE I+D ENTRE GRUPOS DE INVESTIGACIÓN de la Comunidad de Madrid - BIOMEDICINA 2022 coordinado por la Dra. Almudena R Ramiro”-EXPEDIENTE: S2022/BMD-7333. Proyecto titulado “Estrategias inmunomoduladoras en el remodelado vascular: nuevas perspectivas diagnósticas y terapéuticas, acrónimo: INMUNOVAR”. IP del Grupo INMUNOBIOL.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR22/52420019.\n\nThe project leading to these results has received funding from “la Caixa” Foundation under the project code LCF/PR/HR23/52430012\n\nProject “UNderstanding Lipid ImmunoMetabolIsm To trEat Disease, acronym: UNLIMITED” (MSCA-Doctoral Network) has received funding from the European Union’s Horizon 2024 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 101227259 \n\nDiseñando los fármacos del futuro: Una experiencia inmersiva con realidad virtual. Grupo: Fátima Sánchez Cabo\nAyudas TED2021-132296B-C54 y TED2021-131611B-I00, financiadas por MICIU/ AEI/10.13039/501100011033/ y por la Unión Europea NextGenerationEU/ PRTR\n\nProyecto CPP2022-009668, financiado por MICIU/AEI/10.13039/501100011033 y por la Unión Europea NextGenerationEU/PRTR (Plan de Recuperación, Transformación y Resiliencia)\n\nAyuda BIOMARCADORES DE PRECISION PARA LA MEJORA DEL DIAGNOSTICO Y TRATAMIENTO DE LA ENFERMEDAD INFLAMATORIA DEL MIOCARDIO (PreMyo) con expediente PMP22/00105, financiado con fondos públicos por el Instituto de Salud Carlos III y cofinanciado por Unión Europea – NextGenerationEU\n\nAyuda Plan de Formación en Inteligencia Artificial y Big Data para la salud Cardiovascular (CardiotrAIning) con Ref. SOLI/2024/0524/00240212 financiado por los fondos europeos NextGenerationEU en el marco del Plan de Recuperación, Transformación y Resiliencia a través de la iniciativa de los programas de atracción y retención de talento \n\nGRUPO CIBERCV CB22/11/00021\n\nProyecto PID2022-141527OB-I00 financiado por MCIN/AEI/10.13039/501100011033 y por FEDER, UE;\n\nAyuda EQC2024-008195-P financiado por MICIU/AEI /10.13039/501100011033 y por FEDER, UE\n\nThe EU4Health Programme 2021-2027 under Grant Agreement 101126953. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or European Health and Digital Executive Agency (HADEA). Neither the European Union nor the granting authority can be held responsible for them.\n\nProyecto ALGORITMOS DE INTELIGENCIA ARTIFICIAL PARA PREDECIR EL RIESGO CARDIOVASCULAR, EN-PESA financiado por el Mecanismo de Recuperación y Resiliencia de la Unión Europea-Next Generation, en el marco de la convocatoria “Solicitud de Proyectos de I+D de Excelencia en Inteligencia Artificial de la Secretaría de Estado de Digitalización e Inteligencia Artificial”",
    "description": "Este artículo trata sobre \"CNIC en la Noche Europea de los Investigadores 2025\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cnic",
      "en",
      "la"
    ],
    "category": "noticia"
  },
  {
    "title": "Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO",
    "title_es": "Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO",
    "url": "https://www.cnio.es/noticias/nuevo-ensayo-clinico-contra-el-cancer-de-piel-mas-frecuente-con-un-compuesto-derivado-de-descubrimientos-del-cnio/",
    "date": "2025-07-15",
    "source": "CNIO",
    "content_es": "Hace unos 15 años, en 2009, el equipo de la investigadora del Centro Nacional de Investigaciones Oncológicas (CNIO) Marisol Soengas descubrió una nueva forma de matar células tumorales: hacerles creer que han sido infectadas por un virus. Desarrollaron un compuesto, denominado BO-110, con una forma de actuación muy novedosa porque inducía la autodigestión de las […]\nLa entrada Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO se publicó primero en CNIO.",
    "published": "2025-07-15T00:00:00.000Z",
    "summary": "Hace unos 15 años, en 2009, el equipo de la investigadora del Centro Nacional de Investigaciones Oncológicas (CNIO) Marisol Soengas descubrió una nueva forma de matar células tumorales: hacerles creer que han sido infectadas por un virus. Desarrollaron un compuesto, denominado BO-110, con una forma de actuación muy novedosa porque inducía la autodigestión de las […]\nLa entrada Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO se publicó primero en CNIO.",
    "description": "Este artículo trata sobre \"Nuevo ensayo clínico contra el cáncer de piel más frecuente con un compuesto derivado de descubrimientos del CNIO\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nuevo",
      "ensayo",
      "clínico"
    ],
    "category": "noticia"
  },
  {
    "title": "Nature: A gut microbiota metabolite linked to atherosclerosis could revolutionise diagnosis and treatment",
    "title_es": "Nature: A gut microbiota metabolite linked to atherosclerosis could revolutionise diagnosis and treatment",
    "url": "https://www.cnic.es/es/node/235399",
    "date": "2025-07-14",
    "source": "CNIC",
    "content_es": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nA new study led by the CNIC has identified imidazole propionate (ImP), a metabolite produced by gut bacteria, as a driver of atherosclerosis— as a driver of atherosclerosis, the disease behind most heart attacks and strokes\n\n\n\nCardiovascular disease remains the world’s leading cause of death, and often originates in atherosclerosis, a chronic condition in which inflammation and fat deposits cause arteries to harden and narrow. Although clinical practice already targets causal factors like high cholesterol, hypertension, and smoking, detecting atherosclerosis in its early stages continues to be a significant challenge.\nNow, researchers at the Spanish National Center for Cardiovascular Research (CNIC) have identified a gut microbiota–derived metabolite, imidazole propionate (ImP), that appears in the blood during the early stages of active atherosclerosis.\n‘This metabolite is uniquely produced by intestinal bacteria,’ explains CNIC researcher Annalaura Mastrangelo, one of the study’s two first authors. ‘Our study shows that its presence in the bloodstream is associated with the development of active atherosclerosis in people who otherwise appear healthy.’\nThe discovery offers a promising alternative to current diagnostic tools, which typically involve costly and complex imaging techniques. ‘Detecting this blood marker offers a major advantage because current diagnostic tools rely on advanced imaging techniques that are complex, expensive, and not covered by public health systems. Blood levels of ImP provide a diagnostic marker that could help identify apparently healthy individuals with active atherosclerosis, and thus enable earlier treatment.’ says Mastrangelo.\nBut the discovery goes even further. Co–first author Iñaki Robles-Vera explains: ‘We not only observed elevated ImP levels in people with atherosclerosis, but also showed that ImP itself is a causal agent of the disease. In animal models of atherosclerosis, ImP administration led to the formation of arterial plaques. It does this by activating the imidazoline receptor type 1 (I1R), which increases systemic inflammation and promotes atherosclerosis development.’\nDavid Sancho, head of the CNIC Immunobiology Laboratory, lead author on the study and ERC grantee notes that ‘this discovery is important because it opens the way to a completely new line of treatment.’\nThe study shows that blocking the I1R receptor in animal models prevented plaque formation and slowed disease progression, even when the animals were fed a high-cholesterol diet. ‘This suggests that future treatment could combine I1R blockade with cholesterol-lowering drugs to produce a synergistic effect that prevents atherosclerosis development,’ explains Sancho.\n‘These findings open new possibilities for the early detection and personalised treatment of atherosclerosis,’ he continues. ‘Instead of focusing solely on cholesterol and other classic risk factors, we may soon be able to analyse blood for ImP as an early warning signal. At the CNIC, we are also working to develop drugs that block the detrimental effects of ImP.’\n\nThe CNIC-led study was conducted through extensive collaboration with researchers at multiple national and international centres: Mount Sinai Fuster Heart Hospital and the Icahn School of Medicine at Mount Sinai (New York, USA); the Fundación Jiménez Díaz Health Research Institute; the Universidad Autónoma de Madrid; the Spanish cardiovascular research network (CIBER-CV); the University of Gothenburg (Sweden); the University of Athens (Greece); Inmunotek S.L.; the University of Michigan (USA); Hospital de La Princesa; the Center for Metabolomics and Bioanalysis (CEMBIO) from Universidad CEU San Pablo; the University of Heidelberg (Germany); and the Sols-Morreale Biomedical Research Institute (IIBM-CSIC). \nThe study was supported by funding from the European Research Council (Consolidator and Proof of concept grants), Spanish Ministry of Science, Innovation, and Universities; the Spanish State Research Agency; the European Union’s NextGeneration funding mechanism; and the “la Caixa” Foundation.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D., Sancho, D., et al. (2025). Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature. https://doi.org/10.1038/s41586-025-09263-w",
    "published": "2025-07-14T00:00:00.000Z",
    "summary": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nA new study led by the CNIC has identified imidazole propionate (ImP), a metabolite produced by gut bacteria, as a driver of atherosclerosis— as a driver of atherosclerosis, the disease behind most heart attacks and strokes\n\n\n\nCardiovascular disease remains the world’s leading cause of death, and often originates in atherosclerosis, a chronic condition in which inflammation and fat deposits cause arteries to harden and narrow. Although clinical practice already targets causal factors like high cholesterol, hypertension, and smoking, detecting atherosclerosis in its early stages continues to be a significant challenge.\nNow, researchers at the Spanish National Center for Cardiovascular Research (CNIC) have identified a gut microbiota–derived metabolite, imidazole propionate (ImP), that appears in the blood during the early stages of active atherosclerosis.\n‘This metabolite is uniquely produced by intestinal bacteria,’ explains CNIC researcher Annalaura Mastrangelo, one of the study’s two first authors. ‘Our study shows that its presence in the bloodstream is associated with the development of active atherosclerosis in people who otherwise appear healthy.’\nThe discovery offers a promising alternative to current diagnostic tools, which typically involve costly and complex imaging techniques. ‘Detecting this blood marker offers a major advantage because current diagnostic tools rely on advanced imaging techniques that are complex, expensive, and not covered by public health systems. Blood levels of ImP provide a diagnostic marker that could help identify apparently healthy individuals with active atherosclerosis, and thus enable earlier treatment.’ says Mastrangelo.\nBut the discovery goes even further. Co–first author Iñaki Robles-Vera explains: ‘We not only observed elevated ImP levels in people with atherosclerosis, but also showed that ImP itself is a causal agent of the disease. In animal models of atherosclerosis, ImP administration led to the formation of arterial plaques. It does this by activating the imidazoline receptor type 1 (I1R), which increases systemic inflammation and promotes atherosclerosis development.’\nDavid Sancho, head of the CNIC Immunobiology Laboratory, lead author on the study and ERC grantee notes that ‘this discovery is important because it opens the way to a completely new line of treatment.’\nThe study shows that blocking the I1R receptor in animal models prevented plaque formation and slowed disease progression, even when the animals were fed a high-cholesterol diet. ‘This suggests that future treatment could combine I1R blockade with cholesterol-lowering drugs to produce a synergistic effect that prevents atherosclerosis development,’ explains Sancho.\n‘These findings open new possibilities for the early detection and personalised treatment of atherosclerosis,’ he continues. ‘Instead of focusing solely on cholesterol and other classic risk factors, we may soon be able to analyse blood for ImP as an early warning signal. At the CNIC, we are also working to develop drugs that block the detrimental effects of ImP.’\n\nThe CNIC-led study was conducted through extensive collaboration with researchers at multiple national and international centres: Mount Sinai Fuster Heart Hospital and the Icahn School of Medicine at Mount Sinai (New York, USA); the Fundación Jiménez Díaz Health Research Institute; the Universidad Autónoma de Madrid; the Spanish cardiovascular research network (CIBER-CV); the University of Gothenburg (Sweden); the University of Athens (Greece); Inmunotek S.L.; the University of Michigan (USA); Hospital de La Princesa; the Center for Metabolomics and Bioanalysis (CEMBIO) from Universidad CEU San Pablo; the University of Heidelberg (Germany); and the Sols-Morreale Biomedical Research Institute (IIBM-CSIC). \nThe study was supported by funding from the European Research Council (Consolidator and Proof of concept grants), Spanish Ministry of Science, Innovation, and Universities; the Spanish State Research Agency; the European Union’s NextGeneration funding mechanism; and the “la Caixa” Foundation.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D., Sancho, D., et al. (2025). Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature. https://doi.org/10.1038/s41586-025-09263-w",
    "description": "Este artículo trata sobre \"Nature: A gut microbiota metabolite linked to atherosclerosis could revolutionise diagnosis and treatment\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nature",
      "a",
      "gut"
    ],
    "category": "noticia"
  },
  {
    "title": "Nature: Descubren un metabolito de la microbiota intestinal que favorece la aterosclerosis y podría revolucionar su diagnóstico y tratamiento",
    "title_es": "Nature: Descubren un metabolito de la microbiota intestinal que favorece la aterosclerosis y podría revolucionar su diagnóstico y tratamiento",
    "url": "https://www.cnic.es/es/noticias/nature-descubren-un-metabolito-microbiota-intestinal-que-favorece-aterosclerosis-podria",
    "date": "2025-07-14",
    "source": "CNIC",
    "content_es": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nUn estudio liderado por el CNIC desvela que el propionato de imidazol, un metabolito producido por la microbiota intestinal, induce aterosclerosis, una enfermedad que puede desencadenar la obstrucción de las arterias que causa los infartos o accidentes cerebrovasculares\n\n\n\nLas enfermedades cardiovasculares son la principal causa de muerte global y suelen originarse en la aterosclerosis, un endurecimiento y estrechamiento de las arterias por inflamación y acumulación de grasa en la pared arterial. Aunque se controlan factores causales como colesterol, hipertensión o tabaquismo, la detección temprana de la enfermedad es necesaria. Los nuevos resultados liderados por el Centro Nacional de Investigaciones Cardiovasculares (CNIC) y publicados en la revista Nature han identificado que un metabolito generado por bacterias intestinales, el propionato de imidazol (ImP), se detecta en sangre de modo temprano en la aterosclerosis activa. El estudio ha contado con el apoyo de la Fundación “la Caixa” en su Convocatoria CaixaResearch de Investigación en Salud con 967.620,20 €.\nEste metabolito, “está producido exclusivamente por bacterias del intestino”, explica Annalaura Mastrangelo, investigadora del CNIC y primera autora del estudio. “En este trabajo hemos visto que su presencia en sangre se relaciona con el desarrollo de aterosclerosis activa en personas aparentemente sanas”.\nLo relevante de este hallazgo, destaca Mastrangelo, es que “detectar este marcador en sangre representa una gran ventaja dado que las pruebas actuales requieren técnicas de imagen avanzada complejas y costosas que no están cubiertas por la seguridad social. Los niveles de ImP en sangre ofrecen un marcador con valor diagnóstico para facilitar la identificación de personas sanas que tienen aterosclerosis activa y posibilitar su tratamiento temprano”.\n\nPero el hallazgo va más allá. Iñaki Robles-Vera, también primer autor del estudio, añade: “No solo observamos que el ImP está elevado en personas con aterosclerosis, sino que es un agente causal de la enfermedad. El consumo de ImP provocó la aparición de placas en las arterias en modelos animales de aterosclerosis. El ImP activa el receptor imidazolínico de tipo 1 (I1R) generando un aumento de la inflamación sistémica que contribuye al desarrollo de la aterosclerosis”.\nPara David Sancho, jefe del laboratorio de Inmunobiología y líder del estudio, “este descubrimiento es importante porque abre una nueva vía de tratamiento”.\nEn la investigación que se publica en ‘Nature’, añade, se ha visto que, el uso de bloqueantes del receptor I1R previene la inducción de aterosclerosis por ImP y reduce la progresión de aterosclerosis en modelos de ratón donde se induce la enfermedad con dieta alta en colesterol. “Esto abre la posibilidad futura de un tratamiento combinado del bloqueo de I1R junto al bloqueo de la producción de colesterol para lograr un efecto que esperamos que sea sinérgico y que prevenga el desarrollo de aterosclerosis”, asegura David Sancho.\nEstos hallazgos, agrega, “abren nuevas posibilidades para el diagnóstico precoz y el tratamiento personalizado y temprano de la aterosclerosis. Así, en lugar de centrarse únicamente en el colesterol y otros factores clásicos, se podría en el futuro analizar la presencia de ImP en sangre como señal de riesgo. En el CNIC estamos trabajando para desarrollar fármacos que bloqueen los efectos perjudiciales de ImP”.\n\nEste trabajo ha sido liderado por el CNIC pero representa una colaboración global a nivel nacional e internacional, con la participación de instituciones como Mount Sinai Fuster Heart Hospital, Icahn School of Medicine at Mount Sinai en Nueva York (EEUU); Instituto de investigación Sanitaria Fundación Jiménez Díaz; Universidad Autónoma de Madrid; Centro de Investigación biomédica en red de enfermedades cardiovasculares (CIBER-CV); Universidad de Gotemburgo (Suecia); Universidad de Atenas (Grecia);  Inmunotek S.L; Universidad de  Michigan (EEUU);  Hospital de La Princesa; Centro de Metabolómica y Bioanálisis (CEMBIO), de la Universidad CEU San Pablo; Universidad de Heidelberg (Alemania), y el  Instituto de Investigaciones Biomédicas Sols-Morreale IIBM-CSIC.\nEste proyecto ha recibido financiación del European Research Council (ayudas Consolidator y Proof of Concept: 2016-Consolidator Grant 725091; ERC-2023-PoC); Ministerio de Ciencia, Innovación y Universidades; Agencia Estatal de Investigación; Unión Europea a través de NextGeneration, y la Fundación “la Caixa”.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D. Sancho, D., et al. Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature (2025). https://doi.org/10.1038/s41586-025-09263-w",
    "published": "2025-07-14T00:00:00.000Z",
    "summary": "16/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nUn estudio liderado por el CNIC desvela que el propionato de imidazol, un metabolito producido por la microbiota intestinal, induce aterosclerosis, una enfermedad que puede desencadenar la obstrucción de las arterias que causa los infartos o accidentes cerebrovasculares\n\n\n\nLas enfermedades cardiovasculares son la principal causa de muerte global y suelen originarse en la aterosclerosis, un endurecimiento y estrechamiento de las arterias por inflamación y acumulación de grasa en la pared arterial. Aunque se controlan factores causales como colesterol, hipertensión o tabaquismo, la detección temprana de la enfermedad es necesaria. Los nuevos resultados liderados por el Centro Nacional de Investigaciones Cardiovasculares (CNIC) y publicados en la revista Nature han identificado que un metabolito generado por bacterias intestinales, el propionato de imidazol (ImP), se detecta en sangre de modo temprano en la aterosclerosis activa. El estudio ha contado con el apoyo de la Fundación “la Caixa” en su Convocatoria CaixaResearch de Investigación en Salud con 967.620,20 €.\nEste metabolito, “está producido exclusivamente por bacterias del intestino”, explica Annalaura Mastrangelo, investigadora del CNIC y primera autora del estudio. “En este trabajo hemos visto que su presencia en sangre se relaciona con el desarrollo de aterosclerosis activa en personas aparentemente sanas”.\nLo relevante de este hallazgo, destaca Mastrangelo, es que “detectar este marcador en sangre representa una gran ventaja dado que las pruebas actuales requieren técnicas de imagen avanzada complejas y costosas que no están cubiertas por la seguridad social. Los niveles de ImP en sangre ofrecen un marcador con valor diagnóstico para facilitar la identificación de personas sanas que tienen aterosclerosis activa y posibilitar su tratamiento temprano”.\n\nPero el hallazgo va más allá. Iñaki Robles-Vera, también primer autor del estudio, añade: “No solo observamos que el ImP está elevado en personas con aterosclerosis, sino que es un agente causal de la enfermedad. El consumo de ImP provocó la aparición de placas en las arterias en modelos animales de aterosclerosis. El ImP activa el receptor imidazolínico de tipo 1 (I1R) generando un aumento de la inflamación sistémica que contribuye al desarrollo de la aterosclerosis”.\nPara David Sancho, jefe del laboratorio de Inmunobiología y líder del estudio, “este descubrimiento es importante porque abre una nueva vía de tratamiento”.\nEn la investigación que se publica en ‘Nature’, añade, se ha visto que, el uso de bloqueantes del receptor I1R previene la inducción de aterosclerosis por ImP y reduce la progresión de aterosclerosis en modelos de ratón donde se induce la enfermedad con dieta alta en colesterol. “Esto abre la posibilidad futura de un tratamiento combinado del bloqueo de I1R junto al bloqueo de la producción de colesterol para lograr un efecto que esperamos que sea sinérgico y que prevenga el desarrollo de aterosclerosis”, asegura David Sancho.\nEstos hallazgos, agrega, “abren nuevas posibilidades para el diagnóstico precoz y el tratamiento personalizado y temprano de la aterosclerosis. Así, en lugar de centrarse únicamente en el colesterol y otros factores clásicos, se podría en el futuro analizar la presencia de ImP en sangre como señal de riesgo. En el CNIC estamos trabajando para desarrollar fármacos que bloqueen los efectos perjudiciales de ImP”.\n\nEste trabajo ha sido liderado por el CNIC pero representa una colaboración global a nivel nacional e internacional, con la participación de instituciones como Mount Sinai Fuster Heart Hospital, Icahn School of Medicine at Mount Sinai en Nueva York (EEUU); Instituto de investigación Sanitaria Fundación Jiménez Díaz; Universidad Autónoma de Madrid; Centro de Investigación biomédica en red de enfermedades cardiovasculares (CIBER-CV); Universidad de Gotemburgo (Suecia); Universidad de Atenas (Grecia);  Inmunotek S.L; Universidad de  Michigan (EEUU);  Hospital de La Princesa; Centro de Metabolómica y Bioanálisis (CEMBIO), de la Universidad CEU San Pablo; Universidad de Heidelberg (Alemania), y el  Instituto de Investigaciones Biomédicas Sols-Morreale IIBM-CSIC.\nEste proyecto ha recibido financiación del European Research Council (ayudas Consolidator y Proof of Concept: 2016-Consolidator Grant 725091; ERC-2023-PoC); Ministerio de Ciencia, Innovación y Universidades; Agencia Estatal de Investigación; Unión Europea a través de NextGeneration, y la Fundación “la Caixa”.\n\nMastrangelo, A., Robles-Vera, I., Mañanes, D. Sancho, D., et al. Imidazole propionate is a driver and therapeutic target in atherosclerosis. Nature (2025). https://doi.org/10.1038/s41586-025-09263-w",
    "description": "Este artículo trata sobre \"Nature: Descubren un metabolito de la microbiota intestinal que favorece la aterosclerosis y podría revolucionar su diagnóstico y tratamiento\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "nature",
      "descubren",
      "un"
    ],
    "category": "noticia"
  },
  {
    "title": "Ocho de los mejores estudiantes de bachillerato de España participan en el programa ACÉRCATE ",
    "url": "https://www.cnic.es/es/noticias/ocho-mejores-estudiantes-bachillerato-espana-participan-programa-acercate",
    "published": "2025-07-11T00:00:00.000Z",
    "date": "2025-07-11",
    "summary": "11/07/2025\n\n\nSobre el CNIC\nFormación\n\n\n\n\n\n\n\n\nEl objetivo del Programa Acércate es atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular\n\n\n\nUn año más, ocho de los mejores estudiantes de bachillerato de España han participado el programa ACÉRCATE, que organiza el Centro Nacional de Investigaciones Cardiovasculares (CNIC) dentro de su Plan de Formación CNIC-Joven. El objetivo de este plan, una apuesta personal del director general del centro, el Dr. Valentín Fuster, es “atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular”.\nLa convocatoria, abierta a bachilleres de todo el territorio nacional, se ha resuelto este año a favor de 6 alumnas y 2 alumnos de los más de 50 que reunían los requisitos y solicitaron participar en el programa. Este año las personas que participan en el programa proceden de Asturias, Extremadura, Galicia, Comunidad de Madrid, Castilla y León, Comunidad Valenciana y Andalucía.\nIncluyendo a los de esta convocatoria, en total ya han participado en el programa 136 estudiantes. Los jóvenes estudiantes, además de participar en el día a día de un centro de excelencia en investigación como el CNIC, han compartido sus experiencias y sus dudas con los investigadores del centro, pero también con el Dr. Fuster, director del CNIC. El Dr. Fuster considera que empezar el programa de formación en etapas educativas tan tempranas es clave para atraer a los investigadores del futuro porque los jóvenes son el “futuro de la investigación en nuestro país”.\nLas personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024\nEn esta ocasión, las personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024 (Concurso de la Unión Europea para Jóvenes Científicos), un certamen internacional que reconoce los mejores proyectos científicos de jóvenes de entre 14 y 20 años. Kvasnovska, fue seleccionada por su proyecto individual de biomedicina titulado «Biomarcadores potenciales de la inflamación crónica relacionada con la edad».\nLos participantes del programa Acércate al CNIC comparten una gran ilusión por vivir una experiencia enriquecedora que les permita acercarse al mundo real de la investigación biomédica. Así, Alba García Peña quiere profundizar en biomedicina para orientar su futuro profesional. María García Manchado, apasionada por la cardiología, desea conocer de cerca el trabajo investigador, mientras que Lucas Gómez Sánchez espera familiarizarse con el laboratorio y la tecnología aplicada a la medicina.\nLuka Pesich, por su parte, busca reforzar sus conocimientos y habilidades prácticas en biomedicina y Sofía Requena Skalska está interesada en el funcionamiento interno de los grupos de investigación y la conexión entre ciencia y práctica clínica.\nDescubrir el día a día en un laboratorio y confirmar su vocación científica es lo que espera Laura Sánchez Rodríguez, mientras que Carmen Vico Guerra valora la oportunidad de crecer personal y académicamente en un entorno de excelencia.\nPor último, Sara Baldo Muñiz espera comprender de forma directa la labor investigadora y aprender tanto de profesionales como de otros estudiantes con intereses afines.\nTecnología más puntera\nEste programa es el que se dirige a la captación de talento más joven de todos los de formación que hay en el CNIC. El apoyo sostenido de la Fundación Pro CNIC es indispensable para que, año tras año, pueda seguir celebrándose y captando el talento desde la etapa más precoz. “Estamos muy satisfechos de este concepto que comenzamos hace ya más de 20 años”, añade el Dr. Fuster. Y, concluye, “así, si tienen ese ‘gusanillo’ de la investigación, los animamos a seguir adelante”.\nAccede aquí al álbum de fotos de esta convocatoria\nSara Baldó Muñiz \n\nSara cursó sus estudios en el IES Velázquez de Madrid y ha decidido estudiar Bioquímica en la Universidad Autónoma de Madrid. Desde pequeña, ha sentido una fuerte atracción por la investigación científica, impulsada por su curiosidad innata y su deseo de comprender cómo funciona el mundo. \nAlba García Peña \n\nAlba cursó Bachillerato en el IES Álvaro Cunqueiro de Vigo y comenzará el próximo curso la carrera de Biotecnología en la Universidad de Santiago de Compostela. Eligió esta opción porque integra varias disciplinas científicas —Matemáticas, Física, Química y Biología— y le permitirá especializarse más adelante en áreas vinculadas a la investigación biosanitaria. \nMaría García Manchado \n\nMaría estudió en el IES San José de Villanueva de la Serena, Badajoz. Ha optado por estudiar Medicina en la Universidad de Extremadura. Desde niña ha sentido una gran pasión por el conocimiento, que la llevó a interesarse especialmente por Biología y Matemáticas.\nLucas Gómez Sánchez \n\nLucas estudió en el IES Ramiro de Maeztu de Madrid y ahora estudiará Ingeniería Biomédica en la Universidad Carlos III de Madrid. Su curiosidad científica comenzó a los 8 años, participando en actividades como la Noche de los Investigadores y la Semana de la Ciencia. \nLuka Pesich \n\nLuka curso Bachillerato en el Colegio Patrocinio San José de Estepona, Málaga. Ahora iniciará sus estudios en Ciencias Biológicas y Químicas en la Universidad de Limerick (Irlanda), con la intención de especializarse en genética. Su interés por la ciencia fue creciendo de forma natural, motivado por su amor por la naturaleza. \nSofía Requena Skalska \n\nSofía estudió en el CEU San Pablo Valencia de Puerto de Sagunto, Valencia. Sofía cursó parte de su formación secundaria en Quebec, donde tuvo su primer contacto directo con la investigación científica mediante prácticas de laboratorio. Posteriormente, el Bachillerato Internacional fortaleció su interés en la biología y el cuerpo humano. \nLaura Sánchez Rodríguez \n\nLaura estudió en el Colegio Salesiano Santo Ángel de Avilés, Asturias. Empezará el próximo curso la carrera de Biotecnología en la Universidad de Oviedo. Su interés por la ciencia surgió a través de proyectos escolares y viajes STEAM organizados por su centro educativo.\nCarmen Vico Guerra \n\nCarmen cursó Bachillerato en el IES Zorrilla de Valladolid. El próximo cursó comenzará a estudiar Biomedicina y Terapias Avanzadas en la Universidad de Valladolid. Su pasión por la ciencia comenzó en la infancia, cuando pasaba horas hojeando atlas de anatomía y viendo programas divulgativos.",
    "source": "CNIC",
    "title_es": "Ocho de los mejores estudiantes de bachillerato de España participan en el programa ACÉRCATE ",
    "content_es": "11/07/2025\n\n\nSobre el CNIC\nFormación\n\n\n\n\n\n\n\n\nEl objetivo del Programa Acércate es atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular\n\n\n\nUn año más, ocho de los mejores estudiantes de bachillerato de España han participado el programa ACÉRCATE, que organiza el Centro Nacional de Investigaciones Cardiovasculares (CNIC) dentro de su Plan de Formación CNIC-Joven. El objetivo de este plan, una apuesta personal del director general del centro, el Dr. Valentín Fuster, es “atraer y formar a los jóvenes más brillantes desde las edades más tempranas para crear una cantera de investigadores de excelencia en el campo de la investigación cardiovascular”.\nLa convocatoria, abierta a bachilleres de todo el territorio nacional, se ha resuelto este año a favor de 6 alumnas y 2 alumnos de los más de 50 que reunían los requisitos y solicitaron participar en el programa. Este año las personas que participan en el programa proceden de Asturias, Extremadura, Galicia, Comunidad de Madrid, Castilla y León, Comunidad Valenciana y Andalucía.\nIncluyendo a los de esta convocatoria, en total ya han participado en el programa 136 estudiantes. Los jóvenes estudiantes, además de participar en el día a día de un centro de excelencia en investigación como el CNIC, han compartido sus experiencias y sus dudas con los investigadores del centro, pero también con el Dr. Fuster, director del CNIC. El Dr. Fuster considera que empezar el programa de formación en etapas educativas tan tempranas es clave para atraer a los investigadores del futuro porque los jóvenes son el “futuro de la investigación en nuestro país”.\nLas personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024\nEn esta ocasión, las personas que participan en este programa han tenido la oportunidad de intercambiar sus experiencias con Ludmila Kvasnovska, ganadora del Premio CNIC-EUCYS 2024 (Concurso de la Unión Europea para Jóvenes Científicos), un certamen internacional que reconoce los mejores proyectos científicos de jóvenes de entre 14 y 20 años. Kvasnovska, fue seleccionada por su proyecto individual de biomedicina titulado «Biomarcadores potenciales de la inflamación crónica relacionada con la edad».\nLos participantes del programa Acércate al CNIC comparten una gran ilusión por vivir una experiencia enriquecedora que les permita acercarse al mundo real de la investigación biomédica. Así, Alba García Peña quiere profundizar en biomedicina para orientar su futuro profesional. María García Manchado, apasionada por la cardiología, desea conocer de cerca el trabajo investigador, mientras que Lucas Gómez Sánchez espera familiarizarse con el laboratorio y la tecnología aplicada a la medicina.\nLuka Pesich, por su parte, busca reforzar sus conocimientos y habilidades prácticas en biomedicina y Sofía Requena Skalska está interesada en el funcionamiento interno de los grupos de investigación y la conexión entre ciencia y práctica clínica.\nDescubrir el día a día en un laboratorio y confirmar su vocación científica es lo que espera Laura Sánchez Rodríguez, mientras que Carmen Vico Guerra valora la oportunidad de crecer personal y académicamente en un entorno de excelencia.\nPor último, Sara Baldo Muñiz espera comprender de forma directa la labor investigadora y aprender tanto de profesionales como de otros estudiantes con intereses afines.\nTecnología más puntera\nEste programa es el que se dirige a la captación de talento más joven de todos los de formación que hay en el CNIC. El apoyo sostenido de la Fundación Pro CNIC es indispensable para que, año tras año, pueda seguir celebrándose y captando el talento desde la etapa más precoz. “Estamos muy satisfechos de este concepto que comenzamos hace ya más de 20 años”, añade el Dr. Fuster. Y, concluye, “así, si tienen ese ‘gusanillo’ de la investigación, los animamos a seguir adelante”.\nAccede aquí al álbum de fotos de esta convocatoria\nSara Baldó Muñiz \n\nSara cursó sus estudios en el IES Velázquez de Madrid y ha decidido estudiar Bioquímica en la Universidad Autónoma de Madrid. Desde pequeña, ha sentido una fuerte atracción por la investigación científica, impulsada por su curiosidad innata y su deseo de comprender cómo funciona el mundo. \nAlba García Peña \n\nAlba cursó Bachillerato en el IES Álvaro Cunqueiro de Vigo y comenzará el próximo curso la carrera de Biotecnología en la Universidad de Santiago de Compostela. Eligió esta opción porque integra varias disciplinas científicas —Matemáticas, Física, Química y Biología— y le permitirá especializarse más adelante en áreas vinculadas a la investigación biosanitaria. \nMaría García Manchado \n\nMaría estudió en el IES San José de Villanueva de la Serena, Badajoz. Ha optado por estudiar Medicina en la Universidad de Extremadura. Desde niña ha sentido una gran pasión por el conocimiento, que la llevó a interesarse especialmente por Biología y Matemáticas.\nLucas Gómez Sánchez \n\nLucas estudió en el IES Ramiro de Maeztu de Madrid y ahora estudiará Ingeniería Biomédica en la Universidad Carlos III de Madrid. Su curiosidad científica comenzó a los 8 años, participando en actividades como la Noche de los Investigadores y la Semana de la Ciencia. \nLuka Pesich \n\nLuka curso Bachillerato en el Colegio Patrocinio San José de Estepona, Málaga. Ahora iniciará sus estudios en Ciencias Biológicas y Químicas en la Universidad de Limerick (Irlanda), con la intención de especializarse en genética. Su interés por la ciencia fue creciendo de forma natural, motivado por su amor por la naturaleza. \nSofía Requena Skalska \n\nSofía estudió en el CEU San Pablo Valencia de Puerto de Sagunto, Valencia. Sofía cursó parte de su formación secundaria en Quebec, donde tuvo su primer contacto directo con la investigación científica mediante prácticas de laboratorio. Posteriormente, el Bachillerato Internacional fortaleció su interés en la biología y el cuerpo humano. \nLaura Sánchez Rodríguez \n\nLaura estudió en el Colegio Salesiano Santo Ángel de Avilés, Asturias. Empezará el próximo curso la carrera de Biotecnología en la Universidad de Oviedo. Su interés por la ciencia surgió a través de proyectos escolares y viajes STEAM organizados por su centro educativo.\nCarmen Vico Guerra \n\nCarmen cursó Bachillerato en el IES Zorrilla de Valladolid. El próximo cursó comenzará a estudiar Biomedicina y Terapias Avanzadas en la Universidad de Valladolid. Su pasión por la ciencia comenzó en la infancia, cuando pasaba horas hojeando atlas de anatomía y viendo programas divulgativos.",
    "description": "Este artículo trata sobre \"Ocho de los mejores estudiantes de bachillerato de España participan en el programa ACÉRCATE \". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "ocho",
      "de",
      "los"
    ],
    "category": "noticia"
  },
  {
    "title": "Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello",
    "title_es": "Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello",
    "url": "https://www.cnio.es/noticias/un-estudio-pionero-desvela-nuevos-mecanismos-geneticos-implicados-en-tumores-raros-de-cabeza-y-cuello/",
    "date": "2025-07-10",
    "source": "CNIO",
    "content_es": "Los paragangliomas y feocromocitomas son tumores neuroendocrinos muy raros (entre 3 y 8 casos por millón de habitantes) que aparecen en cabeza, cuello y torso, o en las glándulas suprarrenales, y que pueden diseminarse a otros órganos. Cerca de la mitad están causados por alteraciones genéticas heredadas, mutaciones que interesa mucho descubrir: conocerlas permite encontrar familiares portadores de […]\nLa entrada Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello se publicó primero en CNIO.",
    "published": "2025-07-10T00:00:00.000Z",
    "summary": "Los paragangliomas y feocromocitomas son tumores neuroendocrinos muy raros (entre 3 y 8 casos por millón de habitantes) que aparecen en cabeza, cuello y torso, o en las glándulas suprarrenales, y que pueden diseminarse a otros órganos. Cerca de la mitad están causados por alteraciones genéticas heredadas, mutaciones que interesa mucho descubrir: conocerlas permite encontrar familiares portadores de […]\nLa entrada Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello se publicó primero en CNIO.",
    "description": "Este artículo trata sobre \"Un estudio pionero desvela nuevos mecanismos genéticos implicados en tumores raros de cabeza y cuello\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "un",
      "estudio",
      "pionero"
    ],
    "category": "noticia"
  },
  {
    "title": "El Dr. Miguel Torres, Premio Nacional de Genética 2025 por su contribución al desarrollo de terapias regenerativas del corazón",
    "url": "https://www.cnic.es/es/noticias/dr-miguel-torres-premio-nacional-genetica-2025-por-su-contribucion-al-desarrollo-terapias",
    "published": "2025-07-09T00:00:00.000Z",
    "date": "2025-07-09",
    "summary": "09/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nLa Sociedad Española de Genética (SEG) reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa.\n\n\n\nEl investigador Miguel Torres Sánchez, coordinador del Programa de Regeneración Cardiovascular e investigador principal del grupo “Control Genético del Desarrollo y Regeneración de Órganos” en el Centro Nacional de Investigaciones Cardiovasculares (CNIC), ha sido galardonado con el Premio Nacional de Genética 2025 en la modalidad aplicada, otorgado por la Sociedad Española de Genética (SEG).\nEl jurado reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa, destacando especialmente su trabajo sobre cómo la actividad de los genes regula los procesos de regionalización durante el desarrollo embrionario.\nSus investigaciones han permitido desentrañar mecanismos genéticos implicados en el control de la calidad y la regeneración de órganos, sentando así las bases científicas para el desarrollo de terapias regenerativas dirigidas al corazón y al sistema vascular.\nEl fallo también resalta la proyección internacional del Dr. Torres y el alto impacto de sus publicaciones científicas, que lo sitúan como una figura de referencia en el campo de la biomedicina regenerativa.\nEl Dr. Torres lidera desde el CNIC una de las líneas de investigación más innovadoras en medicina regenerativa, con el objetivo de desarrollar nuevas estrategias terapéuticas que permitan reparar los tejidos dañados tras un infarto u otras patologías cardiovasculares, una de las principales causas de muerte en el mundo.\nProyecto REACTIVA\nEntre otros proyectos, el Dr. Torres dirige el proyecto REACTIVA, seleccionado para recibir una prestigiosa ERC Advanced Grant, financiación que respalda una línea de investigación innovadora centrada en la regeneración del tejido cardíaco, con el objetivo de abrir nuevas vías hacia terapias regenerativas del corazón.\nEl Premio Nacional de Genética, financiado por la Fundación Pryconsa, representa uno de los más altos reconocimientos a la excelencia investigadora en genética en nuestro país. Con él, la Sociedad Española de Genética desea rendir homenaje a la destacada trayectoria científica del Dr. Torres, su compromiso con el avance del conocimiento y el impacto significativo que su trabajo ha tenido en la comunidad científica.\nEste galardón, señala Teresa Roldán Arjona, Presidenta de la Sociedad Española de Genética, “enaltece no solo los logros personales del Dr. Torres, sino también a la institución a la que representa y al conjunto de la comunidad genética”.\nLos Premios Nacionales de Genética, impulsados por la SEG, distinguen cada año trayectorias científicas sobresalientes tanto en investigación básica como aplicada. Junto a Miguel Torres, el jurado ha premiado en la modalidad básica a Amparo Latorre Castillo, catedrática de Genética en la Universidad de València, por su pionera labor en el estudio de la variabilidad del ADN mitocondrial y los procesos evolutivos de simbiosis.",
    "source": "CNIC",
    "title_es": "El Dr. Miguel Torres, Premio Nacional de Genética 2025 por su contribución al desarrollo de terapias regenerativas del corazón",
    "content_es": "09/07/2025\n\n\nSobre el CNIC\nPublicaciones\n\n\n\n\n\n\n\n\nLa Sociedad Española de Genética (SEG) reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa.\n\n\n\nEl investigador Miguel Torres Sánchez, coordinador del Programa de Regeneración Cardiovascular e investigador principal del grupo “Control Genético del Desarrollo y Regeneración de Órganos” en el Centro Nacional de Investigaciones Cardiovasculares (CNIC), ha sido galardonado con el Premio Nacional de Genética 2025 en la modalidad aplicada, otorgado por la Sociedad Española de Genética (SEG).\nEl jurado reconoce sus contribuciones seminales en el ámbito de la genética del desarrollo y la medicina regenerativa, destacando especialmente su trabajo sobre cómo la actividad de los genes regula los procesos de regionalización durante el desarrollo embrionario.\nSus investigaciones han permitido desentrañar mecanismos genéticos implicados en el control de la calidad y la regeneración de órganos, sentando así las bases científicas para el desarrollo de terapias regenerativas dirigidas al corazón y al sistema vascular.\nEl fallo también resalta la proyección internacional del Dr. Torres y el alto impacto de sus publicaciones científicas, que lo sitúan como una figura de referencia en el campo de la biomedicina regenerativa.\nEl Dr. Torres lidera desde el CNIC una de las líneas de investigación más innovadoras en medicina regenerativa, con el objetivo de desarrollar nuevas estrategias terapéuticas que permitan reparar los tejidos dañados tras un infarto u otras patologías cardiovasculares, una de las principales causas de muerte en el mundo.\nProyecto REACTIVA\nEntre otros proyectos, el Dr. Torres dirige el proyecto REACTIVA, seleccionado para recibir una prestigiosa ERC Advanced Grant, financiación que respalda una línea de investigación innovadora centrada en la regeneración del tejido cardíaco, con el objetivo de abrir nuevas vías hacia terapias regenerativas del corazón.\nEl Premio Nacional de Genética, financiado por la Fundación Pryconsa, representa uno de los más altos reconocimientos a la excelencia investigadora en genética en nuestro país. Con él, la Sociedad Española de Genética desea rendir homenaje a la destacada trayectoria científica del Dr. Torres, su compromiso con el avance del conocimiento y el impacto significativo que su trabajo ha tenido en la comunidad científica.\nEste galardón, señala Teresa Roldán Arjona, Presidenta de la Sociedad Española de Genética, “enaltece no solo los logros personales del Dr. Torres, sino también a la institución a la que representa y al conjunto de la comunidad genética”.\nLos Premios Nacionales de Genética, impulsados por la SEG, distinguen cada año trayectorias científicas sobresalientes tanto en investigación básica como aplicada. Junto a Miguel Torres, el jurado ha premiado en la modalidad básica a Amparo Latorre Castillo, catedrática de Genética en la Universidad de València, por su pionera labor en el estudio de la variabilidad del ADN mitocondrial y los procesos evolutivos de simbiosis.",
    "description": "Este artículo trata sobre \"El Dr. Miguel Torres, Premio Nacional de Genética 2025 por su contribución al desarrollo de terapias regenerativas del corazón\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "el",
      "dr",
      "miguel"
    ],
    "category": "noticia"
  },
  {
    "title": "Premio a la unidad de cáncer pediátrico del CNIO",
    "title_es": "Premio a la unidad de cáncer pediátrico del CNIO",
    "url": "https://www.cnio.es/noticias/premio-a-la-unidad-de-cancer-pediatrico-del-cnio/",
    "date": "2025-07-07",
    "source": "CNIO",
    "content_es": "Las terapias CAR-T son un tipo de inmunoterapia personalizada en que las células defensivas del paciente son modificadas en el laboratorio para reforzar su capacidad de reconocer y destruir las células tumorales. Su uso, cada vez más frecuente en adultos, es aún reducido en pediatría. La Sociedad Europea de Oncología Pediátrica ha alertado ya de […]\nLa entrada Premio a la unidad de cáncer pediátrico del CNIO se publicó primero en CNIO.",
    "published": "2025-07-07T00:00:00.000Z",
    "summary": "Las terapias CAR-T son un tipo de inmunoterapia personalizada en que las células defensivas del paciente son modificadas en el laboratorio para reforzar su capacidad de reconocer y destruir las células tumorales. Su uso, cada vez más frecuente en adultos, es aún reducido en pediatría. La Sociedad Europea de Oncología Pediátrica ha alertado ya de […]\nLa entrada Premio a la unidad de cáncer pediátrico del CNIO se publicó primero en CNIO.",
    "description": "Este artículo trata sobre \"Premio a la unidad de cáncer pediátrico del CNIO\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "premio",
      "a",
      "la"
    ],
    "category": "noticia"
  },
  {
    "title": "Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer",
    "title_es": "Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer",
    "url": "https://www.cnio.es/noticias/gracias-a-nuestros-amigos-y-amigas-por-ayudarnos-a-acabar-con-el-cancer/",
    "date": "2025-07-07",
    "source": "CNIO",
    "content_es": "“La clave para frenar el cáncer podría estar en la comunicación entre proteínas. Pero sinceramente, creo que la verdadera clave está en nuestra comunicación, en cómo compartimos, cuestionamos y colaboramos; si seguimos manteniendo este diálogo abierto, creo que llegará el día en que realmente entendamos el cáncer… y lo detengamos”, dijo en la Jornada de […]\nLa entrada Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer se publicó primero en CNIO.",
    "published": "2025-07-07T00:00:00.000Z",
    "summary": "“La clave para frenar el cáncer podría estar en la comunicación entre proteínas. Pero sinceramente, creo que la verdadera clave está en nuestra comunicación, en cómo compartimos, cuestionamos y colaboramos; si seguimos manteniendo este diálogo abierto, creo que llegará el día en que realmente entendamos el cáncer… y lo detengamos”, dijo en la Jornada de […]\nLa entrada Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer se publicó primero en CNIO.",
    "description": "Este artículo trata sobre \"Gracias a nuestros ‘Amigos y Amigas’ por ayudarnos a acabar con el cáncer\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "gracias",
      "a",
      "nuestros"
    ],
    "category": "noticia"
  },
  {
    "title": "El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer",
    "url": "https://www.cnio.es/noticias/el-cnio-celebra-la-solidaridad-de-sus-amigos-as-clave-para-atraer-talento-y-avanzar-en-la-investigacion-del-cancer/",
    "published": "2025-07-04T00:00:00.000Z",
    "date": "2025-07-04",
    "summary": "Una parte importante del conocimiento que genera el Centro Nacional de Investigaciones Oncológicas (CNIO), y que se orienta a mejorar la prevención, el diagnóstico y el tratamiento del cáncer, es fruto de la generosidad. La generosidad de las personas, empresas y fundaciones que realizan donaciones al centro a través del programa ‘Amigos/as del CNIO’.  Desde que se estableció, en 2015, todos los fondos […]\nLa entrada El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer se publicó primero en CNIO.",
    "source": "CNIO",
    "title_es": "El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer",
    "content_es": "Una parte importante del conocimiento que genera el Centro Nacional de Investigaciones Oncológicas (CNIO), y que se orienta a mejorar la prevención, el diagnóstico y el tratamiento del cáncer, es fruto de la generosidad. La generosidad de las personas, empresas y fundaciones que realizan donaciones al centro a través del programa ‘Amigos/as del CNIO’.  Desde que se estableció, en 2015, todos los fondos […]\nLa entrada El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer se publicó primero en CNIO.",
    "description": "Este artículo trata sobre \"El CNIO celebra la solidaridad de sus Amigos y Amigas, clave para atraer talento y avanzar en la investigación del cáncer\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "el",
      "cnio",
      "celebra"
    ],
    "category": "noticia"
  },
  {
    "title": "Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio",
    "url": "https://www.cnio.es/noticias/los-danos-en-el-adn-derivados-de-la-contaminacion-atmosferica-podrian-contribuir-al-cancer-de-pulmon-en-personas-no-fumadoras-halla-un-estudio/",
    "published": "2025-07-02T00:00:00.000Z",
    "date": "2025-07-02",
    "summary": "Una cuarta parte de los casos de cáncer de pulmón se dan en personas que no han fumado nunca. ¿Cuál es la causa de estos cánceres? Un estudio que analiza las alteraciones genéticas (mutaciones) en tumores de 871 personas no fumadoras de cuatro continentes apunta a la contaminación atmosférica como una de las posibles causas. […]\nLa entrada Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio se publicó primero en CNIO.",
    "source": "CNIO",
    "title_es": "Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio",
    "content_es": "Una cuarta parte de los casos de cáncer de pulmón se dan en personas que no han fumado nunca. ¿Cuál es la causa de estos cánceres? Un estudio que analiza las alteraciones genéticas (mutaciones) en tumores de 871 personas no fumadoras de cuatro continentes apunta a la contaminación atmosférica como una de las posibles causas. […]\nLa entrada Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio se publicó primero en CNIO.",
    "description": "Este artículo trata sobre \"Los daños en el ADN derivados de la contaminación atmosférica podrían contribuir al cáncer de pulmón en personas no fumadoras, halla un estudio\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "los",
      "daños",
      "en"
    ],
    "category": "noticia"
  },
  {
    "title": "Cell Genomics: CNIC scientists reveal how the cellular energy system evolved—and how this knowledge could improve the diagnosis of rare genetic diseases",
    "url": "https://www.cnic.es/es/node/235158",
    "published": "2025-07-02T00:00:00.000Z",
    "date": "2025-07-02",
    "summary": "02/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nCNIC researchers have uncovered the evolutionary logic of the OxPhos system—the cell’s “engine”—and developed a tool to detect mutations that cause mitochondrial disease\n\n\n\nMitochondria are the body’s “energy factories,” and their proper function is essential for life. Inside mitochondria, a set of complexes called the oxidative phosphorylation (OxPhos) system acts like a biochemical assembly line, transforming oxygen and nutrients into usable energy.\nNow, the study, led by the GENOXPHOS group at the Spanish National Centre for Cardiovascular Research (CNIC) and the Biomedical Research Networking Centre in the area of Frailty and Healthy Ageing (CIBERFES), and directed by Dr. José Antonio Enríquez, has revealed how this system evolved over millions of years—from the first vertebrates to modern humans. “Understanding this evolution helps explain why some genetic mutations cause rare but serious diseases that affect the OxPhos system,” say José Luis Cabrera lead author of the article, whose research is supported by the ‘la Caixa’ Foundation.\nPublished in Cell Genomics, the study describes the molecular evolutionary strategies of the OxPhos system, the main site of metabolic and energy integration in the cell. It also shows how this information can be used to identify mutations that cause disease.\nWorking in collaboration with Fátima Sánchez-Cabo, head of the CNIC Computational Systems Biomedicine group, the researchers analyzed the interaction between the two types of DNA that encode OxPhos proteins: nuclear DNA (inherited from both parents) and mitochondrial DNA (inherited only from the mother).\nThe OxPhos system, explains José Antonio Enríquez—head of the CNIC Functional Genetics of the Oxidative Phosphorylation System (GENOXPHOS) group—comprises five large protein complexes: four that transport electrons and one, called ATP synthase, that produces ATP, the cell’s molecular “fuel.”\n“These complexes can work individually or in combination, depending on the cell’s energy needs. Together, they are made up of 103 proteins encoded by two different genomes: nuclear and mitochondrial,” Enríquez explains. “While nuclear DNA changes slowly over time and gains variation through genetic mixing during reproduction, mitochondrial DNA evolves much more rapidly but is passed only through the maternal line.”\nDr. Cabrera adds that the proteins encoded by mitochondrial DNA form the core of the respiratory complexes, “so proper function depends on precise compatibility between the nuclear and mitochondrial components.”\nThe study also introduces an innovative new tool: ConScore, a predictive index that assesses the clinical relevance of mutations in the 103 OxPhos proteins. “ConScore is based on the evolutionary divergence of these proteins across vertebrates—including primates and other mammals—and complements human population genetic data,” says Enríquez.\nThe authors affirm that ConScore provides a new framework for interpreting potentially pathogenic mutations, opening the door to improved diagnosis and treatment of mitochondrial diseases.\nUltimately, the researchers conclude, this study not only advances our understanding of how human cells evolved, but also brings us closer to new solutions for patients with rare genetic disease.\nThe study has received funding from the European Union's NextGenerationEU/Recovery, Transformation and Resilience Plan/PRTR, CIBERFES; Fundación ‘la Caixa’,Human Frontier Science Fundation; Severo Ochoa grant awarded by MICIU/AEI and the European Social Fund (ESF invests in your future).\n\nCabrera-Alarcón JL, Rosa-Moreno M, Sánchez-García L, Hernansanz Agustín P, Jiménez-Gómez MC, Martínez F, Sánchez-Cabo F, Enríquez JA. Structural diversity and evolutionary constraints of oxidative phosphorylation. Cell Genomics. 2025 Jul 3. doi: 10.1016/j.xgen.2025.100945",
    "source": "CNIC",
    "title_es": "Cell Genomics: CNIC scientists reveal how the cellular energy system evolved—and how this knowledge could improve the diagnosis of rare genetic diseases",
    "content_es": "02/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nCNIC researchers have uncovered the evolutionary logic of the OxPhos system—the cell’s “engine”—and developed a tool to detect mutations that cause mitochondrial disease\n\n\n\nMitochondria are the body’s “energy factories,” and their proper function is essential for life. Inside mitochondria, a set of complexes called the oxidative phosphorylation (OxPhos) system acts like a biochemical assembly line, transforming oxygen and nutrients into usable energy.\nNow, the study, led by the GENOXPHOS group at the Spanish National Centre for Cardiovascular Research (CNIC) and the Biomedical Research Networking Centre in the area of Frailty and Healthy Ageing (CIBERFES), and directed by Dr. José Antonio Enríquez, has revealed how this system evolved over millions of years—from the first vertebrates to modern humans. “Understanding this evolution helps explain why some genetic mutations cause rare but serious diseases that affect the OxPhos system,” say José Luis Cabrera lead author of the article, whose research is supported by the ‘la Caixa’ Foundation.\nPublished in Cell Genomics, the study describes the molecular evolutionary strategies of the OxPhos system, the main site of metabolic and energy integration in the cell. It also shows how this information can be used to identify mutations that cause disease.\nWorking in collaboration with Fátima Sánchez-Cabo, head of the CNIC Computational Systems Biomedicine group, the researchers analyzed the interaction between the two types of DNA that encode OxPhos proteins: nuclear DNA (inherited from both parents) and mitochondrial DNA (inherited only from the mother).\nThe OxPhos system, explains José Antonio Enríquez—head of the CNIC Functional Genetics of the Oxidative Phosphorylation System (GENOXPHOS) group—comprises five large protein complexes: four that transport electrons and one, called ATP synthase, that produces ATP, the cell’s molecular “fuel.”\n“These complexes can work individually or in combination, depending on the cell’s energy needs. Together, they are made up of 103 proteins encoded by two different genomes: nuclear and mitochondrial,” Enríquez explains. “While nuclear DNA changes slowly over time and gains variation through genetic mixing during reproduction, mitochondrial DNA evolves much more rapidly but is passed only through the maternal line.”\nDr. Cabrera adds that the proteins encoded by mitochondrial DNA form the core of the respiratory complexes, “so proper function depends on precise compatibility between the nuclear and mitochondrial components.”\nThe study also introduces an innovative new tool: ConScore, a predictive index that assesses the clinical relevance of mutations in the 103 OxPhos proteins. “ConScore is based on the evolutionary divergence of these proteins across vertebrates—including primates and other mammals—and complements human population genetic data,” says Enríquez.\nThe authors affirm that ConScore provides a new framework for interpreting potentially pathogenic mutations, opening the door to improved diagnosis and treatment of mitochondrial diseases.\nUltimately, the researchers conclude, this study not only advances our understanding of how human cells evolved, but also brings us closer to new solutions for patients with rare genetic disease.\nThe study has received funding from the European Union's NextGenerationEU/Recovery, Transformation and Resilience Plan/PRTR, CIBERFES; Fundación ‘la Caixa’,Human Frontier Science Fundation; Severo Ochoa grant awarded by MICIU/AEI and the European Social Fund (ESF invests in your future).\n\nCabrera-Alarcón JL, Rosa-Moreno M, Sánchez-García L, Hernansanz Agustín P, Jiménez-Gómez MC, Martínez F, Sánchez-Cabo F, Enríquez JA. Structural diversity and evolutionary constraints of oxidative phosphorylation. Cell Genomics. 2025 Jul 3. doi: 10.1016/j.xgen.2025.100945",
    "description": "Este artículo trata sobre \"Cell Genomics: CNIC scientists reveal how the cellular energy system evolved—and how this knowledge could improve the diagnosis of rare genetic diseases\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cell",
      "genomics",
      "cnic"
    ],
    "category": "noticia"
  },
  {
    "title": "Cell Genomics: Revelan cómo ha evolucionado el sistema energético de las células y cómo puede ayudar a entender las enfermedades genéticas ",
    "url": "https://www.cnic.es/es/noticias/cell-genomics-revelan-como-ha-evolucionado-sistema-energetico-celulas-como-puede-ayudar",
    "published": "2025-07-02T00:00:00.000Z",
    "date": "2025-07-02",
    "summary": "02/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nInvestigadores del CNIC descubren las claves evolutivas del sistema OxPhos, el \"motor\" de la célula, y desarrollan una herramienta para detectar mutaciones que causan enfermedades mitocondriales.\n\n\n\nLas mitocondrias son las “fábricas de energía” de nuestro organismo y su funcionamiento correcto es vital para producir la energía que necesitamos. En su interior funciona el sistema de fosforilación oxidativa, OxPhos, un conjunto de proteínas que trabaja como una cadena para transformar el oxígeno y los nutrientes en energía.\nAhora, el estudio, liderado por el grupo GENOXPHOS del Centro Nacional de Investigaciones Cardiovasculares (CNIC) y del Centro de Investigación Biomédica en Red Fragilidad y Envejecimiento Saludable (CIBERFES), y dirigido por el Dr. José Antonio Enríquez, desvela cómo ha evolucionado este sistema a lo largo de millones de años, desde los primeros vertebrados hasta los seres humanos. “Comprender esta evolución ayuda a explicar por qué algunas mutaciones genéticas provocan enfermedades raras y graves que afectan a este sistema”, señala el Dr. José Luis Cabrera, autor principal del artículo cuya investigación cuenta con el apoyo de la Fundación ‘la Caixa’.\nEl estudio, publicado en la revista Cell Genomics, desvela las estrategias evolutivas a nivel molecular que ha seguido el principal centro de integración metabólico y energético de la célula, el sistema OxPhos, y describe como esta información puede ser utilizada para identificar en personas mutaciones causantes de enfermedades.\nLos investigadores, en colaboración con el grupo de Fátima Sánchez-Cabo, jefa del grupo de Biomedicina de Sistemas Computacional del CNIC,  han analizado cómo interactúan los dos tipos de ADN que codifican las proteínas del sistema OxPhos: el ADN nuclear (heredado del padre y la madre) y el ADN mitocondrial (que solo se hereda de la madre).\nEl sistema OxPhos, explica el Dr. Enríquez, jefe del grupo Genética Funcional del Sistema de Fosforilación Oxidativa (GENOXPHOS) del CNIC, está formado por cinco grandes bloques de proteínas: cuatro que transportan electrones y otro, llamado ATP-sintetasa, que produce energía en forma de ATP, el \"combustible\" celular.\n“Estos bloques pueden funcionar por separado o formar grupos según lo que necesite la célula. En total, están formados por unas 103 proteínas, codificadas por dos tipos de ADN: el nuclear y el mitocondrial. Y, mientras que el ADN nuclear cambia poco con el tiempo y gana variedad gracias a la mezcla genética durante la reproducción, el ADN mitocondrial se modifica mucho más rápido, aunque solo se transmite de madres a hijos”, aclara el Dr. Enríquez.\nAñade el Dr. Cabrera que las proteínas codificadas por el ADN mitocondrial constituyen el corazón de los complejos respiratorios, “cuyo correcto funcionamiento depende de que los componentes nucleares y los mitocondriales encajen adecuadamente”.\nAdemás, el estudio presenta una herramienta innovadora: ConScore, un índice de predicción funcional que permite evaluar la relevancia clínica de las mutaciones en las 103 proteínas que componen el sistema OxPhos. “Este índice se basa en la divergencia evolutiva de estas proteínas entre vertebrados —incluidos mamíferos y primates—, y complementa los estudios de variabilidad genética en poblaciones humanas”, señala el Dr. Enríquez.\nConScore ofrece un nuevo marco para interpretar mutaciones potencialmente patológicas, abriendo la puerta al desarrollo de mejores estrategias diagnósticas y terapéuticas frente a enfermedades mitocondriales, aseguran los investigadores.\nEsta investigación, concluyen sus autores, no solo ayuda a entender cómo hemos evolucionado a nivel celular, sino que también acerca nuevas soluciones para mejorar la salud de las personas que sufren enfermedades genéticas raras.\nEl estudio ha recibido financiación de la Unión Europea «NextGenerationEU»/Plan de Recuperación, Transformación y Resiliencia/PRTR, CIBERFES; Fundación ‘la Caixa’, Human Frontier Science Fundation; beca Severo Ochoa concedida por MICIU/AEI y por los Fondos Sociales Europeos (FSE invierte en tu futuro).\n\nCabrera-Alarcón JL, Rosa-Moreno M, Sánchez-García L, Hernansanz Agustín P, Jiménez-Gómez MC, Martínez F, Sánchez-Cabo F, Enríquez JA. Structural diversity and evolutionary constraints of oxidative phosphorylation. Cell Genomics. 2025 Jul 3. doi: 10.1016/j.xgen.2025.100945",
    "source": "CNIC",
    "title_es": "Cell Genomics: Revelan cómo ha evolucionado el sistema energético de las células y cómo puede ayudar a entender las enfermedades genéticas ",
    "content_es": "02/07/2025\n\n\nInvestigación\nPublicaciones\n\n\n\n\n\n\n\n\nInvestigadores del CNIC descubren las claves evolutivas del sistema OxPhos, el \"motor\" de la célula, y desarrollan una herramienta para detectar mutaciones que causan enfermedades mitocondriales.\n\n\n\nLas mitocondrias son las “fábricas de energía” de nuestro organismo y su funcionamiento correcto es vital para producir la energía que necesitamos. En su interior funciona el sistema de fosforilación oxidativa, OxPhos, un conjunto de proteínas que trabaja como una cadena para transformar el oxígeno y los nutrientes en energía.\nAhora, el estudio, liderado por el grupo GENOXPHOS del Centro Nacional de Investigaciones Cardiovasculares (CNIC) y del Centro de Investigación Biomédica en Red Fragilidad y Envejecimiento Saludable (CIBERFES), y dirigido por el Dr. José Antonio Enríquez, desvela cómo ha evolucionado este sistema a lo largo de millones de años, desde los primeros vertebrados hasta los seres humanos. “Comprender esta evolución ayuda a explicar por qué algunas mutaciones genéticas provocan enfermedades raras y graves que afectan a este sistema”, señala el Dr. José Luis Cabrera, autor principal del artículo cuya investigación cuenta con el apoyo de la Fundación ‘la Caixa’.\nEl estudio, publicado en la revista Cell Genomics, desvela las estrategias evolutivas a nivel molecular que ha seguido el principal centro de integración metabólico y energético de la célula, el sistema OxPhos, y describe como esta información puede ser utilizada para identificar en personas mutaciones causantes de enfermedades.\nLos investigadores, en colaboración con el grupo de Fátima Sánchez-Cabo, jefa del grupo de Biomedicina de Sistemas Computacional del CNIC,  han analizado cómo interactúan los dos tipos de ADN que codifican las proteínas del sistema OxPhos: el ADN nuclear (heredado del padre y la madre) y el ADN mitocondrial (que solo se hereda de la madre).\nEl sistema OxPhos, explica el Dr. Enríquez, jefe del grupo Genética Funcional del Sistema de Fosforilación Oxidativa (GENOXPHOS) del CNIC, está formado por cinco grandes bloques de proteínas: cuatro que transportan electrones y otro, llamado ATP-sintetasa, que produce energía en forma de ATP, el \"combustible\" celular.\n“Estos bloques pueden funcionar por separado o formar grupos según lo que necesite la célula. En total, están formados por unas 103 proteínas, codificadas por dos tipos de ADN: el nuclear y el mitocondrial. Y, mientras que el ADN nuclear cambia poco con el tiempo y gana variedad gracias a la mezcla genética durante la reproducción, el ADN mitocondrial se modifica mucho más rápido, aunque solo se transmite de madres a hijos”, aclara el Dr. Enríquez.\nAñade el Dr. Cabrera que las proteínas codificadas por el ADN mitocondrial constituyen el corazón de los complejos respiratorios, “cuyo correcto funcionamiento depende de que los componentes nucleares y los mitocondriales encajen adecuadamente”.\nAdemás, el estudio presenta una herramienta innovadora: ConScore, un índice de predicción funcional que permite evaluar la relevancia clínica de las mutaciones en las 103 proteínas que componen el sistema OxPhos. “Este índice se basa en la divergencia evolutiva de estas proteínas entre vertebrados —incluidos mamíferos y primates—, y complementa los estudios de variabilidad genética en poblaciones humanas”, señala el Dr. Enríquez.\nConScore ofrece un nuevo marco para interpretar mutaciones potencialmente patológicas, abriendo la puerta al desarrollo de mejores estrategias diagnósticas y terapéuticas frente a enfermedades mitocondriales, aseguran los investigadores.\nEsta investigación, concluyen sus autores, no solo ayuda a entender cómo hemos evolucionado a nivel celular, sino que también acerca nuevas soluciones para mejorar la salud de las personas que sufren enfermedades genéticas raras.\nEl estudio ha recibido financiación de la Unión Europea «NextGenerationEU»/Plan de Recuperación, Transformación y Resiliencia/PRTR, CIBERFES; Fundación ‘la Caixa’, Human Frontier Science Fundation; beca Severo Ochoa concedida por MICIU/AEI y por los Fondos Sociales Europeos (FSE invierte en tu futuro).\n\nCabrera-Alarcón JL, Rosa-Moreno M, Sánchez-García L, Hernansanz Agustín P, Jiménez-Gómez MC, Martínez F, Sánchez-Cabo F, Enríquez JA. Structural diversity and evolutionary constraints of oxidative phosphorylation. Cell Genomics. 2025 Jul 3. doi: 10.1016/j.xgen.2025.100945",
    "description": "Este artículo trata sobre \"Cell Genomics: Revelan cómo ha evolucionado el sistema energético de las células y cómo puede ayudar a entender las enfermedades genéticas \". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "cell",
      "genomics",
      "revelan"
    ],
    "category": "noticia"
  },
  {
    "title": "Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España",
    "url": "https://www.cnio.es/noticias/roger-castells-graells-recibe-el-premio-hawk-biosystems-de-la-sociedad-espanola-de-biofisica/",
    "published": "2025-06-27T00:00:00.000Z",
    "date": "2025-06-27",
    "summary": "El investigador Roger Castells-Graells, del Centro Nacional de Investigaciones Oncológicas (CNIO), ha recibido el premio “Hawk Biosystems”, que otorga la Sociedad de Biofísica de España (SBE) en el marco de su XVIII Congreso Internacional. Castells-Graells se incorporó recientemente al CNIO para dirigir el nuevo Grupo de Diseño Biomolecular y Nanomedicina Estructural, dedicado a crear nanopartículas […]\nLa entrada Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España se publicó primero en CNIO.",
    "source": "CNIO",
    "title_es": "Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España",
    "content_es": "El investigador Roger Castells-Graells, del Centro Nacional de Investigaciones Oncológicas (CNIO), ha recibido el premio “Hawk Biosystems”, que otorga la Sociedad de Biofísica de España (SBE) en el marco de su XVIII Congreso Internacional. Castells-Graells se incorporó recientemente al CNIO para dirigir el nuevo Grupo de Diseño Biomolecular y Nanomedicina Estructural, dedicado a crear nanopartículas […]\nLa entrada Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España se publicó primero en CNIO.",
    "description": "Este artículo trata sobre \"Roger Castells-Graells recibe el premio Hawk Biosystems de la Sociedad de Biofísica de España\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "roger",
      "castellsgraells",
      "recibe"
    ],
    "category": "noticia"
  },
  {
    "title": "Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación",
    "url": "https://www.cnio.es/noticias/mariano-barbacid-premio-valor-anadido-a-la-ciencia-e-investigacion/",
    "published": "2025-06-26T00:00:00.000Z",
    "date": "2025-06-26",
    "summary": "Mariano Barbacid, descubridor del primer oncogén humano, ha recibido el Premio Valor Añadido a la Ciencia e Investigación, que reconoce la “labor de cultivo y perfeccionamiento de la investigación, descubrimiento e invención”. Los Premios Valor Añadido son una iniciativa de la Fundación Transforma España, en colaboración con BBVA, para «impulsar el reconocimiento de la aportación […]\nLa entrada Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación se publicó primero en CNIO.",
    "source": "CNIO",
    "title_es": "Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación",
    "content_es": "Mariano Barbacid, descubridor del primer oncogén humano, ha recibido el Premio Valor Añadido a la Ciencia e Investigación, que reconoce la “labor de cultivo y perfeccionamiento de la investigación, descubrimiento e invención”. Los Premios Valor Añadido son una iniciativa de la Fundación Transforma España, en colaboración con BBVA, para «impulsar el reconocimiento de la aportación […]\nLa entrada Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación se publicó primero en CNIO.",
    "description": "Este artículo trata sobre \"Mariano Barbacid, Premio Valor Añadido a la Ciencia e Investigación\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "mariano",
      "barbacid",
      "premio"
    ],
    "category": "noticia"
  },
  {
    "title": "El CNIO crea ‘nanopartículas de proteínas’ para acelerar el desarrollo de fármacos contra el cáncer",
    "url": "https://www.cnio.es/noticias/el-cnio-crea-nanoparticulas-de-proteinas-para-acelerar-el-desarrollo-de-farmacos-contra-el-cancer/",
    "published": "2025-06-24T00:00:00.000Z",
    "date": "2025-06-24",
    "summary": "Las proteínas son moléculas complejas que realizan funciones cruciales en el organismo. Conocerlas es esencial para comprender e intentar curar enfermedades: si se conoce la estructura tridimensional de una proteína implicada en cáncer, por ejemplo, se puede intentar diseñar una molécula capaz de modificar esa proteína para tratarlo.     El Grupo de Diseño Biomolecular y […]\nLa entrada El CNIO crea ‘nanopartículas de proteínas’ para acelerar el desarrollo de fármacos contra el cáncer se publicó primero en CNIO.",
    "source": "CNIO",
    "title_es": "El CNIO crea ‘nanopartículas de proteínas’ para acelerar el desarrollo de fármacos contra el cáncer",
    "content_es": "Las proteínas son moléculas complejas que realizan funciones cruciales en el organismo. Conocerlas es esencial para comprender e intentar curar enfermedades: si se conoce la estructura tridimensional de una proteína implicada en cáncer, por ejemplo, se puede intentar diseñar una molécula capaz de modificar esa proteína para tratarlo.     El Grupo de Diseño Biomolecular y […]\nLa entrada El CNIO crea ‘nanopartículas de proteínas’ para acelerar el desarrollo de fármacos contra el cáncer se publicó primero en CNIO.",
    "description": "Este artículo trata sobre \"El CNIO crea ‘nanopartículas de proteínas’ para acelerar el desarrollo de fármacos contra el cáncer\". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "el",
      "cnio",
      "crea"
    ],
    "category": "noticia"
  },
  {
    "title": "Visita de la Universidad de Shanghai al CNIC para explorar futuras colaboraciones ",
    "url": "https://www.cnic.es/es/noticias/visita-universidad-shanghai-al-cnic-para-explorar-futuras-colaboraciones",
    "published": "2025-06-20T00:00:00.000Z",
    "date": "2025-06-20",
    "summary": "20/06/2025\n\n\nSobre el CNIC\nInvestigación\n\n\n\n\n\n\n\n\nUna delegación de la Universidad de Shanghai (China) ha visitado el CNIC con el objetivo de explorar posibles vías de colaboración en investigación biomédica.\nLa comitiva estuvo encabezada por Gou Yannan, vicepresidente de la Universidad de Shanghai, y contó con la participación de Liu Jinsong, director del Departamento de Activos; Xiao Junjie, decano de la Escuela de Ciencias de la Vida; Wang Haisong, arquitecto jefe de desarrollo del campus y vicedecano de la Academia de Bellas Artes de Shanghai, y Huang Pei, directora adjunta de la Oficina de Asuntos Internacionales.\nDurante la reunión, se discutieron posibles estrategias para establecer proyectos conjuntos de investigación y cooperación institucional entre ambas entidades.\nPor parte del CNIC, participaron Vicente Andrés, director de Investigación Básica; Beatriz Ferreiro, Directora Gestión Científica, y Enrique Lara Pezzi, líder del grupo de Regulación Molecular de la Insuficiencia Cardiaca.\nTras el encuentro, los representantes de la universidad china realizaron una visita a las instalaciones.\nEsta visita marca un primer paso en el establecimiento de lazos científicos entre el CNIC y la Universidad de Shanghai, con el propósito de impulsar el intercambio de conocimiento y el desarrollo de proyectos innovadores en el ámbito de la biomedicina.",
    "source": "CNIC",
    "title_es": "Visita de la Universidad de Shanghai al CNIC para explorar futuras colaboraciones ",
    "content_es": "20/06/2025\n\n\nSobre el CNIC\nInvestigación\n\n\n\n\n\n\n\n\nUna delegación de la Universidad de Shanghai (China) ha visitado el CNIC con el objetivo de explorar posibles vías de colaboración en investigación biomédica.\nLa comitiva estuvo encabezada por Gou Yannan, vicepresidente de la Universidad de Shanghai, y contó con la participación de Liu Jinsong, director del Departamento de Activos; Xiao Junjie, decano de la Escuela de Ciencias de la Vida; Wang Haisong, arquitecto jefe de desarrollo del campus y vicedecano de la Academia de Bellas Artes de Shanghai, y Huang Pei, directora adjunta de la Oficina de Asuntos Internacionales.\nDurante la reunión, se discutieron posibles estrategias para establecer proyectos conjuntos de investigación y cooperación institucional entre ambas entidades.\nPor parte del CNIC, participaron Vicente Andrés, director de Investigación Básica; Beatriz Ferreiro, Directora Gestión Científica, y Enrique Lara Pezzi, líder del grupo de Regulación Molecular de la Insuficiencia Cardiaca.\nTras el encuentro, los representantes de la universidad china realizaron una visita a las instalaciones.\nEsta visita marca un primer paso en el establecimiento de lazos científicos entre el CNIC y la Universidad de Shanghai, con el propósito de impulsar el intercambio de conocimiento y el desarrollo de proyectos innovadores en el ámbito de la biomedicina.",
    "description": "Este artículo trata sobre \"Visita de la Universidad de Shanghai al CNIC para explorar futuras colaboraciones \". Se exploran los aspectos clave relacionados con la ciencia actual.",
    "tags": [
      "visita",
      "de",
      "la"
    ],
    "category": "noticia"
  }
]